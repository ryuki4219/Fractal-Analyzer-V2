"""
Streamlit ã‚¢ãƒ—ãƒª: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã‚’ç”¨ã„ãŸç”»åƒè§£æã‚¢ãƒ—ãƒª
ã€æ–°UIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‘ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆ3ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ + è‰²è¦šãƒãƒªã‚¢ãƒ•ãƒªãƒ¼é…è‰²

æ©Ÿèƒ½:
- é–¾å€¤ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼/æ•°å€¤å…¥åŠ›ï¼‰ã¨ãƒªã‚µã‚¤ã‚ºä¸Šé™ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼/æ•°å€¤å…¥åŠ›ï¼‰ã®2æ–¹å¼ã‚’ç”¨æ„
- ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã§å‡ºåŠ›ã€ç©ºé–“å æœ‰ç‡ã¯å††ã‚°ãƒ©ãƒ•ã§å‡ºåŠ›
- å­¦ç¿’æ©Ÿèƒ½: è§£æçµæœï¼ˆæœ‰åŠ¹/å¤±æ•—ï¼‰ã‚’å­¦ç¿’ã—ã€äºˆæ¸¬çµæœã¨æ¯”è¼ƒè¡¨ç¤º
- ç•°å¸¸å€¤ãƒ»ç•°å¸¸ãªäºŒå€¤åŒ–ã®è‡ªå‹•æ¤œçŸ¥ï¼ˆå¤±æ•—æ‰±ã„ï¼‰ -> å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
- ãƒ•ã‚©ãƒ«ãƒ€å†…ç”»åƒã‚’ä¸€æ‹¬è§£æï¼ˆStreamlitã®ä»•æ§˜ä¸Šã€è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§å¯¾å¿œï¼‰
- 2æšä»¥ä¸Šè§£ææ™‚ã€è‡ªå‹•ã§Excelã«çµæœã‚’ä¿å­˜ãƒ»è¿½è¨˜
- å­¦ç¿’ä»¶æ•°ã®è¡¨ç¤ºã€è§£æç²¾åº¦ï¼ˆMAEãªã©ï¼‰ã®è¡¨ç¤º
- è§£åƒåº¦è£œæ­£AI: ä½è§£åƒåº¦ç”»åƒã‹ã‚‰é«˜è§£åƒåº¦ç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®š

ä½¿ã„æ–¹:
1) å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install -r requirements.txt
2) å®Ÿè¡Œ: streamlit run fractal_app_æ–°UI.py

ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›:
- å­¦ç¿’ãƒ¢ãƒ‡ãƒ«: model_joblib.pkl
- ã‚¹ã‚±ãƒ¼ãƒ©: scaler_joblib.pkl
- çµæœExcel: results.xlsx

æ³¨æ„: æœ¬ä¾‹ã¯å­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç°¡æ½”åŒ–ã—ã¦ã„ã¾ã™ã€‚ç”¨é€”ã«å¿œã˜ã¦ç‰¹å¾´é‡ã‚„ãƒ¢ãƒ‡ãƒ«ã‚’æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚
"""

import streamlit as st
import numpy as np
import pandas as pd
import cv2
from PIL import Image
import io
import os
import joblib
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, accuracy_score, r2_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from skimage import filters, color
from skimage.feature import canny
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

# === è‰²è¦šãƒãƒªã‚¢ãƒ•ãƒªãƒ¼é…è‰²å®šæ•° (Okabe-Ito/Wong palette) ===
COLOR_BLUE = '#0173B2'        # é’ (å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿)
COLOR_GREEN = '#029E73'       # ç·‘ (AIè£œæ­£)
COLOR_ORANGE = '#DE8F05'      # ã‚ªãƒ¬ãƒ³ã‚¸ (å¾“æ¥AI)
COLOR_SKY = '#56B4E9'         # æ°´è‰² (å††ã‚°ãƒ©ãƒ•ãƒ»ç™½)
COLOR_YELLOW = '#ECE133'      # é»„è‰² (å††ã‚°ãƒ©ãƒ•ãƒ»é»’)
COLOR_PINK = '#CC78BC'        # ãƒ”ãƒ³ã‚¯ (è­¦å‘Š)
COLOR_VERMILION = '#D55E00'   # æœ±è‰² (ã‚¨ãƒ©ãƒ¼)

# --- è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ç”¨ã®å®šæ•° ----------------------------------------------
RESOLUTION_MODEL_PATH = 'resolution_correction_model.pkl'
RESOLUTION_SCALER_PATH = 'resolution_correction_scaler.pkl'
RESOLUTION_TRAIN_DATA = 'resolution_training_data.csv'

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° -------------------------------------------------

def load_image_bytes(file) -> np.ndarray:
    bytes_data = file.read()
    img = Image.open(io.BytesIO(bytes_data)).convert('RGB')
    arr = np.array(img)[:, :, ::-1].copy()  # RGB->BGR
    return arr


def resize_image(img: np.ndarray, max_side: float):
    h, w = img.shape[:2]
    scale = 1.0
    if max(h, w) > max_side and max_side > 0:
        scale = max_side / max(h, w)
        new_w = int(w * scale)
        new_h = int(h * scale)
        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return img, scale


def binarize_image_gray(gray: np.ndarray, thresh: float):
    _, bw = cv2.threshold(gray.astype('uint8'), thresh, 255, cv2.THRESH_BINARY)
    return bw


def adaptive_binarize(gray: np.ndarray):
    bw = cv2.adaptiveThreshold(gray.astype('uint8'), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, 11, 2)
    return bw


def boxcount_fractal_dim(bw: np.ndarray, sizes=None):
    S = bw.shape
    if sizes is None:
        max_power = min(int(np.log2(min(S))), 10)
        sizes = np.array([2 ** i for i in range(1, max_power)])
        sizes = sizes[sizes <= min(S)]
        if len(sizes) < 3:
            sizes = np.array([2,4,8,16])
    counts = []
    bw_binary = (bw > 0).astype(np.uint8)
    for size in sizes:
        ny = int(np.ceil(S[0] / size))
        nx = int(np.ceil(S[1] / size))
        count = 0
        for i in range(ny):
            y0 = i * size
            y1 = min(y0 + size, S[0])
            for j in range(nx):
                x0 = j * size
                x1 = min(x0 + size, S[1])
                if np.any(bw_binary[y0:y1, x0:x1]):
                    count += 1
        counts.append(count)
    sizes = np.array(sizes, dtype=float)
    counts = np.array(counts, dtype=float)
    with np.errstate(divide='ignore', invalid='ignore'):
        logs = np.log(counts)
        loginv = np.log(1.0 / sizes)
    A = np.vstack([loginv, np.ones_like(loginv)]).T
    try:
        m, c = np.linalg.lstsq(A, logs, rcond=None)[0]
    except Exception:
        m = 0.0
    return float(m), sizes, counts


def compute_spatial_occupancy(bw: np.ndarray):
    total = bw.size
    white = np.count_nonzero(bw > 0)
    return float(white / total)


def extract_features_from_image(img_bgr: np.ndarray, bw: np.ndarray, fractal_dim: float):
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    mean_int = float(np.mean(gray))
    std_int = float(np.std(gray))
    edge = canny(gray / 255.0)
    edge_density = float(np.count_nonzero(edge) / edge.size)
    occupancy = compute_spatial_occupancy(bw)
    return np.array([mean_int, std_int, edge_density, occupancy, fractal_dim], dtype=float)

# --- è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ç”¨ã®é–¢æ•° ---------------------------------------------

def generate_low_resolution_versions(img_bgr: np.ndarray, scale_factors=[0.5, 0.25, 0.1]):
    low_res_images = []
    for scale in scale_factors:
        h, w = img_bgr.shape[:2]
        new_h, new_w = int(h * scale), int(w * scale)
        if new_h > 10 and new_w > 10:
            low_res = cv2.resize(img_bgr, (new_w, new_h), interpolation=cv2.INTER_AREA)
            upscaled = cv2.resize(low_res, (w, h), interpolation=cv2.INTER_LINEAR)
            low_res_images.append((scale, upscaled))
    return low_res_images


def extract_resolution_features(img_bgr: np.ndarray, bw: np.ndarray, fractal_dim: float):
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape
    
    mean_int = float(np.mean(gray))
    std_int = float(np.std(gray))
    
    edge = canny(gray / 255.0)
    edge_density = float(np.count_nonzero(edge) / edge.size)
    
    occupancy = compute_spatial_occupancy(bw)
    
    kernel_size = max(3, min(h, w) // 20)
    if kernel_size % 2 == 0:
        kernel_size += 1
    local_std = cv2.blur(gray.astype(float)**2, (kernel_size, kernel_size)) - \
                cv2.blur(gray.astype(float), (kernel_size, kernel_size))**2
    texture_variance = float(np.mean(np.sqrt(np.abs(local_std))))
    
    img_size = float(np.log(h * w + 1))
    aspect_ratio = float(w / h)
    
    fft = np.fft.fft2(gray)
    fft_shift = np.fft.fftshift(fft)
    magnitude_spectrum = np.abs(fft_shift)
    high_freq_energy = float(np.mean(magnitude_spectrum[h//4:3*h//4, w//4:3*w//4]))
    
    return np.array([
        mean_int, std_int, edge_density, occupancy, fractal_dim,
        texture_variance, img_size, aspect_ratio, high_freq_energy
    ], dtype=float)


def train_resolution_correction_model(training_data_path=RESOLUTION_TRAIN_DATA):
    if not os.path.exists(training_data_path):
        return None, None, "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    
    df = pd.read_csv(training_data_path)
    
    feature_cols = [col for col in df.columns if col.startswith('feat_')]
    X = df[feature_cols].values
    y = df['target_high_res_fractal'].values
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    model = GradientBoostingRegressor(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=5,
        random_state=42
    )
    model.fit(X_train_scaled, y_train)
    
    y_pred = model.predict(X_test_scaled)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    joblib.dump(model, RESOLUTION_MODEL_PATH)
    joblib.dump(scaler, RESOLUTION_SCALER_PATH)
    
    return model, scaler, f"MAE: {mae:.4f}, RÂ²: {r2:.4f}"


def predict_high_res_fractal(low_res_features, model=None, scaler=None):
    if model is None or scaler is None:
        if os.path.exists(RESOLUTION_MODEL_PATH) and os.path.exists(RESOLUTION_SCALER_PATH):
            model = joblib.load(RESOLUTION_MODEL_PATH)
            scaler = joblib.load(RESOLUTION_SCALER_PATH)
        else:
            return None
    
    X = low_res_features.reshape(1, -1)
    X_scaled = scaler.transform(X)
    predicted_fractal = model.predict(X_scaled)[0]
    
    return float(predicted_fractal)


# --- æ°¸ç¶šåŒ–ãƒ•ã‚¡ã‚¤ãƒ« & ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– ----------------------------------------
MODEL_PATH = 'model_joblib.pkl'
SCALER_PATH = 'scaler_joblib.pkl'
CLASS_PATH = 'classifier_joblib.pkl'
EXCEL_PATH = 'results.xlsx'
TRAIN_CSV = 'train_data.csv'

def load_models():
    models = {}
    if os.path.exists(MODEL_PATH) and os.path.exists(SCALER_PATH):
        try:
            models['reg'] = joblib.load(MODEL_PATH)
            models['scaler'] = joblib.load(SCALER_PATH)
        except Exception:
            models = {}
    if os.path.exists(CLASS_PATH):
        try:
            models['clf'] = joblib.load(CLASS_PATH)
        except Exception:
            pass
    return models


def save_models(reg, scaler, clf=None):
    joblib.dump(reg, MODEL_PATH)
    joblib.dump(scaler, SCALER_PATH)
    if clf is not None:
        joblib.dump(clf, CLASS_PATH)

def append_to_train_csv(features, y_reg, is_valid):
    cols = ['mean_int', 'std_int', 'edge_density', 'occupancy', 'fractal_dim_feature',
            'target_fractal', 'target_occupancy', 'is_valid']
    row = list(features) + [y_reg['fractal'], y_reg['occupancy'], int(is_valid)]
    df = pd.DataFrame([row], columns=cols)
    if os.path.exists(TRAIN_CSV):
        df.to_csv(TRAIN_CSV, mode='a', header=False, index=False)
    else:
        df.to_csv(TRAIN_CSV, index=False)


def load_train_data():
    if os.path.exists(TRAIN_CSV):
        return pd.read_csv(TRAIN_CSV)
    else:
        return None

# ============================================================================
# Streamlit UI - ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆ3ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
# ============================================================================

st.set_page_config(layout='wide', page_title='ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ç”»åƒè§£æã‚¢ãƒ—ãƒª (æ–°UI)')
st.title('ğŸ”¬ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã‚’ç”¨ã„ãŸç”»åƒè§£æã‚¢ãƒ—ãƒª')
st.caption('**æ–°UI**: ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆ3ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ + è‰²è¦šãƒãƒªã‚¢ãƒ•ãƒªãƒ¼é…è‰²')

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ¦‚è¦
with st.expander('â„¹ï¸ ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦ / è§£åƒåº¦è£œæ­£AIæ©Ÿèƒ½', expanded=False):
    col_info1, col_info2 = st.columns(2)
    
    with col_info1:
        st.markdown("""
        ###  åŸºæœ¬æ©Ÿèƒ½
        - **Box-Countingæ³•**ã«ã‚ˆã‚‹ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ
        - **äºŒå€¤åŒ–å‡¦ç†**ã¨ç©ºé–“å æœ‰ç‡ã®è¨ˆç®—
        - **è¤‡æ•°ç”»åƒã®ä¸€æ‹¬è§£æ**ã¨Excelå‡ºåŠ›
        - **æ©Ÿæ¢°å­¦ç¿’**ã«ã‚ˆã‚‹äºˆæ¸¬æ©Ÿèƒ½
        - **ç•°å¸¸å€¤ã®è‡ªå‹•æ¤œçŸ¥**
        """)
    
    with col_info2:
        st.markdown("""
        ### è§£åƒåº¦è£œæ­£AI
        ä½è§£åƒåº¦ç”»åƒã§ã‚‚é«˜è§£åƒåº¦ç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®šï¼
        
        **ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ:**
        1. é«˜è§£åƒåº¦ç”»åƒã‚’ç”¨æ„
        2. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã€ON â†’ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        3. 20ï½100æšç¹°ã‚Šè¿”ã™
        4. ã€Œè§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        5. ã€Œè§£åƒåº¦è£œæ­£ã‚’æœ‰åŠ¹åŒ–ã€ON
        6. ä½è§£åƒåº¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        7. è£œæ­£çµæœã‚’ç¢ºèªï¼
        """)

# === ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ===
st.sidebar.header('âš™ï¸ è¨­å®š')

# è¨­å®šã‚’ãƒãƒƒãƒ—ã‚ªãƒ¼ãƒãƒ¼å†…ã«é›†ç´„
with st.sidebar.popover('ğŸ“ è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š', help='é–¾å€¤ã¨ãƒªã‚µã‚¤ã‚ºã®è©³ç´°è¨­å®š'):
    thresh_mode = st.selectbox('é–¾å€¤å…¥åŠ›æ–¹å¼', ['ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼', 'æ•°å€¤å…¥åŠ›'])
    if thresh_mode == 'ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼':
        thresh_value = st.slider('äºŒå€¤åŒ–é–¾å€¤ (0-255)', min_value=0.0, max_value=255.0, value=128.0)
    else:
        thresh_value = st.number_input('äºŒå€¤åŒ–é–¾å€¤ (0-255)', min_value=0.0, max_value=255.0, value=128.0, step=0.1)
    
    resize_mode = st.selectbox('ãƒªã‚µã‚¤ã‚ºæ–¹å¼', ['ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼', 'æ•°å€¤å…¥åŠ›'])
    if resize_mode == 'ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼':
        max_side = st.slider('ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º (px, 0ã§ãƒªã‚µã‚¤ã‚ºç„¡åŠ¹)', min_value=0.0, max_value=4000.0, value=1024.0)
    else:
        max_side = st.number_input('ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º (px, 0ã§ãƒªã‚µã‚¤ã‚ºç„¡åŠ¹)', min_value=0.0, max_value=10000.0, value=1024.0)

st.sidebar.markdown('---')
st.sidebar.subheader('ğŸ”¬ è§£åƒåº¦è£œæ­£AI')
enable_resolution_correction = st.sidebar.checkbox('è§£åƒåº¦è£œæ­£ã‚’æœ‰åŠ¹åŒ–', value=False, 
    help='ä½è§£åƒåº¦ç”»åƒã‹ã‚‰é«˜è§£åƒåº¦ç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®šã—ã¾ã™')

if st.sidebar.checkbox('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰', value=False, 
    help='é«˜è§£åƒåº¦ç”»åƒã‹ã‚‰ä½è§£åƒåº¦ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è‡ªå‹•ç”Ÿæˆã—ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™'):
    st.sidebar.info('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã‹ã‚‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™')
    generate_training_data = True
else:
    generate_training_data = False

if st.sidebar.button('è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’'):
    with st.spinner('è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...'):
        model_res, scaler_res, result_msg = train_resolution_correction_model()
        if model_res is not None:
            st.sidebar.success(f'å­¦ç¿’å®Œäº†: {result_msg}')
        else:
            st.sidebar.error(result_msg)

if os.path.exists(RESOLUTION_MODEL_PATH):
    st.sidebar.success('âœ“ è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«: èª­ã¿è¾¼ã¿æ¸ˆã¿')
    if os.path.exists(RESOLUTION_TRAIN_DATA):
        df_res = pd.read_csv(RESOLUTION_TRAIN_DATA)
        st.sidebar.write(f'å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_res)}ä»¶')
else:
    st.sidebar.warning('è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«: æœªå­¦ç¿’')

with st.sidebar.expander('ğŸ“– è§£åƒåº¦è£œæ­£AIã®ä½¿ã„æ–¹', expanded=False):
    st.markdown("""
    ### ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰
    
    **1ï¸âƒ£ é«˜è§£åƒåº¦ç”»åƒã‚’ç”¨æ„**
    - ãªã‚‹ã¹ãé«˜å“è³ªãªç”»åƒã‚’æº–å‚™
    
    **2ï¸âƒ£ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ**
    - â˜‘ã€Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã€ON
    - ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    - è‡ªå‹•ã§5æ®µéšã®è§£åƒåº¦ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    
    **3ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿åé›†**
    - è¤‡æ•°ã®ç”»åƒã§ç¹°ã‚Šè¿”ã—
    - æ¨å¥¨: 20ï½100æš
    
    **4ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’**
    - ã€Œè§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    - å­¦ç¿’å®Œäº†ã‚’å¾…ã¤
    
    **5ï¸âƒ£ è£œæ­£ã®æœ‰åŠ¹åŒ–**
    - â˜‘ã€Œè§£åƒåº¦è£œæ­£ã‚’æœ‰åŠ¹åŒ–ã€ON
    
    **6ï¸âƒ£ ä½è§£åƒåº¦ç”»åƒã§æ¤œè¨¼**
    - ä½è§£åƒåº¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    
    **7ï¸âƒ£ çµæœç¢ºèª**
    - é«˜è§£åƒåº¦ç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãŒè¡¨ç¤ºã•ã‚Œã‚‹ï¼
    """)

st.sidebar.markdown('---')
do_train_now = st.sidebar.button('ğŸ¯ å­¦ç¿’ã‚’å®Ÿè¡Œï¼ˆä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ï¼‰')

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
models = load_models()

# ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
st.markdown('## ğŸ“ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰')
uploaded_files = st.file_uploader('ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰', type=['png','jpg','jpeg','bmp','tif','tiff'], accept_multiple_files=True)

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã‚¬ã‚¤ãƒ‰è¡¨ç¤º
if generate_training_data:
    st.info('ğŸ”„ **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰** - é«˜è§£åƒåº¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€è‡ªå‹•çš„ã«5æ®µéšã®è§£åƒåº¦ã§å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™')

# è§£åƒåº¦è£œæ­£æœ‰åŠ¹æ™‚ã®ã‚¬ã‚¤ãƒ‰è¡¨ç¤º
if enable_resolution_correction and os.path.exists(RESOLUTION_MODEL_PATH):
    st.success('âœ… **è§£åƒåº¦è£œæ­£AIæœ‰åŠ¹** - ä½è§£åƒåº¦ç”»åƒã§ã‚‚é«˜è§£åƒåº¦ç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®šã—ã¾ã™')

st.divider()

# === ãƒ¡ã‚¤ãƒ³è§£æã‚¨ãƒªã‚¢ ===
if uploaded_files is not None and len(uploaded_files) > 0:
    results_list = []
    
    for idx, file in enumerate(uploaded_files):
        st.markdown(f"### ğŸ“ {file.name}")
        
        img_bgr = load_image_bytes(file)
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†
        if generate_training_data:
            with st.spinner('ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...'):
                img_high, _ = resize_image(img_bgr, max_side)
                gray_high = cv2.cvtColor(img_high, cv2.COLOR_BGR2GRAY)
                bw_high = binarize_image_gray(gray_high, thresh_value)
                fractal_high, _, _ = boxcount_fractal_dim(bw_high)
                
                low_res_versions = generate_low_resolution_versions(img_high, [0.5, 0.3, 0.2, 0.15, 0.1])
                training_records = []
                for scale, img_low in low_res_versions:
                    gray_low = cv2.cvtColor(img_low, cv2.COLOR_BGR2GRAY)
                    bw_low = binarize_image_gray(gray_low, thresh_value)
                    fractal_low, _, _ = boxcount_fractal_dim(bw_low)
                    features_low = extract_resolution_features(img_low, bw_low, fractal_low)
                    record = {'scale': scale, 'target_high_res_fractal': fractal_high}
                    for feat_idx, feat_val in enumerate(features_low):
                        record[f'feat_{feat_idx}'] = feat_val
                    training_records.append(record)
                
                df_new = pd.DataFrame(training_records)
                if os.path.exists(RESOLUTION_TRAIN_DATA):
                    df_new.to_csv(RESOLUTION_TRAIN_DATA, mode='a', header=False, index=False)
                else:
                    df_new.to_csv(RESOLUTION_TRAIN_DATA, index=False)
            
            st.success(f'âœ“ {len(training_records)}ä»¶ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆè§£åƒåº¦: {[f"{s*100:.0f}%" for s, _ in low_res_versions]}ï¼‰')
            continue
        
        # é€šå¸¸è§£æå‡¦ç†
        img_bgr, scale = resize_image(img_bgr, max_side)
        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
        bw = binarize_image_gray(gray, thresh_value)
        
        fractal_d, sizes, counts = boxcount_fractal_dim(bw)
        occupancy = compute_spatial_occupancy(bw)
        
        # è§£åƒåº¦è£œæ­£AI
        corrected_fractal_d = None
        if enable_resolution_correction and os.path.exists(RESOLUTION_MODEL_PATH):
            try:
                features_res = extract_resolution_features(img_bgr, bw, fractal_d)
                corrected_fractal_d = predict_high_res_fractal(features_res)
            except Exception as e:
                st.warning(f'è§£åƒåº¦è£œæ­£ã‚¨ãƒ©ãƒ¼: {e}')
        
        # å“è³ªãƒã‚§ãƒƒã‚¯
        fail_flag = False
        fail_reasons = []
        if occupancy < 0.01:
            fail_flag = True
            fail_reasons.append('ã»ã¨ã‚“ã©ç™½ãŒç„¡ã„(å æœ‰ç‡ <1%)')
        if occupancy > 0.99:
            fail_flag = True
            fail_reasons.append('ã»ã¨ã‚“ã©ç™½ã§åŸ‹ã¾ã£ã¦ã„ã‚‹(å æœ‰ç‡ >99%)')
        if not (-5.0 < fractal_d < 5.0):
            fail_flag = True
            fail_reasons.append(f'ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãŒç•°å¸¸å€¤:{fractal_d:.3f}')
        
        feat = extract_features_from_image(img_bgr, bw, fractal_d)
        
        # å¾“æ¥AIäºˆæ¸¬
        pred = None
        if 'reg' in models and 'scaler' in models:
            try:
                Xs = models['scaler'].transform(feat.reshape(1, -1))
                ypred = models['reg'].predict(Xs)[0]
                if isinstance(ypred, (list, tuple, np.ndarray)) and len(ypred) >= 2:
                    pred = {'fractal': float(ypred[0]), 'occupancy': float(ypred[1])}
                else:
                    pred = {'fractal': float(ypred), 'occupancy': None}
            except Exception as e:
                pass
        
        # === 3ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ===
        col_left, col_center, col_right = st.columns([1.0, 1.6, 1.0])
        
        # ã€å·¦ã‚«ãƒ©ãƒ ã€‘ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ & è¨­å®š
        with col_left:
            st.markdown('#### ğŸ–¼ï¸ ç”»åƒ')
            preview_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            st.image(preview_rgb, caption='å…ƒç”»åƒ', use_container_width=True)
            st.image(bw, caption='äºŒå€¤åŒ–ç”»åƒ', use_container_width=True)
            
            with st.popover('âš™ï¸ è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿', help='ç¾åœ¨ã®è¨­å®šå€¤ã‚’ç¢ºèª'):
                st.caption(f'**é–¾å€¤**: {thresh_value:.1f}')
                st.caption(f'**ãƒªã‚µã‚¤ã‚ºä¸Šé™**: {max_side:.0f} px' if max_side > 0 else '**ãƒªã‚µã‚¤ã‚ºä¸Šé™**: ãªã—')
                st.caption(f'**ç”»åƒã‚µã‚¤ã‚º**: {img_bgr.shape[1]} Ã— {img_bgr.shape[0]} px')
                st.caption(f'**ãƒªã‚µã‚¤ã‚ºç‡**: {scale*100:.1f}%')
                st.caption(f'**è§£åƒåº¦è£œæ­£AI**: {"âœ“ æœ‰åŠ¹" if enable_resolution_correction else "ç„¡åŠ¹"}')
        
        # ã€ä¸­å¤®ã‚«ãƒ©ãƒ ã€‘ãƒ¡ãƒˆãƒªã‚¯ã‚¹ & ã‚°ãƒ©ãƒ•
        with col_center:
            st.markdown('#### ğŸ“Š è§£æçµæœ')
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
            metric_row = st.columns(3)
            metric_row[0].metric(
                'å®Ÿæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ',
                f'{fractal_d:.4f}',
                help='Box-Countingæ³•ã§è¨ˆæ¸¬'
            )
            
            if corrected_fractal_d is not None:
                delta_val = corrected_fractal_d - fractal_d
                metric_row[1].metric(
                    'AIè£œæ­£ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ',
                    f'{corrected_fractal_d:.4f}',
                    delta=f'{delta_val:+.4f}',
                    help='è§£åƒåº¦è£œæ­£AIã«ã‚ˆã‚‹æ¨å®šå€¤'
                )
            else:
                metric_row[1].metric(
                    'AIè£œæ­£ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ',
                    'ï¼',
                    help='è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«æœªå­¦ç¿’'
                )
            
            metric_row[2].metric(
                'ç©ºé–“å æœ‰ç‡',
                f'{occupancy*100:.2f}%',
                help='ç™½ãƒ”ã‚¯ã‚»ãƒ«ã®å‰²åˆ'
            )
            
            # ã‚°ãƒ©ãƒ•è¡¨ç¤º
            st.markdown('##### ğŸ“ˆ Box-Countingè§£æ')
            x_vals = np.log(1.0 / sizes)
            y_vals = np.log(counts)
            
            fig_main, (ax_line, ax_pie) = plt.subplots(1, 2, figsize=(9.5, 3.8), dpi=90, 
                                                        gridspec_kw={'width_ratios': [2.3, 1]})
            
            # æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ• (è‰²è¦šãƒãƒªã‚¢ãƒ•ãƒªãƒ¼)
            ax_line.plot(x_vals, y_vals, marker='o', linewidth=2.5, markersize=8, 
                        color=COLOR_BLUE, label=f'å®Ÿæ¸¬ (D={fractal_d:.3f})', zorder=3)
            
            if corrected_fractal_d is not None:
                intercept = np.mean(y_vals - corrected_fractal_d * x_vals)
                y_corrected = corrected_fractal_d * x_vals + intercept
                ax_line.plot(x_vals, y_corrected, marker='^', linewidth=2.2, markersize=7, 
                            color=COLOR_GREEN, linestyle='-.', alpha=0.9,
                            label=f'AIè£œæ­£ (D={corrected_fractal_d:.3f})', zorder=2)
            
            if pred is not None and 'fractal' in pred:
                intercept_pred = np.mean(y_vals - pred['fractal'] * x_vals)
                y_pred_line = pred['fractal'] * x_vals + intercept_pred
                ax_line.plot(x_vals, y_pred_line, marker='s', linewidth=2, markersize=6, 
                            color=COLOR_ORANGE, linestyle='--', alpha=0.85,
                            label=f'å¾“æ¥AI (D={pred["fractal"]:.3f})', zorder=1)
            
            ax_line.set_xlabel('log(1/ç®±ã‚µã‚¤ã‚º)', fontsize=10, fontweight='bold')
            ax_line.set_ylabel('log(ã‚«ã‚¦ãƒ³ãƒˆæ•°)', fontsize=10, fontweight='bold')
            ax_line.grid(True, alpha=0.3, linestyle=':', linewidth=1)
            ax_line.legend(loc='best', fontsize=9, framealpha=0.95)
            ax_line.set_title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¯”è¼ƒ', fontsize=11, fontweight='bold', pad=10)
            
            # å††ã‚°ãƒ©ãƒ• (è‰²è¦šãƒãƒªã‚¢ãƒ•ãƒªãƒ¼)
            wedges, texts, autotexts = ax_pie.pie(
                [occupancy, 1 - occupancy],
                labels=['ç™½', 'é»’'],
                autopct='%1.1f%%',
                colors=[COLOR_SKY, COLOR_YELLOW],
                startangle=90,
                textprops={'fontsize': 10, 'weight': 'bold'},
                wedgeprops={'edgecolor': '#333', 'linewidth': 1.5}
            )
            for autotext in autotexts:
                autotext.set_color('#000')
                autotext.set_fontsize(11)
            ax_pie.set_title('ãƒ”ã‚¯ã‚»ãƒ«åˆ†å¸ƒ', fontsize=11, fontweight='bold', pad=10)
            
            plt.tight_layout()
            st.pyplot(fig_main, use_container_width=True)
            plt.close(fig_main)
        
        # ã€å³ã‚«ãƒ©ãƒ ã€‘è©³ç´°è¨ºæ–­ & AIæ¯”è¼ƒ
        with col_right:
            st.markdown('#### ğŸ” è©³ç´°æƒ…å ±')
            
            # å“è³ªåˆ¤å®š
            if fail_flag:
                st.error('âš ï¸ å“è³ª: è¦ç¢ºèª')
                with st.expander('ç•°å¸¸æ¤œå‡ºã®è©³ç´°', expanded=True):
                    for reason in fail_reasons:
                        st.warning(f'â€¢ {reason}')
            else:
                st.success('âœ“ å“è³ª: æ­£å¸¸')
            
            # å¾“æ¥AIã¨ã®æ¯”è¼ƒ
            if pred is not None:
                with st.expander('ğŸ¤– å¾“æ¥AIäºˆæ¸¬', expanded=False):
                    st.metric(
                        'äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ',
                        f"{pred['fractal']:.4f}",
                        delta=f"{fractal_d - pred['fractal']:+.4f}",
                        delta_color="off"
                    )
                    if pred['occupancy'] is not None:
                        st.metric(
                            'äºˆæ¸¬å æœ‰ç‡',
                            f"{pred['occupancy']*100:.2f}%",
                            delta=f"{(occupancy - pred['occupancy'])*100:+.2f}%",
                            delta_color="off"
                        )
            
            # AIè£œæ­£æƒ…å ±
            if corrected_fractal_d is not None:
                with st.expander('ğŸ”¬ AIè£œæ­£ã®è©³ç´°', expanded=False):
                    st.write(f'**è£œæ­£å‰**: {fractal_d:.4f}')
                    st.write(f'**è£œæ­£å¾Œ**: {corrected_fractal_d:.4f}')
                    st.write(f'**å·®åˆ†**: {corrected_fractal_d - fractal_d:+.4f}')
                    improvement = abs(corrected_fractal_d - fractal_d) / max(abs(fractal_d), 0.0001) * 100
                    st.write(f'**å¤‰åŒ–ç‡**: {improvement:.2f}%')
            
            # ç”»åƒçµ±è¨ˆæƒ…å ±
            with st.expander('ğŸ“ ç”»åƒçµ±è¨ˆ', expanded=False):
                st.write(f'**å¹³å‡è¼åº¦**: {np.mean(gray):.2f}')
                st.write(f'**æ¨™æº–åå·®**: {np.std(gray):.2f}')
                st.write(f'**å…ƒã‚µã‚¤ã‚º**: {img_bgr.shape[1]} Ã— {img_bgr.shape[0]} px')
                st.write(f'**ç™½ãƒ”ã‚¯ã‚»ãƒ«æ•°**: {int(occupancy * bw.size):,}')
                st.write(f'**é»’ãƒ”ã‚¯ã‚»ãƒ«æ•°**: {int((1-occupancy) * bw.size):,}')
        
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        rec = {
            'filename': file.name,
            'fractal': fractal_d,
            'occupancy': occupancy,
            'corrected_fractal': corrected_fractal_d,
            'pred_fractal': pred['fractal'] if pred is not None else None,
            'pred_occupancy': pred['occupancy'] if (pred is not None and pred['occupancy'] is not None) else None,
            'is_valid': int(not fail_flag)
        }
        results_list.append(rec)
        append_to_train_csv(feat, {'fractal': fractal_d, 'occupancy': occupancy}, not fail_flag)
        
        st.divider()
    
    # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«æ™‚ã€Excelã«ã¾ã¨ã‚ã¦æ›¸ãè¾¼ã¿
    if len(results_list) >= 2:
        df_results = pd.DataFrame(results_list)
        if os.path.exists(EXCEL_PATH):
            with pd.ExcelWriter(EXCEL_PATH, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:
                sheet_name = pd.Timestamp.now().strftime('run_%Y%m%d_%H%M%S')
                df_results.to_excel(writer, sheet_name=sheet_name, index=False)
            st.info(f'âœ… è§£æçµæœã‚’æ—¢å­˜Excel ({EXCEL_PATH}) ã«è¿½è¨˜ã—ã¾ã—ãŸã€‚')
        else:
            df_results.to_excel(EXCEL_PATH, sheet_name='run', index=False)
            st.info(f'âœ… è§£æçµæœã‚’æ–°è¦Excel ({EXCEL_PATH}) ã«ä¿å­˜ã—ã¾ã—ãŸã€‚')

else:
    st.info('ğŸ‘† ä¸Šéƒ¨ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰è§£æã—ãŸã„ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚')

# === å­¦ç¿’ã‚»ã‚¯ã‚·ãƒ§ãƒ³ (Expanderå†…ã«æ ¼ç´) ===
st.divider()
with st.expander('ğŸ¤– å­¦ç¿’ / ãƒ¢ãƒ‡ãƒ«ç®¡ç†', expanded=False):
    st.markdown('### ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼')
    train_df = load_train_data()
    model_col1, model_col2 = st.columns(2)
    
    with model_col1:
        st.subheader('ğŸ“š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿')
        if train_df is None:
            st.info('ã¾ã å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚è§£æã‚’æ•°å›è¡Œã†ã¨è‡ªå‹•çš„ã«è“„ç©ã•ã‚Œã¾ã™ã€‚')
        else:
            st.metric('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¶æ•°', f'{len(train_df)}ä»¶')
            with st.expander('ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å…ˆé ­10ä»¶)', expanded=False):
                st.dataframe(train_df.head(10), use_container_width=True)
    
    with model_col2:
        st.subheader('âš™ï¸ ãƒ¢ãƒ‡ãƒ«è¨­å®š')
        if train_df is not None and len(train_df) > 0:
            st.success(f'âœ“ å­¦ç¿’å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ï¼ˆ{len(train_df)}ä»¶ï¼‰')
        else:
            st.warning('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™')
    
    st.markdown('---')
    if train_df is not None and len(train_df) > 0:
        if do_train_now:
            st.write('å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...')
            X = train_df[['mean_int','std_int','edge_density','occupancy','fractal_dim_feature']].values
            y_fractal = train_df['target_fractal'].values
            y_occupancy = train_df['target_occupancy'].values
            y_valid = train_df['is_valid'].values
            
            scaler = StandardScaler()
            Xs = scaler.fit_transform(X)
            
            Y_reg = np.vstack([y_fractal, y_occupancy]).T
            reg = RandomForestRegressor(n_estimators=100, random_state=42)
            try:
                reg.fit(Xs, Y_reg)
                st.success('å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚')
            except Exception as e:
                st.error('å›å¸°å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ:' + str(e))
                reg = None
            
            clf = RandomForestClassifier(n_estimators=100, random_state=42)
            try:
                clf.fit(Xs, y_valid)
                st.success('åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚')
            except Exception as e:
                st.error('åˆ†é¡å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ:' + str(e))
                clf = None
            
            if reg is not None:
                save_models(reg, scaler, clf)
                st.info('ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ (model_joblib.pkl, scaler_joblib.pkl)ã€‚')
            
            if reg is not None:
                ypred = reg.predict(Xs)
                mae_fractal = mean_absolute_error(y_fractal, ypred[:,0])
                mae_occ = mean_absolute_error(y_occupancy, ypred[:,1])
                st.write(f'å­¦å†…è©•ä¾¡ MAE - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«: {mae_fractal:.4f}, å æœ‰ç‡: {mae_occ:.4f}')
            if clf is not None:
                ypredc = clf.predict(Xs)
                acc = accuracy_score(y_valid, ypredc)
                st.write(f'åˆ†é¡ãƒ¢ãƒ‡ãƒ« å­¦å†…ç²¾åº¦: {acc:.3f} (æ­£ç­”ç‡)')
    
    if st.button('ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿ç›´ã™(ä¿å­˜æ¸ˆã¿ã‚’ãƒ­ãƒ¼ãƒ‰)', key='reload_model'):
        models2 = load_models()
        if 'reg' in models2:
            st.success('ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚')
        else:
            st.error('ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚')

# ã‚µã‚¤ãƒ‰ãƒãƒ¼å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¶æ•°è¡¨ç¤º
train_df_sidebar = load_train_data()
if train_df_sidebar is not None:
    st.sidebar.markdown('---')
    st.sidebar.write(f'ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: **{len(train_df_sidebar)}**ä»¶')

st.sidebar.markdown('---')
st.sidebar.write('**å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:**')
st.sidebar.caption(f'ğŸ“ {EXCEL_PATH}')
st.sidebar.caption(f'ğŸ“ {MODEL_PATH}')
st.sidebar.caption(f'ğŸ“ {TRAIN_CSV}')

st.markdown('---')
st.caption('ğŸ’¡ **æ³¨æ„**: æœ¬ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã‚µãƒ³ãƒ—ãƒ«å®Ÿè£…ã§ã™ã€‚ç”»åƒã‚µã‚¤ã‚ºã€ç‰¹å¾´é‡ã€ç•°å¸¸åˆ¤å®šåŸºæº–ã€ãƒ¢ãƒ‡ãƒ«é¸å®šã¯ç”¨é€”ã«å¿œã˜ã¦èª¿æ•´ã—ã¦ãã ã•ã„ã€‚')
st.caption('ğŸ¨ **è‰²è¦šãƒãƒªã‚¢ãƒ•ãƒªãƒ¼é…è‰²**: Okabe-Ito/Wong paletteã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚')
