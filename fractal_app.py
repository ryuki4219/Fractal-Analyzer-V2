"""
Streamlit ã‚¢ãƒ—ãƒª: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã‚’ç”¨ã„ãŸç”»åƒè§£æã‚¢ãƒ—ãƒª
æ©Ÿèƒ½:
- é–¾å€¤ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼/æ•°å€¤å…¥åŠ›ï¼‰ã¨ãƒªã‚µã‚¤ã‚ºä¸Šé™ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼/æ•°å€¤å…¥åŠ›ï¼‰ã®2æ–¹å¼ã‚’ç”¨æ„
- ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã§å‡ºåŠ›ã€ç©ºé–“å æœ‰ç‡ã¯å††ã‚°ãƒ©ãƒ•ã§å‡ºåŠ›
- å­¦ç¿’æ©Ÿèƒ½: è§£æçµæœï¼ˆæœ‰åŠ¹/å¤±æ•—ï¼‰ã‚’å­¦ç¿’ã—ã€äºˆæ¸¬çµæœã¨æ¯”è¼ƒè¡¨ç¤º
- ç•°å¸¸å€¤ãƒ»ç•°å¸¸ãªäºŒå€¤åŒ–ã®è‡ªå‹•æ¤œçŸ¥ï¼ˆå¤±æ•—æ‰±ã„ï¼‰ -> å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
- ãƒ•ã‚©ãƒ«ãƒ€å†…ç”»åƒã‚’ä¸€æ‹¬è§£æï¼ˆStreamlitã®ä»•æ§˜ä¸Šã€è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§å¯¾å¿œï¼‰
- 2æšä»¥ä¸Šè§£ææ™‚ã€è‡ªå‹•ã§Excelã«çµæœã‚’ä¿å­˜ãƒ»è¿½è¨˜
- å­¦ç¿’ä»¶æ•°ã®è¡¨ç¤ºã€è§£æç²¾åº¦ï¼ˆMAEãªã©ï¼‰ã®è¡¨ç¤º

ä½¿ã„æ–¹:
1) å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install -r requirements.txt
2) å®Ÿè¡Œ: streamlit run fractal_app.py

ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›:
- å­¦ç¿’ãƒ¢ãƒ‡ãƒ«: model_joblib.pkl
- ã‚¹ã‚±ãƒ¼ãƒ©: scaler_joblib.pkl
- çµæœExcel: results.xlsx

æ³¨æ„: æœ¬ä¾‹ã¯å­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç°¡æ½”åŒ–ã—ã¦ã„ã¾ã™ã€‚ç”¨é€”ã«å¿œã˜ã¦ç‰¹å¾´é‡ã‚„ãƒ¢ãƒ‡ãƒ«ã‚’æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚
"""

import streamlit as st
import numpy as np
import pandas as pd
import cv2
from PIL import Image
import io
import os
import joblib
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, accuracy_score
import matplotlib.pyplot as plt
from skimage import filters, color
from skimage.feature import canny

# matplotlibã§æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®šï¼ˆæ–‡å­—åŒ–ã‘å¯¾ç­–ï¼‰
import matplotlib
matplotlib.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False  # ãƒã‚¤ãƒŠã‚¹è¨˜å·ã®æ–‡å­—åŒ–ã‘å¯¾ç­–

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° -------------------------------------------------

@st.cache_data
def load_image_from_bytes(bytes_data: bytes) -> np.ndarray:
    # ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ BGR(OpenCV) ç”»åƒã‚’è¿”ã™ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰
    img = Image.open(io.BytesIO(bytes_data)).convert('RGB')
    arr = np.array(img)[:, :, ::-1].copy()  # RGB->BGR
    return arr

def load_image_bytes(file) -> np.ndarray:
    # Streamlit ã® UploadedFile ã‹ã‚‰ BGR(OpenCV) ç”»åƒã‚’è¿”ã™
    bytes_data = file.read()
    return load_image_from_bytes(bytes_data)


@st.cache_data
def resize_image(img: np.ndarray, max_side: float):
    # æœ€é•·è¾ºãŒ max_side ã‚’è¶…ãˆã‚‹å ´åˆãƒªã‚µã‚¤ã‚ºã™ã‚‹
    h, w = img.shape[:2]
    scale = 1.0
    if max(h, w) > max_side and max_side > 0:
        scale = max_side / max(h, w)
        new_w = int(w * scale)
        new_h = int(h * scale)
        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return img, scale


@st.cache_data
def binarize_image_gray(gray: np.ndarray, thresh: float):
    # thresh ã¯ 0..255 ã®å®Ÿæ•°å€¤ã€‚ã“ã“ã§ã¯å›ºå®šé–¾å€¤ã«ã‚ˆã‚‹äºŒå€¤åŒ–
    _, bw = cv2.threshold(gray.astype('uint8'), thresh, 255, cv2.THRESH_BINARY)
    return bw


def adaptive_binarize(gray: np.ndarray):
    # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³é©å¿œé–¾å€¤ï¼ˆã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦ï¼‰
    bw = cv2.adaptiveThreshold(gray.astype('uint8'), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, 11, 2)
    return bw


@st.cache_data
def boxcount_fractal_dim(bw: np.ndarray, sizes=None):
    # ç™½(255) ã‚’å¯¾è±¡ã«ç®±ã²ãï¼ˆbox-countingæ³•ï¼‰ã§ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®š
    # bw: äºŒå€¤ç”»åƒï¼ˆ0 or 255ï¼‰
    # sizes: list of box sizes to use (pixels)
    S = bw.shape
    if sizes is None:
        max_dim = max(S)
        min_dim = min(S)
        # ç®±ã‚µã‚¤ã‚ºã¯ 2^k ç³»åˆ—ã§ç”Ÿæˆï¼ˆæœ€å°3ãƒã‚¤ãƒ³ãƒˆç¢ºä¿ï¼‰
        if min_dim >= 8:
            sizes = np.array([2 ** i for i in range(1, int(np.log2(min_dim)) + 1)])
        else:
            sizes = np.array([1, 2, 4])
        sizes = sizes[sizes <= min_dim]
        if len(sizes) < 2:
            sizes = np.array([1, 2, 4, 8])
    counts = []
    for size in sizes:
        # ç”»åƒã‚’ size x size ã®ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²ã—ã¦ã€ç™½ãŒå«ã¾ã‚Œã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ•°ãˆã‚‹
        nx = int(np.ceil(S[1] / size))
        ny = int(np.ceil(S[0] / size))
        count = 0
        for i in range(ny):
            for j in range(nx):
                y0 = i * size
                x0 = j * size
                block = bw[y0:y0 + size, x0:x0 + size]
                if np.any(block > 0):
                    count += 1
        counts.append(count)
    sizes = np.array(sizes, dtype=float)
    counts = np.array(counts, dtype=float)
    # fractal dimension D is slope of log(count) vs log(1/size)
    # linear regression via least squares
    # ã‚¼ãƒ­ã‚„è² ã®å€¤ã‚’é™¤å¤–
    valid_mask = (counts > 0) & (sizes > 0)
    if np.sum(valid_mask) < 2:
        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒ2ã¤æœªæº€ã®å ´åˆã¯ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’è¨ˆç®—ã§ããªã„
        return 0.0, sizes, counts
    
    sizes_valid = sizes[valid_mask]
    counts_valid = counts[valid_mask]
    
    logs = np.log(counts_valid)
    loginv = np.log(1.0 / sizes_valid)
    
    # å˜ç´”ãªç·šå½¢å›å¸°
    A = np.vstack([loginv, np.ones_like(loginv)]).T
    try:
        m, c = np.linalg.lstsq(A, logs, rcond=None)[0]
    except Exception:
        m = 0.0
    return float(m), sizes, counts


@st.cache_data
def compute_spatial_occupancy(bw: np.ndarray):
    # ç™½ï¼ˆ255ï¼‰ãŒå ã‚ã‚‹å‰²åˆ
    total = bw.size
    white = np.count_nonzero(bw > 0)
    return float(white / total)


@st.cache_data
def extract_features_from_image(img_bgr: np.ndarray, bw: np.ndarray, fractal_dim: float):
    # ã‚·ãƒ³ãƒ—ãƒ«ãªç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    mean_int = float(np.mean(gray))
    std_int = float(np.std(gray))
    edge = canny(gray / 255.0)
    edge_density = float(np.count_nonzero(edge) / edge.size)
    occupancy = compute_spatial_occupancy(bw)
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè‡ªèº«ã‚‚ç‰¹å¾´ã¨ã—ã¦å«ã‚ã‚‹
    return np.array([mean_int, std_int, edge_density, occupancy, fractal_dim], dtype=float)

# --- æ°¸ç¶šåŒ–ãƒ•ã‚¡ã‚¤ãƒ« & ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– ----------------------------------------
MODEL_PATH = 'model_joblib.pkl'
SCALER_PATH = 'scaler_joblib.pkl'
CLASS_PATH = 'classifier_joblib.pkl'
EXCEL_PATH = 'results.xlsx'
TRAIN_CSV = 'train_data.csv'

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰é–¢æ•°
@st.cache_resource
def load_models():
    models = {}
    if os.path.exists(MODEL_PATH) and os.path.exists(SCALER_PATH):
        try:
            models['reg'] = joblib.load(MODEL_PATH)
            models['scaler'] = joblib.load(SCALER_PATH)
        except Exception:
            models = {}
    if os.path.exists(CLASS_PATH):
        try:
            models['clf'] = joblib.load(CLASS_PATH)
        except Exception:
            pass
    return models


def save_models(reg, scaler, clf=None):
    joblib.dump(reg, MODEL_PATH)
    joblib.dump(scaler, SCALER_PATH)
    if clf is not None:
        joblib.dump(clf, CLASS_PATH)

# --- ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šæ‰±ã„ --------------------------------------

def append_to_train_csv(features, y_reg, is_valid):
    # features: 1d array, y_reg: dict {'fractal':..., 'occupancy':...}
    cols = ['mean_int', 'std_int', 'edge_density', 'occupancy', 'fractal_dim_feature',
            'target_fractal', 'target_occupancy', 'is_valid']
    row = list(features) + [y_reg['fractal'], y_reg['occupancy'], int(is_valid)]
    df = pd.DataFrame([row], columns=cols)
    if os.path.exists(TRAIN_CSV):
        df.to_csv(TRAIN_CSV, mode='a', header=False, index=False)
    else:
        df.to_csv(TRAIN_CSV, index=False)


@st.cache_data(ttl=1)  # 1ç§’é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒè¿½åŠ ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚çŸ­ã‚ï¼‰
def load_train_data():
    if os.path.exists(TRAIN_CSV):
        return pd.read_csv(TRAIN_CSV)
    else:
        return None

# --- Streamlit UI -------------------------------------------------------

st.set_page_config(layout='wide', page_title='ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ç”»åƒè§£æã‚¢ãƒ—ãƒª')
st.title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã‚’ç”¨ã„ãŸç”»åƒè§£æã‚¢ãƒ—ãƒª')

st.sidebar.header('è¨­å®š')
# é–¾å€¤å…¥åŠ›: æ•°å€¤å…¥åŠ›ã¨ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’ä¸¡æ–¹ç”¨æ„
thresh_mode = st.sidebar.selectbox('é–¾å€¤å…¥åŠ›æ–¹å¼', ['ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼', 'æ•°å€¤å…¥åŠ›'])
if thresh_mode == 'ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼':
    thresh_value = st.sidebar.slider('äºŒå€¤åŒ–é–¾å€¤ (0-255)', min_value=0.0, max_value=255.0, value=128.0)
else:
    thresh_value = st.sidebar.number_input('äºŒå€¤åŒ–é–¾å€¤ (0-255)', min_value=0.0, max_value=255.0, value=128.0, step=0.1)

# ãƒªã‚µã‚¤ã‚ºä¸Šé™: æ•°å€¤ã¨ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
resize_mode = st.sidebar.selectbox('ãƒªã‚µã‚¤ã‚ºæ–¹å¼', ['ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼', 'æ•°å€¤å…¥åŠ›'])
if resize_mode == 'ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼':
    max_side = st.sidebar.slider('ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º (px, 0ã§ãƒªã‚µã‚¤ã‚ºç„¡åŠ¹)', min_value=0.0, max_value=4000.0, value=1024.0)
else:
    max_side = st.sidebar.number_input('ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º (px, 0ã§ãƒªã‚µã‚¤ã‚ºç„¡åŠ¹)', min_value=0.0, max_value=10000.0, value=1024.0)

st.sidebar.markdown('---')
# å­¦ç¿’ãƒœã‚¿ãƒ³
do_train_now = st.sidebar.button('å­¦ç¿’ã‚’å®Ÿè¡Œï¼ˆä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ï¼‰')
# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
models = load_models()

# ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ: è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãƒ•ã‚©ãƒ«ãƒ€å†…ä¸€æ‹¬è§£æã«å¯¾å¿œ
uploaded_files = st.file_uploader('ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰', type=['png','jpg','jpeg','bmp','tif','tiff'], accept_multiple_files=True)

# è§£æ/å­¦ç¿’ç”¨ã®è¡¨ç¤ºé ˜åŸŸ
col1, col2 = st.columns([2,1])

with col1:
    st.header('è§£æçµæœ')
    if uploaded_files is not None and len(uploaded_files) > 0:
        results_list = []
        predictions = []
        for file in uploaded_files:
            st.write('ãƒ•ã‚¡ã‚¤ãƒ«:', file.name)
            img_bgr = load_image_bytes(file)
            img_bgr, scale = resize_image(img_bgr, max_side)
            gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)

            # äºŒå€¤åŒ– (å›ºå®šé–¾å€¤)
            bw = binarize_image_gray(gray, thresh_value)

            # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—
            fractal_d, sizes, counts = boxcount_fractal_dim(bw)
            occupancy = compute_spatial_occupancy(bw)

            # ç•°å¸¸æ¤œçŸ¥: æ¥µç«¯ãªå æœ‰ç‡ã‚„äºŒå€¤åŒ–ãŒã»ã¼å…¨ç™½/å…¨é»’ãªã‚‰å¤±æ•—æ‰±ã„
            white_ratio = occupancy
            fail_flag = False
            fail_reasons = []
            if white_ratio < 0.01:
                fail_flag = True
                fail_reasons.append('ã»ã¨ã‚“ã©ç™½ãŒç„¡ã„(å æœ‰ç‡ <1%)')
            if white_ratio > 0.99:
                fail_flag = True
                fail_reasons.append('ã»ã¨ã‚“ã©ç™½ã§åŸ‹ã¾ã£ã¦ã„ã‚‹(å æœ‰ç‡ >99%)')
            # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®ç¾å®Ÿçš„ãƒ¬ãƒ³ã‚¸ãƒã‚§ãƒƒã‚¯
            if not ( -5.0 < fractal_d < 5.0 ):  # æ§˜ã€…ãªç”»åƒã§ã®ç›®å®‰
                fail_flag = True
                fail_reasons.append(f'ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãŒç•°å¸¸å€¤:{fractal_d:.3f}')

            # ç‰¹å¾´é‡æŠ½å‡º
            feat = extract_features_from_image(img_bgr, bw, fractal_d)

            # äºˆæ¸¬ãŒå¯èƒ½ãªã‚‰å‡ºåŠ›
            pred = None
            if 'reg' in models and 'scaler' in models:
                try:
                    Xs = models['scaler'].transform(feat.reshape(1,-1))
                    ypred = models['reg'].predict(Xs)[0]
                    # reg ã¯ 2å‡ºåŠ›ã‚’æƒ³å®šã—ã¦ã„ã‚‹ (fractal, occupancy)
                    if isinstance(ypred, (list,tuple,np.ndarray)) and len(ypred) >= 2:
                        pred = {'fractal': float(ypred[0]), 'occupancy': float(ypred[1])}
                    else:
                        # å˜ä¸€å‡ºåŠ›ã®å ´åˆã¯ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã®ã¿
                        pred = {'fractal': float(ypred), 'occupancy': None}
                except Exception as e:
                    st.write('äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', e)

            # çµæœè¡¨ç¤º - è¦‹ã‚„ã™ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹å½¢å¼ã§è¡¨ç¤º
            st.subheader('ğŸ“Š è§£æçµæœ')
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’2åˆ—ã§è¡¨ç¤º
            metric_col1, metric_col2 = st.columns(2)
            with metric_col1:
                st.metric(
                    label="ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ",
                    value=f"{fractal_d:.4f}",
                    help="ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯ç”»åƒã®è¤‡é›‘ã•ã‚’è¡¨ã™æŒ‡æ¨™ã§ã™"
                )
            with metric_col2:
                st.metric(
                    label="ç©ºé–“å æœ‰ç‡ï¼ˆç™½ãƒ”ã‚¯ã‚»ãƒ«ï¼‰",
                    value=f"{occupancy*100:.2f}%",
                    help="ç”»åƒå…¨ä½“ã«ãŠã‘ã‚‹ç™½ãƒ”ã‚¯ã‚»ãƒ«ã®å‰²åˆã§ã™"
                )
            
            # äºˆæ¸¬å€¤ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ è¡¨ç¤º
            if pred is not None:
                st.write("**ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬å€¤:**")
                pred_col1, pred_col2 = st.columns(2)
                with pred_col1:
                    delta_fractal = fractal_d - pred['fractal'] if pred['fractal'] is not None else None
                    st.metric(
                        label="äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ",
                        value=f"{pred['fractal']:.4f}" if pred['fractal'] is not None else "N/A",
                        delta=f"{delta_fractal:.4f}" if delta_fractal is not None else None,
                        delta_color="off"
                    )
                with pred_col2:
                    if pred['occupancy'] is not None:
                        delta_occupancy = (occupancy - pred['occupancy']) * 100
                        st.metric(
                            label="äºˆæ¸¬ç©ºé–“å æœ‰ç‡",
                            value=f"{pred['occupancy']*100:.2f}%",
                            delta=f"{delta_occupancy:.2f}%" if delta_occupancy is not None else None,
                            delta_color="off"
                        )
            
            # ç•°å¸¸æ¤œçŸ¥çµæœ
            if fail_flag:
                st.warning('âš ï¸ è‡ªå‹•æ¤œçŸ¥: å¤±æ•—ã¨åˆ¤å®šã•ã‚Œã¾ã—ãŸã€‚ç†ç”±: ' + '; '.join(fail_reasons))
            else:
                st.success('âœ… è‡ªå‹•æ¤œçŸ¥: æ­£å¸¸ã¨åˆ¤å®š')

            st.divider()

            # å…ƒç”»åƒã¨äºŒå€¤åŒ–ç”»åƒã‚’ä¸¦ã¹ã¦è¡¨ç¤º
            col_img1, col_img2 = st.columns(2)
            with col_img1:
                st.subheader('å…ƒç”»åƒ')
                # BGR -> RGB ã«å¤‰æ›ã—ã¦è¡¨ç¤º
                img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
                st.image(img_rgb, use_container_width=True)
            with col_img2:
                st.subheader('äºŒå€¤åŒ–ç”»åƒ')
                st.image(bw, use_container_width=True, clamp=True)

            # ã‚°ãƒ©ãƒ•è¡¨ç¤º
            st.subheader('ğŸ“ˆ ã‚°ãƒ©ãƒ•è¡¨ç¤º')
            
            # ã‚°ãƒ©ãƒ•ã‚’2åˆ—ã§è¡¨ç¤º
            graph_col1, graph_col2 = st.columns(2)
            
            with graph_col1:
                # ã‚°ãƒ©ãƒ•: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æŠ˜ã‚Œç·šï¼ˆsizes vs counts ã‹ã‚‰å¯è¦–åŒ–ï¼‰
                fig1, ax1 = plt.subplots()
                ax1.plot(np.log(1.0/sizes), np.log(counts), marker='o', linewidth=2, markersize=8)
                ax1.set_xlabel('log(1/size)')
                ax1.set_ylabel('log(count)')
                ax1.set_title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æã‚°ãƒ©ãƒ•')
                ax1.grid(True, alpha=0.3)
                st.pyplot(fig1)
                plt.close(fig1)

            with graph_col2:
                # å††ã‚°ãƒ©ãƒ•: ç©ºé–“å æœ‰ç‡
                fig2, ax2 = plt.subplots()
                # ç™½ãƒ”ã‚¯ã‚»ãƒ«ï¼ˆå æœ‰ï¼‰ã¨é»’ãƒ”ã‚¯ã‚»ãƒ«ï¼ˆéå æœ‰ï¼‰ã®å‰²åˆ
                # è‰²ã‚’ç™½ã¨é»’ã«å¯¾å¿œã•ã›ã‚‹
                colors = ['white', 'black']
                wedgeprops = {'edgecolor': 'gray', 'linewidth': 1}
                ax2.pie([occupancy, 1-occupancy], 
                       labels=['ç™½ãƒ”ã‚¯ã‚»ãƒ«', 'é»’ãƒ”ã‚¯ã‚»ãƒ«'], 
                       autopct='%1.1f%%',
                       colors=colors,
                       wedgeprops=wedgeprops,
                       startangle=90)
                ax2.set_title('ç©ºé–“å æœ‰ç‡ï¼ˆç™½ãƒ”ã‚¯ã‚»ãƒ« vs é»’ãƒ”ã‚¯ã‚»ãƒ«ï¼‰')
                st.pyplot(fig2)
                plt.close(fig2)

            # äºˆæ¸¬ã¨å®Ÿæ¸¬ã®æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆï¼ˆã‚ã‚Œã°ï¼‰
            if pred is not None:
                st.subheader('ğŸ” äºˆæ¸¬ vs å®Ÿæ¸¬ã®æ¯”è¼ƒ')
                compare_col1, compare_col2 = st.columns(2)
                
                with compare_col1:
                    # æ¯”è¼ƒãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚°ãƒ©ãƒ•
                    fig3, ax3 = plt.subplots()
                    ax3.plot([0,1],[fractal_d, pred['fractal']], marker='o', linewidth=2, markersize=10)
                    ax3.set_xticks([0,1])
                    ax3.set_xticklabels(['å®Ÿæ¸¬','äºˆæ¸¬'])
                    ax3.set_ylabel('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ')
                    ax3.set_title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¯”è¼ƒ')
                    ax3.grid(True, alpha=0.3)
                    st.pyplot(fig3)
                    plt.close(fig3)
                
                with compare_col2:
                    # æ¯”è¼ƒå æœ‰ç‡
                    if pred['occupancy'] is not None:
                        fig4, ax4 = plt.subplots()
                        ax4.plot([0,1],[occupancy, pred['occupancy']], marker='o', linewidth=2, markersize=10)
                        ax4.set_xticks([0,1])
                        ax4.set_xticklabels(['å®Ÿæ¸¬','äºˆæ¸¬'])
                        ax4.set_ylabel('å æœ‰ç‡')
                        ax4.set_title('ç©ºé–“å æœ‰ç‡ã®æ¯”è¼ƒ')
                        ax4.grid(True, alpha=0.3)
                        st.pyplot(fig4)
                    plt.close(fig4)

            # çµæœãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ
            rec = {
                'filename': file.name,
                'fractal': fractal_d,
                'occupancy': occupancy,
                'pred_fractal': pred['fractal'] if pred is not None else None,
                'pred_occupancy': pred['occupancy'] if (pred is not None and pred['occupancy'] is not None) else None,
                'is_valid': int(not fail_flag)
            }
            results_list.append(rec)

            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è‡ªå‹•è¿½åŠ ï¼ˆæ¤œçŸ¥ã—ãŸå¤±æ•—ã¯ is_valid=0 ã¨ã—ã¦æ·»åŠ ï¼‰
            append_to_train_csv(feat, {'fractal':fractal_d, 'occupancy':occupancy}, not fail_flag)

        # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«æ™‚ã€Excelã«ã¾ã¨ã‚ã¦æ›¸ãè¾¼ã¿ï¼ˆappendï¼‰
        if len(results_list) >= 2:
            df_results = pd.DataFrame(results_list)
            if os.path.exists(EXCEL_PATH):
                # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
                with pd.ExcelWriter(EXCEL_PATH, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:
                    # æ–°ã—ã„ã‚·ãƒ¼ãƒˆã¨ã—ã¦ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ä¿å­˜
                    sheet_name = pd.Timestamp.now().strftime('run_%Y%m%d_%H%M%S')
                    df_results.to_excel(writer, sheet_name=sheet_name, index=False)
                st.info(f'è§£æçµæœã‚’æ—¢å­˜Excel ({EXCEL_PATH}) ã«è¿½è¨˜ã—ã¾ã—ãŸã€‚')
            else:
                df_results.to_excel(EXCEL_PATH, sheet_name='run', index=False)
                st.info(f'è§£æçµæœã‚’æ–°è¦Excel ({EXCEL_PATH}) ã«ä¿å­˜ã—ã¾ã—ãŸã€‚')

        # å­¦ç¿’ä»¶æ•°ã®è¡¨ç¤º
        train_df = load_train_data()
        if train_df is not None:
            st.sidebar.write(f'å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(train_df)}')
        else:
            st.sidebar.write('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚')

with col2:
    st.header('å­¦ç¿’ / ãƒ¢ãƒ‡ãƒ«')
    st.write('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»å†å­¦ç¿’ã‚’è¡Œãˆã¾ã™ã€‚')

    train_df = load_train_data()
    if train_df is None:
        st.info('ã¾ã å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚è§£æã‚’æ•°å›è¡Œã†ã¨è‡ªå‹•çš„ã«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒè“„ç©ã•ã‚Œã¾ã™ã€‚')
    else:
        st.write('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­5è¡Œ:')
        st.dataframe(train_df.head())

        # å­¦ç¿’å®Ÿè¡Œ
        if do_train_now:
            st.write('å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...')
            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ç”¨æ„
            X = train_df[['mean_int','std_int','edge_density','occupancy','fractal_dim_feature']].values
            y_fractal = train_df['target_fractal'].values
            y_occupancy = train_df['target_occupancy'].values
            y_valid = train_df['is_valid'].values

            scaler = StandardScaler()
            Xs = scaler.fit_transform(X)

            # å›å¸°: 2å‡ºåŠ›ã‚’åŒæ™‚ã«å­¦ç¿’ã™ã‚‹ãŸã‚ã€å˜ç´”ã«æ¨ªã«çµåˆ
            Y_reg = np.vstack([y_fractal, y_occupancy]).T
            reg = RandomForestRegressor(n_estimators=100, random_state=42)
            try:
                reg.fit(Xs, Y_reg)
                st.success('å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚')
            except Exception as e:
                st.error('å›å¸°å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ:' + str(e))
                reg = None

            # åˆ†é¡: æœ‰åŠ¹/ç„¡åŠ¹åˆ¤å®š
            clf = RandomForestClassifier(n_estimators=100, random_state=42)
            try:
                clf.fit(Xs, y_valid)
                st.success('åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚')
            except Exception as e:
                st.error('åˆ†é¡å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ:' + str(e))
                clf = None

            # ä¿å­˜
            if reg is not None:
                save_models(reg, scaler, clf)
                st.info('ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ (model_joblib.pkl, scaler_joblib.pkl)ã€‚')

            # ç°¡æ˜“è©•ä¾¡: ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç„¡ã—ã®å­¦å†…è©•ä¾¡
            if reg is not None:
                ypred = reg.predict(Xs)
                mae_fractal = mean_absolute_error(y_fractal, ypred[:,0])
                mae_occ = mean_absolute_error(y_occupancy, ypred[:,1])
                st.write(f'å­¦å†…è©•ä¾¡ MAE - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«: {mae_fractal:.4f}, å æœ‰ç‡: {mae_occ:.4f}')
            if clf is not None:
                ypredc = clf.predict(Xs)
                acc = accuracy_score(y_valid, ypredc)
                st.write(f'åˆ†é¡ãƒ¢ãƒ‡ãƒ« å­¦å†…ç²¾åº¦: {acc:.3f} (æ­£ç­”ç‡)')

    # æ‰‹å‹•ã§å†å­¦ç¿’ã—ãŸã„å ´åˆã®ãƒœã‚¿ãƒ³
    if st.button('ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿ç›´ã™ï¼ˆä¿å­˜æ¸ˆã¿ã‚’ãƒ­ãƒ¼ãƒ‰ï¼‰'):
        models2 = load_models()
        if 'reg' in models2:
            st.success('ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚')
        else:
            st.error('ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚')

st.sidebar.markdown('---')
st.sidebar.write('å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:')
st.sidebar.write(EXCEL_PATH)
st.sidebar.write(MODEL_PATH)
st.sidebar.write(TRAIN_CSV)

st.write('\n')
st.write('---')
st.write('æ³¨æ„: æœ¬ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã‚µãƒ³ãƒ—ãƒ«å®Ÿè£…ã§ã™ã€‚ç”»åƒã‚µã‚¤ã‚ºã€ç‰¹å¾´é‡ã€ç•°å¸¸åˆ¤å®šåŸºæº–ã€ãƒ¢ãƒ‡ãƒ«é¸å®šã¯ç”¨é€”ã«å¿œã˜ã¦èª¿æ•´ã—ã¦ãã ã•ã„ã€‚')