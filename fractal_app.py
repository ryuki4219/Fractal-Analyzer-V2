"""
Streamlit ã‚¢ãƒ—ãƒª: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã‚’ç”¨ã„ãŸç”»åƒè§£æã‚¢ãƒ—ãƒª
æ©Ÿèƒ½:
- é–¾å€¤ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼/æ•°å€¤å…¥åŠ›ï¼‰ã¨ãƒªã‚µã‚¤ã‚ºä¸Šé™ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼/æ•°å€¤å…¥åŠ›ï¼‰ã®2æ–¹å¼ã‚’ç”¨æ„
- ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã§å‡ºåŠ›ã€ç©ºé–“å æœ‰ç‡ã¯å††ã‚°ãƒ©ãƒ•ã§å‡ºåŠ›
- å­¦ç¿’æ©Ÿèƒ½: è§£æçµæœï¼ˆæœ‰åŠ¹/å¤±æ•—ï¼‰ã‚’å­¦ç¿’ã—ã€äºˆæ¸¬çµæœã¨æ¯”è¼ƒè¡¨ç¤º
- ç•°å¸¸å€¤ãƒ»ç•°å¸¸ãªäºŒå€¤åŒ–ã®è‡ªå‹•æ¤œçŸ¥ï¼ˆå¤±æ•—æ‰±ã„ï¼‰ -> å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
- ãƒ•ã‚©ãƒ«ãƒ€å†…ç”»åƒã‚’ä¸€æ‹¬è§£æï¼ˆStreamlitã®ä»•æ§˜ä¸Šã€è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§å¯¾å¿œï¼‰
- 2æšä»¥ä¸Šè§£ææ™‚ã€è‡ªå‹•ã§Excelã«çµæœã‚’ä¿å­˜ãƒ»è¿½è¨˜
- å­¦ç¿’ä»¶æ•°ã®è¡¨ç¤ºã€è§£æç²¾åº¦ï¼ˆMAEãªã©ï¼‰ã®è¡¨ç¤º

ä½¿ã„æ–¹:
1) å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install -r requirements.txt
2) å®Ÿè¡Œ: streamlit run fractal_app.py

ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›:
- å­¦ç¿’ãƒ¢ãƒ‡ãƒ«: model_joblib.pkl
- ã‚¹ã‚±ãƒ¼ãƒ©: scaler_joblib.pkl
- çµæœExcel: results.xlsx

æ³¨æ„: æœ¬ä¾‹ã¯å­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç°¡æ½”åŒ–ã—ã¦ã„ã¾ã™ã€‚ç”¨é€”ã«å¿œã˜ã¦ç‰¹å¾´é‡ã‚„ãƒ¢ãƒ‡ãƒ«ã‚’æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚
"""

import streamlit as st
import numpy as np
import pandas as pd
import cv2
from PIL import Image
import io
import os
import joblib
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, accuracy_score, r2_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from skimage import filters, color
from skimage.feature import canny
import matplotlib
# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ï¼‰
try:
    matplotlib.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'DejaVu Sans', 'sans-serif']
    matplotlib.rcParams['axes.unicode_minus'] = False
except Exception:
    pass  # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–

# --- è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ç”¨ã®å®šæ•° ----------------------------------------------
RESOLUTION_MODEL_PATH = 'resolution_correction_model.pkl'
RESOLUTION_SCALER_PATH = 'resolution_correction_scaler.pkl'
RESOLUTION_TRAIN_DATA = 'resolution_training_data.csv'

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° -------------------------------------------------

@st.cache_data(show_spinner=False)
def load_image_bytes(file_bytes: bytes, file_name: str) -> np.ndarray:
    """
    ç”»åƒãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ BGR(OpenCV) ç”»åƒã‚’è¿”ã™
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ã«ã‚ˆã‚Šã€åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†èª­ã¿è¾¼ã¿ã‚’é«˜é€ŸåŒ–
    """
    img = Image.open(io.BytesIO(file_bytes)).convert('RGB')
    arr = np.array(img)[:, :, ::-1].copy()  # RGB->BGR
    return arr


@st.cache_data(show_spinner=False)
def resize_image(img: np.ndarray, max_side: float):
    """
    æœ€é•·è¾ºãŒ max_side ã‚’è¶…ãˆã‚‹å ´åˆãƒªã‚µã‚¤ã‚ºã™ã‚‹
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ã«ã‚ˆã‚Šã€åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å†è¨ˆç®—ã‚’é˜²ã
    """
    h, w = img.shape[:2]
    scale = 1.0
    if max(h, w) > max_side and max_side > 0:
        scale = max_side / max(h, w)
        new_w = int(w * scale)
        new_h = int(h * scale)
        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return img, scale


@st.cache_data(show_spinner=False)
def binarize_image_gray(gray: np.ndarray, thresh: float):
    """
    thresh ã¯ 0..255 ã®å®Ÿæ•°å€¤ã€‚ã“ã“ã§ã¯å›ºå®šé–¾å€¤ã«ã‚ˆã‚‹äºŒå€¤åŒ–
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ã«ã‚ˆã‚Šã€åŒã˜é–¾å€¤ã§ã®å†è¨ˆç®—ã‚’é˜²ã
    """
    _, bw = cv2.threshold(gray.astype('uint8'), thresh, 255, cv2.THRESH_BINARY)
    return bw


def adaptive_binarize(gray: np.ndarray):
    # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³é©å¿œé–¾å€¤ï¼ˆã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦ï¼‰
    bw = cv2.adaptiveThreshold(gray.astype('uint8'), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, 11, 2)
    return bw


@st.cache_data(show_spinner=False)
def boxcount_fractal_dim(bw: np.ndarray, sizes=None, fast_mode=False):
    """
    ç™½(255) ã‚’å¯¾è±¡ã«ç®±ã²ãï¼ˆbox-countingæ³•ï¼‰ã§ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®š
    
    Args:
        bw: äºŒå€¤ç”»åƒï¼ˆ0 or 255ï¼‰
        sizes: list of box sizes to use (pixels)
        fast_mode: é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼ˆç®±ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›ï¼‰
        
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ã«ã‚ˆã‚Šã€åŒã˜ç”»åƒã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å†è¨ˆç®—ã‚’é˜²ã
    """
    S = bw.shape
    if sizes is None:
        max_dim = max(S)
        # ç®±ã‚µã‚¤ã‚ºã¯ 2^k ç³»åˆ—ã§ç”Ÿæˆï¼ˆã‚µã‚¤ã‚ºã‚’åˆ¶é™ã—ã¦é«˜é€ŸåŒ–ï¼‰
        if fast_mode:
            # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰: ç®±ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›ï¼ˆæœ€å¤§6æ®µéšï¼‰
            max_power = min(int(np.log2(min(S))), 6)
        else:
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: æœ€å¤§10æ®µéš
            max_power = min(int(np.log2(min(S))), 10)
        sizes = np.array([2 ** i for i in range(1, max_power)])
        sizes = sizes[sizes <= min(S)]
        if len(sizes) < 3:
            sizes = np.array([2,4,8,16])
    counts = []
    # NumPyé…åˆ—æ“ä½œã§é«˜é€ŸåŒ–
    bw_binary = (bw > 0).astype(np.uint8)  # äº‹å‰ã«äºŒå€¤åŒ–
    for size in sizes:
        # ç”»åƒã‚’ size x size ã®ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²ã—ã¦ã€ç™½ãŒå«ã¾ã‚Œã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ•°ãˆã‚‹
        ny = int(np.ceil(S[0] / size))
        nx = int(np.ceil(S[1] / size))
        count = 0
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸå‡¦ç†ã§é«˜é€ŸåŒ–
        for i in range(ny):
            y0 = i * size
            y1 = min(y0 + size, S[0])
            for j in range(nx):
                x0 = j * size
                x1 = min(x0 + size, S[1])
                if np.any(bw_binary[y0:y1, x0:x1]):
                    count += 1
        counts.append(count)
    sizes = np.array(sizes, dtype=float)
    counts = np.array(counts, dtype=float)
    # fractal dimension D is slope of log(count) vs log(1/size)
    # linear regression via least squares
    with np.errstate(divide='ignore', invalid='ignore'):
        logs = np.log(counts)
        loginv = np.log(1.0 / sizes)
    # å˜ç´”ãªç·šå½¢å›å¸°
    A = np.vstack([loginv, np.ones_like(loginv)]).T
    try:
        m, c = np.linalg.lstsq(A, logs, rcond=None)[0]
    except Exception:
        m = 0.0
    return float(m), sizes, counts


def compute_spatial_occupancy(bw: np.ndarray):
    # ç™½ï¼ˆ255ï¼‰ãŒå ã‚ã‚‹å‰²åˆ
    total = bw.size
    white = np.count_nonzero(bw > 0)
    return float(white / total)


def extract_features_from_image(img_bgr: np.ndarray, bw: np.ndarray, fractal_dim: float):
    # ã‚·ãƒ³ãƒ—ãƒ«ãªç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    mean_int = float(np.mean(gray))
    std_int = float(np.std(gray))
    edge = canny(gray / 255.0)
    edge_density = float(np.count_nonzero(edge) / edge.size)
    occupancy = compute_spatial_occupancy(bw)
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè‡ªèº«ã‚‚ç‰¹å¾´ã¨ã—ã¦å«ã‚ã‚‹
    return np.array([mean_int, std_int, edge_density, occupancy, fractal_dim], dtype=float)

# --- è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ç”¨ã®é–¢æ•° ---------------------------------------------

def generate_low_resolution_versions(img_bgr: np.ndarray, scale_factors=[0.5, 0.25, 0.1]):
    """
    é«˜è§£åƒåº¦ç”»åƒã‹ã‚‰è¤‡æ•°ã®ä½è§£åƒåº¦ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç”Ÿæˆ
    """
    low_res_images = []
    for scale in scale_factors:
        h, w = img_bgr.shape[:2]
        new_h, new_w = int(h * scale), int(w * scale)
        if new_h > 10 and new_w > 10:  # æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            low_res = cv2.resize(img_bgr, (new_w, new_h), interpolation=cv2.INTER_AREA)
            # å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™ï¼ˆä½è§£åƒåº¦ã®ã¾ã¾æ‹¡å¤§ï¼‰
            upscaled = cv2.resize(low_res, (w, h), interpolation=cv2.INTER_LINEAR)
            low_res_images.append((scale, upscaled))
    return low_res_images


def extract_resolution_features(img_bgr: np.ndarray, bw: np.ndarray, fractal_dim: float):
    """
    è§£åƒåº¦è£œæ­£ç”¨ã®æ‹¡å¼µç‰¹å¾´é‡ã‚’æŠ½å‡º
    ä½è§£åƒåº¦ç”»åƒã®ç‰¹æ€§ã‚’æ‰ãˆã‚‹ç‰¹å¾´é‡
    """
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape
    
    # åŸºæœ¬çµ±è¨ˆé‡
    mean_int = float(np.mean(gray))
    std_int = float(np.std(gray))
    
    # ã‚¨ãƒƒã‚¸ç‰¹å¾´
    edge = canny(gray / 255.0)
    edge_density = float(np.count_nonzero(edge) / edge.size)
    
    # å æœ‰ç‡
    occupancy = compute_spatial_occupancy(bw)
    
    # ãƒ†ã‚¯ã‚¹ãƒãƒ£ç‰¹å¾´ï¼ˆåˆ†æ•£ã®å±€æ‰€çš„ãªå¤‰å‹•ï¼‰
    kernel_size = max(3, min(h, w) // 20)
    if kernel_size % 2 == 0:
        kernel_size += 1
    local_std = cv2.blur(gray.astype(float)**2, (kernel_size, kernel_size)) - \
                cv2.blur(gray.astype(float), (kernel_size, kernel_size))**2
    texture_variance = float(np.mean(np.sqrt(np.abs(local_std))))
    
    # ç”»åƒã‚µã‚¤ã‚ºæƒ…å ±ï¼ˆæ­£è¦åŒ–ï¼‰
    img_size = float(np.log(h * w + 1))
    aspect_ratio = float(w / h)
    
    # å‘¨æ³¢æ•°æˆåˆ†ï¼ˆFFTï¼‰
    fft = np.fft.fft2(gray)
    fft_shift = np.fft.fftshift(fft)
    magnitude_spectrum = np.abs(fft_shift)
    high_freq_energy = float(np.mean(magnitude_spectrum[h//4:3*h//4, w//4:3*w//4]))
    
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒï¼ˆä½è§£åƒåº¦ã§è¨ˆç®—ã•ã‚ŒãŸã‚‚ã®ï¼‰
    
    return np.array([
        mean_int, std_int, edge_density, occupancy, fractal_dim,
        texture_variance, img_size, aspect_ratio, high_freq_energy
    ], dtype=float)


def train_resolution_correction_model(training_data_path=RESOLUTION_TRAIN_DATA):
    """
    è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
    """
    if not os.path.exists(training_data_path):
        return None, None, "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    
    df = pd.read_csv(training_data_path)
    
    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’åˆ†é›¢
    feature_cols = [col for col in df.columns if col.startswith('feat_')]
    X = df[feature_cols].values
    y = df['target_high_res_fractal'].values
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆGradient Boostingã‚’ä½¿ç”¨ï¼‰
    model = GradientBoostingRegressor(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=5,
        random_state=42
    )
    model.fit(X_train_scaled, y_train)
    
    # è©•ä¾¡
    y_pred = model.predict(X_test_scaled)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    # ä¿å­˜
    joblib.dump(model, RESOLUTION_MODEL_PATH)
    joblib.dump(scaler, RESOLUTION_SCALER_PATH)
    
    return model, scaler, f"MAE: {mae:.4f}, RÂ²: {r2:.4f}"


def predict_high_res_fractal(low_res_features, model=None, scaler=None):
    """
    ä½è§£åƒåº¦ç”»åƒã®ç‰¹å¾´é‡ã‹ã‚‰é«˜è§£åƒåº¦ç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’äºˆæ¸¬
    """
    if model is None or scaler is None:
        if os.path.exists(RESOLUTION_MODEL_PATH) and os.path.exists(RESOLUTION_SCALER_PATH):
            model = joblib.load(RESOLUTION_MODEL_PATH)
            scaler = joblib.load(RESOLUTION_SCALER_PATH)
        else:
            return None
    
    X = low_res_features.reshape(1, -1)
    X_scaled = scaler.transform(X)
    predicted_fractal = model.predict(X_scaled)[0]
    
    return float(predicted_fractal)


# --- æ°¸ç¶šåŒ–ãƒ•ã‚¡ã‚¤ãƒ« & ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– ----------------------------------------
MODEL_PATH = 'model_joblib.pkl'
SCALER_PATH = 'scaler_joblib.pkl'
CLASS_PATH = 'classifier_joblib.pkl'
EXCEL_PATH = 'results.xlsx'
TRAIN_CSV = 'train_data.csv'

@st.cache_resource(show_spinner=False)
def load_models():
    """
    ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹
    @st.cache_resource ã«ã‚ˆã‚Šã€ã‚¢ãƒ—ãƒªèµ·å‹•ä¸­ã¯ä¸€åº¦ã ã‘ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹
    """
    models = {}
    if os.path.exists(MODEL_PATH) and os.path.exists(SCALER_PATH):
        try:
            models['reg'] = joblib.load(MODEL_PATH)
            models['scaler'] = joblib.load(SCALER_PATH)
        except Exception:
            models = {}
    if os.path.exists(CLASS_PATH):
        try:
            models['clf'] = joblib.load(CLASS_PATH)
        except Exception:
            pass
    return models

@st.cache_resource(show_spinner=False)
def load_resolution_model():
    """
    è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹
    @st.cache_resource ã«ã‚ˆã‚Šã€ã‚¢ãƒ—ãƒªèµ·å‹•ä¸­ã¯ä¸€åº¦ã ã‘ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹
    """
    if os.path.exists(RESOLUTION_MODEL_PATH) and os.path.exists(RESOLUTION_SCALER_PATH):
        try:
            model = joblib.load(RESOLUTION_MODEL_PATH)
            scaler = joblib.load(RESOLUTION_SCALER_PATH)
            return model, scaler
        except Exception:
            return None, None
    return None, None


def save_models(reg, scaler, clf=None):
    joblib.dump(reg, MODEL_PATH)
    joblib.dump(scaler, SCALER_PATH)
    if clf is not None:
        joblib.dump(clf, CLASS_PATH)

# --- ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šæ‰±ã„ --------------------------------------

def append_to_train_csv(features, y_reg, is_valid):
    # features: 1d array, y_reg: dict {'fractal':..., 'occupancy':...}
    cols = ['mean_int', 'std_int', 'edge_density', 'occupancy', 'fractal_dim_feature',
            'target_fractal', 'target_occupancy', 'is_valid']
    row = list(features) + [y_reg['fractal'], y_reg['occupancy'], int(is_valid)]
    df = pd.DataFrame([row], columns=cols)
    if os.path.exists(TRAIN_CSV):
        df.to_csv(TRAIN_CSV, mode='a', header=False, index=False)
    else:
        df.to_csv(TRAIN_CSV, index=False)


@st.cache_data(show_spinner=False)
def load_train_data():
    """
    å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹
    é »ç¹ã«æ›´æ–°ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€TTLï¼ˆæœ‰åŠ¹æœŸé™ï¼‰ã‚’çŸ­ã‚ã«è¨­å®š
    """
    if os.path.exists(TRAIN_CSV):
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯é »ç¹ã«æ›´æ–°ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯æ§ãˆã‚ã«ã€‚
        try:
            return pd.read_csv(TRAIN_CSV)
        except Exception:
            return None
    else:
        return None

# --- Streamlit UI -------------------------------------------------------

# ãƒšãƒ¼ã‚¸è¨­å®šã¯æœ€åˆã«å‘¼ã³å‡ºã™å¿…è¦ãŒã‚ã‚‹
try:
    st.set_page_config(layout='wide', page_title='ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ç”»åƒè§£æã‚¢ãƒ—ãƒª')
except Exception as e:
    # æ—¢ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ç„¡è¦–
    pass

st.title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã‚’ç”¨ã„ãŸç”»åƒè§£æã‚¢ãƒ—ãƒª')

# ã‚¢ãƒ—ãƒªèµ·å‹•ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ã€æœ¬ç•ªã§ã¯å‰Šé™¤å¯èƒ½ï¼‰
# st.sidebar.success('âœ… ã‚¢ãƒ—ãƒªã¯æ­£å¸¸ã«èµ·å‹•ã—ã¾ã—ãŸ')

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ¦‚è¦ã¨è§£åƒåº¦è£œæ­£AIã®ç´¹ä»‹
with st.expander('â„¹ï¸ ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦ / è§£åƒåº¦è£œæ­£AIæ©Ÿèƒ½', expanded=False):
    col_info1, col_info2 = st.columns(2)
    
    with col_info1:
        st.markdown("""
        ###  åŸºæœ¬æ©Ÿèƒ½
        - **Box-Countingæ³•**ã«ã‚ˆã‚‹ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ
        - **äºŒå€¤åŒ–å‡¦ç†**ã¨ç©ºé–“å æœ‰ç‡ã®è¨ˆç®—
        - **è¤‡æ•°ç”»åƒã®ä¸€æ‹¬è§£æ**ã¨Excelå‡ºåŠ›
        - **æ©Ÿæ¢°å­¦ç¿’**ã«ã‚ˆã‚‹äºˆæ¸¬æ©Ÿèƒ½
        - **ç•°å¸¸å€¤ã®è‡ªå‹•æ¤œçŸ¥**
        """)
    
    with col_info2:
        st.markdown("""
        ### è§£åƒåº¦è£œæ­£AI
        ä½è§£åƒåº¦ç”»åƒã§ã‚‚é«˜è§£åƒåº¦ç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®šï¼
        
        **ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ:**
        1. é«˜è§£åƒåº¦ç”»åƒã‚’ç”¨æ„
        2. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã€ON â†’ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        3. 20ï½100æšç¹°ã‚Šè¿”ã™
        4. ã€Œè§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        5. ã€Œè§£åƒåº¦è£œæ­£ã‚’æœ‰åŠ¹åŒ–ã€ON
        6. ä½è§£åƒåº¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        7. è£œæ­£çµæœã‚’ç¢ºèªï¼
        
        ğŸ“– è©³ç´°ã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œè§£åƒåº¦è£œæ­£AIã®ä½¿ã„æ–¹ã€ã‚’å‚ç…§
        """)

st.sidebar.header('è¨­å®š')
# é–¾å€¤å…¥åŠ›: æ•°å€¤å…¥åŠ›ã¨ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’ä¸¡æ–¹ç”¨æ„
thresh_mode = st.sidebar.selectbox('é–¾å€¤å…¥åŠ›æ–¹å¼', ['ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼', 'æ•°å€¤å…¥åŠ›'])
if thresh_mode == 'ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼':
    thresh_value = st.sidebar.slider('äºŒå€¤åŒ–é–¾å€¤ (0-255)', min_value=0.0, max_value=255.0, value=128.0)
else:
    thresh_value = st.sidebar.number_input('äºŒå€¤åŒ–é–¾å€¤ (0-255)', min_value=0.0, max_value=255.0, value=128.0, step=0.1)

# ãƒªã‚µã‚¤ã‚ºä¸Šé™: æ•°å€¤ã¨ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
resize_mode = st.sidebar.selectbox('ãƒªã‚µã‚¤ã‚ºæ–¹å¼', ['ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼', 'æ•°å€¤å…¥åŠ›'])
if resize_mode == 'ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼':
    max_side = st.sidebar.slider('ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º (px, 0ã§ãƒªã‚µã‚¤ã‚ºç„¡åŠ¹)', min_value=0.0, max_value=4000.0, value=1024.0)
else:
    max_side = st.sidebar.number_input('ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º (px, 0ã§ãƒªã‚µã‚¤ã‚ºç„¡åŠ¹)', min_value=0.0, max_value=10000.0, value=1024.0)

st.sidebar.markdown('---')
# å­¦ç¿’ãƒœã‚¿ãƒ³
do_train_now = st.sidebar.button('å­¦ç¿’ã‚’å®Ÿè¡Œï¼ˆä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ï¼‰')

# è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³
st.sidebar.markdown('---')
st.sidebar.subheader('ğŸ”¬ è§£åƒåº¦è£œæ­£AI')
enable_resolution_correction = st.sidebar.checkbox('è§£åƒåº¦è£œæ­£ã‚’æœ‰åŠ¹åŒ–', value=False, 
    help='ä½è§£åƒåº¦ç”»åƒã‹ã‚‰é«˜è§£åƒåº¦ç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®šã—ã¾ã™')

st.sidebar.markdown('---')
st.sidebar.subheader('âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š')

# å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã®é¸æŠï¼ˆæ–°æ©Ÿèƒ½ï¼‰
processing_mode = st.sidebar.radio(
    'å‡¦ç†ãƒ¢ãƒ¼ãƒ‰',
    ['ğŸš€ é«˜é€Ÿãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼', 'ğŸ¯ é«˜ç²¾åº¦è§£æ'],
    help='é«˜é€Ÿãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: è¨ˆç®—é‡ã‚’å‰Šæ¸›ã—ã¦ç´ æ—©ãçµæœè¡¨ç¤º\né«˜ç²¾åº¦è§£æ: å…¨ã¦ã®è¨ˆç®—ã‚’å®Ÿè¡Œã—ã¦æ­£ç¢ºãªçµæœã‚’å‡ºåŠ›'
)

# é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã®åˆ¤å®šãƒ•ãƒ©ã‚°
fast_mode = (processing_mode == 'ğŸš€ é«˜é€Ÿãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼')

# è‡ªå‹•å†è¨ˆç®—ã®è¨­å®š
auto_recompute = st.sidebar.checkbox('è‡ªå‹•å†è¨ˆç®—ã‚’æœ‰åŠ¹åŒ–', value=True, help='OFFã«ã™ã‚‹ã¨ã€Œè§£æã‚’æ›´æ–°ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸæ™‚ã ã‘é‡ã„å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™')

# é«˜é€Ÿãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã®è©³ç´°èª¬æ˜
if fast_mode:
    st.sidebar.info('âš¡ é«˜é€Ÿãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¢ãƒ¼ãƒ‰:\n- ç®±ã‚µã‚¤ã‚ºå‰Šæ¸›ï¼ˆ6æ®µéšï¼‰\n- ä½DPIã‚°ãƒ©ãƒ•æç”»\n- è¨ˆç®—æ™‚é–“ 50-70%çŸ­ç¸®')
else:
    st.sidebar.success('ğŸ¯ é«˜ç²¾åº¦è§£æãƒ¢ãƒ¼ãƒ‰:\n- ç®±ã‚µã‚¤ã‚ºæœ€å¤§ï¼ˆ10æ®µéšï¼‰\n- é«˜å“è³ªã‚°ãƒ©ãƒ•æç”»\n- æœ€é«˜ç²¾åº¦ã§è§£æ')

run_analyze = st.sidebar.button('è§£æã‚’æ›´æ–°', type='primary', help='è‡ªå‹•å†è¨ˆç®—ãŒOFFã®ã¨ãã«æŠ¼ã—ã¦å®Ÿè¡Œ')

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
if st.sidebar.button('ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢'):
    st.cache_data.clear()
    st.cache_resource.clear()
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚‚ã‚¯ãƒªã‚¢
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    st.sidebar.success('ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ')
    st.rerun()

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰
if st.sidebar.checkbox('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰', value=False, 
    help='é«˜è§£åƒåº¦ç”»åƒã‹ã‚‰ä½è§£åƒåº¦ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è‡ªå‹•ç”Ÿæˆã—ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™'):
    st.sidebar.info('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã‹ã‚‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™')
    generate_training_data = True
else:
    generate_training_data = False

# è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒœã‚¿ãƒ³
if st.sidebar.button('è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’'):
    with st.spinner('è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...'):
        model_res, scaler_res, result_msg = train_resolution_correction_model()
        if model_res is not None:
            st.sidebar.success(f'å­¦ç¿’å®Œäº†: {result_msg}')
        else:
            st.sidebar.error(result_msg)

# è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹è¡¨ç¤º
if os.path.exists(RESOLUTION_MODEL_PATH):
    st.sidebar.success('âœ“ è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«: èª­ã¿è¾¼ã¿æ¸ˆã¿')
    if os.path.exists(RESOLUTION_TRAIN_DATA):
        df_res = pd.read_csv(RESOLUTION_TRAIN_DATA)
        st.sidebar.write(f'å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_res)}ä»¶')
else:
    st.sidebar.warning('è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«: æœªå­¦ç¿’')

# ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰ã®è¡¨ç¤º
with st.sidebar.expander('ğŸ“– è§£åƒåº¦è£œæ­£AIã®ä½¿ã„æ–¹', expanded=False):
    st.markdown("""
    ### ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰
    
    **1ï¸âƒ£ é«˜è§£åƒåº¦ç”»åƒã‚’ç”¨æ„**
    - ãªã‚‹ã¹ãé«˜å“è³ªãªç”»åƒã‚’æº–å‚™
    
    **2ï¸âƒ£ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ**
    - â˜‘ã€Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã€ON
    - ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    - è‡ªå‹•ã§5æ®µéšã®è§£åƒåº¦ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    
    **3ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿åé›†**
    - è¤‡æ•°ã®ç”»åƒã§ç¹°ã‚Šè¿”ã—
    - æ¨å¥¨: 20ï½100æš
    
    **4ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’**
    - ã€Œè§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    - å­¦ç¿’å®Œäº†ã‚’å¾…ã¤
    
    **5ï¸âƒ£ è£œæ­£ã®æœ‰åŠ¹åŒ–**
    - â˜‘ã€Œè§£åƒåº¦è£œæ­£ã‚’æœ‰åŠ¹åŒ–ã€ON
    
    **6ï¸âƒ£ ä½è§£åƒåº¦ç”»åƒã§æ¤œè¨¼**
    - ä½è§£åƒåº¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    
    **7ï¸âƒ£ çµæœç¢ºèª**
    - é«˜è§£åƒåº¦ç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãŒè¡¨ç¤ºã•ã‚Œã‚‹ï¼
    
    ---
    ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: æ§˜ã€…ãªã‚¿ã‚¤ãƒ—ã®ç”»åƒã§å­¦ç¿’ã™ã‚‹ã¨ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™
    """)

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰
try:
    models = load_models()
except Exception as e:
    st.error(f'ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}')
    models = {}

try:
    res_model, res_scaler = load_resolution_model()
except Exception as e:
    st.warning(f'è§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}')
    res_model, res_scaler = None, None

# ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ: è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãƒ•ã‚©ãƒ«ãƒ€å†…ä¸€æ‹¬è§£æã«å¯¾å¿œ
try:
    uploaded_files = st.file_uploader('ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰', type=['png','jpg','jpeg','bmp','tif','tiff'], accept_multiple_files=True)
except Exception as e:
    st.error(f'ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}')
    uploaded_files = []

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã‚¬ã‚¤ãƒ‰è¡¨ç¤º
if generate_training_data:
    st.info('ğŸ”„ **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰** - é«˜è§£åƒåº¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€è‡ªå‹•çš„ã«5æ®µéšã®è§£åƒåº¦ã§å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™')
    st.markdown("""
    **ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—**: 2ï¸âƒ£ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­
    - âœ… é«˜è§£åƒåº¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    - â³ è¤‡æ•°æšï¼ˆ20ï½100æšæ¨å¥¨ï¼‰ç¹°ã‚Šè¿”ã™
    - â­ï¸ å®Œäº†å¾Œã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€Œè§£åƒåº¦è£œæ­£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
    """)

# è§£åƒåº¦è£œæ­£æœ‰åŠ¹æ™‚ã®ã‚¬ã‚¤ãƒ‰è¡¨ç¤º
if enable_resolution_correction and os.path.exists(RESOLUTION_MODEL_PATH):
    st.success('âœ… **è§£åƒåº¦è£œæ­£AIæœ‰åŠ¹** - ä½è§£åƒåº¦ç”»åƒã§ã‚‚é«˜è§£åƒåº¦ç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®šã—ã¾ã™')

# è§£æ/å­¦ç¿’ç”¨ã®è¡¨ç¤ºé ˜åŸŸ
col1, col2 = st.columns([2,1])

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
if 'last_params' not in st.session_state:
    st.session_state['last_params'] = None
if 'cached_results' not in st.session_state:
    st.session_state['cached_results'] = None

# ç¾åœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆï¼ˆå¤‰æ›´æ¤œçŸ¥ç”¨ï¼‰
if uploaded_files:
    current_params = {
        'files': [f.name for f in uploaded_files],
        'thresh': thresh_value,
        'max_side': max_side,
        'fast_mode': fast_mode,
        'enable_resolution': enable_resolution_correction,
        'generate_training': generate_training_data
    }
    params_changed = (st.session_state['last_params'] != current_params)
else:
    params_changed = True
    current_params = None

with col1:
    st.header('è§£æçµæœ')
    if uploaded_files is not None and len(uploaded_files) > 0 and (auto_recompute or run_analyze):
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´æ™‚ã®ã¿å†è¨ˆç®—ã€ãã‚Œä»¥å¤–ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨
        if params_changed or st.session_state['cached_results'] is None:
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šé–‹å§‹
            import time
            start_time = time.time()
            
            results_list = []
            predictions = []
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤ºï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚ï¼‰
            if len(uploaded_files) > 1:
                progress_bar = st.progress(0)
                status_text = st.empty()
            
            for idx, file in enumerate(uploaded_files):
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°
                if len(uploaded_files) > 1:
                    progress = (idx + 1) / len(uploaded_files)
                    progress_bar.progress(progress)
                    status_text.text(f'å‡¦ç†ä¸­: {file.name} ({idx + 1}/{len(uploaded_files)})')
                
                st.write('ãƒ•ã‚¡ã‚¤ãƒ«:', file.name)
                
                # ç”»åƒèª­ã¿è¾¼ã¿ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–æ¸ˆã¿ï¼‰
                file_bytes = file.read()
                img_bgr = load_image_bytes(file_bytes, file.name)
            
                # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
                if generate_training_data:
                    st.info('ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰: è¤‡æ•°è§£åƒåº¦ã§è§£æä¸­...')
                    # å…ƒç”»åƒï¼ˆé«˜è§£åƒåº¦ï¼‰ã®è§£æ
                    img_high, _ = resize_image(img_bgr.copy(), max_side)
                    gray_high = cv2.cvtColor(img_high, cv2.COLOR_BGR2GRAY)
                    bw_high = binarize_image_gray(gray_high, thresh_value)
                    fractal_high, _, _ = boxcount_fractal_dim(bw_high, fast_mode=False)  # é«˜ç²¾åº¦ã§è¨ˆç®—
                    
                    # ä½è§£åƒåº¦ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã¦è§£æ
                    low_res_versions = generate_low_resolution_versions(img_high, [0.5, 0.3, 0.2, 0.15, 0.1])
                    
                    training_records = []
                    for scale, img_low in low_res_versions:
                        gray_low = cv2.cvtColor(img_low, cv2.COLOR_BGR2GRAY)
                        bw_low = binarize_image_gray(gray_low, thresh_value)
                        fractal_low, _, _ = boxcount_fractal_dim(bw_low, fast_mode=fast_mode)
                        
                        # æ‹¡å¼µç‰¹å¾´é‡ã‚’æŠ½å‡º
                        features_low = extract_resolution_features(img_low, bw_low, fractal_low)
                        
                        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜
                        record = {'scale': scale, 'target_high_res_fractal': fractal_high}
                        for idx_feat, feat_val in enumerate(features_low):
                            record[f'feat_{idx_feat}'] = feat_val
                        training_records.append(record)
                    
                    # CSVã«è¿½è¨˜
                    df_new = pd.DataFrame(training_records)
                    if os.path.exists(RESOLUTION_TRAIN_DATA):
                        df_new.to_csv(RESOLUTION_TRAIN_DATA, mode='a', header=False, index=False)
                    else:
                        df_new.to_csv(RESOLUTION_TRAIN_DATA, index=False)
                    
                    st.success(f'âœ“ {len(training_records)}ä»¶ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆè§£åƒåº¦: {[f"{s*100:.0f}%" for s, _ in low_res_versions]}ï¼‰')
                    continue  # æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¸
                
                # ãƒ¡ã‚¤ãƒ³è§£æå‡¦ç†ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ï¼‰
                img_bgr_resized, scale = resize_image(img_bgr.copy(), max_side)
                gray = cv2.cvtColor(img_bgr_resized, cv2.COLOR_BGR2GRAY)
                # äºŒå€¤åŒ– (å›ºå®šé–¾å€¤ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–æ¸ˆã¿)
                bw = binarize_image_gray(gray, thresh_value)

                # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–æ¸ˆã¿ã€fast_modeãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ ï¼‰
                fractal_d, sizes, counts = boxcount_fractal_dim(bw, fast_mode=fast_mode)
                occupancy = compute_spatial_occupancy(bw)
            
                # è§£åƒåº¦è£œæ­£ã®é©ç”¨
                corrected_fractal_d = None
                if enable_resolution_correction and (res_model is not None and res_scaler is not None):
                    try:
                        features_res = extract_resolution_features(img_bgr_resized, bw, fractal_d)
                        # æ—¢ã«ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«/ã‚¹ã‚±ãƒ¼ãƒ©ã‚’ä½¿ã†
                        X = features_res.reshape(1, -1)
                        Xs = res_scaler.transform(X)
                        corrected_fractal_d = float(res_model.predict(Xs)[0])
                        if corrected_fractal_d is not None:
                            st.info(f'ğŸ¤– AIè£œæ­£: {fractal_d:.4f} â†’ {corrected_fractal_d:.4f} (å·®: {abs(corrected_fractal_d - fractal_d):.4f})')
                    except Exception as e:
                        st.warning(f'è§£åƒåº¦è£œæ­£ã‚¨ãƒ©ãƒ¼: {e}')

                # ç•°å¸¸æ¤œçŸ¥: æ¥µç«¯ãªå æœ‰ç‡ã‚„äºŒå€¤åŒ–ãŒã»ã¼å…¨ç™½/å…¨é»’ãªã‚‰å¤±æ•—æ‰±ã„
                white_ratio = occupancy
                fail_flag = False
                fail_reasons = []
                if white_ratio < 0.01:
                    fail_flag = True
                    fail_reasons.append('ã»ã¨ã‚“ã©ç™½ãŒç„¡ã„(å æœ‰ç‡ <1%)')
                if white_ratio > 0.99:
                    fail_flag = True
                    fail_reasons.append('ã»ã¨ã‚“ã©ç™½ã§åŸ‹ã¾ã£ã¦ã„ã‚‹(å æœ‰ç‡ >99%)')
                # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®ç¾å®Ÿçš„ãƒ¬ãƒ³ã‚¸ãƒã‚§ãƒƒã‚¯
                if not ( -5.0 < fractal_d < 5.0 ):  # æ§˜ã€…ãªç”»åƒã§ã®ç›®å®‰
                    fail_flag = True
                    fail_reasons.append(f'ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãŒç•°å¸¸å€¤:{fractal_d:.3f}')

                # ç‰¹å¾´é‡æŠ½å‡º
                feat = extract_features_from_image(img_bgr_resized, bw, fractal_d)

                # äºˆæ¸¬ãŒå¯èƒ½ãªã‚‰å‡ºåŠ›
                pred = None
                if 'reg' in models and 'scaler' in models:
                    try:
                        Xs = models['scaler'].transform(feat.reshape(1,-1))
                        ypred = models['reg'].predict(Xs)[0]
                        # reg ã¯ 2å‡ºåŠ›ã‚’æƒ³å®šã—ã¦ã„ã‚‹ (fractal, occupancy)
                        if isinstance(ypred, (list,tuple,np.ndarray)) and len(ypred) >= 2:
                            pred = {'fractal': float(ypred[0]), 'occupancy': float(ypred[1])}
                        else:
                            # å˜ä¸€å‡ºåŠ›ã®å ´åˆã¯ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã®ã¿
                            pred = {'fractal': float(ypred), 'occupancy': None}
                    except Exception as e:
                        st.write('äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', e)

                # çµæœè¡¨ç¤º
                st.write(f'- ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒï¼ˆå®Ÿæ¸¬ï¼‰: {fractal_d:.4f}')
                if corrected_fractal_d is not None:
                    st.write(f'- ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒï¼ˆAIè£œæ­£å¾Œï¼‰: {corrected_fractal_d:.4f}')
                    st.write(f'- è£œæ­£é‡: {(corrected_fractal_d - fractal_d):+.4f}')
                st.write(f'- ç©ºé–“å æœ‰ç‡: {occupancy*100:.2f}%')
                if fail_flag:
                    st.warning('è‡ªå‹•æ¤œçŸ¥: å¤±æ•—ã¨åˆ¤å®šã•ã‚Œã¾ã—ãŸã€‚ç†ç”±: ' + ';'.join(fail_reasons))
                else:
                    st.success('è‡ªå‹•æ¤œçŸ¥: æ­£å¸¸ã¨åˆ¤å®š')

                # å…ƒç”»åƒã¨äºŒå€¤åŒ–ç”»åƒã®è¡¨ç¤º
                st.subheader('ç”»åƒè¡¨ç¤º')
                img_col1, img_col2 = st.columns(2)
                with img_col1:
                    st.write('**å…ƒç”»åƒ**')
                    # BGRã‹ã‚‰RGBã«å¤‰æ›ã—ã¦è¡¨ç¤º
                    img_rgb = cv2.cvtColor(img_bgr_resized, cv2.COLOR_BGR2RGB)
                    st.image(img_rgb, use_container_width=True)
                with img_col2:
                    st.write('**äºŒå€¤åŒ–ç”»åƒ**')
                    st.image(bw, use_container_width=True)

                # ã‚°ãƒ©ãƒ•: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æŠ˜ã‚Œç·šï¼ˆsizes vs counts ã‹ã‚‰å¯è¦–åŒ–ï¼‰
                st.subheader('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ')
                
                # DPIã‚’å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦èª¿æ•´ï¼ˆé«˜é€Ÿãƒ¢ãƒ¼ãƒ‰: ä½DPIã€é«˜ç²¾åº¦ãƒ¢ãƒ¼ãƒ‰: é«˜DPIï¼‰
                graph_dpi = 60 if fast_mode else 100
                
                fig1, ax1 = plt.subplots(figsize=(8, 5), dpi=graph_dpi)
                
                # å®Ÿæ¸¬å€¤ã®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆé’è‰²ï¼‰
                ax1.plot(np.log(1.0/sizes), np.log(counts), marker='o', linewidth=2, markersize=8, 
                        color='blue', label=f'å®Ÿæ¸¬å€¤ (å‚¾ã={fractal_d:.3f})')
                
                # è§£åƒåº¦è£œæ­£AIäºˆæ¸¬å€¤ãŒã‚ã‚‹å ´åˆã¯ç·‘è‰²ã§è¿½åŠ ãƒ—ãƒ­ãƒƒãƒˆ
                if corrected_fractal_d is not None:
                    x_vals = np.log(1.0/sizes)
                    intercept = np.mean(np.log(counts) - corrected_fractal_d * x_vals)
                    y_corrected = corrected_fractal_d * x_vals + intercept
                    ax1.plot(x_vals, y_corrected, marker='^', linewidth=2, markersize=6, 
                            color='green', linestyle='-.', label=f'è§£åƒåº¦è£œæ­£AI (å‚¾ã={corrected_fractal_d:.3f})', alpha=0.8)
                
                # å¾“æ¥ã®AIäºˆæ¸¬å€¤ãŒã‚ã‚‹å ´åˆã¯èµ¤è‰²ã§è¿½åŠ ãƒ—ãƒ­ãƒƒãƒˆ
                if pred is not None and 'fractal' in pred:
                    pred_fractal = pred['fractal']
                    x_vals = np.log(1.0/sizes)
                    intercept = np.mean(np.log(counts) - pred_fractal * x_vals)
                    y_pred = pred_fractal * x_vals + intercept
                    ax1.plot(x_vals, y_pred, marker='s', linewidth=2, markersize=6, 
                            color='red', linestyle='--', label=f'å¾“æ¥AIäºˆæ¸¬ (å‚¾ã={pred_fractal:.3f})', alpha=0.7)
                
                ax1.set_xlabel('log(1/ç®±ã‚µã‚¤ã‚º)', fontsize=11)
                ax1.set_ylabel('log(ç™½ãƒ”ã‚¯ã‚»ãƒ«ã‚’å«ã‚€ç®±ã®æ•°)', fontsize=11)
                
                # ã‚¿ã‚¤ãƒˆãƒ«ã‚’äºˆæ¸¬ã®æœ‰ç„¡ã§å¤‰æ›´
                title_parts = [f'å®Ÿæ¸¬: {fractal_d:.3f}']
                if corrected_fractal_d is not None:
                    title_parts.append(f'AIè£œæ­£: {corrected_fractal_d:.3f}')
                if pred is not None and 'fractal' in pred:
                    title_parts.append(f'å¾“æ¥AI: {pred["fractal"]:.3f}')
                
                ax1.set_title(f'Box-Countingæ³•ã«ã‚ˆã‚‹ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ\n{" / ".join(title_parts)}', 
                            fontsize=12, fontweight='bold')
                
                ax1.grid(True, alpha=0.3)
                ax1.legend(loc='best', fontsize=10)
                st.pyplot(fig1, use_container_width=True)
                plt.close(fig1)  # ãƒ¡ãƒ¢ãƒªè§£æ”¾

                # å††ã‚°ãƒ©ãƒ•: ç©ºé–“å æœ‰ç‡ï¼ˆç™½ãƒ”ã‚¯ã‚»ãƒ«ã¨é»’ãƒ”ã‚¯ã‚»ãƒ«ï¼‰
                st.subheader('ãƒ”ã‚¯ã‚»ãƒ«åˆ†å¸ƒ')
                fig2, ax2 = plt.subplots(dpi=graph_dpi)
                # ç™½ãƒ”ã‚¯ã‚»ãƒ«ï¼ˆoccupancyï¼‰ã‚’ç™½è‰²ã€é»’ãƒ”ã‚¯ã‚»ãƒ«ï¼ˆ1-occupancyï¼‰ã‚’é»’è‰²ã§è¡¨ç¤º
                colors = ['white', 'black']
                wedges, texts, autotexts = ax2.pie(
                    [occupancy, 1-occupancy], 
                    labels=['ç™½ãƒ”ã‚¯ã‚»ãƒ«', 'é»’ãƒ”ã‚¯ã‚»ãƒ«'], 
                    autopct='%1.1f%%',
                    colors=colors,
                    startangle=90,
                    textprops={'color': 'black', 'weight': 'bold'}
                )
                # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã®æ–‡å­—è‰²ã‚’èª¿æ•´ï¼ˆç™½ã„éƒ¨åˆ†ã¯é»’æ–‡å­—ã€é»’ã„éƒ¨åˆ†ã¯ç™½æ–‡å­—ï¼‰
                autotexts[0].set_color('black')  # ç™½ãƒ”ã‚¯ã‚»ãƒ«éƒ¨åˆ†ã¯é»’æ–‡å­—
                autotexts[1].set_color('white')  # é»’ãƒ”ã‚¯ã‚»ãƒ«éƒ¨åˆ†ã¯ç™½æ–‡å­—
                # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ ã—ã¦è¦‹ã‚„ã™ã
                for wedge in wedges:
                    wedge.set_edgecolor('gray')
                    wedge.set_linewidth(1.5)
                ax2.set_title('ãƒ”ã‚¯ã‚»ãƒ«åˆ†å¸ƒï¼ˆäºŒå€¤åŒ–ç”»åƒï¼‰')
                st.pyplot(fig2, use_container_width=True)
                plt.close(fig2)  # ãƒ¡ãƒ¢ãƒªè§£æ”¾

                # AIäºˆæ¸¬çµæœã®è©³ç´°è¡¨ç¤ºï¼ˆã‚ã‚Œã°ï¼‰
                if pred is not None:
                    st.subheader('AIå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬')
                    col_pred1, col_pred2 = st.columns(2)
                    with col_pred1:
                        st.metric(
                            label="ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ",
                            value=f"{fractal_d:.4f}",
                            delta=f"äºˆæ¸¬ã¨ã®å·®: {(fractal_d - pred['fractal']):.4f}"
                        )
                    with col_pred2:
                        if pred['occupancy'] is not None:
                            st.metric(
                                label="ç©ºé–“å æœ‰ç‡",
                                value=f"{occupancy*100:.2f}%",
                                delta=f"äºˆæ¸¬ã¨ã®å·®: {(occupancy - pred['occupancy'])*100:.2f}%"
                            )
                    
                    # å æœ‰ç‡ã®æ¯”è¼ƒã‚°ãƒ©ãƒ•ï¼ˆäºˆæ¸¬ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
                    if pred['occupancy'] is not None:
                        st.write('**å æœ‰ç‡ã®æ¯”è¼ƒ**')
                        fig4, ax4 = plt.subplots(dpi=graph_dpi)
                        ax4.plot([0,1],[occupancy, pred['occupancy']], marker='o', linewidth=2, markersize=8)
                        ax4.set_xticks([0,1]); ax4.set_xticklabels(['å®Ÿæ¸¬','äºˆæ¸¬'])
                        ax4.set_ylabel('å æœ‰ç‡')
                        st.pyplot(fig4, use_container_width=True)
                        plt.close(fig4)

                # çµæœãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ
                rec = {
                    'filename': file.name,
                    'fractal': fractal_d,
                    'occupancy': occupancy,
                    'pred_fractal': pred['fractal'] if pred is not None else None,
                    'pred_occupancy': pred['occupancy'] if (pred is not None and pred['occupancy'] is not None) else None,
                    'is_valid': int(not fail_flag)
                }
                results_list.append(rec)

                # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è‡ªå‹•è¿½åŠ ï¼ˆæ¤œçŸ¥ã—ãŸå¤±æ•—ã¯ is_valid=0 ã¨ã—ã¦æ·»åŠ ï¼‰
                append_to_train_csv(feat, {'fractal':fractal_d, 'occupancy':occupancy}, not fail_flag)
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
            if len(uploaded_files) > 1:
                progress_bar.empty()
                status_text.empty()
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šçµ‚äº†
            elapsed_time = time.time() - start_time
            st.success(f'âœ… è§£æå®Œäº†ï¼å‡¦ç†æ™‚é–“: {elapsed_time:.2f}ç§’ ({processing_mode})')
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
            st.session_state['last_params'] = current_params
            st.session_state['cached_results'] = results_list
            
        else:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçµæœã‚’ä½¿ç”¨
            results_list = st.session_state['cached_results']
            st.info('ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçµæœã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´ãªã—ï¼‰')
        
        # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«æ™‚ã€Excelã«ã¾ã¨ã‚ã¦æ›¸ãè¾¼ã¿ï¼ˆappendï¼‰
        if results_list and len(results_list) >= 2:
            df_results = pd.DataFrame(results_list)
            if os.path.exists(EXCEL_PATH):
                # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
                with pd.ExcelWriter(EXCEL_PATH, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:
                    # æ–°ã—ã„ã‚·ãƒ¼ãƒˆã¨ã—ã¦ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ä¿å­˜
                    sheet_name = pd.Timestamp.now().strftime('run_%Y%m%d_%H%M%S')
                    df_results.to_excel(writer, sheet_name=sheet_name, index=False)
                st.info(f'è§£æçµæœã‚’æ—¢å­˜Excel ({EXCEL_PATH}) ã«è¿½è¨˜ã—ã¾ã—ãŸã€‚')
            else:
                df_results.to_excel(EXCEL_PATH, sheet_name='run', index=False)
                st.info(f'è§£æçµæœã‚’æ–°è¦Excel ({EXCEL_PATH}) ã«ä¿å­˜ã—ã¾ã—ãŸã€‚')

        # å­¦ç¿’ä»¶æ•°ã®è¡¨ç¤ºï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ï¼‰
        train_df = load_train_data()
        if train_df is not None:
            st.sidebar.write(f'å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(train_df)}')
        else:
            st.sidebar.write('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚')
    elif uploaded_files:
        st.info('âš¡ è‡ªå‹•å†è¨ˆç®—ãŒOFFã§ã™ã€‚ã€Œè§£æã‚’æ›´æ–°ã€ã‚’æŠ¼ã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')

with col2:
    st.header('å­¦ç¿’ / ãƒ¢ãƒ‡ãƒ«')
    st.write('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»å†å­¦ç¿’ã‚’è¡Œãˆã¾ã™ã€‚')

    train_df = load_train_data()
    if train_df is None:
        st.info('ã¾ã å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚è§£æã‚’æ•°å›è¡Œã†ã¨è‡ªå‹•çš„ã«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒè“„ç©ã•ã‚Œã¾ã™ã€‚')
    else:
        st.write('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­5è¡Œ:')
        st.dataframe(train_df.head())

        # å­¦ç¿’å®Ÿè¡Œ
        if do_train_now:
            st.write('å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...')
            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ç”¨æ„
            X = train_df[['mean_int','std_int','edge_density','occupancy','fractal_dim_feature']].values
            y_fractal = train_df['target_fractal'].values
            y_occupancy = train_df['target_occupancy'].values
            y_valid = train_df['is_valid'].values

            scaler = StandardScaler()
            Xs = scaler.fit_transform(X)

            # å›å¸°: 2å‡ºåŠ›ã‚’åŒæ™‚ã«å­¦ç¿’ã™ã‚‹ãŸã‚ã€å˜ç´”ã«æ¨ªã«çµåˆ
            Y_reg = np.vstack([y_fractal, y_occupancy]).T
            reg = RandomForestRegressor(n_estimators=100, random_state=42)
            try:
                reg.fit(Xs, Y_reg)
                st.success('å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚')
            except Exception as e:
                st.error('å›å¸°å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ:' + str(e))
                reg = None

            # åˆ†é¡: æœ‰åŠ¹/ç„¡åŠ¹åˆ¤å®š
            clf = RandomForestClassifier(n_estimators=100, random_state=42)
            try:
                clf.fit(Xs, y_valid)
                st.success('åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚')
            except Exception as e:
                st.error('åˆ†é¡å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ:' + str(e))
                clf = None

            # ä¿å­˜
            if reg is not None:
                save_models(reg, scaler, clf)
                st.info('ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ (model_joblib.pkl, scaler_joblib.pkl)ã€‚')

            # ç°¡æ˜“è©•ä¾¡: ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç„¡ã—ã®å­¦å†…è©•ä¾¡
            if reg is not None:
                ypred = reg.predict(Xs)
                mae_fractal = mean_absolute_error(y_fractal, ypred[:,0])
                mae_occ = mean_absolute_error(y_occupancy, ypred[:,1])
                st.write(f'å­¦å†…è©•ä¾¡ MAE - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«: {mae_fractal:.4f}, å æœ‰ç‡: {mae_occ:.4f}')
            if clf is not None:
                ypredc = clf.predict(Xs)
                acc = accuracy_score(y_valid, ypredc)
                st.write(f'åˆ†é¡ãƒ¢ãƒ‡ãƒ« å­¦å†…ç²¾åº¦: {acc:.3f} (æ­£ç­”ç‡)')

    # æ‰‹å‹•ã§å†å­¦ç¿’ã—ãŸã„å ´åˆã®ãƒœã‚¿ãƒ³
    if st.button('ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿ç›´ã™ï¼ˆä¿å­˜æ¸ˆã¿ã‚’ãƒ­ãƒ¼ãƒ‰ï¼‰'):
        models2 = load_models()
        if 'reg' in models2:
            st.success('ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚')
        else:
            st.error('ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚')

st.sidebar.markdown('---')
st.sidebar.write('å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:')
st.sidebar.write(EXCEL_PATH)
st.sidebar.write(MODEL_PATH)
st.sidebar.write(TRAIN_CSV)

st.write('\n')
st.write('---')
st.write('æ³¨æ„: æœ¬ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã‚µãƒ³ãƒ—ãƒ«å®Ÿè£…ã§ã™ã€‚ç”»åƒã‚µã‚¤ã‚ºã€ç‰¹å¾´é‡ã€ç•°å¸¸åˆ¤å®šåŸºæº–ã€ãƒ¢ãƒ‡ãƒ«é¸å®šã¯ç”¨é€”ã«å¿œã˜ã¦èª¿æ•´ã—ã¦ãã ã•ã„ã€‚')