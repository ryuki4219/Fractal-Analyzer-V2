# fractal_fd_app_optimized.py
# ============================================================
# ä½ç”»è³ªç‰¹åŒ–å‹ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æï¼‹AIè£œæ­£ï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰
# - CuPy ãŒã‚ã‚‹å ´åˆã¯ GPU ã‚’è‡ªå‹•æ¤œå‡ºã—ã¦ä½¿ç”¨
# - ãƒ–ãƒ­ãƒƒã‚¯æ¼”ç®—ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ box-counting ã‚’é«˜é€ŸåŒ–
# - LightGBM ã‚’ä½¿ã£ãŸä½ç”»è³ª->é«˜ç”»è³ªFDäºˆæ¸¬ï¼ˆä¸¦åˆ—åŒ–ï¼‰
# ============================================================

import os
import cv2
import numpy as np
import glob
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, r2_score
from scipy.stats import pearsonr
import streamlit as st
from lightgbm import LGBMRegressor
import time
import pickle
import json
import re
import pandas as pd

# Plotlyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆç ”ç©¶å ±å‘Šç”¨ï¼‰
try:
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False
    print("Warning: plotly not found. Install with: pip install plotly")

# è‚Œå“è³ªè©•ä¾¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from skin_quality_evaluator import SkinQualityEvaluator
    SKIN_EVALUATOR_AVAILABLE = True
except ImportError:
    SKIN_EVALUATOR_AVAILABLE = False
    print("Warning: skin_quality_evaluator.py not found. Skin quality evaluation will be disabled.")

# ç”»åƒå“è³ªåˆ¤å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from image_quality_assessor import (
        assess_image_quality,
        check_device_compatibility,
        RECOMMENDED_DEVICES,
        HIGH_QUALITY_CRITERIA
    )
    IMAGE_QUALITY_ASSESSOR_AVAILABLE = True
except ImportError:
    IMAGE_QUALITY_ASSESSOR_AVAILABLE = False
    print("Warning: image_quality_assessor.py not found. Image quality assessment will be disabled.")

# è‚Œåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from skin_analysis import (
        detect_face_landmarks,
        extract_face_regions,
        detect_skin_troubles,
        create_trouble_report,
        REGION_NAMES_JP,
        TROUBLE_NAMES_JP
    )
    SKIN_ANALYSIS_AVAILABLE = True
except ImportError:
    SKIN_ANALYSIS_AVAILABLE = False
    print("Warning: skin_analysis.py not found. Face region analysis will be disabled.")

# å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from experiment_analysis import (
        ExperimentDataManager,
        calculate_correlations,
        create_scatter_plot,
        create_correlation_heatmap,
        generate_experiment_summary
    )
    EXPERIMENT_ANALYSIS_AVAILABLE = True
except ImportError:
    EXPERIMENT_ANALYSIS_AVAILABLE = False
    print("Warning: experiment_analysis.py not found. Experimental data collection will be disabled.")

# Try import cupy for GPU acceleration (optional)
USE_CUPY = False
xp = np  # alias for numpy/cupy
try:
    import cupy as cp
    # quick check: is CUDA visible?
    _ = cp.zeros(1)
    USE_CUPY = True
    xp = cp
except Exception:
    USE_CUPY = False
    xp = np

# ============================================================
# Data Augmentation (ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ) - ç”»åƒãŒå°‘ãªã„å ´åˆã®å¯¾ç­–
# ============================================================
def augment_image(img, augmentation_type):
    """
    ç”»åƒã«ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨
    
    Args:
        img: å…¥åŠ›ç”»åƒ (BGR)
        augmentation_type: æ‹¡å¼µã‚¿ã‚¤ãƒ—
    
    Returns:
        æ‹¡å¼µã•ã‚ŒãŸç”»åƒ
    """
    if augmentation_type == 'flip_h':
        # æ°´å¹³åè»¢
        return cv2.flip(img, 1)
    elif augmentation_type == 'flip_v':
        # å‚ç›´åè»¢
        return cv2.flip(img, 0)
    elif augmentation_type == 'rotate_90':
        # 90åº¦å›è»¢
        return cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)
    elif augmentation_type == 'rotate_180':
        # 180åº¦å›è»¢
        return cv2.rotate(img, cv2.ROTATE_180)
    elif augmentation_type == 'rotate_270':
        # 270åº¦å›è»¢
        return cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
    elif augmentation_type == 'brightness_up':
        # æ˜ã‚‹ã•å¢—åŠ 
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 2] = hsv[:, :, 2] * 1.2  # æ˜ã‚‹ã•ã‚’20%å¢—åŠ 
        hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)
        hsv = hsv.astype(np.uint8)
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    elif augmentation_type == 'brightness_down':
        # æ˜ã‚‹ã•æ¸›å°‘
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 2] = hsv[:, :, 2] * 0.8  # æ˜ã‚‹ã•ã‚’20%æ¸›å°‘
        hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)
        hsv = hsv.astype(np.uint8)
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    elif augmentation_type == 'contrast_up':
        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¢—åŠ 
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        l = l.astype(np.float32)
        l = (l - 128) * 1.3 + 128  # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’30%å¢—åŠ 
        l = np.clip(l, 0, 255).astype(np.uint8)
        lab = cv2.merge([l, a, b])
        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    elif augmentation_type == 'contrast_down':
        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆæ¸›å°‘
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        l = l.astype(np.float32)
        l = (l - 128) * 0.7 + 128  # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’30%æ¸›å°‘
        l = np.clip(l, 0, 255).astype(np.uint8)
        lab = cv2.merge([l, a, b])
        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    elif augmentation_type == 'gamma_bright':
        # ã‚¬ãƒ³ãƒè£œæ­£ (æ˜ã‚‹ã)
        gamma = 1.2
        inv_gamma = 1.0 / gamma
        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        return cv2.LUT(img, table)
    elif augmentation_type == 'gamma_dark':
        # ã‚¬ãƒ³ãƒè£œæ­£ (æš—ã)
        gamma = 0.8
        inv_gamma = 1.0 / gamma
        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        return cv2.LUT(img, table)
    elif augmentation_type == 'noise':
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºè¿½åŠ 
        noise = np.random.normal(0, 10, img.shape).astype(np.float32)
        noisy = img.astype(np.float32) + noise
        noisy = np.clip(noisy, 0, 255).astype(np.uint8)
        return noisy
    elif augmentation_type == 'blur':
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ã¼ã‹ã—
        return cv2.GaussianBlur(img, (5, 5), 1.0)
    elif augmentation_type == 'sharpen':
        # ã‚·ãƒ£ãƒ¼ãƒ—åŒ–
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1],
                          [-1,-1,-1]])
        return cv2.filter2D(img, -1, kernel)
    elif augmentation_type == 'saturation_up':
        # å½©åº¦å¢—åŠ 
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 1] = hsv[:, :, 1] * 1.3  # å½©åº¦ã‚’30%å¢—åŠ 
        hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
        hsv = hsv.astype(np.uint8)
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    elif augmentation_type == 'saturation_down':
        # å½©åº¦æ¸›å°‘
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 1] = hsv[:, :, 1] * 0.7  # å½©åº¦ã‚’30%æ¸›å°‘
        hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
        hsv = hsv.astype(np.uint8)
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    elif augmentation_type == 'hue_shift':
        # è‰²ç›¸ã‚·ãƒ•ãƒˆ
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.int16)
        hsv[:, :, 0] = (hsv[:, :, 0] + 10) % 180  # è‰²ç›¸ã‚’10åº¦ã‚·ãƒ•ãƒˆ
        hsv = hsv.astype(np.uint8)
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    elif augmentation_type == 'equalize':
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–
        yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
        yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])
        return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
    
    # ============================================================
    # ğŸ¯ AIå­¦ç¿’ã«ç‰¹ã«æœ‰åŠ¹ãªè¿½åŠ æ‹¡å¼µ (ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒå­¦ç¿’æœ€é©åŒ–)
    # ============================================================
    elif augmentation_type == 'scale_up':
        # ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ› (æ‹¡å¤§ 110%) - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§å­¦ç¿’
        h, w = img.shape[:2]
        new_h, new_w = int(h * 1.1), int(w * 1.1)
        scaled = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        # ä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ—ã§å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
        start_h = (new_h - h) // 2
        start_w = (new_w - w) // 2
        return scaled[start_h:start_h+h, start_w:start_w+w]
    
    elif augmentation_type == 'scale_down':
        # ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ› (ç¸®å° 90%) - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§å­¦ç¿’
        h, w = img.shape[:2]
        new_h, new_w = int(h * 0.9), int(w * 0.9)
        scaled = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã§å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
        pad_h = (h - new_h) // 2
        pad_w = (w - new_w) // 2
        return cv2.copyMakeBorder(scaled, pad_h, h-new_h-pad_h, pad_w, w-new_w-pad_w, 
                                  cv2.BORDER_REFLECT)
    
    elif augmentation_type == 'clahe':
        # CLAHE (é©å¿œçš„ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–) - å±€æ‰€çš„ãªãƒ†ã‚¯ã‚¹ãƒãƒ£å¼·èª¿
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã®è©³ç´°ã‚’ä¿æŒã—ãªãŒã‚‰ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå‘ä¸Š
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        lab = cv2.merge([l, a, b])
        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    
    elif augmentation_type == 'bilateral':
        # ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ - ã‚¨ãƒƒã‚¸ä¿å­˜å¹³æ»‘åŒ–
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã®ã‚¨ãƒƒã‚¸ã‚’ä¿ã¡ãªãŒã‚‰ãƒã‚¤ã‚ºé™¤å»
        return cv2.bilateralFilter(img, 9, 75, 75)
    
    elif augmentation_type == 'median':
        # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ - ãƒã‚¤ã‚ºé™¤å»
        # å¡©èƒ¡æ¤’ãƒã‚¤ã‚ºã«å¼·ãã€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã‚’ä¿æŒ
        return cv2.medianBlur(img, 5)
    
    elif augmentation_type == 'temp_warm':
        # æ¸©åº¦èª¿æ•´ (æš–è‰²åŒ–) - ç…§æ˜æ¡ä»¶ã®å¤‰åŒ–ã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§
        # è‚Œç”»åƒã¯ç…§æ˜ã§è‰²æ¸©åº¦ãŒå¤‰ã‚ã‚‹ãŸã‚é‡è¦
        warm_lut = np.array([[[i, 
                                int(np.clip(i * 0.9, 0, 255)), 
                                int(np.clip(i * 0.8, 0, 255))] 
                              for i in range(256)]], dtype=np.uint8)
        b, g, r = cv2.split(img)
        b = cv2.LUT(b, warm_lut[0, :, 2])
        g = cv2.LUT(g, warm_lut[0, :, 1])
        r = cv2.LUT(r, warm_lut[0, :, 0])
        return cv2.merge([b, g, r])
    
    elif augmentation_type == 'temp_cool':
        # æ¸©åº¦èª¿æ•´ (å¯’è‰²åŒ–) - ç…§æ˜æ¡ä»¶ã®å¤‰åŒ–ã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§
        cool_lut = np.array([[[int(np.clip(i * 0.8, 0, 255)), 
                                int(np.clip(i * 0.9, 0, 255)), 
                                i] 
                              for i in range(256)]], dtype=np.uint8)
        b, g, r = cv2.split(img)
        b = cv2.LUT(b, cool_lut[0, :, 0])
        g = cv2.LUT(g, cool_lut[0, :, 1])
        r = cv2.LUT(r, cool_lut[0, :, 2])
        return cv2.merge([b, g, r])
    
    elif augmentation_type == 'rotate_small_cw':
        # å¾®å°å›è»¢ (æ™‚è¨ˆå›ã‚Š5åº¦) - æ–¹å‘ä¸å¤‰æ€§ã®å­¦ç¿’
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯å›è»¢ã«å¯¾ã—ã¦ä¸å¤‰ã§ã‚ã‚‹ã¹ã
        h, w = img.shape[:2]
        center = (w // 2, h // 2)
        angle = 5
        matrix = cv2.getRotationMatrix2D(center, -angle, 1.0)
        return cv2.warpAffine(img, matrix, (w, h), 
                             flags=cv2.INTER_LINEAR, 
                             borderMode=cv2.BORDER_REFLECT)
    
    elif augmentation_type == 'rotate_small_ccw':
        # å¾®å°å›è»¢ (åæ™‚è¨ˆå›ã‚Š5åº¦) - æ–¹å‘ä¸å¤‰æ€§ã®å­¦ç¿’
        h, w = img.shape[:2]
        center = (w // 2, h // 2)
        angle = -5
        matrix = cv2.getRotationMatrix2D(center, -angle, 1.0)
        return cv2.warpAffine(img, matrix, (w, h), 
                             flags=cv2.INTER_LINEAR, 
                             borderMode=cv2.BORDER_REFLECT)
    
    elif augmentation_type == 'unsharp':
        # ã‚¢ãƒ³ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ã‚¯ - ã‚¨ãƒƒã‚¸å¼·èª¿
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã®å¢ƒç•Œã‚’æ˜ç¢ºåŒ–
        gaussian = cv2.GaussianBlur(img, (0, 0), 2.0)
        unsharp = cv2.addWeighted(img, 1.5, gaussian, -0.5, 0)
        return unsharp
    
    elif augmentation_type == 'crop_zoom':
        # ä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ—&ã‚ºãƒ¼ãƒ  (90%ã‚’æ‹¡å¤§)
        h, w = img.shape[:2]
        crop_size = int(min(h, w) * 0.9)
        start_h = (h - crop_size) // 2
        start_w = (w - crop_size) // 2
        cropped = img[start_h:start_h+crop_size, start_w:start_w+crop_size]
        return cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LINEAR)
    else:
        return img

def apply_data_augmentation(high_imgs, low_imgs, high_names, low_names, augmentation_methods):
    """
    ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨ã—ã¦ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã™
    
    Args:
        high_imgs: é«˜ç”»è³ªç”»åƒãƒªã‚¹ãƒˆ
        low_imgs: ä½ç”»è³ªç”»åƒãƒªã‚¹ãƒˆ
        high_names: é«˜ç”»è³ªç”»åƒåãƒªã‚¹ãƒˆ
        low_names: ä½ç”»è³ªç”»åƒåãƒªã‚¹ãƒˆ
        augmentation_methods: é©ç”¨ã™ã‚‹æ‹¡å¼µæ‰‹æ³•ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        æ‹¡å¼µå¾Œã®ç”»åƒãƒªã‚¹ãƒˆã¨åå‰ãƒªã‚¹ãƒˆ
    """
    augmented_high = high_imgs.copy()
    augmented_low = low_imgs.copy()
    augmented_high_names = high_names.copy()
    augmented_low_names = low_names.copy()
    
    for method in augmentation_methods:
        for high, low, h_name, l_name in zip(high_imgs, low_imgs, high_names, low_names):
            aug_high = augment_image(high, method)
            aug_low = augment_image(low, method)
            augmented_high.append(aug_high)
            augmented_low.append(aug_low)
            augmented_high_names.append(f"{h_name}_{method}")
            augmented_low_names.append(f"{l_name}_{method}")
    
    return augmented_high, augmented_low, augmented_high_names, augmented_low_names


# Helper to move array to xp (cupy or numpy)
def to_xp(arr):
    if USE_CUPY:
        return cp.asarray(arr)
    else:
        return np.asarray(arr)

def to_host(arr):
    if USE_CUPY:
        return cp.asnumpy(arr)
    else:
        return arr

# ------------------------------------------------------------
# Utility: ensure image is color BGR uint8
def read_bgr_from_buffer(buf):
    arr = np.frombuffer(buf, np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    return img

def read_bgr_from_path(filepath):
    """æ—¥æœ¬èªãƒ‘ã‚¹ã«å¯¾å¿œã—ãŸç”»åƒèª­ã¿è¾¼ã¿"""
    try:
        # OpenCVã¯æ—¥æœ¬èªãƒ‘ã‚¹ã‚’ç›´æ¥æ‰±ãˆãªã„ãŸã‚ã€numpyã‚’çµŒç”±
        with open(filepath, 'rb') as f:
            buf = f.read()
        arr = np.frombuffer(buf, np.uint8)
        img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
        return img
    except Exception as e:
        return None

# ============================================================
# Fast vectorized standard-deviation box-counting (ä¸­å·å¼ãƒ™ãƒ¼ã‚¹)
# ============================================================
def fast_fractal_std_boxcount_batched(img_bgr, scales=(2,4,8,16,32,64), use_gpu=None):
    """
    img_bgr: HxWx3 uint8 (OpenCV BGR)
    scales: iterable of block sizes (h)
    use_gpu: None => auto (global USE_CUPY), True/False to force
    returns: D, scales_used, Nh_values (host numpy arrays)
    """
    if use_gpu is None:
        use_gpu = USE_CUPY

    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32)
    H, W = img_gray.shape

    Nh_vals = []
    valid_scales = []
    for h in scales:
        # crop to multiple of h for clean reshaping
        Hc = (H // h) * h
        Wc = (W // h) * h
        if Hc < h or Wc < h:
            continue

        gray_crop = img_gray[:Hc, :Wc]

        # move to xp
        arr = to_xp(gray_crop)

        # reshape to blocks: (Hc//h, h, Wc//h, h) then transpose to (Hc//h, Wc//h, h, h)
        new_shape = (Hc//h, h, Wc//h, h)
        try:
            blocks = arr.reshape(new_shape).transpose(0,2,1,3)
        except Exception:
            # fallback per-block (rare)
            blocks_list = []
            for i in range(0, Hc, h):
                row=[]
                for j in range(0, Wc, h):
                    row.append(arr[i:i+h, j:j+h])
                blocks_list.append(row)
            blocks = to_xp(np.array(blocks_list))

        # compute std over last two axes (h,h) -> shape (Hc//h, Wc//h)
        # note: xp.std uses different dtype; do manually for numerical stability
        mean_blk = blocks.mean(axis=(2,3))
        sq_mean = (blocks**2).mean(axis=(2,3))
        std_blk = xp.sqrt(xp.maximum(0, sq_mean - mean_blk**2))

        # nh per block: sigma/h
        nh = std_blk / float(h)

        # sum across blocks and convert to host
        nh_total = float(to_host(nh.sum()))
        Nh_vals.append(nh_total + 1e-12)
        valid_scales.append(h)

    if len(valid_scales) < 3:
        return None, np.array(scales), np.array([1]*len(scales))

    log_h = np.log(np.array(valid_scales, dtype=np.float64))
    log_Nh = np.log(np.array(Nh_vals, dtype=np.float64))

    # linear fit
    coeffs = np.polyfit(log_h, log_Nh, 1)
    slope = coeffs[0]
    
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯å‚¾ãã®çµ¶å¯¾å€¤ã¨ã—ã¦è¨ˆç®—
    # ãŸã ã—ã€æ¨™æº–åå·®æ³•ã§ã¯å‚¾ããŒãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã«å¯¾å¿œ
    # 2Dç”»åƒã®å ´åˆã€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯2ã€œ3ã®ç¯„å›²
    D = abs(slope)
    
    # ç•°å¸¸å€¤ãƒã‚§ãƒƒã‚¯: å‚¾ããŒå¤§ãã™ãã‚‹å ´åˆã¯è¨ˆç®—å¤±æ•—ã¨ã¿ãªã™
    if D > 5.0 or D < 0.5:
        print(f"Warning: fast_fractal_std_boxcount_batched ã§ç•°å¸¸ãªå‚¾ãæ¤œå‡º: {D}")
        print(f"  scales: {valid_scales}")
        print(f"  Nh_vals: {Nh_vals}")
        print(f"  log_h: {log_h}")
        print(f"  log_Nh: {log_Nh}")
        return None, np.array(scales), np.array([1]*len(scales))
    
    # 2Dç”»åƒã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯2ã€œ3ã®ç¯„å›²ã«åˆ¶é™
    D = np.clip(D, 2.0, 3.0)

    return float(D), np.array(valid_scales), np.array(Nh_vals), log_h, log_Nh, coeffs

# ============================================================
# 3D DBC fast version (vectorized)
# ============================================================
def fast_fractal_3d_dbc(img_bgr, scales=None, max_size=256, use_gpu=None):
    """
    Convert grayscale intensity to height and perform vectorized DBC counting.
    Returns (FD_3d, used_scales, counts)
    """
    if use_gpu is None:
        use_gpu = USE_CUPY

    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32)
    H, W = gray.shape
    # resize for speed
    scale_factor = 1.0
    if max(H, W) > max_size:
        scale_factor = max_size / max(H, W)
        gray = cv2.resize(gray, (int(W*scale_factor), int(H*scale_factor)), interpolation=cv2.INTER_AREA)
        H, W = gray.shape

    if scales is None:
        max_box = max(2, min(H, W)//4)
        scales = []
        s = 2
        while s <= max_box:
            scales.append(s)
            s *= 2
        if len(scales) < 3:
            scales = [2,4,8,16]

    counts = []
    arr_host = gray / 255.0
    arr = to_xp(arr_host)
    for r in scales:
        nh = (H // r)
        nw = (W // r)
        if nh < 1 or nw < 1:
            counts.append(0)
            continue

        Hc = nh * r
        Wc = nw * r
        arr_crop = arr[:Hc, :Wc]
        # shape (nh, r, nw, r) -> (nh, nw, r, r)
        blocks = arr_crop.reshape((nh, r, nw, r)).transpose(0,2,1,3)
        # min and max per block
        bmin = blocks.min(axis=(2,3))
        bmax = blocks.max(axis=(2,3))

        # G as in original (small quantization step): use 1/r to scale
        G = max(0.001, 1.0 / r)
        # l = floor(min/G), k = ceil(max/G)
        l = xp.floor(bmin / G)
        k = xp.ceil(bmax / G)
        # number of boxes per block (k-l)
        nr = (k - l).astype(xp.int32)
        # sum, ensure >=1 per block
        nr = xp.maximum(nr, 1)
        total_nr = int(to_host(nr.sum()))
        counts.append(total_nr)

    # check validity
    valid_sizes = []
    valid_counts = []
    for s,c in zip(scales, counts):
        if c > 0:
            valid_sizes.append(s)
            valid_counts.append(c)
    if len(valid_counts) < 3:
        return None, np.array(scales), np.array(counts)

    log_sizes = np.log(np.array(valid_sizes, dtype=np.float64))
    log_counts = np.log(np.array(valid_counts, dtype=np.float64))
    coeffs = np.polyfit(log_sizes, log_counts, 1)
    slope = coeffs[0]
    # FD = 3 - |slope|
    fd3 = 3.0 - abs(slope)
    fd3 = float(np.clip(fd3, 2.0, 3.0))
    return fd3, np.array(valid_sizes), np.array(valid_counts)

# ============================================================
# Feature extraction (vectorized, batch-friendly)
# ============================================================
def extract_feature_vector(img_bgr, size=256, use_gpu=None):
    if use_gpu is None:
        use_gpu = USE_CUPY
    gray = cv2.cvtColor(cv2.resize(img_bgr, (size, size)), cv2.COLOR_BGR2GRAY).astype(np.float32)
    # move to xp for possible GPU ops
    arr = to_xp(gray)
    mean_val = float(to_host(arr.mean()))
    std_val = float(to_host(arr.std()))
    # Sobel edges
    gx = to_host(cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3))
    gy = to_host(cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3))
    edge_mean = float(np.mean(np.sqrt(gx**2 + gy**2)))
    noise_level = float(np.mean(np.abs(gray - cv2.GaussianBlur(gray, (3,3), 1))))
    # entropy
    probs, _ = np.histogram(gray.flatten(), bins=256, range=(0,255), density=True)
    probs = probs + 1e-12
    entropy = -np.sum(probs * np.log2(probs))
    return [mean_val, std_val, edge_mean, noise_level, entropy]

# ç‰¹å¾´é‡åã®ãƒªã‚¹ãƒˆ
FEATURE_NAMES = ['mean', 'std', 'edge_strength', 'noise_level', 'entropy']

# ============================================================
# æœ€å°äºŒä¹—æ³•ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã®ã‚°ãƒ©ãƒ•ã‚’æç”»
# ============================================================
def plot_least_squares_fit(log_h, log_Nh, coeffs, fd_value):
    """
    æœ€å°äºŒä¹—æ³•ã«ã‚ˆã‚‹ç·šå½¢ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã®ã‚°ãƒ©ãƒ•ã‚’æç”»
    
    Args:
        log_h: log(ã‚¹ã‚±ãƒ¼ãƒ«)ã®é…åˆ—
        log_Nh: log(ã‚«ã‚¦ãƒ³ãƒˆå€¤)ã®é…åˆ—
        coeffs: polyfitã®ä¿‚æ•° [slope, intercept]
        fd_value: è¨ˆç®—ã•ã‚ŒãŸãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
    
    Returns:
        matplotlib figure
    """
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š(æ–‡å­—åŒ–ã‘å¯¾ç­–)
    import matplotlib
    matplotlib.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'sans-serif']
    matplotlib.rcParams['axes.unicode_minus'] = False
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # å®Ÿæ¸¬å€¤ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    ax.scatter(log_h, log_Nh, s=100, alpha=0.6, color='blue', 
               label='å®Ÿæ¸¬å€¤', edgecolors='navy', linewidth=2)
    
    # æœ€å°äºŒä¹—æ³•ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ç›´ç·š
    fit_line = coeffs[0] * log_h + coeffs[1]
    ax.plot(log_h, fit_line, 'r-', linewidth=2, 
            label=f'æœ€å°äºŒä¹—æ³•ãƒ•ã‚£ãƒƒãƒˆ\nå‚¾ã = {coeffs[0]:.4f}')
    
    # ã‚°ãƒªãƒƒãƒ‰
    ax.grid(True, alpha=0.3, linestyle='--')
    
    # ãƒ©ãƒ™ãƒ«ã¨ã‚¿ã‚¤ãƒˆãƒ«
    ax.set_xlabel('log(ã‚¹ã‚±ãƒ¼ãƒ«)', fontsize=12, fontweight='bold')
    ax.set_ylabel('log(ã‚«ã‚¦ãƒ³ãƒˆå€¤)', fontsize=12, fontweight='bold')
    ax.set_title(f'Box-Countingæ³•ï¼šæœ€å°äºŒä¹—æ³•ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°\nãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ = {fd_value:.4f}', 
                 fontsize=14, fontweight='bold', pad=20)
    
    # å‡¡ä¾‹
    ax.legend(fontsize=11, loc='best', framealpha=0.9)
    
    # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
    residuals = log_Nh - fit_line
    r_squared = 1 - (np.sum(residuals**2) / np.sum((log_Nh - np.mean(log_Nh))**2))
    
    info_text = f'æ±ºå®šä¿‚æ•° RÂ² = {r_squared:.4f}\nåˆ‡ç‰‡ = {coeffs[1]:.4f}\nãƒ‡ãƒ¼ã‚¿ç‚¹æ•° = {len(log_h)}'
    ax.text(0.02, 0.98, info_text, transform=ax.transAxes,
            fontsize=10, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.tight_layout()
    return fig

# ============================================================
# Train FD predictor (low->high) using LightGBM (fast, parallel)
# ============================================================
def train_fd_predictor_fast(low_imgs, high_imgs, n_estimators=400, max_depth=8):
    # ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
    if len(low_imgs) < 2 or len(high_imgs) < 2:
        raise ValueError(
            f"âŒ **å­¦ç¿’ã«å¿…è¦ãªç”»åƒãƒšã‚¢æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™**\n\n"
            f"- æ¤œå‡ºã•ã‚ŒãŸç”»åƒãƒšã‚¢æ•°: {len(low_imgs)}\n"
            f"- å¿…è¦ãªæœ€å°ãƒšã‚¢æ•°: 2\n\n"
            f"ğŸ’¡ **è§£æ±ºæ–¹æ³•:**\n"
            f"1. ãƒ•ã‚©ãƒ«ãƒ€å†…ã«å°‘ãªãã¨ã‚‚2çµ„ä»¥ä¸Šã®ç”»åƒãƒšã‚¢ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n"
            f"2. ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„\n"
            f"   - ä¾‹: `IMG_0001.jpg` ã¨ `IMG_0001_low1.jpg`\n"
            f"3. ç”»åƒãŒæ­£ã—ãèª­ã¿è¾¼ã‚ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
        )
    
    X = []
    y = []
    for low, high in zip(low_imgs, high_imgs):
        feat = extract_feature_vector(low)
        X.append(feat)
        D_high, *_ = fast_fractal_std_boxcount_batched(high, use_gpu=False)  # computing target on CPU for stability
        if D_high is None:
            # fallback to classic fractal_dimension naive
            D_high, *_ = fractal_dimension_naive(high)
        y.append(D_high)
    X = np.array(X, dtype=np.float32)
    y = np.array(y, dtype=np.float32)
    
    # ç‰¹å¾´é‡åã‚’ä»˜ã‘ã¦DataFrameã«å¤‰æ›
    import pandas as pd
    X_df = pd.DataFrame(X, columns=FEATURE_NAMES)
    
    model = LGBMRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=0.05, n_jobs=-1)
    model.fit(X_df, y)
    return model

# ============================================================
# Model Save/Load (ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿)
# ============================================================
def save_model(model, filepath="trained_fd_model.pkl"):
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
    with open(filepath, 'wb') as f:
        pickle.dump(model, f)
    return filepath

def save_training_history(history, filepath="training_history.json"):
    """å­¦ç¿’å±¥æ­´ã‚’JSONå½¢å¼ã§ä¿å­˜"""
    try:
        # æ—¢å­˜ã®å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€
        if os.path.exists(filepath):
            with open(filepath, 'r', encoding='utf-8') as f:
                all_history = json.load(f)
        else:
            all_history = []
        
        # æ–°ã—ã„å±¥æ­´ã‚’è¿½åŠ 
        all_history.append(history)
        
        # ä¿å­˜
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(all_history, f, indent=2, ensure_ascii=False)
        
        return filepath
    except Exception as e:
        print(f"å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def load_training_history(filepath="training_history.json"):
    """å­¦ç¿’å±¥æ­´ã‚’èª­ã¿è¾¼ã¿"""
    if not os.path.exists(filepath):
        return []
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def calculate_ai_readiness(history):
    """
    AIã®å®Ÿç”¨æº–å‚™çŠ¶æ³ã‚’è©•ä¾¡
    
    Returns:
        dict: {
            'ready': bool (å®Ÿç”¨å¯èƒ½ã‹),
            'confidence': float (0-100, ä¿¡é ¼åº¦),
            'level': str (åˆç´š/ä¸­ç´š/ä¸Šç´š/ãƒ—ãƒ­/ãƒã‚¹ã‚¿ãƒ¼),
            'recommendations': list (æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹),
            'stats': dict (çµ±è¨ˆæƒ…å ±),
            'next_milestone': dict (æ¬¡ã®ç›®æ¨™)
        }
    """
    if not history or len(history) == 0:
        return {
            'ready': False,
            'confidence': 0,
            'level': 'æœªå­¦ç¿’',
            'recommendations': [
                'ğŸ“š ã¾ãšã¯å­¦ç¿’ã‚’é–‹å§‹ã—ã¦ãã ã•ã„',
                'ğŸ¯ æ¨å¥¨: 20çµ„ä»¥ä¸Šã®ç”»åƒãƒšã‚¢ã§å­¦ç¿’',
                'ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½¿ç”¨ã—ã¦å¤šæ§˜æ€§ã‚’ç¢ºä¿'
            ],
            'stats': {
                'total_sessions': 0,
                'total_pairs': 0,
                'best_correlation': 0,
                'best_improvement': 0,
                'avg_mae': 0
            },
            'next_milestone': {
                'target': 'åˆå›å­¦ç¿’å®Œäº†',
                'progress': 0,
                'needed': 'å­¦ç¿’é–‹å§‹'
            }
        }
    
    # çµ±è¨ˆè¨ˆç®—
    total_sessions = len(history)
    total_pairs = sum(h.get('num_pairs', 0) for h in history)
    
    # metricsã‹ã‚‰æ­£ã—ã„ã‚­ãƒ¼ã§å–å¾—
    correlations = []
    improvements = []
    maes = []
    
    for h in history:
        metrics = h.get('metrics', {})
        if metrics:
            # correlation_pred ã¾ãŸã¯ correlation
            corr = metrics.get('correlation_pred', metrics.get('correlation', 0))
            if corr > 0:
                correlations.append(corr)
            
            # improvement ã¾ãŸã¯ improvement_rate
            imp = metrics.get('improvement', metrics.get('improvement_rate', 0))
            if imp != 0:
                improvements.append(imp)
            
            # mae_pred
            mae = metrics.get('mae_pred', 1.0)
            if mae < 1.0:
                maes.append(mae)
    
    best_correlation = max(correlations) if correlations else 0
    avg_correlation = sum(correlations) / len(correlations) if correlations else 0
    best_improvement = max(improvements) if improvements else 0
    avg_improvement = sum(improvements) / len(improvements) if improvements else 0
    best_mae = min(maes) if maes else 1.0
    avg_mae = sum(maes) / len(maes) if maes else 1.0
    
    # æœ€æ–°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æ€§èƒ½ - metricsã‹ã‚‰å–å¾—
    latest = history[-1]
    latest_metrics = latest.get('metrics', {})
    latest_corr = latest_metrics.get('correlation_pred', latest_metrics.get('correlation', 0))
    latest_mae = latest_metrics.get('mae_pred', 1.0)
    latest_improvement = latest_metrics.get('improvement', latest_metrics.get('improvement_rate', 0))
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
    print(f"DEBUG - Latest metrics: correlation={latest_corr}, mae={latest_mae}, improvement={latest_improvement}")
    print(f"DEBUG - History length: {len(history)}, Total pairs: {total_pairs}")
    
    # ä¿¡é ¼åº¦è¨ˆç®— (0-100)
    confidence = 0
    
    # 1. ç›¸é–¢ä¿‚æ•°ã«ã‚ˆã‚‹è©•ä¾¡ (40ç‚¹æº€ç‚¹)
    if latest_corr >= 0.95:
        confidence += 40
    elif latest_corr >= 0.90:
        confidence += 35
    elif latest_corr >= 0.85:
        confidence += 30
    elif latest_corr >= 0.80:
        confidence += 25
    elif latest_corr >= 0.70:
        confidence += 15
    else:
        confidence += latest_corr * 20
    
    # 2. MAEã«ã‚ˆã‚‹è©•ä¾¡ (30ç‚¹æº€ç‚¹)
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯é€šå¸¸2.0-3.0ã®ç¯„å›²ãªã®ã§ã€MAEã®åŸºæº–ã‚’èª¿æ•´
    # æ³¨æ„: å…¨ãƒ¬ãƒ™ãƒ« (low1-10) ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€å“è³ªå·®ãŒå¤§ãã™ãã¦MAEãŒæ‚ªåŒ–ã—ã¾ã™
    #       â†’ æ¨å¥¨: low4-7 (ä¸­åº¦åŠ£åŒ–) ã§å­¦ç¿’ã™ã‚‹ã¨ã€MAE 0.02-0.03 ã‚’é”æˆå¯èƒ½
    if latest_mae < 0.01:
        confidence += 30  # éå¸¸ã«å„ªç§€ (0.3-0.5%ã®ç›¸å¯¾èª¤å·®)
    elif latest_mae < 0.02:
        confidence += 28  # å„ªç§€ (0.7-1.0%ã®ç›¸å¯¾èª¤å·®)
    elif latest_mae < 0.03:
        confidence += 25  # è‰¯å¥½ (1.0-1.5%ã®ç›¸å¯¾èª¤å·®)
    elif latest_mae < 0.05:
        confidence += 20  # å®Ÿç”¨ãƒ¬ãƒ™ãƒ« (1.7-2.5%ã®ç›¸å¯¾èª¤å·®) â† å…¨ãƒ¬ãƒ™ãƒ«ä½¿ç”¨æ™‚ã¯ã“ã“ã«ç•™ã¾ã‚‹
    elif latest_mae < 0.08:
        confidence += 15  # è¨±å®¹ç¯„å›²
    elif latest_mae < 0.10:
        confidence += 10  # è¦æ”¹å–„
    else:
        confidence += max(0, 10 - latest_mae * 50)  # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
    
    # 3. æ”¹å–„ç‡ã«ã‚ˆã‚‹è©•ä¾¡ (20ç‚¹æº€ç‚¹)
    if latest_improvement > 50:
        confidence += 20
    elif latest_improvement > 30:
        confidence += 15
    elif latest_improvement > 10:
        confidence += 10
    elif latest_improvement > 0:
        confidence += 5
    
    # 4. å­¦ç¿’å›æ•°ã¨å®‰å®šæ€§ (10ç‚¹æº€ç‚¹)
    if total_sessions >= 10:
        confidence += 10
    elif total_sessions >= 5:
        confidence += 7
    elif total_sessions >= 3:
        confidence += 5
    else:
        confidence += total_sessions * 1.5
    
    confidence = min(100, confidence)
    
    # ãƒ¬ãƒ™ãƒ«åˆ¤å®š
    if confidence >= 90:
        level = 'ğŸ† ãƒã‚¹ã‚¿ãƒ¼'
        level_desc = 'å®Ÿç”¨ãƒ¬ãƒ™ãƒ« - é«˜ç²¾åº¦äºˆæ¸¬ãŒå¯èƒ½'
    elif confidence >= 75:
        level = 'â­ ãƒ—ãƒ­'
        level_desc = 'å®Ÿç”¨å¯èƒ½ - ä¿¡é ¼ã§ãã‚‹äºˆæ¸¬'
    elif confidence >= 60:
        level = 'ğŸ¥‡ ä¸Šç´š'
        level_desc = 'å®Ÿç”¨ã«è¿‘ã„ - ã•ã‚‰ãªã‚‹æ”¹å–„æ¨å¥¨'
    elif confidence >= 40:
        level = 'ğŸ¥ˆ ä¸­ç´š'
        level_desc = 'å­¦ç¿’ä¸­ - è¿½åŠ ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦'
    elif confidence >= 20:
        level = 'ğŸ¥‰ åˆç´š'
        level_desc = 'å­¦ç¿’é–‹å§‹ - ç¶™ç¶šãŒé‡è¦'
    else:
        level = 'ğŸŒ± å…¥é–€'
        level_desc = 'ãƒ‡ãƒ¼ã‚¿åé›†æ®µéš'
    
    # å®Ÿç”¨å¯èƒ½åˆ¤å®š
    ready = (confidence >= 75 and 
             latest_corr >= 0.85 and 
             latest_mae < 0.01 and
             total_sessions >= 3)
    
    # æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹
    recommendations = []
    
    if latest_corr < 0.85:
        recommendations.append('ğŸ“Š ç›¸é–¢ä¿‚æ•°ãŒä½ã„ â†’ ã‚ˆã‚Šå¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™')
    if latest_mae > 0.01:
        recommendations.append('ğŸ¯ èª¤å·®ãŒå¤§ãã„ â†’ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’å¢—ã‚„ã—ã¦ãã ã•ã„')
    if latest_improvement < 20:
        recommendations.append('âš¡ æ”¹å–„ç‡ãŒä½ã„ â†’ å“è³ªãƒ¬ãƒ™ãƒ«ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„')
    if total_pairs < 100:
        recommendations.append(f'ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿é‡ä¸è¶³ â†’ ç¾åœ¨{total_pairs}çµ„ã€ç›®æ¨™100çµ„ä»¥ä¸Š')
    if total_sessions < 5:
        recommendations.append(f'ğŸ”„ å­¦ç¿’å›æ•° â†’ ç¾åœ¨{total_sessions}å›ã€æ¨å¥¨5å›ä»¥ä¸Š')
    
    if not recommendations:
        recommendations.append('âœ… å„ªã‚ŒãŸæ€§èƒ½ã§ã™ï¼ç¶™ç¶šã—ã¦å­¦ç¿’ã‚’é‡ã­ã¾ã—ã‚‡ã†')
        if confidence < 90:
            recommendations.append('ğŸ–ï¸ ãƒã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«ã‚’ç›®æŒ‡ã—ã¦ã€ã•ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã‚’')
    
    # æ¬¡ã®ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³
    if confidence < 40:
        next_milestone = {
            'target': 'ä¸­ç´šãƒ¬ãƒ™ãƒ«åˆ°é”',
            'progress': confidence / 40 * 100,
            'needed': f'ä¿¡é ¼åº¦ã‚’{40-confidence:.0f}ãƒã‚¤ãƒ³ãƒˆå‘ä¸Š (ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã¨å“è³ªæ”¹å–„)'
        }
    elif confidence < 60:
        next_milestone = {
            'target': 'ä¸Šç´šãƒ¬ãƒ™ãƒ«åˆ°é”',
            'progress': (confidence - 40) / 20 * 100,
            'needed': f'ä¿¡é ¼åº¦ã‚’{60-confidence:.0f}ãƒã‚¤ãƒ³ãƒˆå‘ä¸Š (ç²¾åº¦å‘ä¸ŠãŒå¿…è¦)'
        }
    elif confidence < 75:
        next_milestone = {
            'target': 'ãƒ—ãƒ­ãƒ¬ãƒ™ãƒ«åˆ°é” (å®Ÿç”¨åŒ–)',
            'progress': (confidence - 60) / 15 * 100,
            'needed': f'ä¿¡é ¼åº¦ã‚’{75-confidence:.0f}ãƒã‚¤ãƒ³ãƒˆå‘ä¸Š (å®‰å®šæ€§å‘ä¸Š)'
        }
    elif confidence < 90:
        next_milestone = {
            'target': 'ãƒã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«åˆ°é”',
            'progress': (confidence - 75) / 15 * 100,
            'needed': f'ä¿¡é ¼åº¦ã‚’{90-confidence:.0f}ãƒã‚¤ãƒ³ãƒˆå‘ä¸Š (æœ€é«˜ç²¾åº¦ã‚’ç›®æŒ‡ã™)'
        }
    else:
        next_milestone = {
            'target': 'å®Œç’§ãªç¶­æŒ',
            'progress': 100,
            'needed': 'ç¾åœ¨ã®é«˜æ°´æº–ã‚’ç¶­æŒã—ã¦ãã ã•ã„'
        }
    
    return {
        'ready': ready,
        'confidence': confidence,
        'level': level,
        'level_desc': level_desc,
        'recommendations': recommendations,
        'stats': {
            'total_sessions': total_sessions,
            'total_pairs': total_pairs,
            'best_correlation': best_correlation,
            'avg_correlation': avg_correlation,
            'best_improvement': best_improvement,
            'avg_improvement': avg_improvement,
            'best_mae': best_mae,
            'avg_mae': avg_mae,
            'latest_correlation': latest_corr,
            'latest_mae': latest_mae,
            'latest_improvement': latest_improvement
        },
        'next_milestone': next_milestone
    }

def evaluate_ai_performance(correlation, improvement, mae):
    """
    AIå­¦ç¿’ã®æ€§èƒ½ã‚’è©•ä¾¡
    
    Args:
        correlation: ç›¸é–¢ä¿‚æ•° (0-1)
        improvement: æ”¹å–„ç‡ (%)
        mae: å¹³å‡çµ¶å¯¾èª¤å·®
    
    Returns:
        dict: è©•ä¾¡çµæœ
    """
    # ç›¸é–¢ä¿‚æ•°ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡
    if correlation >= 0.95:
        corr_grade = "S"
        corr_points = 100
    elif correlation >= 0.90:
        corr_grade = "A"
        corr_points = 90
    elif correlation >= 0.85:
        corr_grade = "B"
        corr_points = 80
    elif correlation >= 0.75:
        corr_grade = "C"
        corr_points = 70
    elif correlation >= 0.60:
        corr_grade = "D"
        corr_points = 50
    else:
        corr_grade = "F"
        corr_points = 30
    
    # æ”¹å–„ç‡ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡
    if improvement >= 80:
        improve_points = 100
    elif improvement >= 60:
        improve_points = 80
    elif improvement >= 40:
        improve_points = 60
    elif improvement >= 20:
        improve_points = 40
    elif improvement > 0:
        improve_points = 20
    else:
        improve_points = 0
    
    # MAEãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡
    if mae <= 0.01:
        mae_points = 100
    elif mae <= 0.02:
        mae_points = 90
    elif mae <= 0.03:
        mae_points = 80
    elif mae <= 0.05:
        mae_points = 70
    elif mae <= 0.08:
        mae_points = 50
    else:
        mae_points = 30
    
    # ç·åˆã‚¹ã‚³ã‚¢(é‡ã¿ä»˜ã‘: ç›¸é–¢50%, æ”¹å–„30%, MAE20%)
    total_score = (corr_points * 0.5 + improve_points * 0.3 + mae_points * 0.2)
    
    # ç·åˆè©•ä¾¡
    if total_score >= 90:
        grade = "S (å„ªç§€)"
        emoji = "ğŸŒŸ"
        comment = "ç´ æ™´ã‚‰ã—ã„æ€§èƒ½ã§ã™ï¼"
    elif total_score >= 80:
        grade = "A (è‰¯å¥½)"
        emoji = "â­"
        comment = "è‰¯å¥½ãªæ€§èƒ½ã§ã™"
    elif total_score >= 70:
        grade = "B (æ™®é€š)"
        emoji = "ğŸ‘"
        comment = "æ¨™æº–çš„ãªæ€§èƒ½ã§ã™"
    elif total_score >= 60:
        grade = "C (æ”¹å–„ã®ä½™åœ°ã‚ã‚Š)"
        emoji = "ğŸ“ˆ"
        comment = "ã•ã‚‰ãªã‚‹æ”¹å–„ãŒæœŸå¾…ã§ãã¾ã™"
    else:
        grade = "D (è¦æ”¹å–„)"
        emoji = "âš ï¸"
        comment = "ãƒ‡ãƒ¼ã‚¿é‡ã‚„å“è³ªã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™"
    
    return {
        'grade': grade,
        'emoji': emoji,
        'score': total_score,
        'comment': comment,
        'correlation_grade': corr_grade,
        'details': {
            'correlation': correlation,
            'improvement': improvement,
            'mae': mae,
            'corr_points': corr_points,
            'improve_points': improve_points,
            'mae_points': mae_points
        }
    }

def analyze_learning_growth(history):
    """
    å­¦ç¿’å±¥æ­´ã‹ã‚‰æˆé•·ã‚’åˆ†æ
    
    Args:
        history: å­¦ç¿’å±¥æ­´ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        dict: æˆé•·åˆ†æçµæœ
    """
    if len(history) < 2:
        return {
            'trend': 'ä¸æ˜',
            'trend_emoji': 'â“',
            'correlation_change': 0,
            'improvement_change': 0,
            'best_correlation': 0,
            'recommendation': 'ã¾ã å­¦ç¿’å›æ•°ãŒå°‘ãªã„ãŸã‚ã€ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ¤å®šã§ãã¾ã›ã‚“'
        }
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å«ã‚€å±¥æ­´ã®ã¿ã‚’æŠ½å‡º
    valid_history = [h for h in history if 'metrics' in h]
    
    if len(valid_history) < 2:
        return {
            'trend': 'ä¸æ˜',
            'trend_emoji': 'â“',
            'correlation_change': 0,
            'improvement_change': 0,
            'best_correlation': 0,
            'recommendation': 'è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒä¸è¶³ã—ã¦ã„ã¾ã™'
        }
    
    # æœ€æ–°ã¨å‰å›ã®æ¯”è¼ƒ
    latest = valid_history[-1]['metrics']
    previous = valid_history[-2]['metrics']
    
    corr_change = latest.get('correlation_pred', 0) - previous.get('correlation_pred', 0)
    improve_change = latest.get('improvement', 0) - previous.get('improvement', 0)
    
    # å…¨å±¥æ­´ã®æœ€é«˜è¨˜éŒ²
    best_corr = max([h['metrics'].get('correlation_pred', 0) for h in valid_history])
    best_improve = max([h['metrics'].get('improvement', 0) for h in valid_history])
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
    if corr_change > 0.05:
        trend = "å¤§å¹…æ”¹å–„"
        trend_emoji = "ğŸš€"
        recommendation = "ç´ æ™´ã‚‰ã—ã„æˆé•·ã§ã™ï¼ã“ã®èª¿å­ã§å­¦ç¿’ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚"
    elif corr_change > 0.02:
        trend = "æ”¹å–„ä¸­"
        trend_emoji = "ğŸ“ˆ"
        recommendation = "é †èª¿ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚„å“è³ªãƒ¬ãƒ™ãƒ«ã®èª¿æ•´ã§ã•ã‚‰ã«æ”¹å–„ã§ãã¾ã™ã€‚"
    elif corr_change > -0.02:
        trend = "æ¨ªã°ã„"
        trend_emoji = "â¡ï¸"
        recommendation = "æ€§èƒ½ãŒå®‰å®šã—ã¦ã„ã¾ã™ã€‚ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚„è¨­å®šã‚’è©¦ã—ã¦ã¿ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚"
    elif corr_change > -0.05:
        trend = "ã‚„ã‚„ä½ä¸‹"
        trend_emoji = "ğŸ“‰"
        recommendation = "å‰å›ã‚ˆã‚Šæ€§èƒ½ãŒä¸‹ãŒã£ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã®è³ªã‚„å¤šæ§˜æ€§ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚"
    else:
        trend = "å¤§å¹…ä½ä¸‹"
        trend_emoji = "âš ï¸"
        recommendation = "æ€§èƒ½ãŒå¤§ããä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¤‰æ›´ã—ãŸã‹ã€å¤–ã‚Œå€¤ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
    
    return {
        'trend': trend,
        'trend_emoji': trend_emoji,
        'correlation_change': corr_change,
        'improvement_change': improve_change,
        'best_correlation': best_corr,
        'best_improvement': best_improve,
        'recommendation': recommendation,
        'num_sessions': len(valid_history)
    }

def load_model(filepath="trained_fd_model.pkl"):
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    if not os.path.exists(filepath):
        return None
    with open(filepath, 'rb') as f:
        model = pickle.load(f)
    return model

def calculate_fractal_dimension(img):
    """
    ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒ†ã‚£ãƒ³ã‚°æ³•ã‚’ä½¿ç”¨ã—ã¦ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’ç›´æ¥è¨ˆç®—
    
    é«˜å“è³ªç”»åƒã‚„å“è³ªéå‰°ç”»åƒã«ä½¿ç”¨ã€‚
    AIäºˆæ¸¬ã‚’ä½¿ã‚ãšã€å®Ÿéš›ã®ç”»åƒã‹ã‚‰ç›´æ¥ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’è¨ˆç®—ã™ã‚‹ã€‚
    
    Args:
        img: å…¥åŠ›ç”»åƒ (BGR)
    
    Returns:
        dict: {
            'fd': ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒå€¤,
            'confidence': ä¿¡é ¼åº¦ (95% - ç›´æ¥è¨ˆç®—ã®ãŸã‚é«˜ã„),
            'method': 'ç›´æ¥è§£æ',
            'range': æ¨å®šç¯„å›² [min, max]
        }
    """
    try:
        # é«˜é€Ÿãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒ†ã‚£ãƒ³ã‚°æ³•ã‚’ä½¿ç”¨
        fd_value, scales, counts, log_h, log_Nh, coeffs = fast_fractal_std_boxcount_batched(img, use_gpu=False)
        
        # è¨ˆç®—å¤±æ•—æ™‚ã¯ãƒŠã‚¤ãƒ¼ãƒ–æ³•ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if fd_value is None:
            fd_value, scales, counts = fractal_dimension_naive(img)
            log_h, log_Nh, coeffs = None, None, None
        
        # ã¾ã Noneã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        if fd_value is None:
            raise ValueError("ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯2.0ã€œ3.0ã®ç¯„å›²ã«åˆ¶é™
        # ç•°å¸¸å€¤ã®å ´åˆã¯è­¦å‘Šã‚’å‡ºã—ã¦ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        if fd_value < 2.0 or fd_value > 3.0:
            print(f"Warning: ç•°å¸¸ãªãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒå€¤ã‚’æ¤œå‡º: {fd_value}, 2.0-3.0ã«ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã—ã¾ã™")
            fd_value = np.clip(fd_value, 2.0, 3.0)
        
        # ç›´æ¥è¨ˆç®—ã®ãŸã‚ã€ä¿¡é ¼åº¦ã¯95%ã¨é«˜ãè¨­å®š
        # ç¯„å›²ã¯éå¸¸ã«ç‹­ã„ (Â±0.01ç¨‹åº¦)
        confidence = 95.0
        fd_min = max(2.0, fd_value - 0.01)
        fd_max = min(3.0, fd_value + 0.01)
        
        return {
            'fd': float(fd_value),
            'confidence': confidence,
            'method': 'ç›´æ¥è§£æ (Box-Countingæ³•)',
            'range': [fd_min, fd_max],
            'fitting_data': {
                'log_h': log_h,
                'log_Nh': log_Nh,
                'coeffs': coeffs
            } if log_h is not None else None
        }
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä½ä¿¡é ¼åº¦ã®çµæœã‚’è¿”ã™
        print(f"Error in calculate_fractal_dimension: {e}")
        return {
            'fd': 2.5,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            'confidence': 10.0,
            'method': 'ç›´æ¥è§£æ (ã‚¨ãƒ©ãƒ¼)',
            'range': [2.0, 3.0],
            'error': str(e)
        }

def predict_fd_from_low_quality(low_img, model):
    """
    ä½ç”»è³ªç”»åƒã ã‘ã‹ã‚‰é«˜ç”»è³ªç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’äºˆæ¸¬
    
    Args:
        low_img: ä½ç”»è³ªç”»åƒ (BGR)
        model: å­¦ç¿’æ¸ˆã¿LightGBMãƒ¢ãƒ‡ãƒ«
    
    Returns:
        äºˆæ¸¬ã•ã‚ŒãŸãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
    """
    feat = extract_feature_vector(low_img)
    # DataFrameã«å¤‰æ›ã—ã¦ç‰¹å¾´é‡åã‚’ä»˜ä¸
    import pandas as pd
    feat_df = pd.DataFrame([feat], columns=FEATURE_NAMES)
    D_pred = float(model.predict(feat_df)[0])
    return D_pred

# ============================================================
# ä¿¡é ¼åº¦è¨ˆç®—æ©Ÿèƒ½ (Confidence Scoring)
# ============================================================
def calculate_prediction_confidence(low_img, model, predicted_fd):
    """
    äºˆæ¸¬å€¤ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—
    
    ä¿¡é ¼åº¦æŒ‡æ¨™:
    1. ç‰¹å¾´é‡å“è³ªã‚¹ã‚³ã‚¢ (0-100): å…¥åŠ›ç”»åƒã®å“è³ªè©•ä¾¡
    2. ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦ (0-100): äºˆæ¸¬ã®å®‰å®šæ€§
    3. ç·åˆä¿¡é ¼åº¦ (0-100): å…¨ä½“çš„ãªä¿¡é ¼æ€§
    
    Args:
        low_img: ä½ç”»è³ªç”»åƒ
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        predicted_fd: äºˆæ¸¬ã•ã‚ŒãŸFDå€¤
    
    Returns:
        dict: ä¿¡é ¼åº¦æƒ…å ±
    """
    feat = extract_feature_vector(low_img)
    # DataFrameã«å¤‰æ›ã—ã¦ç‰¹å¾´é‡åã‚’ä»˜ä¸
    import pandas as pd
    feat_df = pd.DataFrame([feat], columns=FEATURE_NAMES)
    
    # 1. ç‰¹å¾´é‡å“è³ªã‚¹ã‚³ã‚¢ (Feature Quality Score)
    # ã‚¨ãƒƒã‚¸å¼·åº¦ã€ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‹ã‚‰è©•ä¾¡
    mean_val, std_val, edge_strength, noise_level, entropy = feat
    
    # ã‚¨ãƒƒã‚¸å¼·åº¦ãŒé«˜ã„ = æ˜ç¢ºãªæ§‹é€  = è‰¯ã„ (0-40ç‚¹)
    edge_score = min(edge_strength / 30.0 * 40, 40)
    
    # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ãŒä½ã„ = è‰¯ã„ (0-30ç‚¹)
    noise_score = max(30 - noise_level / 10.0 * 30, 0)
    
    # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒé©åº¦ (5-7ãŒç†æƒ³) = è‰¯ã„ (0-30ç‚¹)
    entropy_diff = abs(entropy - 6.0)
    entropy_score = max(30 - entropy_diff * 10, 0)
    
    feature_quality = edge_score + noise_score + entropy_score
    feature_quality = np.clip(feature_quality, 0, 100)
    
    # 2. ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦ (Model Confidence)
    # äºˆæ¸¬å€¤ãŒå¦¥å½“ãªç¯„å›²å†…ã‹ (2.0-3.0)
    if 2.0 <= predicted_fd <= 3.0:
        range_score = 50
    elif 1.9 <= predicted_fd <= 3.1:
        range_score = 30
    else:
        range_score = 10
    
    # äºˆæ¸¬å€¤ã®å®‰å®šæ€§ (LightGBMã®å ´åˆã€æœ¨ã®äºˆæ¸¬ã®ã°ã‚‰ã¤ãã‚’æ¨å®š)
    # ç°¡æ˜“ç‰ˆ: äºˆæ¸¬å€¤ãŒæ¥µç«¯ã§ãªã„ã»ã©é«˜ã‚¹ã‚³ã‚¢
    stability_score = 50 - abs(predicted_fd - 2.5) * 20
    stability_score = np.clip(stability_score, 0, 50)
    
    model_confidence = range_score + stability_score
    model_confidence = np.clip(model_confidence, 0, 100)
    
    # 3. ç·åˆä¿¡é ¼åº¦ (Overall Confidence)
    # ç‰¹å¾´é‡å“è³ª 60%, ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦ 40%
    overall_confidence = feature_quality * 0.6 + model_confidence * 0.4
    overall_confidence = np.clip(overall_confidence, 0, 100)
    
    # ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
    if overall_confidence >= 80:
        confidence_level = "éå¸¸ã«é«˜ã„"
        level_emoji = "ğŸŸ¢"
        level_color = "success"
    elif overall_confidence >= 60:
        confidence_level = "é«˜ã„"
        level_emoji = "ğŸ”µ"
        level_color = "info"
    elif overall_confidence >= 40:
        confidence_level = "ä¸­ç¨‹åº¦"
        level_emoji = "ğŸŸ¡"
        level_color = "warning"
    else:
        confidence_level = "ä½ã„"
        level_emoji = "ğŸ”´"
        level_color = "error"
    
    # äºˆæ¸¬åŒºé–“ã®æ¨å®š (ç°¡æ˜“ç‰ˆ)
    # ä¿¡é ¼åº¦ãŒä½ã„ã»ã©åŒºé–“ãŒåºƒã„
    uncertainty = (100 - overall_confidence) / 100 * 0.1
    lower_bound = predicted_fd - uncertainty
    upper_bound = predicted_fd + uncertainty
    
    return {
        'overall_confidence': overall_confidence,
        'feature_quality': feature_quality,
        'model_confidence': model_confidence,
        'confidence_level': confidence_level,
        'level_emoji': level_emoji,
        'level_color': level_color,
        'lower_bound': lower_bound,
        'upper_bound': upper_bound,
        'uncertainty': uncertainty,
        'feature_details': {
            'edge_strength': edge_strength,
            'noise_level': noise_level,
            'entropy': entropy,
            'edge_score': edge_score,
            'noise_score': noise_score,
            'entropy_score': entropy_score
        }
    }

# fallback naive fractal (simple binary box count) used only if needed
def fractal_dimension_naive(img_bgr, scales=(2,4,8,16,32)):
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    H, W = gray.shape
    Nh = []
    valid_scales = []
    for s in scales:
        Hc = (H // s) * s
        Wc = (W // s) * s
        if Hc < s or Wc < s:
            continue
        cropped = gray[:Hc, :Wc]
        blocks = (cropped.reshape(Hc//s, s, Wc//s, s).mean(axis=(1,3)) > 127).astype(np.int32)
        Nh.append(blocks.sum() + 1e-9)
        valid_scales.append(s)
    if len(valid_scales) < 3:
        return None, np.array(scales), np.array([1]*len(scales))
    log_h = np.log(np.array(valid_scales))
    log_Nh = np.log(np.array(Nh))
    coeffs = np.polyfit(log_h, log_Nh, 1)
    return float(abs(coeffs[0])), np.array(valid_scales), np.array(Nh)

# ============================================================
# Evaluate pairs and show metrics & plots
# ============================================================
def evaluate_and_plot(high_imgs, low_imgs, model, use_gpu=None):
    if use_gpu is None:
        use_gpu = USE_CUPY

    D_high_list = []
    D_low_list = []
    D_pred_list = []
    t0 = time.time()
    for high, low in zip(high_imgs, low_imgs):
        # compute FD (fast vectorized)
        D_high, *_ = fast_fractal_std_boxcount_batched(high, use_gpu=use_gpu)
        D_low, *_ = fast_fractal_std_boxcount_batched(low, use_gpu=use_gpu)
        # predicted FD
        feat = extract_feature_vector(low)
        # DataFrameã«å¤‰æ›ã—ã¦ç‰¹å¾´é‡åã‚’ä»˜ä¸
        import pandas as pd
        feat_df = pd.DataFrame([feat], columns=FEATURE_NAMES)
        D_pred = float(model.predict(feat_df)[0])
        D_high_list.append(D_high)
        D_low_list.append(D_low)
        D_pred_list.append(D_pred)
    t1 = time.time()

    D_high_arr = np.array(D_high_list, dtype=np.float32)
    D_low_arr = np.array(D_low_list, dtype=np.float32)
    D_pred_arr = np.array(D_pred_list, dtype=np.float32)

    # metrics
    valid_mask = ~np.isnan(D_high_arr) & ~np.isnan(D_low_arr) & ~np.isnan(D_pred_arr)
    if valid_mask.sum() < 2:
        st.warning("è§£æå¯èƒ½ãªé«˜ç”»è³ªFDãŒå°‘ãªã„ãŸã‚è©•ä¾¡ã§ãã¾ã›ã‚“ã€‚")
        return D_high_list, D_low_list, D_pred_list

    # å®‰å…¨ã«ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
    r_low = 0.0
    r_pred = 0.0
    
    try:
        # æ¨™æº–åå·®ãŒ0ã®å ´åˆã¯nanã«ãªã‚‹ã®ã§å¯¾ç­–
        std_low = np.std(D_low_arr[valid_mask])
        std_high = np.std(D_high_arr[valid_mask])
        std_pred = np.std(D_pred_arr[valid_mask])
        
        if std_low > 1e-10 and std_high > 1e-10:
            r_low_val, _ = pearsonr(D_high_arr[valid_mask], D_low_arr[valid_mask])
            # nanãƒã‚§ãƒƒã‚¯
            if not np.isnan(r_low_val):
                r_low = r_low_val
            else:
                st.warning("âš ï¸ ä½ç”»è³ªã®ç›¸é–¢ä¿‚æ•°ãŒnanã§ã™(æ¨™æº–åå·®ãŒ0ã«è¿‘ã„)")
        else:
            st.warning(f"âš ï¸ ä½ç”»è³ªFDã®åˆ†æ•£ãŒ0ã«è¿‘ã„ãŸã‚ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ (std_low={std_low:.6f}, std_high={std_high:.6f})")
        
        if std_pred > 1e-10 and std_high > 1e-10:
            r_pred_val, _ = pearsonr(D_high_arr[valid_mask], D_pred_arr[valid_mask])
            # nanãƒã‚§ãƒƒã‚¯
            if not np.isnan(r_pred_val):
                r_pred = r_pred_val
            else:
                st.warning("âš ï¸ AIè£œæ­£ã®ç›¸é–¢ä¿‚æ•°ãŒnanã§ã™(æ¨™æº–åå·®ãŒ0ã«è¿‘ã„)")
                st.info(f"AIäºˆæ¸¬å€¤ã®çµ±è¨ˆ: å¹³å‡={np.mean(D_pred_arr[valid_mask]):.4f}, æ¨™æº–åå·®={std_pred:.6f}")
        else:
            st.warning(f"âš ï¸ AIäºˆæ¸¬å€¤ã®åˆ†æ•£ãŒ0ã«è¿‘ã„ãŸã‚ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ (std_pred={std_pred:.6f}, std_high={std_high:.6f})")
            st.error("ğŸ”´ **å•é¡Œ**: AIãŒå…¨ã¦åŒã˜å€¤(ã¾ãŸã¯ã»ã¼åŒã˜å€¤)ã‚’äºˆæ¸¬ã—ã¦ã„ã¾ã™!")
            st.info("ğŸ’¡ **åŸå› **: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ä¸è¶³ã€ã¾ãŸã¯ç‰¹å¾´é‡ãŒåŠ¹æœçš„ã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    except Exception as e:
        st.error(f"ç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        r_low = 0.0
        r_pred = 0.0
    
    mae_low = mean_absolute_error(D_high_arr[valid_mask], D_low_arr[valid_mask])
    mae_pred = mean_absolute_error(D_high_arr[valid_mask], D_pred_arr[valid_mask])
    
    try:
        r2_val = r2_score(D_high_arr[valid_mask], D_pred_arr[valid_mask])
        if not np.isnan(r2_val) and not np.isinf(r2_val):
            r2 = r2_val
        else:
            r2 = 0.0
            st.warning("âš ï¸ RÂ²ã‚¹ã‚³ã‚¢ãŒnanã¾ãŸã¯infã§ã™")
    except Exception as e:
        st.error(f"RÂ²ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        r2 = 0.0
    
    # æ”¹å–„åº¦ã®è¨ˆç®—
    improvement = ((mae_low - mae_pred) / mae_low) * 100 if mae_low > 0 else 0
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    with st.expander("ğŸ” è¨ˆç®—å€¤ã®è©³ç´° (ãƒ‡ãƒãƒƒã‚°ç”¨)"):
        st.write("### åŸºæœ¬çµ±è¨ˆ")
        st.write(f"**ç›¸é–¢ä¿‚æ•° (ä½ç”»è³ª):** r_low = {r_low}")
        st.write(f"**ç›¸é–¢ä¿‚æ•° (AIè£œæ­£):** r_pred = {r_pred}")
        st.write(f"**MAE (ä½ç”»è³ª):** mae_low = {mae_low}")
        st.write(f"**MAE (AIè£œæ­£):** mae_pred = {mae_pred}")
        st.write(f"**RÂ² ã‚¹ã‚³ã‚¢:** r2 = {r2}")
        st.write(f"**æ”¹å–„åº¦:** {improvement}%")
        st.write(f"**æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«æ•°:** {valid_mask.sum()} / {len(D_high_arr)}")
        
        st.write("### AIäºˆæ¸¬å€¤ã®åˆ†æ")
        st.write(f"**äºˆæ¸¬å€¤ã®å¹³å‡:** {np.mean(D_pred_arr[valid_mask]):.4f}")
        st.write(f"**äºˆæ¸¬å€¤ã®æ¨™æº–åå·®:** {np.std(D_pred_arr[valid_mask]):.4f}")
        st.write(f"**äºˆæ¸¬å€¤ã®æœ€å°å€¤:** {np.min(D_pred_arr[valid_mask]):.4f}")
        st.write(f"**äºˆæ¸¬å€¤ã®æœ€å¤§å€¤:** {np.max(D_pred_arr[valid_mask]):.4f}")
        st.write(f"**äºˆæ¸¬å€¤ã®ç¯„å›²:** {np.max(D_pred_arr[valid_mask]) - np.min(D_pred_arr[valid_mask]):.4f}")
        
        st.write("### é«˜ç”»è³ªFDã®åˆ†æ")
        st.write(f"**é«˜ç”»è³ªã®å¹³å‡:** {np.mean(D_high_arr[valid_mask]):.4f}")
        st.write(f"**é«˜ç”»è³ªã®æ¨™æº–åå·®:** {np.std(D_high_arr[valid_mask]):.4f}")
        st.write(f"**é«˜ç”»è³ªã®æœ€å°å€¤:** {np.min(D_high_arr[valid_mask]):.4f}")
        st.write(f"**é«˜ç”»è³ªã®æœ€å¤§å€¤:** {np.max(D_high_arr[valid_mask]):.4f}")
        
        # RÂ²ãŒ0ã«ãªã‚‹ç†ç”±ã‚’èª¬æ˜
        if r2 <= 0.01:
            st.error("âš ï¸ **RÂ²ã‚¹ã‚³ã‚¢ãŒ0ã«è¿‘ã„ç†ç”±:**")
            if np.std(D_pred_arr[valid_mask]) < 0.001:
                st.write("- AIãŒ**ã»ã¼åŒã˜å€¤**ã°ã‹ã‚Šäºˆæ¸¬ã—ã¦ã„ã¾ã™(äºˆæ¸¬å€¤ã®æ¨™æº–åå·®ãŒ0ã«è¿‘ã„)")
                st.write("- ã“ã‚Œã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ä¸è¶³ã€ã¾ãŸã¯ç‰¹å¾´é‡ãŒåŠ¹æœçš„ã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            else:
                st.write("- AIã®äºˆæ¸¬ãŒæ­£è§£å€¤ã¨å…¨ãç›¸é–¢ã—ã¦ã„ã¾ã›ã‚“")
                st.write("- ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒé©åˆ‡ã«è¡Œã‚ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")

    # è©•ä¾¡æŒ‡æ¨™ã‚’è¦‹ã‚„ã™ãè¡¨ç¤º
    st.subheader("ğŸ“Š AIæ€§èƒ½è©•ä¾¡")
    st.markdown("""
    **å„æŒ‡æ¨™ã®æ„å‘³:**
    - ğŸ¯ **æ”¹å–„åº¦**: ä½ç”»è³ªã®èª¤å·®ã‹ã‚‰ã©ã‚Œã ã‘æ”¹å–„ã—ãŸã‹ (é«˜ã„ã»ã©è‰¯ã„)
    - ğŸ“ˆ **ç›¸é–¢ä¿‚æ•°**: äºˆæ¸¬å€¤ã¨æ­£è§£å€¤ã®ä¸€è‡´åº¦ (1.0ã§å®Œå…¨ä¸€è‡´ã€0ã§ç„¡ç›¸é–¢)
    - ğŸ“‰ **MAE**: å¹³å‡çµ¶å¯¾èª¤å·® (å°ã•ã„ã»ã©æ­£ç¢º)
    - ğŸ”¢ **RÂ²**: ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ› (1.0ã§å®Œç’§ã€0ä»¥ä¸‹ã§ãƒ©ãƒ³ãƒ€ãƒ ä»¥ä¸‹)
    """)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric(
            label="ğŸ¯ æ”¹å–„åº¦",
            value=f"{improvement:.1f}%",
            delta=f"{mae_low-mae_pred:.4f}",
            help="ä½ç”»è³ªã‹ã‚‰AIè£œæ­£ã§ã©ã‚Œã ã‘èª¤å·®ãŒæ¸›ã£ãŸã‹ã€‚æ­£ã®å€¤ã¯æ”¹å–„ã€è² ã®å€¤ã¯æ‚ªåŒ–ã‚’æ„å‘³ã—ã¾ã™ã€‚"
        )
        if improvement > 50:
            st.success("âœ… å¤§å¹…æ”¹å–„")
        elif improvement > 20:
            st.info("ğŸ‘ è‰¯å¥½ãªæ”¹å–„")
        elif improvement > 0:
            st.warning("âš ï¸ ã‚ãšã‹ãªæ”¹å–„")
        else:
            st.error("âŒ æ”¹å–„ãªã—")
            
    with col2:
        # nanãƒã‚§ãƒƒã‚¯
        r_pred_display = "N/A" if np.isnan(r_pred) else f"{r_pred:.4f}"
        r_low_safe = 0.0 if np.isnan(r_low) else r_low
        r_pred_safe = 0.0 if np.isnan(r_pred) else r_pred
        delta_r = r_pred_safe - r_low_safe
        
        st.metric(
            label="ğŸ“ˆ ç›¸é–¢ä¿‚æ•° (AI)",
            value=r_pred_display,
            delta=f"+{delta_r:.4f}" if delta_r > 0 else f"{delta_r:.4f}" if not np.isnan(delta_r) else "N/A",
            help="AIè£œæ­£å¾Œã®å€¤ã¨é«˜ç”»è³ªFDã®ç›¸é–¢ã€‚1.0ã«è¿‘ã„ã»ã©äºˆæ¸¬ãŒæ­£ç¢ºã§ã™ã€‚"
        )
        
        if np.isnan(r_pred):
            st.error("âŒ è¨ˆç®—ä¸å¯ (nanã‚¨ãƒ©ãƒ¼)")
        elif r_pred > 0.9:
            st.success("âœ… éå¸¸ã«é«˜ã„ç›¸é–¢")
        elif r_pred > 0.7:
            st.info("ğŸ‘ è‰¯å¥½ãªç›¸é–¢")
        elif r_pred > 0.5:
            st.warning("âš ï¸ ä¸­ç¨‹åº¦ã®ç›¸é–¢")
        else:
            st.error("âŒ ä½ã„ç›¸é–¢")
            
    with col3:
        # nanãƒã‚§ãƒƒã‚¯
        mae_display = "N/A" if np.isnan(mae_pred) else f"{mae_pred:.4f}"
        mae_low_safe = mae_low if not np.isnan(mae_low) else 0.0
        mae_pred_safe = mae_pred if not np.isnan(mae_pred) else 0.0
        delta_mae = mae_low_safe - mae_pred_safe
        
        st.metric(
            label="ğŸ“‰ MAE (AIè£œæ­£)",
            value=mae_display,
            delta=f"-{delta_mae:.4f}" if not np.isnan(delta_mae) else "N/A",
            delta_color="inverse",
            help="AIè£œæ­£å¾Œã®å¹³å‡çµ¶å¯¾èª¤å·®ã€‚å°ã•ã„ã»ã©æ­£ç¢ºãªäºˆæ¸¬ã§ã™ã€‚"
        )
        
        if np.isnan(mae_pred):
            st.error("âŒ è¨ˆç®—ä¸å¯ (nanã‚¨ãƒ©ãƒ¼)")
        elif mae_pred < 0.01:
            st.success("âœ… éå¸¸ã«æ­£ç¢º")
        elif mae_pred < 0.05:
            st.info("ğŸ‘ è‰¯å¥½ãªç²¾åº¦")
        elif mae_pred < 0.1:
            st.warning("âš ï¸ ä¸­ç¨‹åº¦ã®ç²¾åº¦")
        else:
            st.error("âŒ ä½ã„ç²¾åº¦")
            
    with col4:
        # nanãƒã‚§ãƒƒã‚¯
        r2_display = "N/A" if (np.isnan(r2) or np.isinf(r2)) else f"{r2:.4f}"
        st.metric(
            label="ğŸ”¢ R-squared",
            value=r2_display,
            help=f"æ±ºå®šä¿‚æ•°ã€‚ãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ãƒ¼ã‚¿ã‚’ã©ã‚Œã ã‘èª¬æ˜ã§ãã‚‹ã‹ã€‚1.0ã§å®Œç’§ã€0ä»¥ä¸‹ã¯ãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ä»¥ä¸‹ã§ã™ã€‚"
        )
        
        if np.isnan(r2) or np.isinf(r2):
            st.error("âŒ è¨ˆç®—ä¸å¯ (nanã¾ãŸã¯infã‚¨ãƒ©ãƒ¼)")
        elif r2 > 0.8:
            st.success("âœ… å„ªã‚ŒãŸãƒ¢ãƒ‡ãƒ«")
        elif r2 > 0.5:
            st.info("ğŸ‘ è‰¯å¥½ãªãƒ¢ãƒ‡ãƒ«")
        elif r2 > 0.2:
            st.warning("âš ï¸ æ”¹å–„ã®ä½™åœ°ã‚ã‚Š")
        else:
            st.error("âŒ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ä¸è¶³")
    
    # ğŸ” è‡ªå‹•è¨ºæ–­ã¨æ”¹å–„ææ¡ˆ
    st.markdown("---")
    st.subheader("ğŸ” çµæœã®è¨ºæ–­ã¨æ”¹å–„ææ¡ˆ")
    
    problems = []
    suggestions = []
    
    # è¨ºæ–­1: æ”¹å–„åº¦
    if improvement < 0:
        problems.append("âŒ **æ”¹å–„åº¦ãŒè² **: AIãŒä½ç”»è³ªã‚ˆã‚Šã‚‚æ‚ªã„äºˆæ¸¬ã‚’ã—ã¦ã„ã¾ã™")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã™ (ç¾åœ¨: {}çµ„ â†’ æ¨å¥¨: 20çµ„ä»¥ä¸Š)".format(len(high_imgs)))
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ç•°ãªã‚‹å“è³ªãƒ¬ãƒ™ãƒ« (low2, low3) ã‚’è©¦ã™")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ã‚ˆã‚Šå¤šæ§˜ãªã‚·ãƒ¼ãƒ³ãƒ»è¢«å†™ä½“ã®ç”»åƒã‚’è¿½åŠ ")
    elif improvement < 20:
        problems.append("âš ï¸ **æ”¹å–„åº¦ãŒä½ã„**: AIè£œæ­£ã®åŠ¹æœãŒé™å®šçš„ã§ã™")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ç”»åƒã®å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™ (ç•°ãªã‚‹ã‚·ãƒ¼ãƒ³ãƒ»è¢«å†™ä½“)")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ã‚ˆã‚Šä½å“è³ªãªç”»åƒãƒ¬ãƒ™ãƒ« (low2, low3) ã‚’è©¦ã™")
    
    # è¨ºæ–­2: ç›¸é–¢ä¿‚æ•°
    if np.isnan(r_pred) or r_pred <= 0.0:
        problems.append("âŒ **ç›¸é–¢ä¿‚æ•°ãŒ0ã¾ãŸã¯N/A**: AIãŒæœ‰åŠ¹ãªäºˆæ¸¬ã‚’ã—ã¦ã„ã¾ã›ã‚“")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ç”»åƒãƒšã‚¢æ•°ã‚’å¤§å¹…ã«å¢—ã‚„ã™ (æ¨å¥¨: 30çµ„ä»¥ä¸Š)")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: é«˜ç”»è³ªã¨ä½ç”»è³ªã®å·®ãŒæ˜ç¢ºãªãƒšã‚¢ã‚’ä½¿ç”¨")
    elif r_pred < 0.5:
        problems.append("âš ï¸ **ç›¸é–¢ä¿‚æ•°ãŒä½ã„**: äºˆæ¸¬ç²¾åº¦ãŒä¸ååˆ†ã§ã™")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ã‚ˆã‚Šå¤šãã®ç”»åƒãƒšã‚¢ã§å­¦ç¿’ (æ¨å¥¨: 15çµ„ä»¥ä¸Š)")
    
    # è¨ºæ–­3: RÂ²ã‚¹ã‚³ã‚¢
    if r2 <= 0:
        problems.append("âŒ **RÂ²ã‚¹ã‚³ã‚¢ãŒ0ä»¥ä¸‹**: ãƒ¢ãƒ‡ãƒ«ãŒãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ä»¥ä¸‹ã®æ€§èƒ½")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®è³ªã‚’è¦‹ç›´ã™ (åŒã˜ã‚ˆã†ãªç”»åƒã°ã‹ã‚Šã«ãªã£ã¦ã„ãªã„ã‹)")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã™")
    elif r2 < 0.3:
        problems.append("âš ï¸ **RÂ²ã‚¹ã‚³ã‚¢ãŒä½ã„**: ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ›ãŒä¸è¶³")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™")
    
    # è¨ºæ–­4: MAE
    if mae_pred > 0.1:
        problems.append("âš ï¸ **MAEãŒå¤§ãã„**: äºˆæ¸¬èª¤å·®ãŒå¤§ãã„ã§ã™")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ã‚ˆã‚Šå¤šãã®ã‚µãƒ³ãƒ—ãƒ«ã§å­¦ç¿’")
    
    # è¨ºæ–­5: ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§
    if len(high_imgs) < 10:
        problems.append(f"âš ï¸ **ç”»åƒãƒšã‚¢æ•°ãŒå°‘ãªã„**: ç¾åœ¨{len(high_imgs)}çµ„ (æ¨å¥¨: 10çµ„ä»¥ä¸Š)")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ã‚ˆã‚Šå¤šãã®ç”»åƒãƒšã‚¢ã‚’è¿½åŠ ã—ã¦ãã ã•ã„")
    
    # çµæœè¡¨ç¤º
    if problems:
        st.warning("### âš ï¸ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ")
        for problem in problems:
            st.markdown(problem)
        
        st.info("### ğŸ’¡ æ¨å¥¨ã•ã‚Œã‚‹æ”¹å–„ç­–")
        for suggestion in suggestions:
            st.markdown(suggestion)
        
        # å…·ä½“çš„ãªæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
        st.success("""
        ### ğŸ“ æ¬¡ã«è©¦ã™ã“ã¨ (å„ªå…ˆé †ä½é †)
        
        1. **ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã™**
           - ç›®æ¨™: 20çµ„ä»¥ä¸Š (ç¾åœ¨: {}çµ„)
           - ã‚ˆã‚Šå¤šæ§˜ãªã‚·ãƒ¼ãƒ³ãƒ»è¢«å†™ä½“ã‚’å«ã‚ã‚‹
        
        2. **å“è³ªãƒ¬ãƒ™ãƒ«ã‚’å¤‰æ›´**
           - ç¾åœ¨ä½¿ç”¨ä¸­ã®ãƒ¬ãƒ™ãƒ«ã§åŠ¹æœãŒè–„ã„å ´åˆ
           - low1 â†’ low2 â†’ low3 ã®é †ã«è©¦ã™
        
        3. **ç”»åƒã®è³ªã‚’ç¢ºèª**
           - é«˜ç”»è³ªã¨ä½ç”»è³ªã®å·®ãŒæ˜ç¢ºã‹
           - åŒã˜ã‚ˆã†ãªç”»åƒã°ã‹ã‚Šã«ãªã£ã¦ã„ãªã„ã‹
        
        4. **ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™**
           - ç•°ãªã‚‹ç…§æ˜æ¡ä»¶
           - ç•°ãªã‚‹è¢«å†™ä½“
           - ç•°ãªã‚‹ã‚¢ãƒ³ã‚°ãƒ«
        """.format(len(high_imgs)))
    else:
        st.success("""
        ### âœ… è‰¯å¥½ãªçµæœã§ã™!
        
        ç¾åœ¨ã®è¨­å®šã§ååˆ†ãªæ€§èƒ½ãŒå‡ºã¦ã„ã¾ã™ã€‚
        
        **ã•ã‚‰ã«æ”¹å–„ã—ãŸã„å ´åˆ:**
        - ã‚ˆã‚Šå¤šãã®ç”»åƒãƒšã‚¢ã‚’è¿½åŠ  (ç²¾åº¦å‘ä¸Š)
        - ç•°ãªã‚‹å“è³ªãƒ¬ãƒ™ãƒ«ã‚’è©¦ã™ (æ±ç”¨æ€§å‘ä¸Š)
        """)
    
    st.markdown("---")
    
    # æ¯”è¼ƒè¡¨ (è©³ç´°èª¬æ˜ä»˜ã)
    st.subheader("ğŸ“‹ ä½ç”»è³ª vs AIè£œæ­£ æ¯”è¼ƒ")
    st.markdown("""
    **ã“ã®è¡¨ã®è¦‹æ–¹:**
    - **ä½ç”»è³ª(è£œæ­£ãªã—)**: ä½ç”»è³ªç”»åƒã‹ã‚‰ç›´æ¥è¨ˆç®—ã—ãŸãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ€§èƒ½
    - **AIè£œæ­£å¾Œ**: AIãŒä½ç”»è³ªç”»åƒã‹ã‚‰é«˜ç”»è³ªç›¸å½“ã®FDã‚’äºˆæ¸¬ã—ãŸçµæœ
    - **æ”¹å–„**: AIè£œæ­£ã«ã‚ˆã£ã¦ã©ã‚Œã ã‘æ€§èƒ½ãŒå‘ä¸Šã—ãŸã‹ (ãƒ—ãƒ©ã‚¹ã¯æ”¹å–„ã€ãƒã‚¤ãƒŠã‚¹ã¯æ‚ªåŒ–)
    """)
    
    import pandas as pd
    comparison_df = pd.DataFrame({
        "æŒ‡æ¨™": ["ç›¸é–¢ä¿‚æ•° (r)", "å¹³å‡çµ¶å¯¾èª¤å·® (MAE)", "R-squared", "å‡¦ç†æ™‚é–“"],
        "ä½ç”»è³ª(è£œæ­£ãªã—)": [f"{r_low:.4f}", f"{mae_low:.4f}", "-", "-"],
        "AIè£œæ­£å¾Œ": [f"{r_pred:.4f}", f"{mae_pred:.4f}", f"{r2:.4f}", f"{t1-t0:.2f}ç§’"],
        "æ”¹å–„": [
            f"+{r_pred-r_low:.4f}" if r_pred > r_low else f"{r_pred-r_low:.4f}",
            f"-{mae_low-mae_pred:.4f}" if mae_pred < mae_low else f"+{mae_pred-mae_low:.4f}",
            "-",
            "-"
        ]
    })
    
    # è¡¨ã‚’è¦‹ã‚„ã™ãè¡¨ç¤º
    st.dataframe(
        comparison_df, 
        use_container_width=True, 
        hide_index=True,
        column_config={
            "æŒ‡æ¨™": st.column_config.TextColumn("æŒ‡æ¨™", width="medium"),
            "ä½ç”»è³ª(è£œæ­£ãªã—)": st.column_config.TextColumn("ä½ç”»è³ª(è£œæ­£ãªã—)", width="medium"),
            "AIè£œæ­£å¾Œ": st.column_config.TextColumn("AIè£œæ­£å¾Œ", width="medium"),
            "æ”¹å–„": st.column_config.TextColumn("æ”¹å–„", width="medium"),
        }
    )

    # scatter plot (è©³ç´°èª¬æ˜ä»˜ã)
    st.subheader("ğŸ“ˆ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ æ¯”è¼ƒã‚°ãƒ©ãƒ•")
    
    st.markdown("""
    ### ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹
    
    **æ¨ªè»¸ (Xè»¸)**: é«˜ç”»è³ªãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ = **æ­£è§£å€¤** (ç›®æ¨™ã¨ã™ã‚‹å€¤)
    
    **ç¸¦è»¸ (Yè»¸)**: äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ = ä½ç”»è³ªã‹ã‚‰æ¨å®šã—ãŸå€¤
    
    **ğŸ”µ é’ã„ä¸¸**: ä½ç”»è³ªç”»åƒã‹ã‚‰ç›´æ¥è¨ˆç®—ã—ãŸFD (è£œæ­£ãªã—)
    - æ­£è§£å€¤ã‹ã‚‰å¤§ãããšã‚Œã¦ã„ã‚‹ = ä½ç”»è³ªã§ã¯æ­£ç¢ºã«æ¸¬å®šã§ããªã„
    
    **ğŸ”º èµ¤ã„ä¸‰è§’**: AIãŒä½ç”»è³ªã‹ã‚‰äºˆæ¸¬ã—ãŸFD (AIè£œæ­£å¾Œ)
    - é»’ã„ç‚¹ç·šã«è¿‘ã„ã»ã© = é«˜ç”»è³ªç›¸å½“ã®æ­£ç¢ºãªå€¤ã‚’äºˆæ¸¬ã§ãã¦ã„ã‚‹
    
    **âš« é»’ã„ç‚¹ç·š**: å®Œå…¨ä¸€è‡´ãƒ©ã‚¤ãƒ³ (äºˆæ¸¬=æ­£è§£ã¨ãªã‚‹ç†æƒ³çš„ãªçŠ¶æ…‹)
    - ã“ã®ç·šä¸Šã«ã‚ã‚Œã°å®Œç’§ãªäºˆæ¸¬
    
    **ç†æƒ³çš„ãªçµæœ**: èµ¤ã„ä¸‰è§’ãŒé»’ã„ç‚¹ç·šã«æ²¿ã£ã¦ä¸¦ã³ã€é’ã„ä¸¸ã‚ˆã‚Šã‚‚ç‚¹ç·šã«è¿‘ã„
    """)
    
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š(æ–‡å­—åŒ–ã‘å¯¾ç­–)
    try:
        import matplotlib
        matplotlib.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'sans-serif']
        matplotlib.rcParams['axes.unicode_minus'] = False
    except:
        pass
    
    # ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºã‚’å°ã•ãèª¿æ•´
    fig = plt.figure(figsize=(7,5))
    
    # ä½ç”»è³ªã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    plt.scatter(D_high_arr, D_low_arr, 
                label='ä½ç”»è³ª (è£œæ­£ãªã—)', 
                alpha=0.6, s=80, c='#1f77b4', 
                edgecolors='darkblue', linewidth=1.2)
    
    # AIè£œæ­£ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    plt.scatter(D_high_arr, D_pred_arr, 
                label='AIè£œæ­£å¾Œ', 
                alpha=0.9, s=100, c='#ff7f0e', 
                marker='^', edgecolors='darkred', linewidth=1.2)
    
    # ç†æƒ³çš„ãªä¸€è‡´ãƒ©ã‚¤ãƒ³
    plt.plot([2.0,3.0],[2.0,3.0],'k--', linewidth=1.5, label='å®Œå…¨ä¸€è‡´ãƒ©ã‚¤ãƒ³', alpha=0.5)
    
    plt.xlabel('é«˜ç”»è³ªãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ (æ­£è§£å€¤)', fontsize=11, fontweight='bold')
    plt.ylabel('äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ', fontsize=11, fontweight='bold')
    plt.title(f'AIè£œæ­£åŠ¹æœ\nç›¸é–¢: {r_pred:.4f} | MAE: {mae_pred:.4f} | RÂ²: {r2:.4f}', 
              fontsize=12, fontweight='bold', pad=15)
    plt.legend(fontsize=9, loc='upper left', framealpha=0.9)
    plt.grid(True, alpha=0.3, linestyle='--')
    plt.tick_params(labelsize=10)
    
    # è»¸ã®ç¯„å›²ã‚’è‡ªå‹•èª¿æ•´
    all_vals = np.concatenate([D_high_arr, D_low_arr, D_pred_arr])
    vmin, vmax = np.nanmin(all_vals), np.nanmax(all_vals)
    margin = (vmax - vmin) * 0.1
    plt.xlim(vmin - margin, vmax + margin)
    plt.ylim(vmin - margin, vmax + margin)
    
    plt.tight_layout()
    
    # ã‚°ãƒ©ãƒ•ã‚’ä¸­å¤®å¯„ã›ã§è¡¨ç¤º (ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆ)
    col_left, col_center, col_right = st.columns([1, 3, 1])
    with col_center:
        st.pyplot(fig, use_container_width=False)
    plt.close(fig)
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’session_stateã«ä¿å­˜
    st.session_state['metrics'] = {
        'correlation_low': float(r_low),
        'correlation_pred': float(r_pred),
        'mae_low': float(mae_low),
        'mae_pred': float(mae_pred),
        'r2_score': float(r2),
        'improvement': float(improvement),
        'num_samples': int(valid_mask.sum())
    }

    return D_high_list, D_low_list, D_pred_list

# ============================================================
# ç ”ç©¶å ±å‘Šãƒ»å“è³ªã‚¬ã‚¤ãƒ‰è¡¨ç¤ºé–¢æ•°
# ============================================================
def show_quality_optimization_report():
    """å“è³ªãƒ¬ãƒ™ãƒ«æœ€é©åŒ–ç ”ç©¶å ±å‘Šã‚’è¡¨ç¤º"""
    
    st.header("ğŸ“Š å“è³ªãƒ¬ãƒ™ãƒ«æœ€é©åŒ–ç ”ç©¶å ±å‘Š")
    st.markdown("**ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒäºˆæ¸¬ã«ãŠã‘ã‚‹æœ€é©JPEGå“è³ªãƒ¬ãƒ™ãƒ«ã®ç§‘å­¦çš„æ¤œè¨¼**")
    
    # ã‚¿ãƒ–ã§æ§‹æˆ
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ¯ çµè«–ãƒ»æ¨å¥¨äº‹é …",
        "ğŸ“Š å®Œå…¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿", 
        "ğŸ”¬ é‡è¦ãªç™ºè¦‹",
        "ğŸ’¡ å®Ÿç”¨ã‚¬ã‚¤ãƒ‰",
        "ğŸ“ˆ è©³ç´°åˆ†æ",
        "ğŸ“š ç ”ç©¶è©³ç´°"
    ])
    
    # ã‚¿ãƒ–1: çµè«–ãƒ»æ¨å¥¨äº‹é …
    with tab1:
        st.markdown("## ğŸ¯ ç ”ç©¶ã®çµè«–ã¨å®Ÿç”¨æ¨å¥¨")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æœ€å„ªç§€ãƒ¬ãƒ™ãƒ«", "Low5", "MAE 0.0094")
        with col2:
            st.metric("Golden Zone", "Low4-7", "å¹³å‡MAE 0.0124")
        with col3:
            st.metric("ä¿¡é ¼æ€§", "100%", "èª¤å·®<0.05é”æˆ")
        
        st.markdown("---")
        
        st.markdown("### ğŸ“Œ ä½•ãŒåˆ†ã‹ã£ãŸã‹?")
        st.success("""
        **5ã¤ã®é‡è¦ãªç™ºè¦‹:**
        
        1. **æœ€å„ªç§€ãƒ¬ãƒ™ãƒ«**: Low5ãŒå…¨ãƒ¬ãƒ™ãƒ«ä¸­æœ€é«˜ç²¾åº¦ (MAE 0.0094, 0.94%)
        2. **Golden Zone**: Low4-7ãŒæœ€é©å‹•ä½œç¯„å›² (å…¨ã‚±ãƒ¼ã‚¹ã§èª¤å·®<0.05ã‚’é”æˆ)
        3. **Uå­—å‹ã‚«ãƒ¼ãƒ–**: é«˜ç”»è³ªãƒ»ä½ç”»è³ªã®ä¸¡ç«¯ã§æ€§èƒ½åŠ£åŒ–
        4. **è‡¨ç•Œå¢ƒç•Œ**: Low7â†’Low8ã§6.62å€ã®æ€§èƒ½æ‚ªåŒ–
        5. **å¸¸è­˜ã®å¦å®š**: Low1(æœ€é«˜ç”»è³ª)ãŒLow5ã‚ˆã‚Š6.84å€æ‚ªã„
        """)
        
        st.markdown("### ğŸ’¡ ã©ã†ç”Ÿã‹ã›ã‚‹ã‹?")
        
        # ç”¨é€”åˆ¥æ¨å¥¨è¡¨
        st.markdown("#### ç”¨é€”åˆ¥ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹")
        recommendations_df = {
            "ç”¨é€”": ["ğŸ¥ è‡¨åºŠãƒ»ç ”ç©¶", "ğŸ’¼ å•†ç”¨ã‚¢ãƒ—ãƒª", "ğŸ” ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°", "ğŸ“š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯", "âŒ é¿ã‘ã‚‹ã¹ã", "ğŸš« ä½¿ç”¨ç¦æ­¢"],
            "æ¨å¥¨ãƒ¬ãƒ™ãƒ«": ["Low5", "Low4-6", "Low3-7", "Low4-6", "Low1-2", "Low8-10"],
            "æœŸå¾…MAE": ["0.0094", "< 0.015", "< 0.04", "< 0.015", "> 0.055", "> 0.10"],
            "æœŸå¾…èª¤å·®%": ["0.94%", "< 1.5%", "< 4%", "< 1.5%", "> 5.5%", "> 10%"],
            "ç†ç”±": [
                "æœ€é«˜ç²¾åº¦ãƒ»æœ€é«˜ä¿¡é ¼æ€§",
                "ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆã®ãƒãƒ©ãƒ³ã‚¹",
                "å¤§è¦æ¨¡å‡¦ç†ã«é©åˆ",
                "æ¨™æº–åŒ–ãƒ»å†ç¾æ€§é‡è¦–",
                "éå­¦ç¿’ãƒªã‚¹ã‚¯",
                "æƒ…å ±æå¤±æ·±åˆ»"
            ]
        }
        import pandas as pd
        st.dataframe(pd.DataFrame(recommendations_df), use_container_width=True)
        
        st.markdown("---")
        
        st.markdown("### ğŸ¯ å®Ÿè£…ã¸ã®å½±éŸ¿")
        col1, col2 = st.columns(2)
        
        with col1:
            st.info("""
            **ã™ãã«å®Ÿè·µã§ãã‚‹ã“ã¨:**
            
            âœ… å“è³ªãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’**Low5**ã«è¨­å®š
            
            âœ… Golden Zone (Low4-7)ã‚’æ¨å¥¨ç¯„å›²ã¨ã—ã¦å¼·èª¿
            
            âœ… Low1-2, Low8-10ä½¿ç”¨æ™‚ã«è­¦å‘Šè¡¨ç¤º
            
            âœ… äºˆæ¸¬æ™‚ã«æœŸå¾…ç²¾åº¦ã‚’æç¤º
            """)
        
        with col2:
            st.warning("""
            **é–‹ç™ºã«ãŠã‘ã‚‹æ³¨æ„ç‚¹:**
            
            âš ï¸ é«˜ç”»è³ª â‰  é«˜ç²¾åº¦ (å¸¸è­˜ã®å¦å®š)
            
            âš ï¸ Low7/Low8å¢ƒç•Œã¯çµ¶å¯¾ã«è¶…ãˆãªã„
            
            âš ï¸ å…¥åŠ›ç”»åƒã‚’è‡ªå‹•çš„ã«Low5ç›¸å½“ã«æœ€é©åŒ–
            
            âš ï¸ å“è³ªãƒ¬ãƒ™ãƒ«é¸æŠUIã‚’æ”¹å–„
            """)
        
        st.markdown("---")
        
        st.markdown("### ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ")
        st.success("""
        **ã“ã®çŸ¥è¦‹ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§:**
        
        ğŸ¯ **ç²¾åº¦å‘ä¸Š**: æœ€é©å“è³ªãƒ¬ãƒ™ãƒ«é¸æŠã«ã‚ˆã‚Šäºˆæ¸¬ç²¾åº¦ãŒæœ€å¤§6.84å€æ”¹å–„
        
        ğŸ’° **ã‚³ã‚¹ãƒˆå‰Šæ¸›**: ä¸è¦ãªé«˜ç”»è³ªåŒ–å‡¦ç†ã‚’å‰Šæ¸›ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æœ€é©åŒ–
        
        âš¡ **å‡¦ç†é«˜é€ŸåŒ–**: é©åˆ‡ãªå“è³ªãƒ¬ãƒ™ãƒ«ã§å‡¦ç†æ™‚é–“çŸ­ç¸®
        
        ğŸ”¬ **å†ç¾æ€§å‘ä¸Š**: ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ãæ¨™æº–åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«
        
        ğŸ“Š **ä¿¡é ¼æ€§ç¢ºä¿**: 100%ã®è¨±å®¹èª¤å·®é”æˆ(Golden Zone)
        """)
    
    # ã‚¿ãƒ–2: å®Œå…¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
    with tab2:
        st.markdown("## ğŸ“Š å…¨å“è³ªãƒ¬ãƒ™ãƒ«ã®æ€§èƒ½ä¸€è¦§")
        
        # å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        quality_data = {
            "å“è³ªãƒ¬ãƒ™ãƒ«": ["Low1", "Low2", "Low3", "Low4", "Low5", "Low6", "Low7", "Low8", "Low9", "Low10"],
            "MAE": [0.0643, 0.0559, 0.0356, 0.0099, 0.0094, 0.0142, 0.0160, 0.1059, 0.1119, 0.1205],
            "å¹³å‡èª¤å·®%": [2.42, 2.10, 1.34, 0.37, 0.35, 0.53, 0.60, 3.98, 4.21, 4.53],
            "æœ€å¤§èª¤å·®": [0.1548, 0.1724, 0.1282, 0.0338, 0.0281, 0.0420, 0.0373, 0.3614, 0.3473, 0.4609],
            "æœ€æ‚ªèª¤å·®%": [6.16, 6.90, 5.13, 1.31, 1.02, 1.52, 1.35, 12.64, 12.15, 16.12],
            "Low5æ¯”": ["6.84Ã—", "5.95Ã—", "3.79Ã—", "1.05Ã—", "1.00Ã—", "1.51Ã—", "1.70Ã—", "11.27Ã—", "11.90Ã—", "12.82Ã—"],
            "è©•ä¾¡": ["âš ï¸ ä¸­", "âš ï¸ ä¸­", "âœ¨ è‰¯", "ğŸŒŸ å„ªç§€", "ğŸŒŸ æœ€å„ªç§€", "ğŸŒŸ å„ªç§€", "ğŸŒŸ å„ªç§€", "âŒ ä¸è‰¯", "âŒ ä¸è‰¯", "âŒ æœ€ä¸è‰¯"]
        }
        df = pd.DataFrame(quality_data)
        
        # èƒŒæ™¯è‰²ä»˜ãã§è¡¨ç¤º
        def highlight_quality(row):
            if row["å“è³ªãƒ¬ãƒ™ãƒ«"] == "Low5":
                return ['background-color: #90EE90'] * len(row)  # æœ€å„ªç§€: ç·‘
            elif row["å“è³ªãƒ¬ãƒ™ãƒ«"] in ["Low4", "Low6", "Low7"]:
                return ['background-color: #FFE4B5'] * len(row)  # Golden Zone: è–„ã‚ªãƒ¬ãƒ³ã‚¸
            elif row["å“è³ªãƒ¬ãƒ™ãƒ«"] in ["Low8", "Low9", "Low10"]:
                return ['background-color: #FFB6C1'] * len(row)  # ä¸è‰¯: è–„èµ¤
            elif row["å“è³ªãƒ¬ãƒ™ãƒ«"] in ["Low1", "Low2"]:
                return ['background-color: #FFFFE0'] * len(row)  # éå­¦ç¿’: è–„é»„
            else:
                return [''] * len(row)
        
        st.dataframe(df.style.apply(highlight_quality, axis=1), use_container_width=True)
        
        st.caption("""
        **å‡¡ä¾‹:**
        ğŸŸ¢ ç·‘: æœ€å„ªç§€(Low5) | ğŸŸ¡ è–„ã‚ªãƒ¬ãƒ³ã‚¸: Golden Zone(Low4,6,7) | 
        ğŸ”´ è–„èµ¤: ä½¿ç”¨ç¦æ­¢(Low8-10) | ğŸŸ¡ è–„é»„: é¿ã‘ã‚‹ã¹ã(Low1-2)
        """)
        
        st.markdown("---")
        
        st.markdown("### ğŸ“ˆ ç²¾åº¦ã‚«ãƒ¼ãƒ–ã®å¯è¦–åŒ–")
        
        # ã‚°ãƒ©ãƒ•æç”»
        import plotly.graph_objects as go
        
        fig = go.Figure()
        
        quality_levels = list(range(1, 11))
        mae_values = [0.0643, 0.0559, 0.0356, 0.0099, 0.0094, 0.0142, 0.0160, 0.1059, 0.1119, 0.1205]
        
        # èƒŒæ™¯é ˜åŸŸã‚’è¿½åŠ  (Golden Zone)
        fig.add_shape(
            type="rect", 
            x0=3.5, x1=7.5, 
            y0=0, y1=max(mae_values),
            fillcolor="lightgreen", 
            opacity=0.2, 
            line_width=0
        )
        
        # Golden Zoneã®ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
        fig.add_annotation(
            x=5.5,
            y=max(mae_values) * 0.95,
            text="Golden Zone",
            showarrow=False,
            font=dict(size=14, color="darkgreen"),
            bgcolor="rgba(255, 255, 255, 0.7)"
        )
        
        # MAEãƒ©ã‚¤ãƒ³
        fig.add_trace(go.Scatter(
            x=quality_levels,
            y=mae_values,
            mode='lines+markers',
            name='MAE',
            marker=dict(size=12, color=mae_values, colorscale='RdYlGn_r', showscale=True),
            line=dict(width=3)
        ))
        
        # Low5ã‚’å¼·èª¿
        fig.add_trace(go.Scatter(
            x=[5],
            y=[0.0094],
            mode='markers+text',
            name='Best (Low5)',
            marker=dict(size=20, color='green', symbol='star'),
            text=['Best!'],
            textposition='top center'
        ))
        
        fig.update_layout(
            title="å“è³ªãƒ¬ãƒ™ãƒ« vs MAE (Uå­—å‹ã‚«ãƒ¼ãƒ–)",
            xaxis_title="å“è³ªãƒ¬ãƒ™ãƒ« (Low1=æœ€é«˜ç”»è³ª, Low10=æœ€ä½ç”»è³ª)",
            yaxis_title="MAE (Mean Absolute Error)",
            hovermode='x unified',
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        
        st.markdown("### ğŸ“Š èª¤å·®åˆ†å¸ƒã®è©³ç´°")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### é«˜ç²¾åº¦ã‚±ãƒ¼ã‚¹ (èª¤å·® < 0.02)")
            precision_data = {
                "ãƒ¬ãƒ™ãƒ«": ["Low3", "Low4", "Low5", "Low6", "Low7"],
                "å‰²åˆ": ["91%", "91%", "97%", "88%", "85%"],
                "ã‚±ãƒ¼ã‚¹æ•°": ["30/33", "30/33", "32/33", "29/33", "28/33"]
            }
            st.dataframe(pd.DataFrame(precision_data), use_container_width=True)
        
        with col2:
            st.markdown("#### è¨±å®¹ç¯„å›² (èª¤å·® < 0.05)")
            acceptable_data = {
                "ãƒ¬ãƒ™ãƒ«": ["Low3", "Low4", "Low5", "Low6", "Low7", "Low8"],
                "å‰²åˆ": ["91%", "100%", "100%", "100%", "100%", "36%"],
                "ã‚±ãƒ¼ã‚¹æ•°": ["30/33", "33/33 âœ“", "33/33 âœ“", "33/33 âœ“", "33/33 âœ“", "12/33"]
            }
            st.dataframe(pd.DataFrame(acceptable_data), use_container_width=True)
        
        st.info("**é‡è¦**: Golden Zone(Low4-7)ã¯å…¨33ã‚±ãƒ¼ã‚¹ã§èª¤å·®<0.05ã‚’é”æˆ!")
    
    # ã‚¿ãƒ–3: é‡è¦ãªç™ºè¦‹
    with tab3:
        st.markdown("## ğŸ”¬ 3ã¤ã®é‡è¦ãªç™ºè¦‹")
        
        # ç™ºè¦‹1: è‡¨ç•Œå¢ƒç•Œ
        st.markdown("### 1ï¸âƒ£ è‡¨ç•Œå¢ƒç•Œã®ç™ºè¦‹")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.info("""
            **å¢ƒç•ŒA: Low2 â†’ Low3**
            
            **éå­¦ç¿’ã‹ã‚‰ã®è„±å´**
            
            - Low2: MAE 0.0559 (5.59%)
            - Low3: MAE 0.0356 (3.56%)
            - **æ”¹å–„**: 1.57å€
            
            **è§£é‡ˆ**: éå‰°ãªç”»è³ª(éå­¦ç¿’ãƒªã‚¹ã‚¯é ˜åŸŸ)ã‹ã‚‰é©æ­£ãªæƒ…å ±é‡ã¸ã®ç§»è¡Œç‚¹
            """)
        
        with col2:
            st.error("""
            **å¢ƒç•ŒB: Low7 â†’ Low8** âš ï¸ **CRITICAL**
            
            **æƒ…å ±æå¤±ã®é–‹å§‹**
            
            - Low7: MAE 0.0160 (1.60%)
            - Low8: MAE 0.1059 (10.59%)
            - **æ‚ªåŒ–**: 6.62å€ â† æ€§èƒ½å´–!
            
            **è§£é‡ˆ**: JPEGåœ§ç¸®ã«ã‚ˆã‚‹æƒ…å ±æå¤±ãŒäºˆæ¸¬ç²¾åº¦ã«è‡´å‘½çš„å½±éŸ¿ã‚’ä¸ãˆã‚‹é–¾å€¤
            
            **ã“ã®å¢ƒç•Œã‚’è¶…ãˆã¦ã¯ãªã‚‰ãªã„**
            """)
        
        st.markdown("---")
        
        # ç™ºè¦‹2: Low1ã®é€†èª¬
        st.markdown("### 2ï¸âƒ£ Low1(æœ€é«˜ç”»è³ª)ã®é€†èª¬çš„åŠ£åŒ–")
        
        st.warning("""
        **å¸¸è­˜ã‚’è¦†ã™ç™ºè¦‹: é«˜ç”»è³ª â‰  é«˜ç²¾åº¦**
        
        å¾“æ¥ã®å¸¸è­˜: ã€Œç”»è³ªã¯é«˜ã‘ã‚Œã°é«˜ã„ã»ã©è‰¯ã„ã€
        
        å®Ÿéš›ã®çµæœ: **Low1(æœ€é«˜ç”»è³ª)ãŒLow5(ä¸­ç¨‹åº¦)ã‚ˆã‚Š6.84å€ã‚‚æ‚ªã„!**
        """)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Low1 (æœ€é«˜ç”»è³ª)", "MAE 0.0643", "6.84Ã— æ‚ªã„ â¬‡ï¸", delta_color="inverse")
        with col2:
            st.metric("Low5 (ä¸­ç¨‹åº¦)", "MAE 0.0094", "æœ€è‰¯ â¬†ï¸")
        with col3:
            st.metric("æ€§èƒ½æ¯”", "6.84å€", "Low1ã¯Low5ã‚ˆã‚Šæ‚ªã„")
        
        st.markdown("#### åŸå› ã®è€ƒå¯Ÿ")
        
        st.markdown("""
        **1. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã®å“è³ªãƒŸã‚¹ãƒãƒƒãƒ**
        - ãƒ¢ãƒ‡ãƒ«ã¯Low4-7ç¨‹åº¦ã®å“è³ªã§è¨“ç·´ã•ã‚ŒãŸå¯èƒ½æ€§ãŒé«˜ã„
        - è¨“ç·´æ™‚ã«è¦‹ãªã‹ã£ãŸå“è³ªé ˜åŸŸã§ã¯æ±åŒ–æ€§èƒ½ãŒä½ä¸‹
        
        **2. å¾®ç´°ãªé•ã„ã¸ã®éæ•æ€§**
        - é«˜ç”»è³ªã™ãã‚‹ã¨è¨“ç·´æ™‚ã«å­˜åœ¨ã—ãªã‹ã£ãŸå¾®ç´°ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã«åå¿œ
        - ãƒã‚¤ã‚ºã¨ä¿¡å·ã®åŒºåˆ¥ãŒå›°é›£ã«ãªã‚‹
        
        **3. éå­¦ç¿’ã®è¨¼æ‹ **
        - å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã«ã‚ˆã‚‹éå­¦ç¿’ã®æ–°ã—ã„è¦–ç‚¹
        - ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»æ¨™æº–åŒ–ã®é‡è¦æ€§ã‚’å®Ÿè¨¼
        """)
        
        st.markdown("#### å•é¡Œç”»åƒã®äº‹ä¾‹")
        
        case_data = {
            "ç”»åƒ": ["IMG_5049", "IMG_5050"],
            "å®Ÿæ¸¬FD": [2.4978, 2.5180],
            "Low1äºˆæ¸¬": [2.6517, 2.6728],
            "Low1èª¤å·®": ["+0.1538 (6.16%)", "+0.1548 (6.15%)"],
            "Low5äºˆæ¸¬": [2.5701, 2.5321],
            "Low5èª¤å·®": ["+0.0723 (2.89%)", "+0.0141 (0.56%)"],
            "æ”¹å–„": ["2.13å€", "10.94å€"]
        }
        st.dataframe(pd.DataFrame(case_data), use_container_width=True)
        
        st.markdown("---")
        
        # ç™ºè¦‹3: Low8-10ã®æƒ…å ±æå¤±
        st.markdown("### 3ï¸âƒ£ Low8-10ã®æ·±åˆ»ãªæƒ…å ±æå¤±")
        
        st.error("""
        **JPEGåœ§ç¸®ã«ã‚ˆã‚‹ä¸å¯é€†çš„ãªæƒ…å ±æå¤±**
        
        Low8ä»¥é™ã§ã¯ã€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æã«å¿…è¦ãªæƒ…å ±ãŒå¤±ã‚ã‚Œã€å®Ÿç”¨ä¸å¯èƒ½ã€‚
        """)
        
        st.markdown("#### IMG_5039ã®æŒ™å‹•åˆ†æ (é«˜ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒç”»åƒ)")
        
        img5039_data = {
            "å“è³ªãƒ¬ãƒ™ãƒ«": ["Low1", "Low5", "Low7", "Low8", "Low9", "Low10"],
            "äºˆæ¸¬FD": [2.8910, 2.8384, 2.8397, 2.4975, 2.5116, 2.3979],
            "èª¤å·®": ["+0.0321", "-0.0204", "-0.0192", "-0.3614", "-0.3473", "-0.4609"],
            "ç›¸å¯¾èª¤å·®%": ["1.12%", "0.71%", "0.67%", "12.64%", "12.15%", "16.12%"],
            "è©•ä¾¡": ["âœ“ è‰¯å¥½", "âœ“ å„ªç§€", "âœ“ å„ªç§€", "âœ— å®Œå…¨å´©å£Š", "âœ— æ·±åˆ»", "âœ— äºˆæ¸¬å¤±æ•—"]
        }
        st.dataframe(pd.DataFrame(img5039_data), use_container_width=True)
        st.caption("å®Ÿæ¸¬FD: 2.8589 (é«˜è¤‡é›‘åº¦)")
        
        st.markdown("#### æƒ…å ±æå¤±ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **JPEGåœ§ç¸®ã®å½±éŸ¿:**
            
            1. é«˜å‘¨æ³¢æˆåˆ†ã®æ¶ˆå¤± (DCTå¤‰æ›ã§å„ªå…ˆå‰Šæ¸›)
            2. 8Ã—8ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚¤ã‚º (å¢ƒç•Œã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ)
            3. ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®åŠ£åŒ– (å¾®ç´°ãƒ‘ã‚¿ãƒ¼ãƒ³ç ´å£Š)
            4. ã‚¨ãƒƒã‚¸ã®æ›–æ˜§åŒ– (å¢ƒç•Œæƒ…å ±ä¸æ˜ç­)
            """)
        
        with col2:
            st.markdown("""
            **ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æã¸ã®å½±éŸ¿:**
            
            - Box-countingæ³•ã®å°ã‚¹ã‚±ãƒ¼ãƒ«æƒ…å ±æ¬ è½
            - è‡ªå·±ç›¸ä¼¼æ€§ã‚’ç¤ºã™æ§‹é€ ãŒå¤±ã‚ã‚Œã‚‹
            - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãŒå®Ÿéš›ã‚ˆã‚Šä½ãè¦‹ç©ã‚‚ã‚‰ã‚Œã‚‹
            - äºˆæ¸¬ãŒä¸å®‰å®šãƒ»ä¿¡é ¼æ€§å–ªå¤±
            """)
        
        st.info("**çµè«–**: Low8ä»¥é™ã§ã¯ã€æƒ…å ±ãŒä¸å¯é€†çš„ã«å¤±ã‚ã‚Œã¦ãŠã‚Šã€å®Ÿç”¨ã«è€ãˆãªã„ã€‚")
    
    # ã‚¿ãƒ–4: å®Ÿç”¨ã‚¬ã‚¤ãƒ‰
    with tab4:
        st.markdown("## ğŸ’¡ å®Ÿç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³")
        
        st.markdown("### ğŸ¥ è‡¨åºŠãƒ»åŒ»å­¦ç ”ç©¶ç”¨é€”")
        st.success("""
        **æ¨å¥¨ãƒ¬ãƒ™ãƒ«: Low5**
        
        **æ€§èƒ½:**
        - MAE: 0.0094 (0.94%)
        - æœ€å¤§èª¤å·®: 1.02%
        - é«˜ç²¾åº¦ç‡: 97% (èª¤å·®<0.02)
        
        **ãƒ¡ãƒªãƒƒãƒˆ:**
        âœ“ è¨ºæ–­ç²¾åº¦ã®æœ€å¤§åŒ–
        âœ“ æœ€ã‚‚å®‰å®šã—ãŸäºˆæ¸¬
        âœ“ å†ç¾æ€§ãŒé«˜ã„
        âœ“ æ¨™æº–åŒ–ã—ã‚„ã™ã„
        
        **é©ç”¨ä¾‹:**
        - ãŒã‚“çµ„ç¹”ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æ
        - ç—…ç†è¨ºæ–­æ”¯æ´
        - ç–¾æ‚£é€²è¡Œãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
        - å­¦è¡“ç ”ç©¶ãƒ»è«–æ–‡ç™ºè¡¨
        """)
        
        st.markdown("---")
        
        st.markdown("### ğŸ’¼ å•†ç”¨ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³")
        st.info("""
        **æ¨å¥¨ãƒ¬ãƒ™ãƒ«: Low4-6**
        
        **æ€§èƒ½:**
        - å¹³å‡MAE: 0.0128 (1.28%)
        - è¨±å®¹èª¤å·®é”æˆç‡: 100%
        
        **ãƒ¡ãƒªãƒƒãƒˆ:**
        âœ“ ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆã®ãƒãƒ©ãƒ³ã‚¹
        âœ“ å‡¦ç†é€Ÿåº¦ãŒé©åˆ‡
        âœ“ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸åŠ¹ç‡è‰¯å¥½
        âœ“ å®Ÿç”¨æ€§ãŒé«˜ã„
        
        **é©ç”¨ä¾‹:**
        - å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
        - è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–
        - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è§£æ
        - ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒª
        """)
        
        st.markdown("---")
        
        st.markdown("### ğŸ” ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»å¤§è¦æ¨¡è§£æ")
        st.info("""
        **æ¨å¥¨ãƒ¬ãƒ™ãƒ«: Low3-7**
        
        **æ€§èƒ½:**
        - MAEç¯„å›²: 0.009-0.036
        - å®Ÿç”¨çš„ç²¾åº¦ã‚’ç¢ºä¿
        
        **ãƒ¡ãƒªãƒƒãƒˆ:**
        âœ“ å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„å‡¦ç†
        âœ“ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆå‰Šæ¸›
        âœ“ å‡¦ç†é€Ÿåº¦ã®å‘ä¸Š
        âœ“ ååˆ†ãªç²¾åº¦ã‚’ç¶­æŒ
        
        **é©ç”¨ä¾‹:**
        - ç–«å­¦èª¿æŸ»
        - äººå£ãƒ™ãƒ¼ã‚¹ç ”ç©¶
        - ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿è§£æ
        - äºˆå‚™ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        """)
        
        st.markdown("---")
        
        st.markdown("### ğŸ“š ç ”ç©¶ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”¨é€”")
        st.info("""
        **æ¨å¥¨ãƒ¬ãƒ™ãƒ«: Low4, Low5, Low6**
        
        **æ€§èƒ½:**
        - Golden Zoneã®ä¸­æ ¸
        - æ¨™æº–åŒ–ã«æœ€é©
        
        **ãƒ¡ãƒªãƒƒãƒˆ:**
        âœ“ ç ”ç©¶é–“ã®æ¯”è¼ƒå¯èƒ½æ€§
        âœ“ å†ç¾æ€§ã®ç¢ºä¿
        âœ“ ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ¨™æº–åŒ–
        âœ“ å›½éš›çš„ãªäº’æ›æ€§
        
        **é©ç”¨ä¾‹:**
        - å­¦è¡“è«–æ–‡
        - å›½éš›å…±åŒç ”ç©¶
        - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        - æ–¹æ³•è«–ã®æ¯”è¼ƒ
        """)
        
        st.markdown("---")
        
        st.markdown("### âŒ é¿ã‘ã‚‹ã¹ããƒ¬ãƒ™ãƒ«")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.warning("""
            **Low1-2: éå­¦ç¿’ãƒªã‚¹ã‚¯é ˜åŸŸ**
            
            **å•é¡Œç‚¹:**
            âœ— é«˜ç”»è³ªãªã®ã«ç²¾åº¦ãŒä½ã„ï¼ˆé€†èª¬çš„ï¼‰
            âœ— MAE 0.056-0.064 (Golden Zoneã®4-6å€æ‚ªã„)
            âœ— ç”»åƒã”ã¨ã®ã°ã‚‰ã¤ããŒå¤§ãã„
            âœ— äºˆæ¸¬ãŒä¸å®‰å®š
            
            **æŠ€è¡“çš„ç†ç”±:**
            - è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å“è³ªç¯„å›²å¤–
            - å¾®ç´°ãªå¤‰å‹•ã«ãƒ¢ãƒ‡ãƒ«ãŒéæ•åå¿œ
            - æ±åŒ–æ€§èƒ½ã®ä½ä¸‹
            - ãƒã‚¤ã‚ºã¨ä¿¡å·ã®åŒºåˆ¥å›°é›£
            
            **æ¨å¥¨: ä½¿ç”¨ã—ãªã„**
            """)
        
        with col2:
            st.error("""
            **Low8-10: æƒ…å ±æå¤±é ˜åŸŸ**
            
            **å•é¡Œç‚¹:**
            âœ— æ·±åˆ»ãªç²¾åº¦åŠ£åŒ–
            âœ— MAE 0.106-0.121 (Golden Zoneã®7-13å€æ‚ªã„)
            âœ— ä¸€éƒ¨ç”»åƒã§å®Œå…¨ãªäºˆæ¸¬å¤±æ•—ï¼ˆèª¤å·® > 10%ï¼‰
            âœ— ä¿¡é ¼æ€§ãŒè‘—ã—ãä½ã„
            
            **æŠ€è¡“çš„ç†ç”±:**
            - JPEGåœ§ç¸®ã«ã‚ˆã‚‹æƒ…å ±ã®ä¸å¯é€†çš„æå¤±
            - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã®ç ´å£Š
            - é«˜å‘¨æ³¢æˆåˆ†ã®æ¶ˆå¤±
            - ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚¤ã‚ºã®å½±éŸ¿
            
            **æ¨å¥¨: çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ï¼ˆå®Ÿç”¨ä¸å¯ï¼‰**
            """)
    
    # ã‚¿ãƒ–5: è©³ç´°åˆ†æ
    with tab5:
        st.markdown("## ğŸ“ˆ Golden Zone (Low4-7) è©³ç´°åˆ†æ")
        
        st.markdown("### Golden Zoneã®çµ±è¨ˆçš„ç‰¹å¾´")
        
        golden_stats = {
            "æŒ‡æ¨™": ["å¹³å‡MAE", "MAEç¯„å›²", "å…¨ãƒ¬ãƒ™ãƒ«ã§MAE", "æœ€æ‚ªã‚±ãƒ¼ã‚¹ã§ã‚‚", "è¨±å®¹èª¤å·®é”æˆç‡"],
            "å€¤": ["0.0124 (1.24%)", "0.0094 - 0.0160", "< 0.02 âœ“", "ç›¸å¯¾èª¤å·® < 2% âœ“", "100% (å…¨33ã‚±ãƒ¼ã‚¹ã§èª¤å·® < 0.05)"]
        }
        st.table(pd.DataFrame(golden_stats))
        
        st.markdown("---")
        
        # å„ãƒ¬ãƒ™ãƒ«ã®è©³ç´°
        st.markdown("### å„ãƒ¬ãƒ™ãƒ«ã®è©³ç´°ç‰¹æ€§")
        
        level_col1, level_col2 = st.columns(2)
        
        with level_col1:
            st.markdown("#### ğŸ¥‡ Low5 (æœ€å„ªç§€)")
            st.success("""
            **æ€§èƒ½æŒ‡æ¨™:**
            - MAE: 0.0094 (0.94%)
            - æœ€å¤§èª¤å·®: 0.0281 (1.02%)
            - é«˜ç²¾åº¦ã‚±ãƒ¼ã‚¹ç‡: 97% (èª¤å·® < 0.02)
            - è¨±å®¹èª¤å·®é”æˆç‡: 100% (èª¤å·® < 0.05)
            
            **ç‰¹å¾´:**
            âœ“ å…¨ãƒ¬ãƒ™ãƒ«ä¸­æœ€è‰¯ã®å¹³å‡ç²¾åº¦
            âœ“ æœ€ã‚‚å®‰å®šã—ãŸäºˆæ¸¬ï¼ˆèª¤å·®åˆ†å¸ƒãŒé›†ä¸­ï¼‰
            âœ“ æœ€å°ã®æœ€å¤§èª¤å·®
            âœ“ è‡¨åºŠãƒ»ç ”ç©¶ç”¨é€”ã«æœ€é©
            """)
            
            st.markdown("#### ğŸ¥‰ Low6 (å„ªç§€)")
            st.info("""
            **æ€§èƒ½æŒ‡æ¨™:**
            - MAE: 0.0142 (1.42%)
            - æœ€å¤§èª¤å·®: 0.0420 (1.52%)
            - é«˜ç²¾åº¦ã‚±ãƒ¼ã‚¹ç‡: 88% (èª¤å·® < 0.02)
            - è¨±å®¹èª¤å·®é”æˆç‡: 100% (èª¤å·® < 0.05)
            
            **ç‰¹å¾´:**
            âœ“ å®Ÿç”¨ä¸Šååˆ†ãªç²¾åº¦
            âœ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨ã®ãƒãƒ©ãƒ³ã‚¹è‰¯å¥½
            âœ“ å•†ç”¨ã‚¢ãƒ—ãƒªã«é©åˆ
            """)
        
        with level_col2:
            st.markdown("#### ğŸ¥ˆ Low4 (æº–æœ€å„ªç§€)")
            st.success("""
            **æ€§èƒ½æŒ‡æ¨™:**
            - MAE: 0.0099 (0.99%)
            - æœ€å¤§èª¤å·®: 0.0338 (1.31%)
            - é«˜ç²¾åº¦ã‚±ãƒ¼ã‚¹ç‡: 91% (èª¤å·® < 0.02)
            - è¨±å®¹èª¤å·®é”æˆç‡: 100% (èª¤å·® < 0.05)
            
            **ç‰¹å¾´:**
            âœ“ Low5ã¨ã»ã¼åŒç­‰ã®æ€§èƒ½
            âœ“ å¤–ã‚Œå€¤ãŒå°‘ãªãå®‰å®š
            âœ“ æ¨™æº–çš„ãªé¸æŠè‚¢ã¨ã—ã¦å„ªç§€
            """)
            
            st.markdown("#### â­ Low7 (Golden Zoneä¸Šé™)")
            st.info("""
            **æ€§èƒ½æŒ‡æ¨™:**
            - MAE: 0.0160 (1.60%)
            - æœ€å¤§èª¤å·®: 0.0373 (1.35%)
            - é«˜ç²¾åº¦ã‚±ãƒ¼ã‚¹ç‡: 85% (èª¤å·® < 0.02)
            - è¨±å®¹èª¤å·®é”æˆç‡: 100% (èª¤å·® < 0.04)
            
            **ç‰¹å¾´:**
            âœ“ Golden Zoneã®å¢ƒç•Œ
            âœ“ ã“ã®å“è³ªä»¥ä¸‹ã¯æ¨å¥¨ã—ãªã„
            âœ“ ã‚³ã‚¹ãƒˆé‡è¦–ã®ç”¨é€”ã«
            """)
        
        st.markdown("---")
        
        st.markdown("### ğŸ¯ å®Ÿè£…æ¨å¥¨ã‚³ãƒ¼ãƒ‰")
        
        st.code('''
# å“è³ªãƒ¬ãƒ™ãƒ«æ¨å¥¨è¨­å®š
QUALITY_RECOMMENDATIONS = {
    # ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
    "best": "low5",  # MAE 0.0094 - æœ€é«˜ç²¾åº¦
    
    # Golden Zoneï¼ˆæ¨å¥¨ç¯„å›²ï¼‰
    "golden_zone": ["low4", "low5", "low6", "low7"],  # MAE < 0.02
    
    # è¨±å®¹ç¯„å›²
    "acceptable": ["low3", "low4", "low5", "low6", "low7"],  # MAE < 0.04
    
    # ä½¿ç”¨ç¦æ­¢
    "avoid": ["low1", "low2", "low8", "low9", "low10"]
}

# ç”¨é€”åˆ¥æ¨å¥¨
USE_CASE_MAPPING = {
    "clinical_research": "low5",  # è‡¨åºŠãƒ»ç ”ç©¶: æœ€é«˜ç²¾åº¦
    "commercial": ["low4", "low5", "low6"],  # å•†ç”¨: ãƒãƒ©ãƒ³ã‚¹
    "screening": ["low3", "low4", "low5", "low6", "low7"],  # ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    "benchmark": ["low4", "low5", "low6"]  # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯: æ¨™æº–åŒ–
}

# è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
WARNING_MESSAGES = {
    "low1": "âš ï¸ éå­¦ç¿’ãƒªã‚¹ã‚¯ - Low5æ¨å¥¨ (6.84å€ç²¾åº¦æ‚ªåŒ–)",
    "low2": "âš ï¸ éå­¦ç¿’ãƒªã‚¹ã‚¯ - Low5æ¨å¥¨ (5.95å€ç²¾åº¦æ‚ªåŒ–)",
    "low8": "âŒ æƒ…å ±æå¤±æ·±åˆ» - ä½¿ç”¨ç¦æ­¢ (11.27å€ç²¾åº¦æ‚ªåŒ–)",
    "low9": "âŒ æƒ…å ±æå¤±æ·±åˆ» - ä½¿ç”¨ç¦æ­¢ (11.90å€ç²¾åº¦æ‚ªåŒ–)",
    "low10": "âŒ æƒ…å ±æå¤±æ·±åˆ» - ä½¿ç”¨ç¦æ­¢ (12.82å€ç²¾åº¦æ‚ªåŒ–)"
}

# ç²¾åº¦æœŸå¾…å€¤
EXPECTED_ACCURACY = {
    "low5": {"mae": 0.0094, "avg_error": "0.35%", "reliability": "æœ€å„ªç§€"},
    "low4": {"mae": 0.0099, "avg_error": "0.37%", "reliability": "å„ªç§€"},
    "low6": {"mae": 0.0142, "avg_error": "0.53%", "reliability": "å„ªç§€"},
    # ... ä»–ã®ãƒ¬ãƒ™ãƒ«
}
''', language='python')
    
    # ã‚¿ãƒ–6: ç ”ç©¶è©³ç´°
    with tab6:
        st.markdown("## ğŸ“š ç ”ç©¶ã®è©³ç´°æƒ…å ±")
        
        st.markdown("### ç ”ç©¶ã®èƒŒæ™¯ã¨ç›®çš„")
        st.markdown("""
        åŒ»ç™‚ç”»åƒè§£æã‚„ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒäºˆæ¸¬ã«ãŠã„ã¦ã€**å…¥åŠ›ç”»åƒã®å“è³ªãŒäºˆæ¸¬ç²¾åº¦ã«ä¸ãˆã‚‹å½±éŸ¿**ã¯é•·å¹´ã®èª²é¡Œã§ã—ãŸã€‚
        
        **å¾“æ¥ã®å¸¸è­˜:**
        - ã€Œé«˜ç”»è³ª = é«˜ç²¾åº¦ã€ã¨ã„ã†æš—é»™ã®ä»®å®š
        - ç”»è³ªã¯é«˜ã‘ã‚Œã°é«˜ã„ã»ã©è‰¯ã„ã¨ã„ã†è€ƒãˆ
        - ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ãå“è³ªåŸºæº–ã®ä¸åœ¨
        
        **ã“ã®ç ”ç©¶ã®ç›®çš„:**
        1. **å®šé‡çš„è©•ä¾¡**: 10æ®µéšã®å“è³ªãƒ¬ãƒ™ãƒ«ã§ç³»çµ±çš„ã«ç²¾åº¦ã‚’æ¸¬å®š
        2. **æœ€é©ç¯„å›²ã®ç‰¹å®š**: ã©ã®å“è³ªãƒ¬ãƒ™ãƒ«ãŒæœ€ã‚‚é«˜ç²¾åº¦ã‹?
        3. **å®Ÿç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³**: ç”¨é€”åˆ¥ã®æ¨å¥¨ãƒ¬ãƒ™ãƒ«ã‚’æ˜ç¢ºåŒ–
        4. **ç§‘å­¦çš„æ ¹æ‹ **: éå­¦ç¿’ãƒ»æƒ…å ±æå¤±ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’è§£æ˜
        """)
        
        st.markdown("---")
        
        st.markdown("### ç ”ç©¶æ–¹æ³•")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:**
            - æ¤œè¨¼ç”»åƒæ•°: 33æš
            - å“è³ªãƒ¬ãƒ™ãƒ«: Low1-10 (å…¨10æ®µéš)
            - ç”»åƒ: IMG_5023-5052, IMG_5202, IMG_5204, IMG_5205
            
            **è©•ä¾¡æŒ‡æ¨™:**
            - MAE (Mean Absolute Error)
            - å¹³å‡ç›¸å¯¾èª¤å·® (%)
            - æœ€å¤§çµ¶å¯¾èª¤å·®
            - æœ€æ‚ªã‚±ãƒ¼ã‚¹ç›¸å¯¾èª¤å·® (%)
            - èª¤å·®åˆ†å¸ƒ (é«˜ç²¾åº¦ã‚±ãƒ¼ã‚¹ã®å‰²åˆ)
            """)
        
        with col2:
            st.markdown("""
            **æ¤œè¨¼ãƒ—ãƒ­ã‚»ã‚¹:**
            1. å„å“è³ªãƒ¬ãƒ™ãƒ«ã§é«˜ç”»è³ªâ†’ä½ç”»è³ªãƒšã‚¢ã‚’ä½œæˆ
            2. ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒäºˆæ¸¬ã‚’å®Ÿè¡Œ
            3. å®Ÿæ¸¬å€¤ã¨ã®èª¤å·®ã‚’çµ±è¨ˆçš„ã«åˆ†æ
            4. 10æ®µéšå…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ãƒ»æ¯”è¼ƒ
            5. Uå­—å‹ã‚«ãƒ¼ãƒ–ã¨è‡¨ç•Œå¢ƒç•Œã‚’ç™ºè¦‹
            6. ç”¨é€”åˆ¥æ¨å¥¨äº‹é …ã‚’ç­–å®š
            """)
        
        st.markdown("---")
        
        st.markdown("### å­¦è¡“çš„æ„ç¾©")
        
        st.success("""
        **1. ç”»è³ªã¨äºˆæ¸¬ç²¾åº¦ã®éç·šå½¢é–¢ä¿‚ã®å®Ÿè¨¼**
        - å¾“æ¥ã®ä»®å®š: é«˜ç”»è³ª = é«˜ç²¾åº¦
        - æœ¬ç ”ç©¶ã®ç™ºè¦‹: Uå­—å‹ã®é–¢ä¿‚æ€§ï¼ˆä¸¡ç«¯ã§åŠ£åŒ–ï¼‰
        - æ„ç¾©: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å“è³ªæœ€é©åŒ–ã®é‡è¦æ€§ã‚’å®Ÿè¨¼
        
        **2. éå­¦ç¿’ã®æ–°ã—ã„è¦–ç‚¹**
        - å¾“æ¥: ãƒ‡ãƒ¼ã‚¿é‡ã‚„è¤‡é›‘ã•ã«ã‚ˆã‚‹éå­¦ç¿’
        - æœ¬ç ”ç©¶: å…¥åŠ›å“è³ªã«ã‚ˆã‚‹éå­¦ç¿’ã‚’ç™ºè¦‹
        - æ„ç¾©: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»æ¨™æº–åŒ–ã®å†è©•ä¾¡ãŒå¿…è¦
        
        **3. JPEGåœ§ç¸®ã®å½±éŸ¿ã®å®šé‡åŒ–**
        - å¾“æ¥: å®šæ€§çš„ãªç†è§£ã®ã¿
        - æœ¬ç ”ç©¶: å®šé‡çš„ãªé–¾å€¤ã‚’ç‰¹å®š(Low7/Low8å¢ƒç•Œ)
        - æ„ç¾©: åŒ»ç™‚ç”»åƒè§£æã§ã®æ¨™æº–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ç­–å®šã«è²¢çŒ®
        
        **4. å®Ÿç”¨çš„ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®æä¾›**
        - å¾“æ¥: çµŒé¨“å‰‡ãƒ™ãƒ¼ã‚¹
        - æœ¬ç ”ç©¶: ãƒ‡ãƒ¼ã‚¿é§†å‹•ã®å…·ä½“çš„åŸºæº–
        - æ„ç¾©: å†ç¾æ€§ã®ã‚ã‚‹ç ”ç©¶ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ç¢ºç«‹
        """)
        
        st.markdown("---")
        
        st.markdown("### è«–æ–‡åŒ–ã¸ã®ææ¡ˆ")
        
        st.info("""
        **ã‚¿ã‚¤ãƒˆãƒ«æ¡ˆ:**
        
        è‹±èª: "JPEG Compression Quality Optimization for Fractal Dimension Prediction: 
        Discovery of U-shaped Accuracy Curve and Golden Zone"
        
        æ—¥æœ¬èª: "ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒäºˆæ¸¬ã«ãŠã‘ã‚‹JPEGåœ§ç¸®å“è³ªæœ€é©åŒ–: 
        Uå­—å‹ç²¾åº¦ã‚«ãƒ¼ãƒ–ã¨ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¾ãƒ¼ãƒ³ã®ç™ºè¦‹"
        
        **æŠ•ç¨¿å…ˆå€™è£œ:**
        1. Medical Image Analysis (IF: 10.7) - åŒ»ç™‚ç”»åƒè§£æã®ãƒˆãƒƒãƒ—ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«
        2. IEEE Transactions on Medical Imaging (IF: 10.6) - ç”»åƒå‡¦ç†ã¨åŒ»ç™‚ã®èåˆ
        3. Pattern Recognition (IF: 8.0) - ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜å…¨èˆ¬
        4. Journal of Digital Imaging (IF: 4.4) - ãƒ‡ã‚¸ã‚¿ãƒ«åŒ»ç™‚ç”»åƒ
        
        **è«–æ–‡æ§‹æˆæ¡ˆ:**
        1. Abstract: Uå­—ã‚«ãƒ¼ãƒ–ã€Golden Zoneã€2ã¤ã®è‡¨ç•Œå¢ƒç•Œ
        2. Introduction: ç”»è³ªã¨äºˆæ¸¬ç²¾åº¦ã®é–¢ä¿‚æ€§ã®é‡è¦æ€§
        3. Methods: 10æ®µéšæ¤œè¨¼ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€çµ±è¨ˆçš„è©•ä¾¡æ‰‹æ³•
        4. Results: è©³ç´°ãªçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã€å¯è¦–åŒ–ã€ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£
        5. Discussion: éå­¦ç¿’ã¨æƒ…å ±æå¤±ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€è‡¨åºŠçš„æ„ç¾©
        6. Conclusion: å®Ÿç”¨çš„ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€ä»Šå¾Œã®å±•æœ›
        """)
        
        st.markdown("---")
        
        st.markdown("### ä»Šå¾Œã®ç ”ç©¶èª²é¡Œ")
        
        st.markdown("""
        **1. åŸå› ã®æ·±æ˜ã‚Šèª¿æŸ»**
        - ãªãœLow5ãŒæœ€é©ãªã®ã‹? (è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å“è³ªåˆ†å¸ƒã‚’èª¿æŸ»)
        - Low7/Low8å¢ƒç•Œã§ä½•ãŒå¤±ã‚ã‚Œã‚‹ã®ã‹? (å‘¨æ³¢æ•°è§£æ)
        - ç‰¹ç•°ç”»åƒã®åŸå› ã¯?
        
        **2. ãƒ¢ãƒ‡ãƒ«æ”¹å–„ã®å¯èƒ½æ€§**
        - ãƒãƒ«ãƒå“è³ªå­¦ç¿’ (Low1-10å…¨ã¦ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å«ã‚ã‚‹)
        - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥ (å“è³ªãƒ¬ãƒ™ãƒ«ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ)
        - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ (è¤‡æ•°å“è³ªãƒ¬ãƒ™ãƒ«ã®äºˆæ¸¬ã‚’çµ±åˆ)
        - å“è³ªè‡ªå‹•é¸æŠ (å…¥åŠ›ç”»åƒã®å“è³ªã‚’è‡ªå‹•æ¤œå‡º)
        
        **3. ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æ¤œè¨¼**
        - ç•°ãªã‚‹çµ„ç¹”ã‚¿ã‚¤ãƒ— (çš®è†šã€è‚ºã€è„³ãªã©)
        - ç•°ãªã‚‹æ’®å½±æ¡ä»¶ (é¡•å¾®é¡ã‚¿ã‚¤ãƒ—ã€å€ç‡ã€æŸ“è‰²)
        - ç•°ãªã‚‹è¢«é¨“è€…é›†å›£ (å¹´é½¢å±¤ã€ç–¾æ‚£ã‚¿ã‚¤ãƒ—ã€äººç¨®)
        
        **4. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–**
        - å“è³ªè‡ªå‹•æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        - é©å¿œçš„å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        - äºˆæ¸¬ä¿¡é ¼åº¦ã®æ¨å®šæ‰‹æ³•
        - ã‚¨ãƒ©ãƒ¼æ¤œå‡ºãƒ»è£œæ­£æ©Ÿèƒ½
        """)
        
        st.markdown("---")
        
        st.markdown("### ç ”ç©¶ç’°å¢ƒãƒ»ãƒ‡ãƒ¼ã‚¿")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **æ¤œè¨¼ç’°å¢ƒ:**
            - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: Fractal-Analyzer-V2
            - ãƒ¢ãƒ‡ãƒ«: CNN-based FD Predictor
            - æ¤œè¨¼æ—¥: 2025å¹´11æœˆ11æ—¥
            - ç”»åƒæ•°: 33æš
            """)
        
        with col2:
            st.markdown("""
            **ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«:**
            - Low1-10ã®æ¤œè¨¼çµæœCSV
            - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ« (pkl)
            - ç ”ç©¶ãƒ¬ãƒãƒ¼ãƒˆ (MD)
            """)
        
        st.markdown("---")
        
        st.markdown("### å¼•ç”¨")
        st.code("""
Fractal-Analyzer-V2 Quality Optimization Study (2025)
"JPEG Compression Quality Optimization for Fractal Dimension Prediction"
GitHub: ryuki4219/Fractal-Analyzer-V2
        """, language='text')

# ============================================================
# Streamlit app
# ============================================================
def app():
    # ============================================================
    # ğŸ“± ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ¢ãƒ¼ãƒ‰ã®åˆæœŸåŒ–ï¼ˆæœ€å„ªå…ˆã§å®Ÿè¡Œï¼‰
    # ============================================================
    if 'layout_mode' not in st.session_state:
        st.session_state['layout_mode'] = 'ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ
    
    st.set_page_config(layout="centered", page_title="Fractal Analyzer V2 - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ")
    st.title("ï¿½ Fractal Analyzer V2 - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æã‚·ã‚¹ãƒ†ãƒ ")
    
    # ============================================================
    # âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …ãƒ»å…è²¬äº‹é …ï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆç‰ˆï¼‰
    # ============================================================
    with st.expander("âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …ï¼ˆå¿…ãšãŠèª­ã¿ãã ã•ã„ï¼‰", expanded=False):
        st.warning("""
        **æœ¬ã‚µãƒ¼ãƒ“ã‚¹ã¯ç ”ç©¶ãƒ»æ•™è‚²ç›®çš„ã®ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚Šã€åŒ»ç™‚è¨ºæ–­ã‚’ç›®çš„ã¨ã—ãŸã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚**
        
        - ğŸ”¬ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å¹¾ä½•å­¦ã®ç ”ç©¶ãƒ»å­¦ç¿’ç”¨ãƒ„ãƒ¼ãƒ«ã§ã™
        - âŒ åŒ»ç™‚è¨ºæ–­ãƒ»å¥åº·åˆ¤å®šã«ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„
        - âš•ï¸ åŒ»ç™‚ã«é–¢ã™ã‚‹åˆ¤æ–­ã¯ã€å¿…ãšåŒ»ç™‚æ©Ÿé–¢ãƒ»åŒ»å¸«ã«ã”ç›¸è«‡ãã ã•ã„
        - ğŸ“Š è§£æçµæœã¯å‚è€ƒå€¤ã¨ã—ã¦ã”åˆ©ç”¨ãã ã•ã„
        
        æœ¬ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€[åˆ©ç”¨è¦ç´„](https://github.com/ryuki4219/Fractal-Analyzer-V2/blob/main/TERMS_OF_SERVICE.md)ã«åŒæ„ã—ãŸã‚‚ã®ã¨ã¿ãªã•ã‚Œã¾ã™ã€‚
        """)
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¸ã®ãƒªãƒ³ã‚¯ï¼ˆ2åˆ—Ã—2è¡Œã§ãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œï¼‰
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("ğŸ“– [ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰](https://github.com/ryuki4219/Fractal-Analyzer-V2/blob/main/USER_GUIDE.md)")
            st.markdown("ğŸ”’ [ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼](https://github.com/ryuki4219/Fractal-Analyzer-V2/blob/main/PRIVACY_POLICY.md)")
        with col2:
            st.markdown("ğŸ“œ [åˆ©ç”¨è¦ç´„](https://github.com/ryuki4219/Fractal-Analyzer-V2/blob/main/TERMS_OF_SERVICE.md)")
            st.markdown("ğŸ’» [GitHubãƒªãƒã‚¸ãƒˆãƒª](https://github.com/ryuki4219/Fractal-Analyzer-V2)")
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚‚ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«
    with st.expander("â„¹ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±", expanded=False):
        st.info("CuPy ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ GPU ã‚’è‡ªå‹•ã§ä½¿ã„ã¾ã™ã€‚ç„¡ã‘ã‚Œã° CPU (NumPy) ã§å‡¦ç†ã—ã¾ã™ã€‚")
    
    # ============================================================
    # ï¿½ è‡ªå‹•ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æ©Ÿèƒ½ - ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«å®Ÿè¡Œï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
    # ============================================================
    if 'model_loaded' not in st.session_state:
        st.session_state['model_loaded'] = False
        st.session_state['persistent_model'] = None
        st.session_state['model_info'] = None
        st.session_state['auto_load_attempted'] = False
        
        # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¢ã™
        default_model_path = "trained_fd_model.pkl"
        history_path = "training_history.json"
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨å­¦ç¿’å±¥æ­´ã®å­˜åœ¨ç¢ºèª
        model_exists = os.path.exists(default_model_path)
        history_exists = os.path.exists(history_path)
        
        if model_exists:
            try:
                model = load_model(default_model_path)
                st.session_state['persistent_model'] = model
                st.session_state['model_loaded'] = True
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ—¥æ™‚ã‚’å–å¾—
                model_mtime = os.path.getmtime(default_model_path)
                model_date = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(model_mtime))
                
                st.session_state['model_info'] = {
                    'path': default_model_path,
                    'loaded_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'trained_at': model_date,
                    'source': 'è‡ªå‹•èª­ã¿è¾¼ã¿ï¼ˆå‰å›ã®å­¦ç¿’çµæœï¼‰',
                    'file_size': os.path.getsize(default_model_path)
                }
                st.session_state['auto_load_attempted'] = True
            except Exception as e:
                st.session_state['auto_load_error'] = str(e)
                pass  # èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯ç„¡è¦–
        
        # å­¦ç¿’å±¥æ­´ã®çµ±è¨ˆã‚’å–å¾—
        if history_exists:
            try:
                history = load_training_history()
                st.session_state['history_stats'] = {
                    'total_sessions': len(history),
                    'last_trained': history[-1].get('timestamp', 'ä¸æ˜') if history else 'ä¸æ˜',
                    'total_samples': sum(h.get('total_samples', 0) for h in history)
                }
            except:
                pass
    
    # ============================================================
    # ï¿½ğŸ”” èµ·å‹•æ™‚ã®ç¶™ç¶šæ€§é€šçŸ¥ï¼ˆsession_stateåˆæœŸåŒ–å¾Œã«å®Ÿè¡Œï¼‰
    # ============================================================
    if 'startup_notification_shown' not in st.session_state:
        st.session_state['startup_notification_shown'] = True
        
        # ãƒ¢ãƒ‡ãƒ«ã¨å­¦ç¿’å±¥æ­´ã®çŠ¶æ…‹ã‚’ç¢ºèª
        model_loaded = st.session_state.get('model_loaded', False)
        history_stats = st.session_state.get('history_stats', {})
        total_sessions = history_stats.get('total_sessions', 0)
        
        if model_loaded and total_sessions > 0:
            # å‰å›ã®å­¦ç¿’ãŒç¶™ç¶šã•ã‚Œã¦ã„ã‚‹å ´åˆ
            st.success(f"""
            âœ… **å‰å›ã®å­¦ç¿’çŠ¶æ…‹ã‚’å¾©å…ƒã—ã¾ã—ãŸï¼**
            
            - ğŸ“š å­¦ç¿’å›æ•°: {total_sessions}å›
            - ğŸ“ ç´¯è¨ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {history_stats.get('total_samples', 0):,}çµ„
            - ğŸ“… æœ€çµ‚å­¦ç¿’: {history_stats.get('last_trained', 'ä¸æ˜')}
            - ğŸ¤– ãƒ¢ãƒ‡ãƒ«: è‡ªå‹•èª­ã¿è¾¼ã¿å®Œäº†
            
            ğŸ’¡ å‰å›ã®å­¦ç¿’çµæœãŒãã®ã¾ã¾ä½¿ãˆã¾ã™ã€‚æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§ã™ãã«è§£æã§ãã¾ã™ï¼
            """)
        elif total_sessions > 0:
            # å­¦ç¿’å±¥æ­´ã¯ã‚ã‚‹ãŒãƒ¢ãƒ‡ãƒ«ãŒç„¡ã„å ´åˆ
            st.warning(f"""
            âš ï¸ **å­¦ç¿’å±¥æ­´ã‚’æ¤œå‡ºã—ã¾ã—ãŸãŒã€ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“**
            
            - ğŸ“š å­¦ç¿’å±¥æ­´: {total_sessions}å›
            - ğŸ“… æœ€çµ‚å­¦ç¿’: {history_stats.get('last_trained', 'ä¸æ˜')}
            
            ğŸ’¡ å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã§å†å­¦ç¿’ã™ã‚‹ã¨ã€AIãŒå¾©æ´»ã—ã¾ã™ã€‚
            """)
        else:
            # åˆã‚ã¦ã®èµ·å‹•
            st.info("""
            ğŸ‘‹ **ã‚ˆã†ã“ãï¼ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æAIã¸**
            
            ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ã‚ãªãŸã®å­¦ç¿’å±¥æ­´ã¨AIãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•çš„ã«ä¿å­˜ã—ã¾ã™ã€‚
            
            **æ¬¡å›èµ·å‹•æ™‚ã‚‚:**
            - âœ… å­¦ç¿’ã—ãŸçŸ¥è­˜ãŒç¶™ç¶š
            - âœ… AIãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•èª­ã¿è¾¼ã¿
            - âœ… å­¦ç¿’å±¥æ­´ãŒä¿æŒ
            
            ğŸ’¡ ã¾ãšã¯ã€Œå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã€ã§AIã‚’å­¦ç¿’ã•ã›ã¾ã—ã‚‡ã†ï¼
            """)
    
    # ============================================================
    # ğŸ“± ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆé¸æŠæ©Ÿèƒ½ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
    # ============================================================
    with st.sidebar:
        st.markdown("### ğŸ“± è¡¨ç¤ºãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š")
        layout_mode = st.radio(
            "ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
            options=['ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ', 'ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ç‰ˆ'],
            index=0 if st.session_state['layout_mode'] == 'ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ' else 1,
            help="""ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ: 2åˆ—è¡¨ç¤ºã€ç¸¦ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æœ€é©åŒ–
ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ç‰ˆ: 4-5åˆ—è¡¨ç¤ºã€æ¨ªå¹…æœ€å¤§æ´»ç”¨"""
        )
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ¢ãƒ¼ãƒ‰ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯å†èª­ã¿è¾¼ã¿
        if layout_mode != st.session_state['layout_mode']:
            st.session_state['layout_mode'] = layout_mode
            st.info(f"ğŸ’¡ {layout_mode}ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
            st.button("ğŸ”„ å†èª­ã¿è¾¼ã¿", on_click=lambda: st.rerun())
        
        st.divider()
    
    # ============================================================
    # ğŸ¯ AIæˆé•·çŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒˆãƒƒãƒ—ã«è¡¨ç¤ºï¼‰
    # ============================================================
    training_history_preview = load_training_history()
    ai_status = calculate_ai_readiness(training_history_preview)
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦åˆ—æ•°ã‚’å¤‰æ›´
    is_mobile = st.session_state['layout_mode'] == 'ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ'
    
    # AIã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºï¼ˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦åˆ—æ•°å¤‰æ›´ï¼‰
    if is_mobile:
        # ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ: 2Ã—2ã‚°ãƒªãƒƒãƒ‰
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ¯ AIä¿¡é ¼åº¦", f"{ai_status['confidence']:.0f}%", 
                     delta=ai_status['level'])
        with col2:
            status_emoji = "âœ…" if ai_status['ready'] else "âš ï¸"
            status_text = "å®Ÿç”¨å¯èƒ½" if ai_status['ready'] else "å­¦ç¿’ä¸­"
            st.metric("ğŸ“Š å®Ÿç”¨åŒ–çŠ¶æ³", f"{status_emoji} {status_text}", 
                     delta=f"{ai_status['stats']['total_sessions']}å›å­¦ç¿’")
        
        col3, col4 = st.columns(2)
        with col3:
            if ai_status['stats']['total_sessions'] > 0:
                st.metric("ğŸ“ˆ æœ€æ–°ç›¸é–¢ä¿‚æ•°", 
                         f"{ai_status['stats']['latest_correlation']:.3f}",
                         delta=f"ç›®æ¨™: 0.850+")
            else:
                st.metric("ğŸ“ˆ æœ€æ–°ç›¸é–¢ä¿‚æ•°", "æœªå­¦ç¿’", delta="å­¦ç¿’é–‹å§‹ã—ã¦ãã ã•ã„")
        with col4:
            if ai_status['stats']['total_sessions'] > 0:
                st.metric("ğŸ¯ æœ€æ–°èª¤å·®(MAE)", 
                         f"{ai_status['stats']['latest_mae']:.4f}",
                         delta=f"ç›®æ¨™: 0.010ä»¥ä¸‹",
                         delta_color="inverse")
            else:
                st.metric("ğŸ¯ æœ€æ–°èª¤å·®(MAE)", "æœªå­¦ç¿’", delta="")
    else:
        # ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ç‰ˆ: 1Ã—4æ¨ªä¸¦ã³
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ¯ AIä¿¡é ¼åº¦", f"{ai_status['confidence']:.0f}%", 
                     delta=ai_status['level'])
        with col2:
            status_emoji = "âœ…" if ai_status['ready'] else "âš ï¸"
            status_text = "å®Ÿç”¨å¯èƒ½" if ai_status['ready'] else "å­¦ç¿’ä¸­"
            st.metric("ğŸ“Š å®Ÿç”¨åŒ–çŠ¶æ³", f"{status_emoji} {status_text}", 
                     delta=f"{ai_status['stats']['total_sessions']}å›å­¦ç¿’")
        with col3:
            if ai_status['stats']['total_sessions'] > 0:
                st.metric("ğŸ“ˆ æœ€æ–°ç›¸é–¢ä¿‚æ•°", 
                         f"{ai_status['stats']['latest_correlation']:.3f}",
                         delta=f"ç›®æ¨™: 0.850+")
            else:
                st.metric("ğŸ“ˆ æœ€æ–°ç›¸é–¢ä¿‚æ•°", "æœªå­¦ç¿’", delta="å­¦ç¿’é–‹å§‹ã—ã¦ãã ã•ã„")
        with col4:
            if ai_status['stats']['total_sessions'] > 0:
                st.metric("ğŸ¯ æœ€æ–°èª¤å·®(MAE)", 
                         f"{ai_status['stats']['latest_mae']:.4f}",
                         delta=f"ç›®æ¨™: 0.010ä»¥ä¸‹",
                         delta_color="inverse")
            else:
                st.metric("ğŸ¯ æœ€æ–°èª¤å·®(MAE)", "æœªå­¦ç¿’", delta="")
    
    # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã¯ã‚¨ã‚¯ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã§
    if ai_status['stats']['total_sessions'] > 0:
        with st.expander("ğŸ“Š AIæˆé•·ãƒ¬ãƒãƒ¼ãƒˆï¼ˆè©³ç´°ï¼‰", expanded=False):
            tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ æˆé•·çŠ¶æ³", "ğŸ“š å­¦ç¿’å±¥æ­´", "ğŸ¯ æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹"])
            
            with tab1:
                st.markdown("### ğŸ¯ AIå®Ÿç”¨åŒ–é€²æ—")
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
                st.progress(ai_status['confidence'] / 100, 
                           text=f"ä¿¡é ¼åº¦: {ai_status['confidence']:.1f}% - {ai_status['level']}")
                
                col_a, col_b = st.columns(2)
                with col_a:
                    st.markdown("#### ğŸ“Š ç¾åœ¨ã®æ€§èƒ½")
                    stats = ai_status['stats']
                    perf_data = {
                        "æŒ‡æ¨™": ["ç›¸é–¢ä¿‚æ•°", "å¹³å‡èª¤å·®", "æ”¹å–„ç‡", "å­¦ç¿’å›æ•°", "ç·ãƒ‡ãƒ¼ã‚¿æ•°"],
                        "ç¾åœ¨å€¤": [
                            f"{stats['latest_correlation']:.4f}",
                            f"{stats['latest_mae']:.4f}",
                            f"{stats['latest_improvement']:.1f}%",
                            f"{stats['total_sessions']}å›",
                            f"{stats['total_pairs']}çµ„"
                        ],
                        "ç›®æ¨™å€¤": ["0.850+", "0.010ä»¥ä¸‹", "20%+", "5å›+", "100çµ„+"],
                        "é”æˆ": [
                            "âœ…" if stats['latest_correlation'] >= 0.85 else "ğŸ”„",
                            "âœ…" if stats['latest_mae'] <= 0.01 else "ğŸ”„",
                            "âœ…" if stats['latest_improvement'] >= 20 else "ğŸ”„",
                            "âœ…" if stats['total_sessions'] >= 5 else "ğŸ”„",
                            "âœ…" if stats['total_pairs'] >= 100 else "ğŸ”„"
                        ]
                    }
                    st.dataframe(perf_data, use_container_width=True, hide_index=True)
                
                with col_b:
                    st.markdown("#### ğŸ¯ æ¬¡ã®ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³")
                    milestone = ai_status['next_milestone']
                    st.write(f"**ç›®æ¨™:** {milestone['target']}")
                    st.progress(milestone['progress'] / 100)
                    st.info(f"ğŸ’¡ {milestone['needed']}")
                    
                    st.markdown("#### ğŸ“ˆ ãƒ™ã‚¹ãƒˆè¨˜éŒ²")
                    st.write(f"**æœ€é«˜ç›¸é–¢ä¿‚æ•°:** {stats['best_correlation']:.4f}")
                    st.write(f"**æœ€å°èª¤å·®:** {stats['best_mae']:.4f}")
                    st.write(f"**æœ€å¤§æ”¹å–„ç‡:** {stats['best_improvement']:.1f}%")
                
                # å®Ÿç”¨åŒ–åˆ¤å®š
                st.markdown("---")
                if ai_status['ready']:
                    st.success("""
                    ### âœ… å®Ÿç”¨åŒ–å¯èƒ½ãƒ¬ãƒ™ãƒ«ã«åˆ°é”ï¼
                    
                    **ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼** ã“ã®AIã¯æœ¬ç•ªã‚¢ãƒ—ãƒªã«æ­è¼‰ã§ãã‚‹æ°´æº–ã§ã™ã€‚
                    
                    **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:**
                    1. ğŸ¯ ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆ`trained_fd_model.pkl`ï¼‰
                    2. ğŸš€ æœ¬ç•ªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«çµ±åˆ
                    3. ğŸ“Š å®Ÿé‹ç”¨ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
                    4. ğŸ”„ å®šæœŸçš„ãªå†å­¦ç¿’ã§ç²¾åº¦ç¶­æŒ
                    """)
                else:
                    st.warning(f"""
                    ### âš ï¸ ç¾åœ¨ã¯å­¦ç¿’ä¸­ - ä¿¡é ¼åº¦ {ai_status['confidence']:.0f}%
                    
                    å®Ÿç”¨åŒ–ã«ã¯ **ä¿¡é ¼åº¦75%ä»¥ä¸Š** ãŒå¿…è¦ã§ã™ã€‚
                    ã‚ã¨ **{75 - ai_status['confidence']:.0f}ãƒã‚¤ãƒ³ãƒˆ** ã®æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚
                    
                    **æ”¹å–„æ–¹æ³•ã¯ã€Œæ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã€ã‚¿ãƒ–ã‚’ã”ç¢ºèªãã ã•ã„ã€‚**
                    """)
            
            with tab2:
                st.markdown("### ğŸ“š å­¦ç¿’å±¥æ­´ä¸€è¦§")
                if len(training_history_preview) > 0:
                    history_data = []
                    for i, record in enumerate(training_history_preview[-10:], 1):  # æœ€æ–°10ä»¶
                        metrics = record.get('metrics', {})
                        history_data.append({
                            "å›": len(training_history_preview) - 10 + i,
                            "æ—¥æ™‚": record.get('timestamp', '')[:16],
                            "ãƒ‡ãƒ¼ã‚¿æ•°": record.get('num_pairs', 0),
                            "å“è³ªãƒ¬ãƒ™ãƒ«": record.get('quality_level', 'ä¸æ˜'),
                            "æ‹¡å¼µ": record.get('augmentation_count', 0),
                            "ç›¸é–¢": f"{metrics.get('correlation_pred', 0):.3f}",
                            "èª¤å·®": f"{metrics.get('mae_pred', 0):.4f}",
                            "æ”¹å–„": f"{metrics.get('improvement', 0):.1f}%"
                        })
                    
                    import pandas as pd
                    st.dataframe(pd.DataFrame(history_data), use_container_width=True, hide_index=True)
                    
                    # ã‚°ãƒ©ãƒ•ã§æˆé•·ã‚’å¯è¦–åŒ–
                    st.markdown("#### ğŸ“ˆ æˆé•·ã‚°ãƒ©ãƒ•")
                    import matplotlib.pyplot as plt
                    
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
                    
                    sessions = list(range(1, len(training_history_preview) + 1))
                    correlations = [h.get('metrics', {}).get('correlation_pred', 0) for h in training_history_preview]
                    maes = [h.get('metrics', {}).get('mae_pred', 0) for h in training_history_preview]
                    
                    ax1.plot(sessions, correlations, marker='o', linewidth=2, markersize=6)
                    ax1.axhline(y=0.85, color='g', linestyle='--', label='ç›®æ¨™: 0.85')
                    ax1.set_xlabel('å­¦ç¿’å›æ•°')
                    ax1.set_ylabel('ç›¸é–¢ä¿‚æ•°')
                    ax1.set_title('ç›¸é–¢ä¿‚æ•°ã®æ¨ç§»')
                    ax1.legend()
                    ax1.grid(True, alpha=0.3)
                    
                    ax2.plot(sessions, maes, marker='s', linewidth=2, markersize=6, color='orange')
                    ax2.axhline(y=0.01, color='g', linestyle='--', label='ç›®æ¨™: 0.01')
                    ax2.set_xlabel('å­¦ç¿’å›æ•°')
                    ax2.set_ylabel('å¹³å‡çµ¶å¯¾èª¤å·® (MAE)')
                    ax2.set_title('èª¤å·®ã®æ¨ç§»')
                    ax2.legend()
                    ax2.grid(True, alpha=0.3)
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                else:
                    st.info("ã¾ã å­¦ç¿’å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
            
            with tab3:
                st.markdown("### ğŸ’¡ æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
                for i, rec in enumerate(ai_status['recommendations'], 1):
                    st.write(f"**{i}.** {rec}")
                
                st.markdown("---")
                st.markdown("""
                ### ğŸ“– åŠ¹æœçš„ãªå­¦ç¿’ã®ãƒã‚¤ãƒ³ãƒˆ
                
                #### 1. ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¢—ã‚„ã™
                - **ç›®æ¨™:** 100çµ„ä»¥ä¸Šã®ç”»åƒãƒšã‚¢
                - **æ–¹æ³•:** ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’æ´»ç”¨ï¼ˆç¾åœ¨28ç¨®é¡åˆ©ç”¨å¯èƒ½ï¼‰
                - **åŠ¹æœ:** ç²¾åº¦å‘ä¸Šã€éå­¦ç¿’é˜²æ­¢
                
                #### 2. å“è³ªãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´
                - **low1-3:** è»½åº¦åŠ£åŒ– - å­¦ç¿’ãŒå®¹æ˜“
                - **low4-7:** ä¸­åº¦åŠ£åŒ– - ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ï¼ˆæ¨å¥¨ï¼‰
                - **low8-10:** é‡åº¦åŠ£åŒ– - é›£æ˜“åº¦é«˜ã€å®Ÿç”¨çš„
                
                #### 3. ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§
                - ç•°ãªã‚‹ç…§æ˜æ¡ä»¶ã®ç”»åƒ
                - ç•°ãªã‚‹è¢«å†™ä½“
                - ç•°ãªã‚‹ã‚¢ãƒ³ã‚°ãƒ«
                
                #### 4. å®šæœŸçš„ãªå­¦ç¿’
                - é€±1å›ä»¥ä¸Šã®å­¦ç¿’ã‚’æ¨å¥¨
                - æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦å†å­¦ç¿’
                - æ€§èƒ½ã®å®‰å®šæ€§ã‚’ç¢ºèª
                """)
    else:
        st.info("ğŸ’¡ å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã¨ã€AIã®æˆé•·çŠ¶æ³ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ä¸‹ã®ã€Œå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã•ã›ã¦ãã ã•ã„ã€‚")
    
    st.markdown("---")

    gpu_auto = USE_CUPY
    st.sidebar.header("è¨­å®š")
    st.sidebar.write(f"GPU åˆ©ç”¨å¯èƒ½: {USE_CUPY}")
    use_gpu_checkbox = st.sidebar.checkbox("GPU ã‚’ä½¿ã†(è‡ªå‹•åˆ¤å®š)", value=USE_CUPY)
    st.sidebar.write("â€» GPU ãŒç„¡ã„å ´åˆã¯è‡ªå‹•çš„ã« CPU ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
    
    # ============================================================
    # ğŸ“Š ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã‚’è¡¨ç¤º
    # ============================================================
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹")
    if st.session_state.get('model_loaded', False):
        model_info = st.session_state.get('model_info', {})
        st.sidebar.success("âœ… **ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æ¸ˆã¿**")
        
        with st.sidebar.expander("ğŸ“‹ ãƒ¢ãƒ‡ãƒ«è©³ç´°æƒ…å ±", expanded=True):
            st.write(f"**èª­ã¿è¾¼ã¿å…ƒ:** {model_info.get('source', 'ä¸æ˜')}")
            st.write(f"**å­¦ç¿’æ—¥æ™‚:** {model_info.get('trained_at', 'ä¸æ˜')}")
            st.write(f"**èª­ã¿è¾¼ã¿æ™‚åˆ»:** {model_info.get('loaded_at', 'ä¸æ˜')}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’è¡¨ç¤º
            file_size = model_info.get('file_size', 0)
            if file_size > 0:
                size_mb = file_size / (1024 * 1024)
                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:** {size_mb:.2f} MB")
            
            # å­¦ç¿’å±¥æ­´çµ±è¨ˆ
            if 'history_stats' in st.session_state:
                stats = st.session_state['history_stats']
                st.write("---")
                st.write("**ğŸ“š å­¦ç¿’å±¥æ­´çµ±è¨ˆ:**")
                st.write(f"- å­¦ç¿’å›æ•°: {stats.get('total_sessions', 0)}å›")
                st.write(f"- ç´¯è¨ˆã‚µãƒ³ãƒ—ãƒ«æ•°: {stats.get('total_samples', 0):,}çµ„")
                st.write(f"- æœ€çµ‚å­¦ç¿’: {stats.get('last_trained', 'ä¸æ˜')}")
        
        st.sidebar.info("ğŸ’¡ ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯æ¬¡å›èµ·å‹•æ™‚ã‚‚è‡ªå‹•çš„ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã™")
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ãƒœã‚¿ãƒ³
        if st.sidebar.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆ"):
            st.session_state['persistent_model'] = None
            st.session_state['model_loaded'] = False
            st.session_state['model_info'] = None
            st.rerun()
    else:
        st.sidebar.warning("âš ï¸ **ãƒ¢ãƒ‡ãƒ«æœªèª­ã¿è¾¼ã¿**")
        
        # è‡ªå‹•èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
        if 'auto_load_error' in st.session_state:
            st.sidebar.error(f"ã‚¨ãƒ©ãƒ¼: {st.session_state['auto_load_error']}")
        
        st.sidebar.write("**ãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ã™ã‚‹æ–¹æ³•:**")
        st.sidebar.write("1. å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã§æ–°è¦å­¦ç¿’")
        st.sidebar.write("2. æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        # å­¦ç¿’å±¥æ­´ãŒã‚ã‚‹å ´åˆã®è¡¨ç¤º
        if 'history_stats' in st.session_state:
            stats = st.session_state['history_stats']
            if stats.get('total_sessions', 0) > 0:
                st.sidebar.info(f"ğŸ“š å­¦ç¿’å±¥æ­´: {stats['total_sessions']}å›\næœ€çµ‚å­¦ç¿’: {stats['last_trained']}")
                st.sidebar.write("ğŸ’¡ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")
    
    # ============================================================
    # ğŸ“š å­¦ç¿’å±¥æ­´ã‚’è¡¨ç¤º
    # ============================================================
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“š å­¦ç¿’å±¥æ­´")
    training_history = load_training_history()
    
    # AIæº–å‚™çŠ¶æ³è©•ä¾¡
    ai_readiness = calculate_ai_readiness(training_history)
    
    # AIã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    st.sidebar.markdown("### ğŸ¯ AIå®Ÿç”¨åŒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
    
    # ä¿¡é ¼åº¦ãƒ¡ãƒ¼ã‚¿ãƒ¼
    confidence = ai_readiness['confidence']
    confidence_color = (
        "ğŸŸ¢" if confidence >= 75 else
        "ğŸŸ¡" if confidence >= 50 else
        "ğŸŸ " if confidence >= 30 else
        "ğŸ”´"
    )
    st.sidebar.metric(
        label="ä¿¡é ¼åº¦",
        value=f"{confidence:.0f}%",
        delta=f"{ai_readiness['level']}"
    )
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    st.sidebar.progress(confidence / 100)
    
    # å®Ÿç”¨å¯å¦ã®åˆ¤å®š
    if ai_readiness['ready']:
        st.sidebar.success("âœ… **å®Ÿç”¨å¯èƒ½** - æœ¬ç•ªã‚¢ãƒ—ãƒªã«æ­è¼‰ã§ãã¾ã™")
    else:
        st.sidebar.warning("âš ï¸ **å­¦ç¿’ä¸­** - ã•ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
    
    st.sidebar.write(f"**ãƒ¬ãƒ™ãƒ«:** {ai_readiness['level']}")
    st.sidebar.write(f"_{ai_readiness['level_desc']}_")
    
    # çµ±è¨ˆæƒ…å ±
    with st.sidebar.expander("ğŸ“Š è©³ç´°çµ±è¨ˆ"):
        stats = ai_readiness['stats']
        st.write(f"**å­¦ç¿’å›æ•°:** {stats['total_sessions']}å›")
        st.write(f"**ç·ãƒ‡ãƒ¼ã‚¿æ•°:** {stats['total_pairs']}çµ„")
        st.write(f"**æœ€é«˜ç›¸é–¢:** {stats['best_correlation']:.3f}")
        st.write(f"**å¹³å‡ç›¸é–¢:** {stats['avg_correlation']:.3f}")
        st.write(f"**æœ€å°èª¤å·®:** {stats['best_mae']:.4f}")
        st.write(f"**å¹³å‡èª¤å·®:** {stats['avg_mae']:.4f}")
    
    # æ¬¡ã®ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³
    milestone = ai_readiness['next_milestone']
    with st.sidebar.expander("ğŸ¯ æ¬¡ã®ç›®æ¨™"):
        st.write(f"**ç›®æ¨™:** {milestone['target']}")
        st.progress(milestone['progress'] / 100)
        st.write(f"_{milestone['needed']}_")
    
    # æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹
    with st.sidebar.expander("ğŸ’¡ æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹"):
        for rec in ai_readiness['recommendations']:
            st.write(f"â€¢ {rec}")
    
    # ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆé–‹ç™ºè€…å‘ã‘ï¼‰
    with st.sidebar.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±"):
        st.write("### æœ€æ–°å­¦ç¿’ãƒ‡ãƒ¼ã‚¿")
        if training_history and len(training_history) > 0:
            latest = training_history[-1]
            st.json({
                'timestamp': latest.get('timestamp'),
                'num_pairs': latest.get('num_pairs'),
                'total_samples': latest.get('total_samples'),
                'quality_level': latest.get('quality_level'),
                'augmentation_count': latest.get('augmentation_count'),
                'metrics': latest.get('metrics', {})
            })
            
            st.write("### ä¿¡é ¼åº¦è¨ˆç®—ã«ä½¿ç”¨ã—ãŸå€¤")
            metrics = latest.get('metrics', {})
            st.write(f"- correlation_pred: {metrics.get('correlation_pred', 'ãªã—')}")
            st.write(f"- improvement: {metrics.get('improvement', 'ãªã—')}")
            st.write(f"- mae_pred: {metrics.get('mae_pred', 'ãªã—')}")
            st.write(f"**è¨ˆç®—ã•ã‚ŒãŸä¿¡é ¼åº¦:** {ai_readiness['confidence']:.1f}%")
            
            # å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ãƒœã‚¿ãƒ³
            st.write("---")
            if st.button("ğŸ—‘ï¸ å­¦ç¿’å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ", help="å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¦æ–°ã—ãå­¦ç¿’ã—ç›´ã—ã¾ã™"):
                try:
                    if os.path.exists("training_history.json"):
                        os.remove("training_history.json")
                        st.success("âœ… å­¦ç¿’å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                        st.rerun()
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.write("å­¦ç¿’å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # å­¦ç¿’å±¥æ­´è©³ç´°
    if training_history:
        st.sidebar.write(f"")
        st.sidebar.write(f"**å­¦ç¿’è¨˜éŒ²:** {len(training_history)}å›")
        
        # æœ€æ–°ã®å­¦ç¿’æƒ…å ±ã‚’è¡¨ç¤º
        if len(training_history) > 0:
            latest = training_history[-1]
            st.sidebar.write(f"**æœ€æ–°å­¦ç¿’:** {latest.get('timestamp', 'ä¸æ˜')[:16]}")
            if 'metrics' in latest:
                metrics = latest['metrics']
                corr = metrics.get('correlation_pred', 0)
                improve = metrics.get('improvement', 0)
                st.sidebar.write(f"ğŸ“ˆ ç›¸é–¢: {corr:.3f}")
                st.sidebar.write(f"ğŸ¯ æ”¹å–„: {improve:.1f}%")
                
                # AIè©•ä¾¡ã‚’è¡¨ç¤º
                evaluation = evaluate_ai_performance(corr, improve, metrics.get('mae_pred', 0))
                st.sidebar.write(f"**ç·åˆè©•ä¾¡:** {evaluation['grade']} {evaluation['emoji']}")
        
        # å­¦ç¿’æˆé•·åˆ†æ
        if len(training_history) >= 2:
            with st.sidebar.expander("ï¿½ AIæˆé•·åˆ†æ"):
                growth_analysis = analyze_learning_growth(training_history)
                st.write(f"**æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰:** {growth_analysis['trend']} {growth_analysis['trend_emoji']}")
                st.write(f"**ç›¸é–¢ä¿‚æ•°ã®å¤‰åŒ–:** {growth_analysis['correlation_change']:+.3f}")
                st.write(f"**æ”¹å–„ç‡ã®å¤‰åŒ–:** {growth_analysis['improvement_change']:+.1f}%")
                st.write(f"**æœ€é«˜è¨˜éŒ² (ç›¸é–¢):** {growth_analysis['best_correlation']:.3f}")
                st.write("")
                st.write(growth_analysis['recommendation'])
        
        # å±¥æ­´ã®è©³ç´°ã‚’å±•é–‹å¯èƒ½ã«
        with st.sidebar.expander("ğŸ“‹ å…¨å±¥æ­´ã‚’è¡¨ç¤º"):
            for i, record in enumerate(reversed(training_history[-10:]), 1):
                idx = len(training_history) - i + 1
                st.write(f"**#{idx}** {record.get('timestamp', 'ä¸æ˜')}")
                st.write(f"  - ã‚µãƒ³ãƒ—ãƒ«æ•°: {record.get('total_samples', 0)}")
                st.write(f"  - æ‹¡å¼µ: {record.get('augmentation_count', 0)}ç¨®é¡")
                if 'metrics' in record:
                    metrics = record['metrics']
                    corr = metrics.get('correlation_pred', 0)
                    improve = metrics.get('improvement', 0)
                    st.write(f"  - ç›¸é–¢: {corr:.3f}")
                    st.write(f"  - æ”¹å–„: {improve:.1f}%")
                    # å„è¨˜éŒ²ã®è©•ä¾¡
                    eval_result = evaluate_ai_performance(corr, improve, metrics.get('mae_pred', 0))
                    st.write(f"  - è©•ä¾¡: {eval_result['grade']} {eval_result['emoji']}")
                st.write("---")
    else:
        st.sidebar.info("ã¾ã å­¦ç¿’è¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # æ”¹å–„æ–¹æ³•ã‚¬ã‚¤ãƒ‰
    with st.sidebar.expander("ğŸ’¡ çµæœã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•"):
        st.markdown("""
        ### ğŸ¯ è‰¯ã„çµæœã‚’å¾—ã‚‹ãŸã‚ã®ãƒã‚¤ãƒ³ãƒˆ
        
        #### 1ï¸âƒ£ **ç”»åƒã®è³ªã¨å¤šæ§˜æ€§**
        - âœ… **æœ€ä½ã§ã‚‚10çµ„ä»¥ä¸Š**ã®ç”»åƒãƒšã‚¢ã‚’ç”¨æ„
        - âœ… **ç•°ãªã‚‹è¢«å†™ä½“ãƒ»ã‚·ãƒ¼ãƒ³**ã‚’å«ã‚ã‚‹
        - âœ… é«˜ç”»è³ªã¨ä½ç”»è³ªã®**å·®ãŒæ˜ç¢º**ãªãƒšã‚¢ã‚’ä½¿ç”¨
        - ğŸ”„ **ç”»åƒãŒå°‘ãªã„å ´åˆ**: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ©Ÿèƒ½ã‚’ä½¿ç”¨
        
        #### 2ï¸âƒ£ **ç”»è³ªãƒ¬ãƒ™ãƒ«ã®é¸æŠ**
        - ğŸ“Œ `low1` (æœ€ã‚‚é«˜å“è³ª) â†’ å·®ãŒå°ã•ã„
        - ğŸ“Œ `low2` (ä¸­ç¨‹åº¦) â†’ **æ¨å¥¨**
        - ğŸ“Œ `low3` (æœ€ã‚‚ä½å“è³ª) â†’ å·®ãŒå¤§ãã„
        
        **ğŸ’¡ ãƒ’ãƒ³ãƒˆ**: ã¾ãš `low2` ã‚’è©¦ã—ã¦ã€çµæœãŒæ‚ªã‘ã‚Œã° `low3` ã‚’è©¦ã—ã¦ãã ã•ã„
        
        #### 3ï¸âƒ£ **ç”»åƒãŒè¶³ã‚Šãªã„å ´åˆã®å¯¾ç­–**
        
        **ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ (Data Augmentation) ã‚’ä½¿ç”¨**
        - ã‚¢ãƒ—ãƒªå†…ã§è‡ªå‹•çš„ã«ç”»åƒã‚’å¢—ã‚„ã›ã¾ã™
        - æ°´å¹³åè»¢ã€å›è»¢ã€æ˜ã‚‹ã•èª¿æ•´ãªã©
        - ä¾‹: 5çµ„ â†’ æ‹¡å¼µå¾Œ 15çµ„ä»¥ä¸Š
        
        **ğŸ“¸ è¿½åŠ ã®ç”»åƒã‚’ç”¨æ„**
        - ç•°ãªã‚‹è§’åº¦ã‹ã‚‰æ’®å½±
        - ç•°ãªã‚‹ç…§æ˜æ¡ä»¶ã§æ’®å½±
        - ç•°ãªã‚‹è¢«å†™ä½“ã‚’è¿½åŠ 
        
        **âš ï¸ æœ€ä½é™å¿…è¦ãªæšæ•°**
        - å­¦ç¿’ã«ã¯æœ€ä½2çµ„å¿…è¦
        - æ¨å¥¨: 10çµ„ä»¥ä¸Š (æ‹¡å¼µå‰)
        - ç†æƒ³: 20çµ„ä»¥ä¸Š
        
        #### 4ï¸âƒ£ **æ”¹å–„åº¦ãŒä½ã„/è² ã®å ´åˆ**
        - âŒ **åŸå› **: ç”»åƒã®å¤šæ§˜æ€§ä¸è¶³
        - âœ… **å¯¾ç­–1**: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’å¢—ã‚„ã™
        - âœ… **å¯¾ç­–2**: ç•°ãªã‚‹å“è³ªãƒ¬ãƒ™ãƒ« (low2, low3) ã‚’è©¦ã™
        - âœ… **å¯¾ç­–3**: ç•°ãªã‚‹ã‚·ãƒ¼ãƒ³ã®ç”»åƒã‚’è¿½åŠ 
        
        #### 5ï¸âƒ£ **ç›¸é–¢ä¿‚æ•°ãŒ0.0ã¾ãŸã¯N/Aã®å ´åˆ**
        - âŒ **åŸå› **: AIãŒåŒã˜å€¤ã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹
        - âœ… **å¯¾ç­–1**: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã§ç”»åƒã®å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™
        - âœ… **å¯¾ç­–2**: ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã™ (20çµ„ä»¥ä¸Šæ¨å¥¨)
        - âœ… **å¯¾ç­–3**: ç•°ãªã‚‹å“è³ªãƒ¬ãƒ™ãƒ«ã‚’è©¦ã™
        
        #### 6ï¸âƒ£ **RÂ²ã‚¹ã‚³ã‚¢ãŒ0ä»¥ä¸‹ã®å ´åˆ**
        - âŒ **åŸå› **: ãƒ¢ãƒ‡ãƒ«ãŒãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ä»¥ä¸‹
        - âœ… **å¯¾ç­–**: ä¸Šè¨˜1ã€œ4ã‚’å…¨ã¦å®Ÿæ–½
        
        ---
        
        ### ğŸ“Š è‰¯ã„çµæœã®ç›®å®‰
        - âœ… **æ”¹å–„åº¦**: 30%ä»¥ä¸Š
        - âœ… **ç›¸é–¢ä¿‚æ•° (AI)**: 0.7ä»¥ä¸Š
        - âœ… **MAE (AIè£œæ­£)**: 0.05ä»¥ä¸‹
        - âœ… **RÂ²ã‚¹ã‚³ã‚¢**: 0.5ä»¥ä¸Š
        """)
    
    st.sidebar.markdown("---")
    
    # ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰ï¼ˆAIæº–å‚™çŠ¶æ³ã«å¿œã˜ã¦è¡¨ç¤ºï¼‰
    if ai_status['stats']['total_sessions'] > 0:
        with st.sidebar.expander("ğŸš€ æœ¬ç•ªã‚¢ãƒ—ãƒªé–‹ç™ºã«ã¤ã„ã¦"):
            if ai_status['ready']:
                st.success("âœ… AIã¯å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã§ã™ï¼")
            else:
                st.warning(f"âš ï¸ ä¿¡é ¼åº¦ {ai_status['confidence']:.0f}% - ã‚ã¨{75-ai_status['confidence']:.0f}ãƒã‚¤ãƒ³ãƒˆ")
            
            st.markdown("""
            ### ğŸ¯ ã‚¢ãƒ—ãƒªã®æœ€çµ‚ç›®æ¨™
            
            ä½ç”»è³ªç”»åƒã§ã‚‚æ­£ç¢ºãªãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’äºˆæ¸¬ã§ãã‚‹AIæ­è¼‰ã‚¢ãƒ—ãƒª
            
            ---
            
            ### âœ… æ¨å¥¨: ã“ã®ã‚¢ãƒ—ãƒªã‚’æ”¹è‰¯
            
            **ãƒ¡ãƒªãƒƒãƒˆ:**
            - å­¦ç¿’ã¨æ¨è«–ãŒçµ±åˆæ¸ˆã¿
            - ãƒ¢ãƒ‡ãƒ«æ›´æ–°ãŒå®¹æ˜“
            - é–‹ç™ºæ™‚é–“ãŒçŸ­ã„
            
            **æ”¹è‰¯ã®æµã‚Œ:**
            1. ä¿¡é ¼åº¦75%é”æˆã¾ã§å­¦ç¿’
            2. æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã‚’ãƒ¡ã‚¤ãƒ³ã«
            3. è‡ªå‹•å“è³ªåˆ¤å®šã‚’è¿½åŠ 
            4. UIã‚’ã‚·ãƒ³ãƒ—ãƒ«åŒ–
            
            ---
            
            ### ğŸ”„ ã¾ãŸã¯: æ–°è¦ã‚¢ãƒ—ãƒªä½œæˆ
            
            **æ–¹æ³•:**
            1. `trained_fd_model.pkl` ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            2. æ¨è«–å°‚ç”¨ã‚¢ãƒ—ãƒªã‚’æ–°è¦ä½œæˆ
            3. ã‚·ãƒ³ãƒ—ãƒ«ãªUIã§å®Ÿè£…
            
            **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ:** é–‹ç™ºæ™‚é–“ã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹2å€
            
            ---
            
            **ğŸ’¡ ã©ã¡ã‚‰ã‚’é¸ã¶ã¹ã?**
            
            â†’ **æ”¹è‰¯æ¨å¥¨** (åŠ¹ç‡çš„ã€æŸ”è»Ÿæ€§é«˜)
            """)

    st.sidebar.markdown("---")

    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    st.sidebar.header("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰")
    app_mode = st.sidebar.radio(
        "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
        [
            "ğŸ”® æ¨è«–ãƒ¢ãƒ¼ãƒ‰ (ä½ç”»è³ªç”»åƒã®ã¿ã§äºˆæ¸¬)",
            "ğŸ“ å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ (ç”»åƒãƒšã‚¢ãŒå¿…è¦)", 
            "ğŸ“Š ç ”ç©¶å ±å‘Šãƒ»å“è³ªã‚¬ã‚¤ãƒ‰",
            "ğŸŒ¸ é¡”å…¨ä½“åˆ†æãƒ¢ãƒ¼ãƒ‰",
            "ğŸ”¬ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿åé›†",
            "ğŸ“ˆ ç›¸é–¢åˆ†æ"
        ],
        index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š
        help="æ¨è«–ãƒ¢ãƒ¼ãƒ‰: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ä½ç”»è³ªç”»åƒã‹ã‚‰äºˆæ¸¬ï¼ˆãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ï¼‰\nå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰: é«˜ç”»è³ª+ä½ç”»è³ªãƒšã‚¢ã§AIã‚’å­¦ç¿’\nç ”ç©¶å ±å‘Š: å“è³ªæœ€é©åŒ–ç ”ç©¶ã®çµæœã¨å®Ÿç”¨ã‚¬ã‚¤ãƒ‰\né¡”å…¨ä½“åˆ†æ: é¡”ã®å„éƒ¨ä½ã‚’è‡ªå‹•æ¤œå‡ºã—ã¦åˆ†æ\nå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿åé›†: è‚ŒçŠ¶æ…‹ã¨FDã®ç›¸é–¢å®Ÿé¨“ç”¨ãƒ‡ãƒ¼ã‚¿åé›†\nç›¸é–¢åˆ†æ: åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆåˆ†æ"
    )
    
    st.sidebar.markdown("---")

    # æ¨è«–ãƒ¢ãƒ¼ãƒ‰
    if app_mode == "ğŸ”® æ¨è«–ãƒ¢ãƒ¼ãƒ‰ (ä½ç”»è³ªç”»åƒã®ã¿ã§äºˆæ¸¬)":
        st.header("ğŸ”® æ¨è«–ãƒ¢ãƒ¼ãƒ‰ - ä½ç”»è³ªç”»åƒã ã‘ã§é«˜å“è³ªFDã‚’äºˆæ¸¬")
        
        # ã‚µãƒ–ãƒ¢ãƒ¼ãƒ‰é¸æŠã‚’è¿½åŠ 
        st.markdown("### ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
        inference_submode = st.radio(
            "å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰",
            ["ğŸ”® é€šå¸¸äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰", "ğŸ¯ ç²¾åº¦æ¤œè¨¼ãƒ¢ãƒ¼ãƒ‰ (é«˜ç”»è³ªãƒšã‚¢ã§æ¤œè¨¼)"],
            help="é€šå¸¸äºˆæ¸¬: ä½ç”»è³ªç”»åƒã®ã¿ã§äºˆæ¸¬\nç²¾åº¦æ¤œè¨¼: é«˜ç”»è³ªãƒšã‚¢ã¨æ¯”è¼ƒã—ã¦äºˆæ¸¬ç²¾åº¦ã‚’ç¢ºèª"
        )
        
        st.markdown("---")
        
        if inference_submode == "ğŸ”® é€šå¸¸äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰":
            st.markdown("""
            ### ã“ã®ãƒ¢ãƒ¼ãƒ‰ã«ã¤ã„ã¦
            
            **å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€ä½ç”»è³ªã®è‚Œç”»åƒã ã‘ã‹ã‚‰é«˜å“è³ªç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’äºˆæ¸¬ã—ã¾ã™ã€‚**
            
            #### ğŸ“‹ ä½¿ã„æ–¹
            1. ã¾ãšã€Œå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã€ã§ç”»åƒãƒšã‚¢ã‚’ä½¿ã£ã¦AIã‚’å­¦ç¿’
            2. ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            3. ã“ã®ãƒ¢ãƒ¼ãƒ‰ã§ä½ç”»è³ªç”»åƒã ã‘ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            4. **AIãŒè‡ªå‹•çš„ã«é«˜å“è³ªç›¸å½“ã®FDã‚’äºˆæ¸¬**
            
            #### âœ¨ ãƒ¡ãƒªãƒƒãƒˆ
            - ä½ç”»è³ªç”»åƒã ã‘ã§OK (é«˜ç”»è³ªç”»åƒä¸è¦)
            - é«˜é€Ÿå‡¦ç†
            - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯å†åˆ©ç”¨å¯èƒ½
            """)
        else:
            st.markdown("""
            ### ğŸ¯ ç²¾åº¦æ¤œè¨¼ãƒ¢ãƒ¼ãƒ‰ã«ã¤ã„ã¦
            
            **é«˜ç”»è³ªãƒ»ä½ç”»è³ªã®ãƒšã‚¢ç”»åƒã‚’ä½¿ã£ã¦ã€AIã®äºˆæ¸¬ç²¾åº¦ã‚’è©³ã—ãæ¤œè¨¼ã§ãã¾ã™ã€‚**
            
            #### ğŸ“‹ ä½¿ã„æ–¹
            1. é«˜ç”»è³ªç”»åƒã¨ä½ç”»è³ªç”»åƒã‚’ãƒšã‚¢ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            2. AIãŒä½ç”»è³ªã‹ã‚‰é«˜å“è³ªFDã‚’äºˆæ¸¬
            3. å®Ÿéš›ã®é«˜ç”»è³ªç”»åƒã®FDã¨æ¯”è¼ƒ
            4. **äºˆæ¸¬ç²¾åº¦ã‚’å®šé‡çš„ã«è©•ä¾¡**
            
            #### âœ¨ ã§ãã‚‹ã“ã¨
            - äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤ã®æ¯”è¼ƒ
            - èª¤å·®ã®çµ±è¨ˆåˆ†æ
            - ç›¸é–¢ä¿‚æ•°ãƒ»MAEãƒ»RMSE ã®è¨ˆç®—
            - æ•£å¸ƒå›³ãƒ»èª¤å·®åˆ†å¸ƒã®å¯è¦–åŒ–
            - ç”»åƒã”ã¨ã®è©³ç´°ãªç²¾åº¦ç¢ºèª
            
            ğŸ’¡ **ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å®¢è¦³çš„ã«è©•ä¾¡ã—ã€æ”¹å–„ç‚¹ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã¾ã™**
            """)
        
        # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        st.subheader("ğŸ“‚ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿")
        
        # æ°¸ç¶šåŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèª
        if st.session_state.get('model_loaded', False):
            model = st.session_state['persistent_model']
            model_info = st.session_state.get('model_info', {})
            st.success(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æ¸ˆã¿ ({model_info.get('source', 'ä¸æ˜')})")
            
            st.info(f"""
            **ãƒ¢ãƒ‡ãƒ«æƒ…å ±:**
            - ç¨®é¡: {type(model).__name__}
            - æ¨å®šå™¨æ•°: {model.n_estimators if hasattr(model, 'n_estimators') else 'N/A'}
            - æœ€å¤§æ·±åº¦: {model.max_depth if hasattr(model, 'max_depth') else 'N/A'}
            - èª­ã¿è¾¼ã¿æ—¥æ™‚: {model_info.get('loaded_at', 'ä¸æ˜')}
            """)
        else:
            model = None
            st.warning("âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # è¿½åŠ ã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ©Ÿèƒ½
        with st.expander("ğŸ“¤ åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"):
            model_file = st.file_uploader(
                "å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (.pkl)",
                type=['pkl'],
                help="å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã§ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                key="inference_model_uploader"
            )
            
            if model_file is not None:
                try:
                    new_model = pickle.load(model_file)
                    st.success("âœ… æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ!")
                    
                    # æ°¸ç¶šåŒ–
                    st.session_state['persistent_model'] = new_model
                    st.session_state['model_loaded'] = True
                    st.session_state['model_info'] = {
                        'path': model_file.name,
                        'loaded_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                        'source': 'ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'
                    }
                    
                    st.info(f"""
                    **æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«æƒ…å ±:**
                    - ç¨®é¡: {type(new_model).__name__}
                    - æ¨å®šå™¨æ•°: {new_model.n_estimators if hasattr(new_model, 'n_estimators') else 'N/A'}
                    - æœ€å¤§æ·±åº¦: {new_model.max_depth if hasattr(new_model, 'max_depth') else 'N/A'}
                    """)
                    
                    model = new_model
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        
        if model is not None:
            # ========================================
            # ğŸ”® é€šå¸¸äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰
            # ========================================
            if inference_submode == "ğŸ”® é€šå¸¸äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰":
                # ä½ç”»è³ªç”»åƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                st.subheader("ğŸ“¤ ä½ç”»è³ªç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
                
                st.success("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚äºˆæ¸¬ã®æº–å‚™å®Œäº†!")
                
                low_quality_imgs = st.file_uploader(
                    "ä½ç”»è³ªã®è‚Œç”»åƒ",
                    type=['png', 'jpg', 'jpeg'],
                    accept_multiple_files=True,
                    help="ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’äºˆæ¸¬ã—ãŸã„ä½ç”»è³ªç”»åƒ",
                    key="inference_image_uploader"
                )
                
                if low_quality_imgs:
                    st.success(f"âœ… {len(low_quality_imgs)}æšã®ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                    
                    # ğŸ†• ç”»åƒå“è³ªè‡ªå‹•åˆ¤å®š
                    if IMAGE_QUALITY_ASSESSOR_AVAILABLE:
                        with st.expander("ğŸ” ç”»åƒå“è³ªãƒã‚§ãƒƒã‚¯", expanded=False):
                            st.markdown("""
                            **ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã®å“è³ªã‚’è‡ªå‹•åˆ¤å®šã—ã¾ã™**
                            - âœ… **é«˜å“è³ªãƒ»æ¨å¥¨**: very_high / high ä¿¡é ¼åº¦ã§è§£æå¯èƒ½
                            - âœ… **å“è³ªéå‰°**: ç›´æ¥è§£ææ¨å¥¨ï¼ˆAIäºˆæ¸¬ã«ã¯ä¸å‘ãï¼‰
                            - âš ï¸ **ä¿¡é ¼åº¦ä½ä¸‹**: ç”»è³ªãŒä½ãã€è§£æç²¾åº¦ãŒä¸‹ãŒã‚‹å¯èƒ½æ€§
                            - â„¹ï¸ **å…¨ã¦ã®ç”»åƒãŒè§£æå¯èƒ½**: ä¿¡é ¼åº¦ã¯ç•°ãªã‚Šã¾ã™ãŒã€å…¨ã¦å‡¦ç†ã§ãã¾ã™
                            """)
                            
                            quality_results = []
                            quality_check_progress = st.progress(0)
                            
                            for idx, img_file in enumerate(low_quality_imgs):
                                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¦å“è³ªè©•ä¾¡
                                import tempfile
                                with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(img_file.name)[1]) as tmp:
                                    tmp.write(img_file.getvalue())
                                    tmp_path = tmp.name
                                
                                # å“è³ªè©•ä¾¡
                                quality_result = assess_image_quality(tmp_path)
                                quality_results.append({
                                    'filename': img_file.name,
                                    'result': quality_result
                                })
                                
                                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                                os.unlink(tmp_path)
                                
                                quality_check_progress.progress((idx + 1) / len(low_quality_imgs))
                            
                            # å“è³ªåˆ¤å®šçµæœã®è¡¨ç¤º
                            st.markdown("### ğŸ“Š å“è³ªåˆ¤å®šçµæœ")
                            
                            quality_df_data = []
                            for qr in quality_results:
                                result = qr['result']
                                if 'error' not in result:
                                    rec = result['recommendation']
                                    metrics = result['metrics']
                                    quality_df_data.append({
                                        "ç”»åƒå": qr['filename'],
                                        "åˆ¤å®š": f"{rec['icon']} {rec['title']}",
                                        "å“è³ªãƒ¬ãƒ™ãƒ«": result['quality_level'],
                                        "ä¿¡é ¼åº¦": rec['confidence'],
                                        "è§£åƒåº¦": metrics['resolution'],
                                        "é®®æ˜åº¦": f"{metrics['sharpness']:.1f}",
                                        "JPEGå“è³ª": metrics['estimated_jpeg_quality']
                                    })
                                else:
                                    quality_df_data.append({
                                        "ç”»åƒå": qr['filename'],
                                        "åˆ¤å®š": "âŒ ã‚¨ãƒ©ãƒ¼",
                                        "å“è³ªãƒ¬ãƒ™ãƒ«": "-",
                                        "ä¿¡é ¼åº¦": "-",
                                        "è§£åƒåº¦": "-",
                                        "é®®æ˜åº¦": "-",
                                        "JPEGå“è³ª": "-"
                                    })
                            
                            quality_df = pd.DataFrame(quality_df_data)
                            st.dataframe(quality_df, use_container_width=True, hide_index=True)
                            
                            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
                            total_count = len(quality_results)
                            high_quality_count = sum(1 for qr in quality_results if qr['result'].get('quality_level') == 'high')
                            low47_count = sum(1 for qr in quality_results if qr['result'].get('quality_level') == 'low4-7')
                            low13_count = sum(1 for qr in quality_results if qr['result'].get('quality_level') == 'low1-3')
                            low810_count = sum(1 for qr in quality_results if qr['result'].get('quality_level') == 'low8-10')
                            
                            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦åˆ—æ•°å¤‰æ›´
                            if is_mobile:
                                # ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ: 2Ã—2ã‚°ãƒªãƒƒãƒ‰
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.metric("ç·ç”»åƒæ•°", total_count)
                                with col2:
                                    st.metric("é«˜å“è³ª", high_quality_count)
                                
                                col3, col4 = st.columns(2)
                                with col3:
                                    st.metric("Golden Zone", low47_count)
                                with col4:
                                    st.metric("ä½ä¿¡é ¼åº¦", low810_count)
                            else:
                                # ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ç‰ˆ: 1Ã—4æ¨ªä¸¦ã³
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    st.metric("ç·ç”»åƒæ•°", total_count)
                                with col2:
                                    st.metric("é«˜å“è³ª", high_quality_count)
                                with col3:
                                    st.metric("Golden Zone", low47_count)
                                with col4:
                                    st.metric("ä½ä¿¡é ¼åº¦", low810_count)
                            
                            # æƒ…å ±è¡¨ç¤º
                            if low810_count > 0:
                                st.info(f"""
                                â„¹ï¸ **{low810_count}æšã®ç”»åƒã¯ä¿¡é ¼åº¦ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™**
                                
                                è§£æã¯å¯èƒ½ã§ã™ãŒã€ã‚ˆã‚Šé«˜å“è³ªãªç”»åƒã§ã®å†æ’®å½±ã‚’æ¨å¥¨ã—ã¾ã™:
                                - iPhone 8ä»¥é™
                                - Galaxy S8ä»¥é™
                                - Pixel 2ä»¥é™
                                - ä¸€çœ¼ãƒ¬ãƒ•ãƒ»ãƒŸãƒ©ãƒ¼ãƒ¬ã‚¹ã‚«ãƒ¡ãƒ©
                                """)
                            
                            if low13_count > 0:
                                st.info(f"""
                                â„¹ï¸ **{low13_count}æšã®ç”»åƒã¯å“è³ªéå‰°ã§ã™**
                                
                                JPEGå“è³ªãŒé«˜ã™ãã‚‹ãŸã‚ã€AIäºˆæ¸¬ã«ã¯ä¸å‘ãã§ã™ãŒã€
                                **ç›´æ¥è§£æã‚’ä½¿ç”¨ã™ã‚Œã°é«˜ç²¾åº¦ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã™**ã€‚
                                
                                ã¾ãŸã¯ã€JPEGå“è³ªã‚’70-85%ç¨‹åº¦ã«èª¿æ•´ã—ã¦å†æ’®å½±ã—ã€
                                AIäºˆæ¸¬ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚
                                """)
                    
                    # äºˆæ¸¬å®Ÿè¡Œãƒœã‚¿ãƒ³
                    if st.button("ğŸ”® ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’äºˆæ¸¬"):
                        st.info("å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
                        
                        # session_stateã«çµæœã‚’ä¿å­˜
                        st.session_state['inference_results'] = []
                        results = []
                        progress_bar = st.progress(0)
                        
                        for idx, img_file in enumerate(low_quality_imgs):
                            # ç”»åƒèª­ã¿è¾¼ã¿
                            img_file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
                            img = read_bgr_from_buffer(img_file.read())
                            
                            if img is not None:
                                # å“è³ªãƒ¬ãƒ™ãƒ«ã‚’å–å¾—ï¼ˆæ—¢ã«è©•ä¾¡æ¸ˆã¿ï¼‰
                                quality_info = quality_results[idx]['result']
                                quality_level = quality_info.get('quality_level', 'unknown')
                                processing_method = quality_info['recommendation']['processing_method']
                                
                                # å‡¦ç†æ–¹æ³•ã«å¿œã˜ã¦åˆ†å²
                                if processing_method == 'direct_analysis':
                                    # ç›´æ¥è§£æ(high, low1-3)
                                    st.info(f"ğŸ“ {img_file.name}: ç›´æ¥è§£æã‚’å®Ÿè¡Œä¸­...")
                                    fd_result_dict = calculate_fractal_dimension(img)
                                    fd_value = fd_result_dict['fd']
                                    
                                    results.append({
                                        'filename': img_file.name,
                                        'predicted_fd': fd_value,
                                        'image': img,
                                        'method': 'direct_analysis',
                                        'quality_level': quality_level,
                                        'fitting_data': fd_result_dict.get('fitting_data'),
                                        'confidence': {
                                            'overall_confidence': fd_result_dict['confidence'],
                                            'confidence_level': 'é«˜ä¿¡é ¼åº¦',
                                            'level_emoji': 'âœ…',
                                            'lower_bound': fd_result_dict['range'][0],
                                            'upper_bound': fd_result_dict['range'][1]
                                        }
                                    })
                                else:
                                    # AIäºˆæ¸¬ï¼ˆlow4-7, low8-10ï¼‰
                                    predicted_fd = predict_fd_from_low_quality(img, model)
                                    
                                    # ä¿¡é ¼åº¦è¨ˆç®—
                                    confidence_info = calculate_prediction_confidence(img, model, predicted_fd)
                                    
                                    results.append({
                                        'filename': img_file.name,
                                        'predicted_fd': predicted_fd,
                                        'image': img,
                                        'method': 'ai_prediction',
                                        'quality_level': quality_level,
                                        'confidence': confidence_info
                                    })
                            
                            progress_bar.progress((idx + 1) / len(low_quality_imgs))
                        
                        # session_stateã«çµæœã‚’ä¿å­˜
                        st.session_state['inference_results'] = results
                        
                        st.success("âœ… å‡¦ç†å®Œäº†!")
                    
                    # çµæœãŒå­˜åœ¨ã™ã‚‹å ´åˆã«è¡¨ç¤ºï¼ˆãƒœã‚¿ãƒ³ã®å¤–ã§å‡¦ç†ï¼‰
                    if 'inference_results' in st.session_state and st.session_state['inference_results']:
                        results = st.session_state['inference_results']
                        
                        # çµæœè¡¨ç¤º
                        st.subheader("ğŸ“Š è§£æãƒ»äºˆæ¸¬çµæœ")
                        
                        # å‡¦ç†æ–¹æ³•åˆ¥ã«åˆ†é¡
                        direct_analysis_results = [r for r in results if r['method'] == 'direct_analysis']
                        ai_prediction_results = [r for r in results if r['method'] == 'ai_prediction']
                        
                        st.markdown(f"""
                        **å‡¦ç†çµæœã‚µãƒãƒªãƒ¼:**
                        - ğŸ“ **ç›´æ¥è§£æ**: {len(direct_analysis_results)}æš (é«˜å“è³ªãƒ»å“è³ªéå‰°ã®ç”»åƒ)
                        - ğŸ”® **AIäºˆæ¸¬**: {len(ai_prediction_results)}æš (Golden Zoneã®ç”»åƒ)
                        
                        ğŸ’¡ **ç›´æ¥è§£æã¯å®Ÿæ¸¬å€¤ã€AIäºˆæ¸¬ã¯æ¨å®šå€¤ã§ã™**
                        """)
                        
                        # çµæœãƒ†ãƒ¼ãƒ–ãƒ« (å‡¦ç†æ–¹æ³•ä»˜ã)
                        import pandas as pd
                        
                        def get_method_icon(method):
                            return "ğŸ“ ç›´æ¥è§£æ" if method == 'direct_analysis' else "ğŸ”® AIäºˆæ¸¬"
                        
                        df = pd.DataFrame({
                            "No.": range(1, len(results) + 1),
                            "ç”»åƒå": [r['filename'] for r in results],
                            "å‡¦ç†æ–¹æ³•": [get_method_icon(r['method']) for r in results],
                            "ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ": [f"{r['predicted_fd']:.4f}" for r in results],
                            "ä¿¡é ¼åº¦": [f"{r['confidence']['overall_confidence']:.1f}%" for r in results],
                            "ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«": [f"{r['confidence']['level_emoji']} {r['confidence']['confidence_level']}" for r in results],
                            "æ¨å®šç¯„å›²": [f"{r['confidence']['lower_bound']:.4f} - {r['confidence']['upper_bound']:.4f}" for r in results]
                        })
                        
                        st.dataframe(df, use_container_width=True, hide_index=True)
                        
                        # å‡¦ç†æ–¹æ³•åˆ¥ã®è©³ç´°è¡¨ç¤º
                        if len(direct_analysis_results) > 0:
                            with st.expander("ğŸ“ ç›´æ¥è§£æã®è©³ç´°", expanded=False):
                                st.markdown("""
                                **ç›´æ¥è§£æã—ãŸç”»åƒ:**
                                - é«˜å“è³ªç”»åƒï¼ˆhighï¼‰ã¾ãŸã¯å“è³ªéå‰°ç”»åƒï¼ˆlow1-3ï¼‰
                                - ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒ†ã‚£ãƒ³ã‚°æ³•ã«ã‚ˆã‚‹å®Ÿæ¸¬å€¤
                                - ä¿¡é ¼åº¦: 95%ä»¥ä¸Šï¼ˆå®Ÿæ¸¬ã®ãŸã‚é«˜ç²¾åº¦ï¼‰
                                """)
                                
                                direct_df = pd.DataFrame({
                                    "ç”»åƒå": [r['filename'] for r in direct_analysis_results],
                                    "å“è³ªãƒ¬ãƒ™ãƒ«": [r['quality_level'] for r in direct_analysis_results],
                                    "ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ": [f"{r['predicted_fd']:.4f}" for r in direct_analysis_results],
                                })
                                st.dataframe(direct_df, use_container_width=True, hide_index=True)
                        
                        if len(ai_prediction_results) > 0:
                            with st.expander("ğŸ”® AIäºˆæ¸¬ã®è©³ç´°", expanded=False):
                                st.markdown("""
                                **AIäºˆæ¸¬ã—ãŸç”»åƒ:**
                                - Golden Zoneç”»åƒï¼ˆlow4-7ï¼‰ã¾ãŸã¯ä½å“è³ªç”»åƒï¼ˆlow8-10ï¼‰
                                - ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚‹æ¨å®šå€¤
                                - ä¿¡é ¼åº¦: ç”»åƒå“è³ªã¨ãƒ¢ãƒ‡ãƒ«ã®ç¢ºä¿¡åº¦ã«ä¾å­˜
                                """)
                                
                                ai_df = pd.DataFrame({
                                    "ç”»åƒå": [r['filename'] for r in ai_prediction_results],
                                    "å“è³ªãƒ¬ãƒ™ãƒ«": [r['quality_level'] for r in ai_prediction_results],
                                    "äºˆæ¸¬FD": [f"{r['predicted_fd']:.4f}" for r in ai_prediction_results],
                                    "ä¿¡é ¼åº¦": [f"{r['confidence']['overall_confidence']:.1f}%" for r in ai_prediction_results],
                                })
                                st.dataframe(ai_df, use_container_width=True, hide_index=True)
                        
                        # ğŸ†• è‚Œå“è³ªè©•ä¾¡ã®è¿½åŠ 
                        if SKIN_EVALUATOR_AVAILABLE:
                            st.markdown("---")
                            st.subheader("ğŸŒŸ è‚Œå“è³ªè©•ä¾¡ï¼ˆãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãƒ™ãƒ¼ã‚¹ï¼‰")
                            
                            st.markdown("""
                            **ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‹ã‚‰è‚Œã®æ»‘ã‚‰ã‹ã•ã‚’è©•ä¾¡ã—ã¾ã™:**
                            
                            ã€å‚è€ƒæ–‡çŒ®ã€‘ä¸­å·åŒ¡å¼˜ã€Œè‚Œã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ è§£æã€å…‰å­¦ 39å·»11å· (2010)
                            
                            > ğŸ’¡ **é‡è¦:** æ»‘ã‚‰ã‹ãªè‚Œã»ã©ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ãŒè¤‡é›‘åŒ–ã—ã€FDå€¤ãŒ3ã«è¿‘ããªã‚Šã¾ã™ã€‚
                            
                            **è©•ä¾¡åŸºæº–:**
                            - **S (Superior)**: FD â‰¥ 2.90 - éå¸¸ã«æ»‘ã‚‰ã‹ï¼ˆãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ãŒéå¸¸ã«è¤‡é›‘ï¼‰
                            - **A (Excellent)**: 2.80 â‰¤ FD < 2.90 - æ»‘ã‚‰ã‹ï¼ˆæ§‹é€ ãŒè¤‡é›‘ï¼‰
                            - **B (Good)**: 2.50 â‰¤ FD < 2.80 - æ™®é€šï¼ˆæ§‹é€ ã¯ä¸­ç¨‹åº¦ï¼‰
                            - **C (Fair)**: 2.40 â‰¤ FD < 2.50 - ã‚„ã‚„ç²—ã„ï¼ˆæ§‹é€ ãŒã‚„ã‚„å˜ç´”ï¼‰
                            - **D (Poor)**: FD < 2.40 - ç²—ã„ï¼ˆæ§‹é€ ãŒå˜ç´”ï¼‰
                            """)
                            
                            evaluator = SkinQualityEvaluator()
                            skin_evaluation_data = []
                            
                            for r in results:
                                fd = r['predicted_fd']
                                grade = evaluator.get_grade(fd)
                                grade_info = evaluator.grade_criteria[grade]
                                
                                skin_evaluation_data.append({
                                    "ç”»åƒå": r['filename'],
                                    "äºˆæ¸¬FD": f"{fd:.4f}",
                                    "è©•ä¾¡": f"{grade_info['icon']} {grade}",
                                    "è‚ŒçŠ¶æ…‹": grade_info['description'],
                                    "è§£é‡ˆ": grade_info['interpretation'][:30] + "..."  # çŸ­ç¸®ç‰ˆ
                                })
                            
                            skin_df = pd.DataFrame(skin_evaluation_data)
                            st.dataframe(skin_df, use_container_width=True, hide_index=True)
                            
                            # è©•ä¾¡ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ
                            grade_counts = {}
                            for r in results:
                                grade = evaluator.get_grade(r['predicted_fd'])
                                grade_counts[grade] = grade_counts.get(grade, 0) + 1
                            
                            st.markdown("### ğŸ“Š è‚Œå“è³ªã‚°ãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ")
                            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦è¡¨ç¤ºå¤‰æ›´
                            grade_list = ['S', 'A', 'B', 'C', 'D']
                            if is_mobile:
                                # ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ: 2åˆ—ã‚°ãƒªãƒƒãƒ‰
                                for i in range(0, len(grade_list), 2):
                                    cols = st.columns(2)
                                    for j, col in enumerate(cols):
                                        if i + j < len(grade_list):
                                            grade = grade_list[i + j]
                                            count = grade_counts.get(grade, 0)
                                            icon = evaluator.grade_criteria[grade]['icon']
                                            grade_info = evaluator.grade_criteria[grade]
                                            with col:
                                                st.metric(f"{icon} ã‚°ãƒ¬ãƒ¼ãƒ‰{grade}", f"{count}æš", delta=grade_info['description'])
                            else:
                                # ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ç‰ˆ: 1Ã—5æ¨ªä¸¦ã³
                                cols = st.columns(5)
                                for idx, grade in enumerate(grade_list):
                                    count = grade_counts.get(grade, 0)
                                    icon = evaluator.grade_criteria[grade]['icon']
                                    grade_info = evaluator.grade_criteria[grade]
                                    with cols[idx]:
                                        st.metric(f"{icon} {grade}", f"{count}æš", delta=grade_info['description'])
                            
                            # è©³ç´°ãªæ¨å¥¨ã‚±ã‚¢
                            with st.expander("ğŸ’¡ æ¨å¥¨ã‚±ã‚¢ã®è©³ç´°"):
                                for r in results:
                                    fd = r['predicted_fd']
                                    grade = evaluator.get_grade(fd)
                                    grade_info = evaluator.grade_criteria[grade]
                                    
                                    st.markdown(f"---")
                                    st.markdown(f"### {r['filename']}")
                                    st.markdown(f"**ã‚°ãƒ¬ãƒ¼ãƒ‰:** {grade_info['icon']} {grade} - {grade_info['description']}")
                                    st.markdown(f"**FDå€¤:** {fd:.4f}")
                                    st.markdown(f"**è§£é‡ˆ:** {grade_info['interpretation']}")
                                    st.markdown(f"**æ¨å¥¨ã‚±ã‚¢:** {grade_info['recommendation']}")
                        
                        # çµ±è¨ˆæƒ…å ±
                        predicted_fds = [r['predicted_fd'] for r in results]
                        avg_confidence = np.mean([r['confidence']['overall_confidence'] for r in results])
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.info(f"""
                            **äºˆæ¸¬å€¤ã®çµ±è¨ˆ:**
                            - å¹³å‡FD: {np.mean(predicted_fds):.4f}
                            - æ¨™æº–åå·®: {np.std(predicted_fds):.4f}
                            - æœ€å°å€¤: {np.min(predicted_fds):.4f}
                            - æœ€å¤§å€¤: {np.max(predicted_fds):.4f}
                            """)
                        
                        with col2:
                            st.info(f"""
                            **ä¿¡é ¼åº¦ã®çµ±è¨ˆ:**
                            - å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.1f}%
                            - é«˜ä¿¡é ¼åº¦(â‰¥80%): {sum(1 for r in results if r['confidence']['overall_confidence'] >= 80)}æš
                            - ä¸­ä¿¡é ¼åº¦(60-80%): {sum(1 for r in results if 60 <= r['confidence']['overall_confidence'] < 80)}æš
                            - ä½ä¿¡é ¼åº¦(<60%): {sum(1 for r in results if r['confidence']['overall_confidence'] < 60)}æš
                            """)
                        
                        # è©³ç´°ãªä¿¡é ¼åº¦æƒ…å ± (å±•é–‹å¯èƒ½)
                        with st.expander("ğŸ” ä¿¡é ¼åº¦ã®è©³ç´°æƒ…å ±"):
                            st.markdown("""
                            ### ä¿¡é ¼åº¦ã®è¨ˆç®—æ–¹æ³•
                            
                            **ç·åˆä¿¡é ¼åº¦**ã¯ä»¥ä¸‹ã®2ã¤ã®è¦ç´ ã‹ã‚‰è¨ˆç®—ã•ã‚Œã¾ã™:
                            
                            1. **ç‰¹å¾´é‡å“è³ªã‚¹ã‚³ã‚¢ (60%ã®é‡ã¿)**
                               - ã‚¨ãƒƒã‚¸å¼·åº¦: ç”»åƒã®æ§‹é€ ãŒæ˜ç¢ºã‹
                               - ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: ãƒã‚¤ã‚ºãŒå°‘ãªã„ã‹
                               - ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: æƒ…å ±é‡ãŒé©åˆ‡ã‹
                            
                            2. **ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦ (40%ã®é‡ã¿)**
                               - ç¯„å›²å¦¥å½“æ€§: äºˆæ¸¬å€¤ãŒæ­£å¸¸ç¯„å›²å†…ã‹ (2.0-3.0)
                               - äºˆæ¸¬å®‰å®šæ€§: äºˆæ¸¬å€¤ãŒæ¥µç«¯ã§ãªã„ã‹
                            
                            **ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«:**
                            - ğŸŸ¢ éå¸¸ã«é«˜ã„ (80%ä»¥ä¸Š): äºˆæ¸¬å€¤ã¯éå¸¸ã«ä¿¡é ¼ã§ãã‚‹
                            - ğŸ”µ é«˜ã„ (60-80%): äºˆæ¸¬å€¤ã¯ä¿¡é ¼ã§ãã‚‹
                            - ğŸŸ¡ ä¸­ç¨‹åº¦ (40-60%): äºˆæ¸¬å€¤ã¯å‚è€ƒç¨‹åº¦
                            - ğŸ”´ ä½ã„ (40%æœªæº€): äºˆæ¸¬å€¤ã¯æ…é‡ã«æ‰±ã†ã¹ã
                            """)
                            
                            # å„ç”»åƒã®è©³ç´°
                            for idx, result in enumerate(results):
                                conf = result['confidence']
                                st.markdown(f"---")
                                st.markdown(f"### {idx+1}. {result['filename']}")
                                
                                # å‡¦ç†æ–¹æ³•ã«ã‚ˆã£ã¦è¡¨ç¤ºå†…å®¹ã‚’å¤‰æ›´
                                if result['method'] == 'ai_prediction':
                                    # AIäºˆæ¸¬ã®å ´åˆ: 3ã¤ã®æŒ‡æ¨™ã‚’è¡¨ç¤º
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric(
                                            "ç·åˆä¿¡é ¼åº¦",
                                            f"{conf['overall_confidence']:.1f}%",
                                            delta=None
                                        )
                                    with col2:
                                        st.metric(
                                            "ç‰¹å¾´é‡å“è³ª",
                                            f"{conf['feature_quality']:.1f}%"
                                        )
                                    with col3:
                                        st.metric(
                                            "ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦",
                                            f"{conf['model_confidence']:.1f}%"
                                        )
                                    
                                    # ç‰¹å¾´é‡ã®è©³ç´°
                                    feat_details = conf['feature_details']
                                    st.write(f"""
                                    **ç‰¹å¾´é‡ã®è©³ç´°:**
                                    - ã‚¨ãƒƒã‚¸å¼·åº¦: {feat_details['edge_strength']:.2f} (ã‚¹ã‚³ã‚¢: {feat_details['edge_score']:.1f}/40)
                                    - ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {feat_details['noise_level']:.2f} (ã‚¹ã‚³ã‚¢: {feat_details['noise_score']:.1f}/30)
                                    - ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {feat_details['entropy']:.2f} (ã‚¹ã‚³ã‚¢: {feat_details['entropy_score']:.1f}/30)
                                    """)
                                else:
                                    # ç›´æ¥è§£æã®å ´åˆ: ä¿¡é ¼åº¦ã®ã¿è¡¨ç¤º
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.metric(
                                            "ä¿¡é ¼åº¦",
                                            f"{conf['overall_confidence']:.1f}%",
                                            delta=None
                                        )
                                    with col2:
                                        st.metric(
                                            "ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«",
                                            f"{conf['confidence_level']}"
                                        )
                                    
                                    st.write(f"""
                                    **æ¨å®šç¯„å›²:** {conf['lower_bound']:.4f} - {conf['upper_bound']:.4f}
                                    """)
                        
                        # ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ä¿¡é ¼åº¦ä»˜ã)
                        st.subheader("ğŸ“· ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ä¸Šä½3æš)")
                        cols = st.columns(min(3, len(results)))
                        for idx, result in enumerate(results[:3]):
                            with cols[idx]:
                                conf = result['confidence']
                                st.image(
                                    cv2.cvtColor(result['image'], cv2.COLOR_BGR2RGB),
                                    caption=f"{result['filename']}",
                                    use_container_width=True
                                )
                                st.markdown(f"""
                                **FD:** {result['predicted_fd']:.4f}  
                                **ä¿¡é ¼åº¦:** {conf['level_emoji']} {conf['overall_confidence']:.1f}%  
                                **åŒºé–“:** {conf['lower_bound']:.4f} - {conf['upper_bound']:.4f}
                                """)
                        
                        # CSVå‡ºåŠ› (ä¿¡é ¼åº¦æƒ…å ±å«ã‚€)
                        csv = df.to_csv(index=False).encode('utf-8-sig')
                        st.download_button(
                            label="ğŸ“¥ çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ä¿¡é ¼åº¦å«ã‚€)",
                            data=csv,
                            file_name="predicted_fractal_dimensions_with_confidence.csv",
                            mime="text/csv"
                        )
                        
                        # ============================================================
                        # ğŸŒ¸ è‚Œå“è³ªè©•ä¾¡ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                        # ============================================================
                        if SKIN_EVALUATOR_AVAILABLE:
                            st.markdown("---")
                            st.subheader("ğŸŒ¸ è‚Œå“è³ªè©•ä¾¡ (ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒåˆ†æ)")
                            
                            st.info("""
                            ğŸ’¡ **ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¨è‚Œã®é–¢ä¿‚**
                            
                            - **ä½ã„FDå€¤ (2.0-2.4)**: ãã‚ç´°ã‹ãã€ã‚¹ãƒ ãƒ¼ã‚ºãªè‚Œ
                            - **ä¸­ç¨‹åº¦ã®FDå€¤ (2.4-2.6)**: æ™®é€šã®è‚Œè³ª
                            - **é«˜ã„FDå€¤ (2.6-3.0)**: ç²—ã„è‚Œã€æ¯›ç©´ã‚„ã‚·ãƒ¯ãŒç›®ç«‹ã¤
                            
                            ã“ã®AIã¯ä½ç”»è³ªç”»åƒã‹ã‚‰é«˜ç”»è³ªç›¸å½“ã®FDå€¤ã‚’äºˆæ¸¬ã—ã€æ­£ç¢ºãªè‚Œè©•ä¾¡ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
                            """)
                            
                            # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰é¸æŠ
                            eval_mode = st.radio(
                                "è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰",
                                ["ç·åˆè©•ä¾¡", "å€‹åˆ¥è©•ä¾¡", "å¹´é½¢å±¤æ¯”è¼ƒ"],
                                horizontal=True,
                                key="skin_evaluation_mode"
                            )
                            
                            evaluator = SkinQualityEvaluator()
                            
                            if eval_mode == "ç·åˆè©•ä¾¡":
                                # å…¨ç”»åƒã®ç·åˆè©•ä¾¡
                                fd_values = [r['predicted_fd'] for r in results]
                                labels = [r['filename'] for r in results]
                                
                                multi_eval = evaluator.evaluate_multiple(fd_values, labels)
                                
                                if multi_eval:
                                    st.markdown("### ğŸ“Š ç·åˆè©•ä¾¡çµæœ")
                                    
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric(
                                            "ç·åˆè©•ä¾¡",
                                            f"{multi_eval['overall']['grade_emoji']} {multi_eval['overall']['grade']}",
                                            delta=f"ã‚¹ã‚³ã‚¢: {multi_eval['overall']['score']:.1f}/100"
                                        )
                                    with col2:
                                        st.metric(
                                            "å¹³å‡FDå€¤",
                                            f"{multi_eval['statistics']['mean']:.4f}",
                                            delta=f"æ¨™æº–åå·®: {multi_eval['statistics']['std']:.4f}"
                                        )
                                    with col3:
                                        st.metric(
                                            "ä¸€è²«æ€§",
                                            multi_eval['consistency']['level'],
                                            delta=multi_eval['consistency']['message']
                                        )
                                
                                # è§£é‡ˆã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹
                                st.markdown("#### ğŸ’­ è§£é‡ˆ")
                                st.info(multi_eval['overall']['interpretation'])
                                
                                st.markdown("#### ğŸ“ æ”¹å–„ææ¡ˆ")
                                for rec in multi_eval['overall']['recommendations']:
                                    st.write(rec)
                                
                                # çµ±è¨ˆæƒ…å ±
                                with st.expander("ğŸ“ˆ è©³ç´°çµ±è¨ˆ"):
                                    stats = multi_eval['statistics']
                                    st.write(f"**æœ€å°å€¤:** {stats['min']:.4f}")
                                    st.write(f"**æœ€å¤§å€¤:** {stats['max']:.4f}")
                                    st.write(f"**ä¸­å¤®å€¤:** {stats['median']:.4f}")
                                    st.write(f"**ç¯„å›²:** {stats['range']:.4f}")
                            
                            elif eval_mode == "å€‹åˆ¥è©•ä¾¡":
                                # å€‹åˆ¥ç”»åƒã®è©³ç´°è©•ä¾¡
                                st.markdown("### ğŸ“‹ å€‹åˆ¥ç”»åƒè©•ä¾¡")
                                
                                selected_idx = st.selectbox(
                                    "è©•ä¾¡ã™ã‚‹ç”»åƒã‚’é¸æŠ",
                                    range(len(results)),
                                    format_func=lambda i: results[i]['filename'],
                                    key="selected_image_idx"
                                )
                                
                                if selected_idx is not None:
                                    result = results[selected_idx]
                                    fd_value = result['predicted_fd']
                                    
                                    single_eval = evaluator.evaluate_single(fd_value)
                                    
                                    col1, col2 = st.columns([1, 2])
                                    
                                    with col1:
                                        st.image(
                                            cv2.cvtColor(result['image'], cv2.COLOR_BGR2RGB),
                                            caption=result['filename'],
                                            use_container_width=True
                                        )
                                    
                                    with col2:
                                        st.markdown(f"### {single_eval['grade_emoji']} {single_eval['grade']}")
                                        st.metric("ã‚¹ã‚³ã‚¢", f"{single_eval['score']:.1f}/100")
                                        st.metric("FDå€¤", f"{fd_value:.4f}")
                                        
                                        st.markdown("#### ç‰¹å¾´åˆ†æ")
                                        features = single_eval['features']
                                        st.write(f"- **ã‚¹ãƒ ãƒ¼ã‚ºã•:** {features['smoothness']}")
                                        st.write(f"- **ãã‚ç´°ã‹ã•:** {features['texture']}")
                                        st.write(f"- **è¤‡é›‘åº¦:** {features['complexity']}")
                                    
                                    # æœ€å°äºŒä¹—æ³•ã®ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                                    show_fitting_graph = st.checkbox(
                                        "ğŸ”¬ æœ€å°äºŒä¹—æ³•ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º", 
                                        value=False,
                                        key="show_least_squares_graph"
                                    )
                                    
                                    if show_fitting_graph:
                                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                                        if 'fitting_data' not in result:
                                            st.warning("âš ï¸ ã“ã®ç”»åƒã¯AIäºˆæ¸¬ã§å‡¦ç†ã•ã‚ŒãŸãŸã‚ã€æœ€å°äºŒä¹—æ³•ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                                            st.info("ğŸ’¡ ç›´æ¥è§£æï¼ˆé«˜å“è³ªç”»åƒã¾ãŸã¯low1-3ç”»åƒï¼‰ã®ã¿ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã§ãã¾ã™ã€‚")
                                        elif result.get('fitting_data') is None:
                                            st.warning("âš ï¸ ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                                        else:
                                            fitting_data = result['fitting_data']
                                            if fitting_data.get('log_h') is None:
                                                st.warning("âš ï¸ è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ãŒä¸å®Œå…¨ã§ã™ã€‚")
                                            else:
                                                st.markdown("#### ğŸ“Š æœ€å°äºŒä¹—æ³•ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°è§£æ")
                                                try:
                                                    fig = plot_least_squares_fit(
                                                        fitting_data['log_h'],
                                                        fitting_data['log_Nh'],
                                                        fitting_data['coeffs'],
                                                        fd_value
                                                    )
                                                    st.pyplot(fig)
                                                    plt.close(fig)
                                                    
                                                    st.caption("""
                                                    **ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹:**
                                                    - é’ã„ç‚¹: å®Ÿéš›ã®æ¸¬å®šãƒ‡ãƒ¼ã‚¿ (log(ã‚¹ã‚±ãƒ¼ãƒ«) vs log(ãƒœãƒƒã‚¯ã‚¹æ•°))
                                                    - èµ¤ã„ç·š: æœ€å°äºŒä¹—æ³•ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ç›´ç·š
                                                    - å‚¾ãã®çµ¶å¯¾å€¤ãŒãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ(FD)å€¤ã«ãªã‚Šã¾ã™
                                                    - RÂ²å€¤ãŒ1ã«è¿‘ã„ã»ã©ã€ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã®ç²¾åº¦ãŒé«˜ã„ã“ã¨ã‚’ç¤ºã—ã¾ã™
                                                    """)
                                                except Exception as e:
                                                    st.error(f"âŒ ã‚°ãƒ©ãƒ•æç”»ã‚¨ãƒ©ãƒ¼: {str(e)}")
                                    
                                    st.markdown("#### ğŸ’­ è§£é‡ˆ")
                                    st.info(single_eval['interpretation'])
                                    
                                    st.markdown("#### ğŸ“ æ”¹å–„ææ¡ˆ")
                                    for rec in single_eval['recommendations']:
                                        st.write(rec)
                            
                            else:  # å¹´é½¢å±¤æ¯”è¼ƒ
                                st.markdown("### ğŸ‘¥ å¹´é½¢å±¤ã¨ã®æ¯”è¼ƒ")
                                
                                age_group = st.selectbox(
                                    "ã‚ãªãŸã®å¹´é½¢å±¤ã‚’é¸æŠ",
                                    ['10-20', '20-30', '30-40', '40-50', '50+'],
                                    format_func=lambda x: f"{x}ä»£" if x != '50+' else '50ä»£ä»¥ä¸Š',
                                    key="age_group_selection"
                                )
                                
                                # å¹³å‡FDå€¤ã‚’ä½¿ç”¨
                                fd_values = [r['predicted_fd'] for r in results]
                                avg_fd = np.mean(fd_values)
                                
                                comparison = evaluator.compare_with_age_group(avg_fd, age_group)
                                
                                if 'error' not in comparison:
                                    col1, col2, col3 = st.columns(3)
                                    
                                    with col1:
                                        st.metric(
                                            "ã‚ãªãŸã®FDå€¤",
                                            f"{comparison['your_value']:.4f}"
                                        )
                                    
                                    with col2:
                                        st.metric(
                                            "å¹´é½¢å±¤å¹³å‡",
                                            f"{comparison['age_average']:.4f}",
                                            delta=f"å·®: {comparison['difference']:+.4f}"
                                        )
                                    
                                    with col3:
                                        st.metric(
                                            "ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«",
                                            f"{comparison['percentile']:.0f}%"
                                        )
                                    
                                    st.markdown("#### ğŸ’­ æ¯”è¼ƒçµæœ")
                                    st.info(comparison['interpretation'])
                                    
                                    # Z-scoreã®è§£èª¬
                                    with st.expander("ğŸ“Š çµ±è¨ˆçš„è§£é‡ˆ"):
                                        st.write(f"**Z-ã‚¹ã‚³ã‚¢:** {comparison['z_score']:.2f}")
                                        st.write("Z-ã‚¹ã‚³ã‚¢ã®æ„å‘³:")
                                        st.write("- 0ä»˜è¿‘: å¹³å‡çš„")
                                        st.write("- -1ï½-2: å¹³å‡ã‚ˆã‚Šè‰¯å¥½")
                                        st.write("- -2ä»¥ä¸‹: éå¸¸ã«è‰¯å¥½")
                                        st.write("- +1ï½+2: å¹³å‡ã‚ˆã‚Šé«˜ã‚")
                                        st.write("- +2ä»¥ä¸Š: è¦æ”¹å–„")
            
            # ========================================
            # ğŸ¯ ç²¾åº¦æ¤œè¨¼ãƒ¢ãƒ¼ãƒ‰
            # ========================================
            else:  # inference_submode == "ğŸ¯ ç²¾åº¦æ¤œè¨¼ãƒ¢ãƒ¼ãƒ‰ (é«˜ç”»è³ªãƒšã‚¢ã§æ¤œè¨¼)"
                st.subheader("ğŸ“¤ ç”»åƒãƒšã‚¢ã‚’æº–å‚™")
                
                st.success("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚æ¤œè¨¼ã®æº–å‚™å®Œäº†!")
                
                # èª­ã¿è¾¼ã¿ãƒ¢ãƒ¼ãƒ‰é¸æŠ
                validation_mode = st.radio(
                    "ç”»åƒèª­ã¿è¾¼ã¿ãƒ¢ãƒ¼ãƒ‰",
                    ["ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è‡ªå‹•ãƒšã‚¢ãƒªãƒ³ã‚°", "ğŸ“¤ æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"],
                    help="ãƒ•ã‚©ãƒ«ãƒ€ãƒ¢ãƒ¼ãƒ‰: åŒã˜ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”»åƒã‚’è‡ªå‹•ã§ãƒšã‚¢ãƒªãƒ³ã‚°\næ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰: å€‹åˆ¥ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
                )
                
                if validation_mode == "ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è‡ªå‹•ãƒšã‚¢ãƒªãƒ³ã‚°":
                    st.markdown("""
                    **ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€è‡ªå‹•çš„ã«ãƒšã‚¢ã‚’æ¤œå‡ºã—ã¾ã™ã€‚**
                    - é«˜ç”»è³ªç”»åƒ: `IMG_XXXX.jpg`
                    - ä½ç”»è³ªç”»åƒ: `IMG_XXXX_low1.jpg` (low1-10ã«å¯¾å¿œ)
                    """)
                    
                    folder_path = st.text_input(
                        "ğŸ“ ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹",
                        value=r"E:\ç”»è³ªåˆ¥é ¬ç”»åƒ(å…ƒç”»åƒï¼‹10æ®µéš)",
                        help="é«˜ç”»è³ªã¨ä½ç”»è³ªã®ç”»åƒãŒå…¥ã£ãŸãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
                    )
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        file_pattern = st.selectbox(
                            "ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³",
                            ["IMG_*.jpg", "*.jpg", "*.png", "ã‚«ã‚¹ã‚¿ãƒ "],
                            help="æ¤œå‡ºã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³"
                        )
                        if file_pattern == "ã‚«ã‚¹ã‚¿ãƒ ":
                            file_pattern = st.text_input("ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³", value="*.jpg")
                    
                    with col2:
                        quality_level_val = st.selectbox(
                            "ä½ç”»è³ªãƒ¬ãƒ™ãƒ«",
                            ["low1", "low2", "low3", "low4", "low5", "low6", "low7", "low8", "low9", "low10", "è‡ªå‹•æ¤œå‡º"],
                            index=3,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§low4
                            help="æ¤œè¨¼ã«ä½¿ç”¨ã™ã‚‹ä½ç”»è³ªãƒ¬ãƒ™ãƒ«"
                        )
                    
                    if folder_path and os.path.exists(folder_path):
                        # ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç”»åƒãƒšã‚¢ã‚’è‡ªå‹•æ¤œå‡º
                        all_files = sorted(glob.glob(os.path.join(folder_path, file_pattern)))
                        
                        # é«˜ç”»è³ªç”»åƒã‚’æ¤œå‡º(_lowãŒã¤ã„ã¦ã„ãªã„ã‚‚ã®)
                        high_files = [f for f in all_files if not re.search(r'_low\d+', os.path.basename(f))]
                        
                        if len(high_files) > 0:
                            st.info(f"ğŸ“‚ æ¤œå‡ºã•ã‚ŒãŸé«˜ç”»è³ªç”»åƒ: {len(high_files)}æš")
                            
                            # å¯¾å¿œã™ã‚‹ä½ç”»è³ªç”»åƒã‚’æ¤œç´¢ã—ã¦ãƒšã‚¢ä½œæˆ
                            pairs = []
                            
                            if quality_level_val == "è‡ªå‹•æ¤œå‡º":
                                # ã™ã¹ã¦ã®low1-10ã‚’æ¤œå‡º
                                for hf in high_files:
                                    base_name = os.path.splitext(os.path.basename(hf))[0]
                                    ext = os.path.splitext(os.path.basename(hf))[1]
                                    
                                    for lv in range(1, 11):
                                        low_file = os.path.join(folder_path, f"{base_name}_low{lv}{ext}")
                                        if os.path.exists(low_file):
                                            pairs.append({
                                                'base_name': base_name,
                                                'high_file': hf,
                                                'low_file': low_file,
                                                'quality_level': f"low{lv}"
                                            })
                            else:
                                # æŒ‡å®šã•ã‚ŒãŸå“è³ªãƒ¬ãƒ™ãƒ«ã®ã¿
                                for hf in high_files:
                                    base_name = os.path.splitext(os.path.basename(hf))[0]
                                    ext = os.path.splitext(os.path.basename(hf))[1]
                                    low_file = os.path.join(folder_path, f"{base_name}_{quality_level_val}{ext}")
                                    
                                    if os.path.exists(low_file):
                                        pairs.append({
                                            'base_name': base_name,
                                            'high_file': hf,
                                            'low_file': low_file,
                                            'quality_level': quality_level_val
                                        })
                            
                            if len(pairs) > 0:
                                st.success(f"âœ… {len(pairs)}çµ„ã®ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                                
                                # ãƒšã‚¢ä¸€è¦§ã‚’è¡¨ç¤º
                                with st.expander("ğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸãƒšã‚¢ä¸€è¦§"):
                                    import pandas as pd
                                    pair_df = pd.DataFrame({
                                        "No.": range(1, len(pairs) + 1),
                                        "ãƒ™ãƒ¼ã‚¹å": [p['base_name'] for p in pairs],
                                        "å“è³ªãƒ¬ãƒ™ãƒ«": [p['quality_level'] for p in pairs],
                                        "é«˜ç”»è³ªç”»åƒ": [os.path.basename(p['high_file']) for p in pairs],
                                        "ä½ç”»è³ªç”»åƒ": [os.path.basename(p['low_file']) for p in pairs]
                                    })
                                    st.dataframe(pair_df, use_container_width=True, hide_index=True)
                                
                                # æ¤œè¨¼å®Ÿè¡Œã«é€²ã‚€ï¼ˆå¾Œã§å®Ÿè£…ï¼‰
                                validation_pairs = pairs
                                
                            else:
                                st.warning(f"âš ï¸ ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å“è³ªãƒ¬ãƒ™ãƒ«ã€Œ{quality_level_val}ã€ã®ç”»åƒãŒã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                                validation_pairs = None
                        else:
                            st.warning("âš ï¸ é«˜ç”»è³ªç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                            validation_pairs = None
                    elif folder_path:
                        st.error(f"âŒ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {folder_path}")
                        validation_pairs = None
                    else:
                        validation_pairs = None
                
                else:  # æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                    st.markdown("""
                    **é«˜ç”»è³ªç”»åƒã¨ä½ç”»è³ªç”»åƒã‚’ãƒšã‚¢ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚**
                    - ãƒ•ã‚¡ã‚¤ãƒ«åãŒä¸€è‡´ã™ã‚‹ã‚‚ã®ã‚’è‡ªå‹•ã§ãƒšã‚¢ãƒªãƒ³ã‚°ã—ã¾ã™
                    - ä¾‹: `IMG_001.jpg` (é«˜ç”»è³ª) ã¨ `IMG_001_low4.jpg` (ä½ç”»è³ª)
                    """)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        high_quality_imgs = st.file_uploader(
                            "é«˜ç”»è³ªç”»åƒ",
                            type=['png', 'jpg', 'jpeg'],
                            accept_multiple_files=True,
                            help="æ­£è§£ã¨ãªã‚‹é«˜ç”»è³ªã®è‚Œç”»åƒ",
                            key="validation_high_quality_uploader"
                        )
                    
                    with col2:
                        low_quality_imgs_val = st.file_uploader(
                            "ä½ç”»è³ªç”»åƒ",
                            type=['png', 'jpg', 'jpeg'],
                            accept_multiple_files=True,
                            help="AIã§äºˆæ¸¬ã™ã‚‹ä½ç”»è³ªã®è‚Œç”»åƒ",
                            key="validation_low_quality_uploader"
                        )
                    
                    if high_quality_imgs and low_quality_imgs_val:
                        st.success(f"âœ… é«˜ç”»è³ª: {len(high_quality_imgs)}æš, ä½ç”»è³ª: {len(low_quality_imgs_val)}æš")
                        
                        # ğŸ†• ç”»åƒå“è³ªè‡ªå‹•åˆ¤å®šï¼ˆå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ç”¨ï¼‰
                        if IMAGE_QUALITY_ASSESSOR_AVAILABLE:
                            with st.expander("ğŸ” ç”»åƒå“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆé«˜ç”»è³ªç”»åƒï¼‰", expanded=False):
                                st.markdown("""
                                **é«˜ç”»è³ªç”»åƒã®å“è³ªã‚’ç¢ºèªã—ã¾ã™**
                                - âœ… æ¨å¥¨: è§£åƒåº¦ãƒ»é®®æ˜åº¦ãŒååˆ†
                                - âš ï¸ æ³¨æ„: å“è³ªãŒåŸºæº–ã‚’æº€ãŸã•ãªã„å¯èƒ½æ€§
                                """)
                                
                                high_quality_results = []
                                for img_file in high_quality_imgs:
                                    import tempfile
                                    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(img_file.name)[1]) as tmp:
                                        tmp.write(img_file.getvalue())
                                        tmp_path = tmp.name
                                    
                                    quality_result = assess_image_quality(tmp_path)
                                    high_quality_results.append({
                                        'filename': img_file.name,
                                        'result': quality_result
                                    })
                                    os.unlink(tmp_path)
                                
                                # ç°¡æ˜“ã‚µãƒãƒªãƒ¼
                                high_count = sum(1 for r in high_quality_results if r['result'].get('quality_level') == 'high')
                                low47_count = sum(1 for r in high_quality_results if r['result'].get('quality_level') == 'low4-7')
                                low_count = len(high_quality_results) - high_count - low47_count
                                
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("é«˜å“è³ª", f"{high_count}/{len(high_quality_results)}")
                                with col2:
                                    st.metric("ä¸­å“è³ª", low47_count)
                                with col3:
                                    st.metric("ä½å“è³ª", low_count)
                                
                                if low_count > 0:
                                    st.warning(f"âš ï¸ {low_count}æšã®é«˜ç”»è³ªç”»åƒãŒåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚å­¦ç¿’ç²¾åº¦ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                        
                        # ãƒšã‚¢ãƒªãƒ³ã‚°å‡¦ç†
                        st.subheader("ğŸ”— ãƒšã‚¢ãƒªãƒ³ã‚°")
                        
                        def extract_base_name(filename):
                            """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ™ãƒ¼ã‚¹åã‚’æŠ½å‡º (low1-10ã®ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»)"""
                            # æ‹¡å¼µå­ã‚’é™¤å»
                            name_without_ext = os.path.splitext(filename)[0]
                            # _low1 ã‹ã‚‰ _low10 ã‚’é™¤å»
                            base_name = re.sub(r'_low\d+$', '', name_without_ext)
                            return base_name
                        
                        # ãƒšã‚¢ä½œæˆ
                        high_dict = {extract_base_name(f.name): f for f in high_quality_imgs}
                        low_dict = {}
                        
                        for f in low_quality_imgs_val:
                            base = extract_base_name(f.name)
                            if base not in low_dict:
                                low_dict[base] = []
                            low_dict[base].append(f)
                        
                        # ãƒãƒƒãƒãƒ³ã‚°
                        validation_pairs = []
                        for base_name in high_dict.keys():
                            if base_name in low_dict:
                                for low_file in low_dict[base_name]:
                                    validation_pairs.append({
                                        'base_name': base_name,
                                        'high_file': high_dict[base_name],
                                        'low_file': low_file
                                    })
                        
                        if validation_pairs:
                            st.success(f"âœ… {len(validation_pairs)}çµ„ã®ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                            
                            # ãƒšã‚¢ä¸€è¦§ã‚’è¡¨ç¤º
                            with st.expander("ğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸãƒšã‚¢ä¸€è¦§"):
                                import pandas as pd
                                # æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã¯file objectãªã®ã§.nameã‚’ä½¿ç”¨
                                pair_df = pd.DataFrame({
                                    "No.": range(1, len(validation_pairs) + 1),
                                    "ãƒ™ãƒ¼ã‚¹å": [p['base_name'] for p in validation_pairs],
                                    "é«˜ç”»è³ªç”»åƒ": [p['high_file'].name for p in validation_pairs],
                                    "ä½ç”»è³ªç”»åƒ": [p['low_file'].name for p in validation_pairs]
                                })
                                st.dataframe(pair_df, use_container_width=True, hide_index=True)
                        else:
                            st.warning("âš ï¸ ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                            validation_pairs = None
                    else:
                        validation_pairs = None
                
                # ========================================
                # æ¤œè¨¼å®Ÿè¡Œï¼ˆãƒ•ã‚©ãƒ«ãƒ€ãƒ¢ãƒ¼ãƒ‰ãƒ»æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…±é€šï¼‰
                # ========================================
                if validation_pairs and len(validation_pairs) > 0:
                    if st.button("ğŸ¯ ç²¾åº¦æ¤œè¨¼ã‚’å®Ÿè¡Œ", type="primary"):
                        st.info("æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™...")
                        
                        validation_results = []
                        progress_bar = st.progress(0)
                        
                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
                        debug_info = st.empty()
                        
                        for idx, pair in enumerate(validation_pairs):
                            debug_info.info(f"å‡¦ç†ä¸­: {idx+1}/{len(validation_pairs)} - {pair['base_name']}")
                            
                            # ç”»åƒèª­ã¿è¾¼ã¿ï¼ˆãƒ•ã‚©ãƒ«ãƒ€ãƒ¢ãƒ¼ãƒ‰=ãƒ‘ã‚¹ã€æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰=file bufferï¼‰
                            if isinstance(pair['high_file'], str):  # ãƒ•ã‚©ãƒ«ãƒ€ãƒ¢ãƒ¼ãƒ‰
                                high_img = read_bgr_from_path(pair['high_file'])
                                low_img = read_bgr_from_path(pair['low_file'])
                                high_filename = os.path.basename(pair['high_file'])
                                low_filename = os.path.basename(pair['low_file'])
                            else:  # æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                                high_img = read_bgr_from_buffer(pair['high_file'].read())
                                low_img = read_bgr_from_buffer(pair['low_file'].read())
                                high_filename = pair['high_file'].name
                                low_filename = pair['low_file'].name
                            
                            if high_img is not None and low_img is not None:
                                # é«˜ç”»è³ªç”»åƒã®å®Ÿéš›ã®FDè¨ˆç®—ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜æ–¹æ³•ã‚’ä½¿ç”¨ï¼‰
                                actual_fd, _, _ = fast_fractal_std_boxcount_batched(high_img, use_gpu=False)
                                if actual_fd is None:
                                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: naiveãƒ¡ã‚½ãƒƒãƒ‰ã‚’è©¦ã™
                                    actual_fd, _, _ = fractal_dimension_naive(high_img)
                                
                                debug_info.info(f"""
                                {pair['base_name']}:
                                - é«˜ç”»è³ªç”»åƒã‚µã‚¤ã‚º: {high_img.shape}
                                - å®Ÿæ¸¬FD: {actual_fd}
                                """)
                                
                                if actual_fd is None:
                                    st.warning(f"âš ï¸ {pair['base_name']}: FDè¨ˆç®—å¤±æ•—ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
                                    continue
                                
                                # ä½ç”»è³ªç”»åƒã‹ã‚‰ã®äºˆæ¸¬FD
                                predicted_fd = predict_fd_from_low_quality(low_img, model)
                                
                                debug_info.info(f"""
                                {pair['base_name']}:
                                - ä½ç”»è³ªç”»åƒã‚µã‚¤ã‚º: {low_img.shape}
                                - äºˆæ¸¬FD: {predicted_fd}
                                """)
                                
                                # èª¤å·®è¨ˆç®—
                                error = predicted_fd - actual_fd
                                abs_error = abs(error)
                                relative_error = (abs_error / actual_fd) * 100 if actual_fd != 0 else 0
                                
                                validation_results.append({
                                    'base_name': pair['base_name'],
                                    'high_filename': high_filename,
                                    'low_filename': low_filename,
                                    'actual_fd': actual_fd,
                                    'predicted_fd': predicted_fd,
                                    'error': error,
                                    'abs_error': abs_error,
                                    'relative_error': relative_error,
                                    'high_img': high_img,
                                    'low_img': low_img
                                })
                            else:
                                st.warning(f"âš ï¸ {pair['base_name']}: ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—")
                            
                            progress_bar.progress((idx + 1) / len(validation_pairs))
                        
                        debug_info.empty()  # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚¯ãƒªã‚¢
                        
                        st.success(f"âœ… æ¤œè¨¼å®Œäº†! {len(validation_results)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
                        
                        # ãƒ‡ãƒ¼ã‚¿æ•°ãƒã‚§ãƒƒã‚¯
                        if len(validation_results) == 0:
                            st.error("âŒ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        elif len(validation_results) == 1:
                            st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒ1ä»¶ã®ã¿ã§ã™ã€‚çµ±è¨ˆåˆ†æã«ã¯æœ€ä½3ä»¶ä»¥ä¸Šã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
                        
                        # ========================================
                        # ğŸ“Š ç²¾åº¦æ¤œè¨¼çµæœã®è¡¨ç¤º
                        # ========================================
                        st.subheader("ğŸ“Š ç²¾åº¦æ¤œè¨¼çµæœ")
                        
                        if validation_results:
                            # çµ±è¨ˆæŒ‡æ¨™ã®è¨ˆç®—
                            actual_fds = np.array([r['actual_fd'] for r in validation_results])
                            predicted_fds = np.array([r['predicted_fd'] for r in validation_results])
                            errors = np.array([r['error'] for r in validation_results])
                            abs_errors = np.array([r['abs_error'] for r in validation_results])
                            
                            # ãƒ‡ãƒ¼ã‚¿æ•°ã¨å¤‰å‹•ãƒã‚§ãƒƒã‚¯
                            n_samples = len(validation_results)
                            actual_std = np.std(actual_fds)
                            predicted_std = np.std(predicted_fds)
                            
                            st.info(f"""
                            **æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿æƒ…å ±:**
                            - ãƒ‡ãƒ¼ã‚¿æ•°: {n_samples}ä»¶
                            - å®Ÿæ¸¬FDã®å¤‰å‹•: {actual_std:.4f}
                            - äºˆæ¸¬FDã®å¤‰å‹•: {predicted_std:.4f}
                            """)
                            
                            # ç›¸é–¢ä¿‚æ•°ï¼ˆå¤‰å‹•ãŒãªã„å ´åˆã¯nanã«ãªã‚‹ï¼‰
                            if actual_std > 0 and predicted_std > 0:
                                correlation = np.corrcoef(actual_fds, predicted_fds)[0, 1]
                            else:
                                correlation = np.nan
                                st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã®å¤‰å‹•ãŒãªã„ãŸã‚ã€ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚ç•°ãªã‚‹ç”»åƒã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
                            
                            # MAE (å¹³å‡çµ¶å¯¾èª¤å·®)
                            mae = np.mean(abs_errors)
                            
                            # RMSE (äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®)
                            rmse = np.sqrt(np.mean(errors ** 2))
                            
                            # RÂ² (æ±ºå®šä¿‚æ•°)
                            ss_res = np.sum(errors ** 2)
                            ss_tot = np.sum((actual_fds - np.mean(actual_fds)) ** 2)
                            r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
                            
                            # ç·åˆè©•ä¾¡
                            st.markdown("### ğŸ¯ ç·åˆè©•ä¾¡")
                            
                            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦åˆ—æ•°å¤‰æ›´
                            if is_mobile:
                                # ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ: 2Ã—2ã‚°ãƒªãƒƒãƒ‰
                                col1, col2 = st.columns(2)
                            else:
                                # ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ç‰ˆ: 1Ã—4æ¨ªä¸¦ã³
                                col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                # ç›¸é–¢ä¿‚æ•°ã®è©•ä¾¡
                                if np.isnan(correlation):
                                    corr_grade = "N/A"
                                    corr_emoji = "ğŸ’«"
                                    corr_display = "nan"
                                elif correlation >= 0.95:
                                    corr_grade = "S"
                                    corr_emoji = "ğŸŒŸ"
                                    corr_display = f"{correlation:.4f}"
                                elif correlation >= 0.90:
                                    corr_grade = "A"
                                    corr_emoji = "â­"
                                    corr_display = f"{correlation:.4f}"
                                elif correlation >= 0.85:
                                    corr_grade = "B"
                                    corr_emoji = "âœ¨"
                                    corr_display = f"{correlation:.4f}"
                                else:
                                    corr_grade = "C"
                                    corr_emoji = "ğŸ’«"
                                    corr_display = f"{correlation:.4f}"
                                
                                st.metric(
                                    "ç›¸é–¢ä¿‚æ•°",
                                    corr_display,
                                    delta=f"{corr_grade}è©•ä¾¡ {corr_emoji}"
                                )
                            
                            with col2:
                                # MAEã®è©•ä¾¡
                                if mae <= 0.03:
                                    mae_grade = "S"
                                    mae_emoji = "ğŸŒŸ"
                                elif mae <= 0.05:
                                    mae_grade = "A"
                                    mae_emoji = "â­"
                                elif mae <= 0.08:
                                    mae_grade = "B"
                                    mae_emoji = "âœ¨"
                                else:
                                    mae_grade = "C"
                                    mae_emoji = "ğŸ’«"
                                
                                st.metric(
                                    "MAE (å¹³å‡çµ¶å¯¾èª¤å·®)",
                                    f"{mae:.4f}",
                                    delta=f"{mae_grade}è©•ä¾¡ {mae_emoji}"
                                )
                            
                            # ãƒ¢ãƒã‚¤ãƒ«ç‰ˆã®å ´åˆã¯2è¡Œç›®ã‚’ä½œæˆ
                            if is_mobile:
                                col3, col4 = st.columns(2)
                            
                            with col3:
                                st.metric(
                                    "RMSE",
                                    f"{rmse:.4f}",
                                    delta=f"Â±{rmse:.4f}"
                                )
                            
                            with col4:
                                # RÂ²ã®è©•ä¾¡
                                if r2 >= 0.90:
                                    r2_emoji = "ğŸŒŸ"
                                elif r2 >= 0.80:
                                    r2_emoji = "â­"
                                elif r2 >= 0.70:
                                    r2_emoji = "âœ¨"
                                else:
                                    r2_emoji = "ğŸ’«"
                                
                                st.metric(
                                    "RÂ² (æ±ºå®šä¿‚æ•°)",
                                    f"{r2:.4f}",
                                    delta=r2_emoji
                                )
                            
                            # è©³ç´°çµ±è¨ˆ
                            st.markdown("### ğŸ“ˆ è©³ç´°çµ±è¨ˆ")
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.info(f"""
                                **å®Ÿæ¸¬å€¤ (é«˜ç”»è³ªFD) ã®çµ±è¨ˆ:**
                                - å¹³å‡: {np.mean(actual_fds):.4f}
                                - æ¨™æº–åå·®: {np.std(actual_fds):.4f}
                                - æœ€å°å€¤: {np.min(actual_fds):.4f}
                                - æœ€å¤§å€¤: {np.max(actual_fds):.4f}
                                - ç¯„å›²: {np.max(actual_fds) - np.min(actual_fds):.4f}
                                """)
                            
                            with col2:
                                st.info(f"""
                                **äºˆæ¸¬å€¤ (AIäºˆæ¸¬FD) ã®çµ±è¨ˆ:**
                                - å¹³å‡: {np.mean(predicted_fds):.4f}
                                - æ¨™æº–åå·®: {np.std(predicted_fds):.4f}
                                - æœ€å°å€¤: {np.min(predicted_fds):.4f}
                                - æœ€å¤§å€¤: {np.max(predicted_fds):.4f}
                                - ç¯„å›²: {np.max(predicted_fds) - np.min(predicted_fds):.4f}
                                """)
                            
                            st.warning(f"""
                            **èª¤å·®ã®çµ±è¨ˆ:**
                            - å¹³å‡èª¤å·® (Bias): {np.mean(errors):.4f}
                            - MAE: {mae:.4f}
                            - RMSE: {rmse:.4f}
                            - æœ€å¤§èª¤å·®: {np.max(abs_errors):.4f}
                            - èª¤å·®ã®æ¨™æº–åå·®: {np.std(errors):.4f}
                            """)
                            
                            # å¯è¦–åŒ–
                            st.markdown("### ğŸ“Š å¯è¦–åŒ–")
                            
                            import matplotlib.pyplot as plt
                            
                            fig, axes = plt.subplots(1, 3, figsize=(18, 5))
                            
                            # 1. æ•£å¸ƒå›³ (äºˆæ¸¬ vs å®Ÿæ¸¬)
                            axes[0].scatter(actual_fds, predicted_fds, alpha=0.6, s=100)
                            axes[0].plot([actual_fds.min(), actual_fds.max()], 
                                        [actual_fds.min(), actual_fds.max()], 
                                        'r--', lw=2, label='ç†æƒ³ç·š (y=x)')
                            axes[0].set_xlabel('å®Ÿæ¸¬FD (é«˜ç”»è³ª)', fontsize=12)
                            axes[0].set_ylabel('äºˆæ¸¬FD (AI)', fontsize=12)
                            axes[0].set_title(f'äºˆæ¸¬ vs å®Ÿæ¸¬\nç›¸é–¢ä¿‚æ•°: {correlation:.4f}', fontsize=14)
                            axes[0].legend()
                            axes[0].grid(True, alpha=0.3)
                            
                            # 2. èª¤å·®åˆ†å¸ƒ (ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ )
                            axes[1].hist(errors, bins=20, edgecolor='black', alpha=0.7)
                            axes[1].axvline(0, color='red', linestyle='--', linewidth=2, label='èª¤å·®ã‚¼ãƒ­')
                            axes[1].axvline(np.mean(errors), color='green', linestyle='--', 
                                          linewidth=2, label=f'å¹³å‡èª¤å·®: {np.mean(errors):.4f}')
                            axes[1].set_xlabel('èª¤å·® (äºˆæ¸¬ - å®Ÿæ¸¬)', fontsize=12)
                            axes[1].set_ylabel('é »åº¦', fontsize=12)
                            axes[1].set_title(f'èª¤å·®åˆ†å¸ƒ\nMAE: {mae:.4f}, RMSE: {rmse:.4f}', fontsize=14)
                            axes[1].legend()
                            axes[1].grid(True, alpha=0.3)
                            
                            # 3. çµ¶å¯¾èª¤å·®ã®åˆ†å¸ƒ
                            axes[2].hist(abs_errors, bins=20, edgecolor='black', alpha=0.7, color='orange')
                            axes[2].axvline(mae, color='red', linestyle='--', 
                                          linewidth=2, label=f'MAE: {mae:.4f}')
                            axes[2].set_xlabel('çµ¶å¯¾èª¤å·® |äºˆæ¸¬ - å®Ÿæ¸¬|', fontsize=12)
                            axes[2].set_ylabel('é »åº¦', fontsize=12)
                            axes[2].set_title('çµ¶å¯¾èª¤å·®åˆ†å¸ƒ', fontsize=14)
                            axes[2].legend()
                            axes[2].grid(True, alpha=0.3)
                            
                            plt.tight_layout()
                            st.pyplot(fig)
                            
                            # çµæœãƒ†ãƒ¼ãƒ–ãƒ«
                            st.markdown("### ğŸ“‹ è©³ç´°çµæœãƒ†ãƒ¼ãƒ–ãƒ«")
                            
                            import pandas as pd
                            result_df = pd.DataFrame({
                                "No.": range(1, len(validation_results) + 1),
                                "ãƒ™ãƒ¼ã‚¹å": [r['base_name'] for r in validation_results],
                                "å®Ÿæ¸¬FD": [f"{r['actual_fd']:.4f}" for r in validation_results],
                                "äºˆæ¸¬FD": [f"{r['predicted_fd']:.4f}" for r in validation_results],
                                "èª¤å·®": [f"{r['error']:+.4f}" for r in validation_results],
                                "çµ¶å¯¾èª¤å·®": [f"{r['abs_error']:.4f}" for r in validation_results],
                                "ç›¸å¯¾èª¤å·®%": [f"{r['relative_error']:.2f}%" for r in validation_results]
                            })
                            
                            st.dataframe(result_df, use_container_width=True, hide_index=True)
                            
                            # CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            csv = result_df.to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                label="ğŸ“¥ çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=csv,
                                file_name=f"validation_results_{time.strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv"
                            )
                            
                            # ç”»åƒã”ã¨ã®è©³ç´°ç¢ºèª
                            st.markdown("### ğŸ–¼ï¸ ç”»åƒã”ã¨ã®è©³ç´°ç¢ºèª")
                            
                            with st.expander("ç”»åƒã¨èª¤å·®ã‚’è¡¨ç¤º"):
                                for i, result in enumerate(validation_results):
                                    st.markdown(f"#### {i+1}. {result['base_name']}")
                                    
                                    col1, col2, col3 = st.columns([1, 1, 1])
                                    
                                    with col1:
                                        st.image(cv2.cvtColor(result['high_img'], cv2.COLOR_BGR2RGB), 
                                                caption=f"é«˜ç”»è³ª: {result['high_filename']}", 
                                                use_container_width=True)
                                        st.write(f"**å®Ÿæ¸¬FD:** {result['actual_fd']:.4f}")
                                    
                                    with col2:
                                        st.image(cv2.cvtColor(result['low_img'], cv2.COLOR_BGR2RGB), 
                                                caption=f"ä½ç”»è³ª: {result['low_filename']}", 
                                                use_container_width=True)
                                        st.write(f"**äºˆæ¸¬FD:** {result['predicted_fd']:.4f}")
                                    
                                    with col3:
                                        # èª¤å·®è©•ä¾¡
                                        if result['abs_error'] <= 0.02:
                                            error_level = "ğŸŒŸ å„ªç§€"
                                        elif result['abs_error'] <= 0.05:
                                            error_level = "â­ è‰¯å¥½"
                                        elif result['abs_error'] <= 0.08:
                                            error_level = "âœ¨ è¨±å®¹"
                                        else:
                                            error_level = "ğŸ’« è¦æ”¹å–„"
                                        
                                        st.metric("èª¤å·®", f"{result['error']:+.4f}", delta=error_level)
                                        st.write(f"**çµ¶å¯¾èª¤å·®:** {result['abs_error']:.4f}")
                                        st.write(f"**ç›¸å¯¾èª¤å·®:** {result['relative_error']:.2f}%")
                                    
                                    st.markdown("---")
                            
                            # è©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆ
                            st.markdown("### ğŸ’¬ è©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆ")
                            
                            if correlation >= 0.95 and mae <= 0.03:
                                st.success("""
                                ğŸŒŸ **å„ªç§€ãªç²¾åº¦ã§ã™ï¼**
                                - äºˆæ¸¬ã¨å®Ÿæ¸¬ã®ç›¸é–¢ãŒéå¸¸ã«é«˜ãã€MAEã‚‚å°ã•ã„ã§ã™
                                - ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã§ä½¿ç”¨ã§ãã¾ã™
                                - è‚Œå“è³ªè©•ä¾¡ã«ååˆ†ãªç²¾åº¦ã‚’æŒã£ã¦ã„ã¾ã™
                                """)
                            elif correlation >= 0.90 and mae <= 0.05:
                                st.info("""
                                â­ **è‰¯å¥½ãªç²¾åº¦ã§ã™ï¼**
                                - äºˆæ¸¬ç²¾åº¦ã¯å®Ÿç”¨çš„ãªãƒ¬ãƒ™ãƒ«ã§ã™
                                - ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã§æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™
                                """)
                            elif correlation >= 0.85 and mae <= 0.08:
                                st.warning("""
                                âœ¨ **è¨±å®¹ç¯„å›²ã®ç²¾åº¦ã§ã™**
                                - åŸºæœ¬çš„ãªäºˆæ¸¬ã¯å¯èƒ½ã§ã™ãŒã€æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™
                                - ãƒ‡ãƒ¼ã‚¿æ•°å¢—åŠ ã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€å“è³ªãƒ¬ãƒ™ãƒ«ã®è¦‹ç›´ã—ã‚’æ¤œè¨ã—ã¦ãã ã•ã„
                                """)
                            else:
                                st.error("""
                                ğŸ’« **ç²¾åº¦æ”¹å–„ãŒå¿…è¦ã§ã™**
                                - äºˆæ¸¬ç²¾åº¦ãŒä½ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
                                - ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:
                                  1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°ã¯ååˆ†ã‹ (æœ€ä½100çµ„ä»¥ä¸Šæ¨å¥¨)
                                  2. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¯é©åˆ‡ã‹ (15ç¨®é¡ä»¥ä¸Šæ¨å¥¨)
                                  3. å“è³ªãƒ¬ãƒ™ãƒ«ã®é¸æŠã¯é©åˆ‡ã‹ (low4-7æ¨å¥¨)
                                  4. ç”»åƒã®å“è³ªã¯é©åˆ‡ã‹
                                """)
                        
                        else:
                            st.error("æ¤œè¨¼çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    
                    else:
                        st.warning("âš ï¸ ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        st.info("""
                        **ãƒšã‚¢ãƒªãƒ³ã‚°ã®æ¡ä»¶:**
                        - é«˜ç”»è³ª: `IMG_001.jpg`
                        - ä½ç”»è³ª: `IMG_001_low4.jpg` (ãƒ™ãƒ¼ã‚¹åãŒåŒã˜ã§ã€_low{æ•°å­—}ãŒã¤ã)
                        """)
        
        return  # æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã¯ã“ã“ã§çµ‚äº†
    
    # ============================================================
    # ğŸ“Š ç ”ç©¶å ±å‘Šãƒ»å“è³ªã‚¬ã‚¤ãƒ‰ãƒ¢ãƒ¼ãƒ‰
    # ============================================================
    elif app_mode == "ğŸ“Š ç ”ç©¶å ±å‘Šãƒ»å“è³ªã‚¬ã‚¤ãƒ‰":
        show_quality_optimization_report()
        return  # ç ”ç©¶å ±å‘Šãƒ¢ãƒ¼ãƒ‰ã¯ã“ã“ã§çµ‚äº†

    # ============================================================
    # å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ (æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰)
    # ============================================================
    st.header("ğŸ“ å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ - AIã‚’å­¦ç¿’ã•ã›ã‚‹")
    
    # ğŸ¯ å­¦ç¿’å‰ã®è¨ºæ–­ã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹
    with st.expander("ğŸ’¡ åŠ¹æœçš„ãªå­¦ç¿’ã®ãŸã‚ã®ã‚¬ã‚¤ãƒ‰", expanded=False):
        st.markdown("""
        ### ğŸ¯ ä¿¡é ¼åº¦10%ã‹ã‚‰75%ä»¥ä¸Šã‚’ç›®æŒ‡ã™ãŸã‚ã«
        
        #### âš ï¸ ä¿¡é ¼åº¦ãŒä½ã„ä¸»ãªåŸå› 
        
        1. **ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãŒä¸è¶³** â† æœ€é‡è¦ï¼
           - å…ƒç”»åƒ30æšã ã‘ã§ã¯ä¸ååˆ†
           - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã§100çµ„ä»¥ä¸Šã«å¢—ã‚„ã™å¿…è¦ã‚ã‚Š
        
        2. **å“è³ªãƒ¬ãƒ™ãƒ«ã®é¸æŠãƒŸã‚¹**
           - low1-3: å·®ãŒå°ã•ã™ãã¦å­¦ç¿’å›°é›£
           - **æ¨å¥¨: low4-7** (ä¸­åº¦åŠ£åŒ–ã€ãƒãƒ©ãƒ³ã‚¹è‰¯å¥½)
           - ä¸Šç´š: low8-10 (é‡åº¦åŠ£åŒ–ã€å®Ÿç”¨çš„)
           - **âš ï¸ å…¨ãƒ¬ãƒ™ãƒ« (low1-10) ã¯éæ¨å¥¨** â†’ å·®ãŒå¤§ãã™ãã¦MAEæ‚ªåŒ–
        
        3. **å˜ä¸€ãƒ¬ãƒ™ãƒ«ã®å­¦ç¿’**
           - 1ã¤ã®ãƒ¬ãƒ™ãƒ«ã ã‘ã§ã¯æ±ç”¨æ€§ä¸è¶³
           - **ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠã§è¤‡æ•°ãƒ¬ãƒ™ãƒ«åŒæ™‚å­¦ç¿’ã‚’æ¨å¥¨**
        
        ---
        
        ### âœ… æ¨å¥¨è¨­å®šï¼ˆä¿¡é ¼åº¦75%ä»¥ä¸Šã‚’ç›®æŒ‡ã™ï¼‰
        
        | é …ç›® | æ¨å¥¨è¨­å®š | ç†ç”± |
        |------|----------|------|
        | **å“è³ªãƒ¬ãƒ™ãƒ«** | ğŸŸ¡ low4-7 (ã‚°ãƒ«ãƒ¼ãƒ—) | ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ãã€112çµ„ã®ãƒ‡ãƒ¼ã‚¿ |
        | **ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ** | 15ç¨®é¡ä»¥ä¸Šé¸æŠ | æœ€ä½100çµ„ã€ç†æƒ³200çµ„ä»¥ä¸Š |
        | **æ¨å¥¨æ‹¡å¼µ** | æ°´å¹³åè»¢ã€å›è»¢ã€æ˜ã‚‹ã•ã€ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ | åŠ¹æœçš„ãªå¤‰åŒ– |
        
        ---
        
        ### ğŸ“Š è¨­å®šä¾‹ï¼šä¿¡é ¼åº¦75%é”æˆã®å®Ÿä¾‹
        
        **è¨­å®š:**
        - å…ƒç”»åƒ: 30çµ„
        - å“è³ªãƒ¬ãƒ™ãƒ«: low4-7 (ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠ)
        - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ: 20ç¨®é¡
        - æœŸå¾…ãƒ‡ãƒ¼ã‚¿æ•°: 30 Ã— 4ãƒ¬ãƒ™ãƒ« Ã— (1 + 20æ‹¡å¼µ) = **2,520çµ„**
        
        **çµæœäºˆæ¸¬:**
        - ç›¸é–¢ä¿‚æ•°: 0.85-0.90
        - èª¤å·®(MAE): 0.005-0.010
        - ä¿¡é ¼åº¦: **75-85%** (å®Ÿç”¨ãƒ¬ãƒ™ãƒ«)
        
        ---
        
        ### ğŸš€ ä»Šã™ãã§ãã‚‹æ”¹å–„ç­–
        
        1. **å“è³ªãƒ¬ãƒ™ãƒ«**ã‚’ã€ŒğŸŸ¡ low4-7 (ä¸­åº¦åŠ£åŒ–)ã€ã«å¤‰æ›´
        2. **ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ**ã‚¿ãƒ–ã§ä»¥ä¸‹ã‚’é¸æŠ:
           - âœ… æ°´å¹³åè»¢
           - âœ… å‚ç›´åè»¢  
           - âœ… 90åº¦å›è»¢
           - âœ… 180åº¦å›è»¢
           - âœ… æ˜ã‚‹ã•èª¿æ•´ï¼ˆæš—ãï¼‰
           - âœ… æ˜ã‚‹ã•èª¿æ•´ï¼ˆæ˜ã‚‹ãï¼‰
           - âœ… ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ï¼ˆä½ï¼‰
           - âœ… ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ï¼ˆé«˜ï¼‰
           - âœ… ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼
           - âœ… ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚º
           - âœ… ã‚½ãƒ«ãƒˆãƒšãƒƒãƒ‘ãƒ¼ãƒã‚¤ã‚º
           - âœ… JPEGåœ§ç¸®ï¼ˆå“è³ª50ï¼‰
           - âœ… ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹å¼·èª¿
           - âœ… ã‚¨ãƒƒã‚¸å¼·èª¿
           - âœ… ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å¹³å¦åŒ–
        
        3. **ã€Œã™ã¹ã¦é¸æŠã€ãƒœã‚¿ãƒ³**ã‚’ã‚¯ãƒªãƒƒã‚¯ï¼ˆ28ç¨®é¡ã™ã¹ã¦é¸æŠï¼‰
        
        **æœŸå¾…ã•ã‚Œã‚‹çµæœ:**
        - ãƒ‡ãƒ¼ã‚¿æ•°: 30 Ã— 4 Ã— 29 = **3,480çµ„**
        - ä¿¡é ¼åº¦: **80-90%** (ãƒ—ãƒ­ï½ãƒã‚¹ã‚¿ãƒ¼ãƒ¬ãƒ™ãƒ«)
        """)
        
        st.success("""
        ### âœ¨ ç°¡å˜ãªæ‰‹é †
        
        1. ä¸‹ã®ã€Œå“è³ªãƒ¬ãƒ™ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ã€ã§ **ã€ŒğŸ“˜ ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠã€** ã‚’é¸ã¶
        2. **ã€ŒğŸŸ¡ low4-7 (ä¸­åº¦åŠ£åŒ– - æ™®é€š)ã€** ã‚’é¸æŠ
        3. ã€Œãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€ã‚¿ãƒ–ã§ **ã€Œã™ã¹ã¦é¸æŠã€** ã‚’ã‚¯ãƒªãƒƒã‚¯
        4. **ã€ŒğŸš€ å­¦ç¿’é–‹å§‹ã€** ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        5. 10-15åˆ†å¾…ã¤ï¼ˆGPUä½¿ç”¨æ™‚ã¯5-8åˆ†ï¼‰
        6. ä¿¡é ¼åº¦ãŒ **75%ä»¥ä¸Š** ã«ãªã‚‹ã“ã¨ã‚’ç¢ºèªï¼
        """)
    
    # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆã¯é€šçŸ¥
    if st.session_state.get('model_loaded', False):
        model_info = st.session_state.get('model_info', {})
        st.info(f"""
        â„¹ï¸ æ—¢ã«ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ ({model_info.get('source', 'ä¸æ˜')})
        
        - ã“ã®ã¾ã¾æ–°ã—ãå­¦ç¿’ã™ã‚‹ã¨ã€**æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã¯ä¸Šæ›¸ã**ã•ã‚Œã¾ã™
        - æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä¿æŒã—ãŸã„å ´åˆã¯ã€å…ˆã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„
        - æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã‚Œã°ã€æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã§ãã¾ã™
        """)
    
    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    mode = st.radio(
        "ç”»åƒèª­ã¿è¾¼ã¿ãƒ¢ãƒ¼ãƒ‰",
        ["ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è‡ªå‹•ãƒšã‚¢ãƒªãƒ³ã‚°", "ğŸ“¤ æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"],
        help="ãƒ•ã‚©ãƒ«ãƒ€ãƒ¢ãƒ¼ãƒ‰: åŒã˜åå‰ã®ç”»åƒã‚’è‡ªå‹•çš„ã«ãƒšã‚¢ãƒªãƒ³ã‚°\næ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰: å€‹åˆ¥ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
    )

    if mode == "ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è‡ªå‹•ãƒšã‚¢ãƒªãƒ³ã‚°":
        st.markdown("""
        ### ãƒ•ã‚©ãƒ«ãƒ€é¸æŠã‚¬ã‚¤ãƒ‰
        ç”»åƒãƒšã‚¢ã®æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³:
        1. **IMG_XXX.jpg + IMG_XXX_low1.jpg** å½¢å¼ (ä¾‹: `E:\\é ¬ç”»åƒã€€ç”»è³ªåˆ¥\\ç”»è³ªåˆ¥ï¼¿é ¬ç”»åƒ`)
        2. **é«˜ç”»è³ª/ä½ç”»è³ªãƒ•ã‚©ãƒ«ãƒ€åˆ†é›¢** å½¢å¼ (ä»Šå¾Œå¯¾å¿œäºˆå®š)
        3. **ãã®ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³** - æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã‚’ã”åˆ©ç”¨ãã ã•ã„
        """)
        
        folder_path = st.text_input(
            "ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹",
            value=r"E:\ç”»è³ªåˆ¥é ¬ç”»åƒ(å…ƒç”»åƒï¼‹10æ®µéš)",
            help="é«˜ç”»è³ªã¨ä½ç”»è³ªã®ç”»åƒãŒå…¥ã£ãŸãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
        )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠ
        col1, col2 = st.columns(2)
        with col1:
            file_pattern = st.selectbox(
                "ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³",
                ["IMG_*.jpg", "*.jpg", "*.png", "ã‚«ã‚¹ã‚¿ãƒ "],
                help="æ¤œå‡ºã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³"
            )
            if file_pattern == "ã‚«ã‚¹ã‚¿ãƒ ":
                file_pattern = st.text_input("ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³", value="*.jpg")
        
        with col2:
            # å“è³ªãƒ¬ãƒ™ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠã‚’è¿½åŠ 
            quality_group = st.radio(
                "å“è³ªãƒ¬ãƒ™ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—",
                ["ğŸ“— å€‹åˆ¥é¸æŠ", "ğŸ“˜ ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠ"],
                horizontal=True,
                help="å€‹åˆ¥ã§é¸æŠã™ã‚‹ã‹ã€ã‚°ãƒ«ãƒ¼ãƒ—ã§ä¸€æ‹¬é¸æŠã™ã‚‹ã‹"
            )
            
            if quality_group == "ğŸ“— å€‹åˆ¥é¸æŠ":
                quality_level = st.selectbox(
                    "ä½ç”»è³ªãƒ¬ãƒ™ãƒ«ã‚’é¸æŠ",
                    ["low1", "low2", "low3", "low4", "low5", "low6", "low7", "low8", "low9", "low10", "ã‚«ã‚¹ã‚¿ãƒ "],
                    index=4,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§low5ã‚’é¸æŠ
                    help="æ¯”è¼ƒã™ã‚‹ä½ç”»è³ªãƒ¬ãƒ™ãƒ«ã‚’é¸æŠ (low1ãŒæœ€ã‚‚é«˜å“è³ªã€low10ãŒæœ€ã‚‚ä½å“è³ª)"
                )
                if quality_level == "ã‚«ã‚¹ã‚¿ãƒ ":
                    quality_level = st.text_input("ã‚«ã‚¹ã‚¿ãƒ ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹", value="low1")
                quality_levels = [quality_level]  # ãƒªã‚¹ãƒˆã«å¤‰æ›
            else:
                # ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠ
                quality_group_select = st.selectbox(
                    "å“è³ªã‚°ãƒ«ãƒ¼ãƒ—ã‚’é¸æŠ",
                    [
                        "ğŸŸ¢ low1-3 (è»½åº¦åŠ£åŒ– - æ˜“ã—ã„)",
                        "ğŸŸ¡ low4-7 (ä¸­åº¦åŠ£åŒ– - æ™®é€š) ğŸŒŸæ¨å¥¨",
                        "ğŸ”´ low8-10 (é‡åº¦åŠ£åŒ– - é›£ã—ã„)",
                        "ğŸŒˆ å…¨ãƒ¬ãƒ™ãƒ« (low1-10) âš ï¸éæ¨å¥¨"
                    ],
                    index=1,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§low4-7ã‚’é¸æŠ
                    help="è¤‡æ•°ã®å“è³ªãƒ¬ãƒ™ãƒ«ã‚’ä¸€æ‹¬ã§å­¦ç¿’ã«ä½¿ç”¨ã—ã¾ã™"
                )
                
                if quality_group_select == "ğŸŸ¢ low1-3 (è»½åº¦åŠ£åŒ– - æ˜“ã—ã„)":
                    quality_levels = ["low1", "low2", "low3"]
                elif quality_group_select == "ğŸŸ¡ low4-7 (ä¸­åº¦åŠ£åŒ– - æ™®é€š) ğŸŒŸæ¨å¥¨":
                    quality_levels = ["low4", "low5", "low6", "low7"]
                elif quality_group_select == "ğŸ”´ low8-10 (é‡åº¦åŠ£åŒ– - é›£ã—ã„)":
                    quality_levels = ["low8", "low9", "low10"]
                else:  # å…¨ãƒ¬ãƒ™ãƒ«
                    quality_levels = [f"low{i}" for i in range(1, 11)]
                    st.warning("""
                    âš ï¸ **å…¨ãƒ¬ãƒ™ãƒ« (low1-10) ã¯æ¨å¥¨ã•ã‚Œã¾ã›ã‚“**
                    
                    **ç†ç”±:**
                    - å“è³ªå·®ãŒå¤§ãã™ãã¦AIãŒæ··ä¹±ã—ã¾ã™
                    - MAEï¼ˆå¹³å‡çµ¶å¯¾èª¤å·®ï¼‰ãŒæ‚ªåŒ–ã—ã¾ã™
                    - ä¿¡é ¼åº¦ãŒ70%ä»¥ä¸‹ã«ç•™ã¾ã‚Šã¾ã™
                    
                    **æ¨å¥¨:**
                    - ğŸŸ¡ low4-7 (ä¸­åº¦åŠ£åŒ–) ã‚’é¸æŠã—ã¦ãã ã•ã„
                    - ä¿¡é ¼åº¦85%ä»¥ä¸Šã‚’ç›®æŒ‡ã›ã¾ã™
                    """)
                
                st.info(f"âœ… é¸æŠ: {', '.join(quality_levels)} ({len(quality_levels)}ãƒ¬ãƒ™ãƒ«)")
                quality_level = quality_levels[0]  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æœ€åˆã®ãƒ¬ãƒ™ãƒ«ã‚’ä»£å…¥
        
        
        if folder_path and os.path.exists(folder_path):
            # ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç”»åƒãƒšã‚¢ã‚’è‡ªå‹•æ¤œå‡º
            all_files = sorted(glob.glob(os.path.join(folder_path, file_pattern)))
            
            # é«˜ç”»è³ªç”»åƒã‚’æ¤œå‡º(_lowãŒã¤ã„ã¦ã„ãªã„ã‚‚ã®)
            # æ­£è¦è¡¨ç¾ã‚’ä½¿ã£ã¦_low + æ•°å­—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å¤–
            high_files = [f for f in all_files if not re.search(r'_low\d+', os.path.basename(f))]
            
            if len(all_files) > 0:
                st.info(f"ğŸ“‚ æ¤œå‡ºã•ã‚ŒãŸå…¨ç”»åƒ: {len(all_files)}æš")
            
            if len(high_files) > 0:
                st.success(f"âœ… {len(high_files)}æšã®é«˜ç”»è³ªç”»åƒã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
                
                # ãƒ‡ãƒãƒƒã‚°: æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¡¨ç¤º
                with st.expander("ğŸ” æ¤œå‡ºã•ã‚ŒãŸç”»åƒãƒ‘ã‚¹ (ãƒ‡ãƒãƒƒã‚°æƒ…å ±)"):
                    st.write(f"**ãƒ•ã‚©ãƒ«ãƒ€:** {folder_path}")
                    st.write(f"**ãƒ‘ã‚¿ãƒ¼ãƒ³:** {file_pattern}")
                    st.write(f"**å…¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°:** {len(all_files)}")
                    st.write(f"**é«˜ç”»è³ªãƒ•ã‚¡ã‚¤ãƒ«æ•°:** {len(high_files)}")
                    st.write(f"**é«˜ç”»è³ªä¾‹:** {os.path.basename(high_files[0]) if high_files else 'ãªã—'}")
                    if len(high_files) > 1:
                        st.write(f"**ä»–ã®ä¾‹:** {', '.join([os.path.basename(f) for f in high_files[1:min(4, len(high_files))]])}")
                
                # å¯¾å¿œã™ã‚‹ä½ç”»è³ªç”»åƒã‚’æ¤œç´¢
                # ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠã®å ´åˆã¯è¤‡æ•°ãƒ¬ãƒ™ãƒ«ã‚’åé›†
                low_files_all = []
                high_files_all = []
                missing_files = []
                debug_info = []  # ãƒ‡ãƒãƒƒã‚°ç”¨
                
                for quality_lv in quality_levels:
                    for hf in high_files:
                        base_name = os.path.splitext(os.path.basename(hf))[0]
                        ext = os.path.splitext(os.path.basename(hf))[1]
                        low_file = os.path.join(folder_path, f"{base_name}_{quality_lv}{ext}")
                        # ãƒ‘ã‚¹ã®æ­£è¦åŒ–
                        low_file = os.path.normpath(low_file)
                        
                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¨˜éŒ²(æœ€åˆã®å“è³ªãƒ¬ãƒ™ãƒ«ã®ã¿)
                        if quality_lv == quality_levels[0]:
                            exists = os.path.exists(low_file)
                            debug_info.append({
                                'high': os.path.basename(hf),
                                'base': base_name,
                                'ext': ext,
                                'quality': quality_lv,
                                'expected': os.path.basename(low_file),
                                'full_path': low_file,  # ãƒ•ãƒ«ãƒ‘ã‚¹ã‚‚è¿½åŠ 
                                'exists': exists
                            })
                        
                        if os.path.exists(low_file):
                            low_files_all.append(low_file)
                            high_files_all.append(hf)
                        else:
                            if quality_lv == quality_levels[0]:  # æœ€åˆã®ãƒ¬ãƒ™ãƒ«ã®ã¿è¨˜éŒ²
                                missing_files.append(f"{base_name}_{quality_lv}{ext}")
                
                # å¤‰æ•°åã‚’çµ±ä¸€
                low_files = low_files_all
                high_files_for_pairs = high_files_all
                
                # ãƒ‡ãƒãƒƒã‚°: ä½ç”»è³ªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚‚è¡¨ç¤º
                with st.expander("ğŸ” ãƒšã‚¢ç”»åƒãƒ‘ã‚¹ (ãƒ‡ãƒãƒƒã‚°æƒ…å ±)", expanded=False):
                    st.write(f"**ğŸ“ æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€:** `{folder_path}`")
                    st.write(f"**ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³:** `{file_pattern}`")
                    st.write(f"**ğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸå…¨ç”»åƒ:** {len(all_files)}æš")
                    st.write(f"**ğŸ“‹ é«˜ç”»è³ªç”»åƒ:** {len(high_files)}æš")
                    if len(quality_levels) > 1:
                        st.write(f"**ğŸšï¸ é¸æŠã—ãŸå“è³ªãƒ¬ãƒ™ãƒ«:** `{', '.join(quality_levels)}` ({len(quality_levels)}ãƒ¬ãƒ™ãƒ«)")
                        st.write(f"**ğŸ“Š å…ƒç”»åƒæ•°:** {len(high_files)}")
                        st.write(f"**ğŸ“Š åé›†ãƒšã‚¢æ•°:** {len(low_files)} (æœŸå¾…: {len(high_files) * len(quality_levels)})")
                    else:
                        st.write(f"**ğŸšï¸ é¸æŠã—ãŸå“è³ªãƒ¬ãƒ™ãƒ«:** `{quality_level}`")
                        st.write(f"**ğŸ“Š é«˜ç”»è³ªãƒ•ã‚¡ã‚¤ãƒ«æ•°:** {len(high_files)}")
                        st.write(f"**ğŸ“Š ä½ç”»è³ªãƒ•ã‚¡ã‚¤ãƒ«æ•°:** {len(low_files)}")
                    st.write("")
                    
                    if len(debug_info) > 0:
                        st.write("### æœ€åˆã®5ä»¶ã®æ¤œç´¢çµæœ:")
                        for i, info in enumerate(debug_info[:5]):
                            st.write(f"**{i+1}. {info['high']}**")
                            st.write(f"  - ãƒ™ãƒ¼ã‚¹å: `{info['base']}`")
                            st.write(f"  - æ‹¡å¼µå­: `{info['ext']}`")
                            st.write(f"  - å“è³ªãƒ¬ãƒ™ãƒ«: `{info['quality']}`")
                            st.write(f"  - æ¢ã™ãƒ•ã‚¡ã‚¤ãƒ«: `{info['expected']}`")
                            st.write(f"  - ãƒ•ãƒ«ãƒ‘ã‚¹: `{info['full_path']}`")
                            st.write(f"  - å­˜åœ¨: {'âœ… ã¯ã„' if info['exists'] else 'âŒ ã„ã„ãˆ'}")
                            st.write("---")
                    
                    if len(low_files) > 0:
                        st.success(f"**è¦‹ã¤ã‹ã£ãŸä½ç”»è³ªãƒ•ã‚¡ã‚¤ãƒ«ä¾‹:** {os.path.basename(low_files[0])}")
                    
                    if missing_files:
                        st.error(f"**è¦‹ã¤ã‹ã‚‰ãªã„ãƒ•ã‚¡ã‚¤ãƒ«:** {len(missing_files)}ä»¶")
                        st.write("æœ€åˆã®5ä»¶:")
                        for f in missing_files[:5]:
                            st.write(f"  - `{f}`")
                        
                        # å®Ÿéš›ã«ãƒ•ã‚©ãƒ«ãƒ€å†…ã«ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
                        st.write("### ãƒ•ã‚©ãƒ«ãƒ€å†…ã®å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ« (æœ€åˆã®20ä»¶):")
                        actual_files = sorted(glob.glob(os.path.join(folder_path, "*.jpg")))[:20]
                        for f in actual_files:
                            fname = os.path.basename(f)
                            # ã„ãšã‚Œã‹ã®quality_levelã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
                            is_target = any(f"_{ql}" in fname for ql in quality_levels)
                            if is_target:
                                st.write(f"  - âœ… `{fname}`")
                            else:
                                st.write(f"  - `{fname}`")
                
                
                # ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠã®å ´åˆã¯æœŸå¾…å€¤ãŒç•°ãªã‚‹
                if len(quality_levels) > 1:
                    expected_pairs = len(high_files) * len(quality_levels)
                    if len(low_files) == expected_pairs:
                        st.success(f"âœ… {len(low_files)}çµ„ã®å®Œå…¨ãªãƒšã‚¢ã‚’æ¤œå‡ºã—ã¾ã—ãŸ ({len(high_files)}ç”»åƒ Ã— {len(quality_levels)}ãƒ¬ãƒ™ãƒ«)")
                        uploaded_high = high_files_for_pairs
                        uploaded_low = low_files
                        auto_mode = True
                    else:
                        st.warning(f"âš ï¸ ä¸€éƒ¨ã®ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (æœŸå¾…: {expected_pairs}çµ„, æ¤œå‡º: {len(low_files)}çµ„)")
                        if len(low_files) > 0:
                            if st.checkbox("æ¤œå‡ºã•ã‚ŒãŸãƒšã‚¢ã®ã¿ã§ç¶šè¡Œã™ã‚‹"):
                                uploaded_high = high_files_for_pairs
                                uploaded_low = low_files
                                auto_mode = True
                                st.info(f"âœ… {len(low_files)}çµ„ã®ãƒšã‚¢ã‚’ä½¿ç”¨ã—ã¾ã™")
                            else:
                                uploaded_high = None
                                uploaded_low = None
                                auto_mode = False
                        else:
                            uploaded_high = None
                            uploaded_low = None
                            auto_mode = False
                else:
                    # å€‹åˆ¥é¸æŠã®å ´åˆ(å¾“æ¥é€šã‚Š)
                    if len(low_files) == len(high_files):
                        st.success(f"âœ… {len(low_files)}çµ„ã®å®Œå…¨ãªãƒšã‚¢ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
                        uploaded_high = high_files
                        uploaded_low = low_files
                        auto_mode = True
                    else:
                        st.error(f"âŒ ãƒšã‚¢ãŒä¸å®Œå…¨ã§ã™ (é«˜ç”»è³ª: {len(high_files)}æš, ä½ç”»è³ª: {len(low_files)}æš)")
                        if len(low_files) > 0:
                            st.warning(f"ä¸€éƒ¨ã®ãƒšã‚¢ã®ã¿ä½¿ç”¨ã—ã¾ã™ã‹? (å®Œå…¨ãªãƒšã‚¢: {len(low_files)}çµ„)")
                            if st.checkbox("ä¸å®Œå…¨ã§ã‚‚ç¶šè¡Œã™ã‚‹"):
                                # å®Œå…¨ãªãƒšã‚¢ã®ã¿ä½¿ç”¨
                                valid_high = []
                                valid_low = []
                                for hf in high_files:
                                    base_name = os.path.splitext(os.path.basename(hf))[0]
                                    ext = os.path.splitext(os.path.basename(hf))[1]
                                    low_file = os.path.join(folder_path, f"{base_name}_{quality_level}{ext}")
                                    # ãƒ‘ã‚¹ã®æ­£è¦åŒ–
                                    low_file = os.path.normpath(low_file)
                                    if os.path.exists(low_file):
                                        valid_high.append(hf)
                                        valid_low.append(low_file)
                                uploaded_high = valid_high
                                uploaded_low = valid_low
                                auto_mode = True
                                st.info(f"âœ… {len(valid_high)}çµ„ã®å®Œå…¨ãªãƒšã‚¢ã‚’ä½¿ç”¨ã—ã¾ã™")
                            else:
                                uploaded_high = None
                                uploaded_low = None
                                auto_mode = False
                        else:
                            uploaded_high = None
                            uploaded_low = None
                            auto_mode = False
            else:
                st.warning(f"âš ï¸ ãƒ•ã‚©ãƒ«ãƒ€å†…ã«'{file_pattern}'ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                uploaded_high = None
                uploaded_low = None
                auto_mode = False
        elif folder_path:
            st.error(f"âŒ **ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ãŒç„¡åŠ¹ã§ã™**")
            st.info(f"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹: `{folder_path}`")
            st.info(f"ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
            # ãƒ‘ã‚¹ã®å­˜åœ¨ç¢ºèªã®è©³ç´°
            parent_dir = os.path.dirname(folder_path)
            if os.path.exists(parent_dir):
                st.warning(f"è¦ªãƒ•ã‚©ãƒ«ãƒ€ã¯å­˜åœ¨ã—ã¾ã™: `{parent_dir}`")
                # è¦ªãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ã‚’è¡¨ç¤º
                try:
                    subdirs = [d for d in os.listdir(parent_dir) if os.path.isdir(os.path.join(parent_dir, d))]
                    if subdirs:
                        st.info(f"åˆ©ç”¨å¯èƒ½ãªã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€: {', '.join(subdirs[:5])}")
                except:
                    pass
            else:
                st.error(f"è¦ªãƒ•ã‚©ãƒ«ãƒ€ã‚‚å­˜åœ¨ã—ã¾ã›ã‚“: `{parent_dir}`")
            
            uploaded_high = None
            uploaded_low = None
            auto_mode = False
        else:
            st.info("ğŸ‘† ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            uploaded_high = None
            uploaded_low = None
            auto_mode = False
    else:
        uploaded_high = st.file_uploader("é«˜ç”»è³ªç”»åƒã‚’ãƒšã‚¢ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰(åŒæšæ•°)", type=['png','jpg','jpeg'], accept_multiple_files=True)
        uploaded_low = st.file_uploader("ä½ç”»è³ªç”»åƒã‚’ãƒšã‚¢ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰(åŒæšæ•°)", type=['png','jpg','jpeg'], accept_multiple_files=True)
        auto_mode = False


    if uploaded_high and uploaded_low:
        if not auto_mode and len(uploaded_high) != len(uploaded_low):
            st.error("é«˜ç”»è³ªã¨ä½ç”»è³ªã®æšæ•°ã‚’æƒãˆã¦ãã ã•ã„(ãƒšã‚¢ã§è§£æã—ã¾ã™)ã€‚")
            return

        # read images
        if auto_mode:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿(æ—¥æœ¬èªãƒ‘ã‚¹å¯¾å¿œ)
            high_imgs = []
            low_imgs = []
            failed_files = []
            
            for hf, lf in zip(uploaded_high, uploaded_low):
                h_img = read_bgr_from_path(hf)
                l_img = read_bgr_from_path(lf)
                
                if h_img is None:
                    failed_files.append(f"é«˜ç”»è³ª: {os.path.basename(hf)}")
                if l_img is None:
                    failed_files.append(f"ä½ç”»è³ª: {os.path.basename(lf)}")
                
                if h_img is not None and l_img is not None:
                    high_imgs.append(h_img)
                    low_imgs.append(l_img)
            
            if failed_files:
                st.error(f"ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ:\n" + "\n".join(failed_files[:5]))
                if len(failed_files) > 5:
                    st.error(f"...ä»– {len(failed_files)-5} ä»¶")
                return
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
            high_names = [os.path.basename(f) for f in uploaded_high]
            low_names = [os.path.basename(f) for f in uploaded_low]
        else:
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            high_imgs = [read_bgr_from_buffer(f.read()) for f in uploaded_high]
            low_imgs = [read_bgr_from_buffer(f.read()) for f in uploaded_low]
            high_names = [f.name for f in uploaded_high]
            low_names = [f.name for f in uploaded_low]

        if len(high_imgs) == 0:
            st.error("âŒ ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.markdown("---")
        st.subheader("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ (Data Augmentation)")
        
        if len(high_imgs) < 10:
            st.warning(f"""
            âš ï¸ **ç”»åƒãƒšã‚¢æ•°ãŒå°‘ãªã„ã§ã™** (ç¾åœ¨: {len(high_imgs)}çµ„)
            
            ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€å°‘ãªã„ç”»åƒã‹ã‚‰å¤šãã®å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚
            """)
        
        st.markdown("""
        **ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨ã¯ï¼Ÿ**
        
        ç”»åƒã«å¤‰æ›ã‚’åŠ ãˆã¦å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¢—ã‚„ã™æ‰‹æ³•ã§ã™ã€‚ç”»åƒãŒå°‘ãªã„å ´åˆã«æœ‰åŠ¹ã§ã™ã€‚
        
        **ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªå¤‰æ› (å…¨28ç¨®é¡):**
        
        **ğŸ”„ å¹¾ä½•å­¦å¤‰æ› (7ç¨®é¡)**
        - æ°´å¹³åè»¢ã€å‚ç›´åè»¢
        - 90åº¦å›è»¢ã€180åº¦å›è»¢ã€270åº¦å›è»¢
        - å¾®å°å›è»¢ (Â±5åº¦) - æ–¹å‘ä¸å¤‰æ€§å­¦ç¿’
        
        **ğŸ’¡ æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ (6ç¨®é¡)**
        - æ˜ã‚‹ã•å¢—åŠ /æ¸›å°‘
        - ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¢—åŠ /æ¸›å°‘
        - ã‚¬ãƒ³ãƒè£œæ­£ (æ˜ã‚‹ã/æš—ã)
        
        **ğŸ¨ è‰²èª¿æ•´ (5ç¨®é¡)**
        - å½©åº¦å¢—åŠ /æ¸›å°‘
        - è‰²ç›¸ã‚·ãƒ•ãƒˆ
        - æ¸©åº¦èª¿æ•´ (æš–è‰²/å¯’è‰²) - ç…§æ˜æ¡ä»¶å¯¾å¿œ ğŸŒŸ
        
        **ğŸ”§ ç”»è³ªå‡¦ç† (6ç¨®é¡)**
        - ãƒã‚¤ã‚ºè¿½åŠ ã€ã¼ã‹ã—
        - ã‚·ãƒ£ãƒ¼ãƒ—åŒ–ã€ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–
        - ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã€ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ ğŸŒŸ
        
        **ğŸ¯ AIå­¦ç¿’æœ€é©åŒ– (4ç¨®é¡) - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒå­¦ç¿’ã«ç‰¹åŒ– ğŸŒŸ**
        - ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ› (æ‹¡å¤§/ç¸®å°) - ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§å­¦ç¿’
        - CLAHE - å±€æ‰€çš„ãƒ†ã‚¯ã‚¹ãƒãƒ£å¼·èª¿
        - ã‚¢ãƒ³ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ã‚¯ - ã‚¨ãƒƒã‚¸å¼·èª¿
        
        **ğŸŒŸ = AIå­¦ç¿’ã«ç‰¹ã«åŠ¹æœçš„**
        
        **æ³¨æ„**: æ‹¡å¼µã«ã‚ˆã‚Šå‡¦ç†æ™‚é–“ãŒå¢—åŠ ã—ã¾ã™
        """)
        
        # augmentation_methodsã‚’åˆæœŸåŒ–ï¼ˆuse_augmentationã®å¤–å´ã§å®šç¾©ï¼‰
        augmentation_methods = []
        
        use_augmentation = st.checkbox(
            "ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½¿ç”¨ã™ã‚‹",
            value=len(high_imgs) < 10,
            help="ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã—ã¾ã™ã€‚ç”»åƒãŒ10çµ„æœªæº€ã®å ´åˆã«æ¨å¥¨"
        )
        
        if use_augmentation:
            st.info("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚ªãƒ—ã‚·ãƒ§ãƒ³ - ä½¿ç”¨ã™ã‚‹å¤‰æ›ã‚’é¸æŠ")
            
            # ============================================================
            # ğŸ¯ å…¨é¸æŠãƒœã‚¿ãƒ³æ©Ÿèƒ½
            # ============================================================
            col_btn1, col_btn2, col_btn3 = st.columns([2, 2, 3])
            with col_btn1:
                if st.button("âœ… å…¨ã¦é¸æŠ", use_container_width=True, help="å…¨ã¦ã®æ‹¡å¼µæ©Ÿèƒ½ã‚’ã‚ªãƒ³ã«ã—ã¾ã™", type="primary"):
                    st.session_state['select_all_augmentation'] = True
                    # ã‚¿ãƒ–ã”ã¨ã®çŠ¶æ…‹ã‚‚ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.pop('geo_select_all', None)
                    st.session_state.pop('bright_select_all', None)
                    st.session_state.pop('color_select_all', None)
                    st.session_state.pop('quality_select_all', None)
                    st.session_state.pop('ai_select_all', None)
                    st.session_state.pop('recommended_preset', None)
                    st.rerun()
            with col_btn2:
                if st.button("âŒ å…¨ã¦è§£é™¤", use_container_width=True, help="å…¨ã¦ã®æ‹¡å¼µæ©Ÿèƒ½ã‚’ã‚ªãƒ•ã«ã—ã¾ã™"):
                    st.session_state['select_all_augmentation'] = False
                    # ã‚¿ãƒ–ã”ã¨ã®çŠ¶æ…‹ã‚‚ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.pop('geo_select_all', None)
                    st.session_state.pop('bright_select_all', None)
                    st.session_state.pop('color_select_all', None)
                    st.session_state.pop('quality_select_all', None)
                    st.session_state.pop('ai_select_all', None)
                    st.session_state.pop('recommended_preset', None)
                    st.rerun()
            with col_btn3:
                # ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¡¨ç¤º
                select_all_state = st.session_state.get('select_all_augmentation', None)
                if select_all_state == True:
                    st.success("âœ… å…¨é¸æŠä¸­ (28ç¨®é¡)")
                elif select_all_state == False:
                    st.warning("å…¨è§£é™¤ä¸­")
            
            # ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯æ¨å¥¨è¨­å®šãƒœã‚¿ãƒ³ï¼ˆæ–°è¦è¿½åŠ ï¼‰
            st.markdown("---")
            st.markdown("### ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯è¨­å®š")
            col_quick1, col_quick2 = st.columns(2)
            
            with col_quick1:
                if st.button("â­ æ¨å¥¨è¨­å®šï¼ˆ15ç¨®é¡ï¼‰", use_container_width=True, type="secondary",
                            help="ä¿¡é ¼åº¦75%é”æˆã«æœ€ã‚‚åŠ¹æœçš„ãª15ç¨®é¡ã‚’è‡ªå‹•é¸æŠ\næœŸå¾…ãƒ‡ãƒ¼ã‚¿æ•°: 30Ã—4ãƒ¬ãƒ™ãƒ«Ã—16 = 1,920çµ„"):
                    # æ¨å¥¨è¨­å®šã‚’é©ç”¨
                    st.session_state['select_all_augmentation'] = None  # å…¨é¸æŠçŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
                    st.session_state['geo_select_all'] = None
                    st.session_state['bright_select_all'] = None
                    st.session_state['color_select_all'] = None
                    st.session_state['quality_select_all'] = None
                    st.session_state['ai_select_all'] = None
                    
                    # æ¨å¥¨è¨­å®šãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
                    st.session_state['recommended_preset'] = True
                    st.success("âœ… æ¨å¥¨è¨­å®šã‚’é©ç”¨ï¼ ä¿¡é ¼åº¦75%ä»¥ä¸Šã‚’ç›®æŒ‡ã—ã¾ã™")
                    st.info("ğŸ“Š æœŸå¾…ãƒ‡ãƒ¼ã‚¿æ•°: ç´„1,920çµ„ï¼ˆ30ç”»åƒ Ã— 4ãƒ¬ãƒ™ãƒ« Ã— 16å€ï¼‰")
                    st.rerun()
            
            with col_quick2:
                if st.button("ğŸ† ãƒã‚¹ã‚¿ãƒ¼è¨­å®šï¼ˆå…¨28ç¨®é¡ï¼‰", use_container_width=True, type="secondary",
                            help="ä¿¡é ¼åº¦90%ä»¥ä¸Šã‚’ç›®æŒ‡ã™ä¸Šç´šè€…å‘ã‘è¨­å®š\næœŸå¾…ãƒ‡ãƒ¼ã‚¿æ•°: 30Ã—4ãƒ¬ãƒ™ãƒ«Ã—29 = 3,480çµ„"):
                    st.session_state['select_all_augmentation'] = True
                    st.session_state.pop('geo_select_all', None)
                    st.session_state.pop('bright_select_all', None)
                    st.session_state.pop('color_select_all', None)
                    st.session_state.pop('quality_select_all', None)
                    st.session_state.pop('ai_select_all', None)
                    st.session_state.pop('recommended_preset', None)
                    st.success("âœ… ãƒã‚¹ã‚¿ãƒ¼è¨­å®šã‚’é©ç”¨ï¼ ä¿¡é ¼åº¦90%ä»¥ä¸Šã‚’ç›®æŒ‡ã—ã¾ã™")
                    st.info("ğŸ“Š æœŸå¾…ãƒ‡ãƒ¼ã‚¿æ•°: ç´„3,480çµ„ï¼ˆ30ç”»åƒ Ã— 4ãƒ¬ãƒ™ãƒ« Ã— 29å€ï¼‰")
                    st.rerun()
            
            st.markdown("---")
            
            # å…¨é¸æŠ/è§£é™¤ã®çŠ¶æ…‹ã‚’å–å¾—
            select_all = st.session_state.get('select_all_augmentation', None)
            recommended = st.session_state.get('recommended_preset', False)
            
            # å…¨é¸æŠ/è§£é™¤ã®çŠ¶æ…‹ã‚’å–å¾—
            select_all = st.session_state.get('select_all_augmentation', None)
            
            # ã‚¿ãƒ–ã§åˆ†é¡ - 5ã¤ã®ã‚¿ãƒ–ã«æ‹¡å¼µ
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "ğŸ”„ å¹¾ä½•å­¦å¤‰æ›", 
                "ğŸ’¡ æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ", 
                "ğŸ¨ è‰²èª¿æ•´", 
                "ğŸ”§ ç”»è³ªå‡¦ç†",
                "ğŸ¯ AIå­¦ç¿’æœ€é©åŒ– ğŸŒŸ"
            ])
            
            with tab1:
                st.markdown("**å¹¾ä½•å­¦å¤‰æ› - ç”»åƒã®å‘ãã‚„è§’åº¦ã‚’å¤‰æ›´**")
                
                # ã‚¿ãƒ–ã”ã¨ã®å…¨é¸æŠãƒœã‚¿ãƒ³
                col_tab_btn1, col_tab_btn2 = st.columns([1, 3])
                with col_tab_btn1:
                    if st.button("âœ… å…¨é¸æŠ", key="geo_all", help="å¹¾ä½•å­¦å¤‰æ›ã‚’å…¨ã¦ã‚ªãƒ³"):
                        st.session_state['geo_select_all'] = True
                        st.rerun()
                with col_tab_btn2:
                    if st.button("âŒ å…¨è§£é™¤", key="geo_clear", help="å¹¾ä½•å­¦å¤‰æ›ã‚’å…¨ã¦ã‚ªãƒ•"):
                        st.session_state['geo_select_all'] = False
                        st.rerun()
                
                geo_select = st.session_state.get('geo_select_all', None)
                default_geo = True if (select_all or geo_select) else (False if (select_all == False or geo_select == False) else True)
                default_geo_off = False if (select_all == False or geo_select == False) else (True if (select_all or geo_select) else False)
                
                # æ¨å¥¨è¨­å®šã®å ´åˆã®å€¤ã‚’è¨­å®š
                if recommended:
                    rec_flip_h = True
                    rec_flip_v = False
                    rec_rot90 = True
                    rec_rot180 = True
                    rec_rot270 = False
                    rec_rot_small_cw = False
                    rec_rot_small_ccw = False
                else:
                    rec_flip_h = default_geo
                    rec_flip_v = default_geo_off
                    rec_rot90 = default_geo
                    rec_rot180 = default_geo_off
                    rec_rot270 = default_geo_off
                    rec_rot_small_cw = default_geo_off
                    rec_rot_small_ccw = default_geo_off
                
                col1, col2 = st.columns(2)
                with col1:
                    use_flip_h = st.checkbox("ğŸ”„ æ°´å¹³åè»¢ (å·¦å³åè»¢)", value=rec_flip_h, help="ç”»åƒã‚’å·¦å³åè»¢", key="aug_flip_h")
                    use_flip_v = st.checkbox("ğŸ”ƒ å‚ç›´åè»¢ (ä¸Šä¸‹åè»¢)", value=rec_flip_v, help="ç”»åƒã‚’ä¸Šä¸‹åè»¢", key="aug_flip_v")
                    use_rotate_90 = st.checkbox("â†©ï¸ 90åº¦å›è»¢", value=rec_rot90, help="æ™‚è¨ˆå›ã‚Šã«90åº¦å›è»¢", key="aug_rot90")
                    use_rotate_180 = st.checkbox("ğŸ” 180åº¦å›è»¢", value=rec_rot180, help="180åº¦å›è»¢", key="aug_rot180")
                with col2:
                    use_rotate_270 = st.checkbox("â†ªï¸ 270åº¦å›è»¢", value=rec_rot270, help="æ™‚è¨ˆå›ã‚Šã«270åº¦å›è»¢", key="aug_rot270")
                    use_rotate_small_cw = st.checkbox("ğŸ”„ å¾®å°å›è»¢(+5Â°) ğŸŒŸ", value=rec_rot_small_cw, help="æ™‚è¨ˆå›ã‚Šã«5åº¦å›è»¢ - æ–¹å‘ä¸å¤‰æ€§å­¦ç¿’ã«åŠ¹æœçš„", key="aug_rot_small_cw")
                    use_rotate_small_ccw = st.checkbox("ğŸ”„ å¾®å°å›è»¢(-5Â°) ğŸŒŸ", value=rec_rot_small_ccw, help="åæ™‚è¨ˆå›ã‚Šã«5åº¦å›è»¢ - æ–¹å‘ä¸å¤‰æ€§å­¦ç¿’ã«åŠ¹æœçš„", key="aug_rot_small_ccw")
            
            with tab2:
                st.markdown("**æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ - ç”»åƒã®æ˜ã‚‹ã•ã‚„ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’èª¿æ•´**")
                
                # ã‚¿ãƒ–ã”ã¨ã®å…¨é¸æŠãƒœã‚¿ãƒ³
                col_tab_btn1, col_tab_btn2 = st.columns([1, 3])
                with col_tab_btn1:
                    if st.button("âœ… å…¨é¸æŠ", key="bright_all", help="æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å…¨ã¦ã‚ªãƒ³"):
                        st.session_state['bright_select_all'] = True
                        st.rerun()
                with col_tab_btn2:
                    if st.button("âŒ å…¨è§£é™¤", key="bright_clear", help="æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å…¨ã¦ã‚ªãƒ•"):
                        st.session_state['bright_select_all'] = False
                        st.rerun()
                
                bright_select = st.session_state.get('bright_select_all', None)
                default_bright = False if (select_all == False or bright_select == False) else (True if (select_all or bright_select) else False)
                
                # æ¨å¥¨è¨­å®šã®å ´åˆã®å€¤ã‚’è¨­å®šï¼ˆæ˜ã‚‹ã•èª¿æ•´ã¯é‡è¦ï¼‰
                if recommended:
                    rec_bright = True  # æ˜ã‚‹ã•ç³»ã¯å…¨ã¦æ¨å¥¨
                else:
                    rec_bright = default_bright
                
                col1, col2 = st.columns(2)
                with col1:
                    use_brightness_up = st.checkbox("â˜€ï¸ æ˜ã‚‹ã•å¢—åŠ  (+20%)", value=rec_bright, help="ç”»åƒã‚’20%æ˜ã‚‹ã", key="aug_br_up")
                    use_brightness_down = st.checkbox("ğŸŒ™ æ˜ã‚‹ã•æ¸›å°‘ (-20%)", value=rec_bright, help="ç”»åƒã‚’20%æš—ã", key="aug_br_down")
                    use_contrast_up = st.checkbox("ğŸ“ˆ ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¢—åŠ ", value=rec_bright, help="ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·ã", key="aug_cont_up")
                with col2:
                    use_contrast_down = st.checkbox("ğŸ“‰ ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆæ¸›å°‘", value=rec_bright, help="ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼±ã", key="aug_cont_down")
                    use_gamma_bright = st.checkbox("âœ¨ ã‚¬ãƒ³ãƒè£œæ­£ (æ˜ã‚‹ã)", value=rec_bright if recommended else default_bright, help="ã‚¬ãƒ³ãƒè£œæ­£ã§æ˜ã‚‹ã", key="aug_gamma_br")
                    use_gamma_dark = st.checkbox("ğŸŒ‘ ã‚¬ãƒ³ãƒè£œæ­£ (æš—ã)", value=rec_bright if recommended else default_bright, help="ã‚¬ãƒ³ãƒè£œæ­£ã§æš—ã", key="aug_gamma_dk")
            
            with tab3:
                st.markdown("**è‰²èª¿æ•´ - ç”»åƒã®è‰²åˆã„ã‚„å½©åº¦ã‚’å¤‰æ›´**")
                
                # ã‚¿ãƒ–ã”ã¨ã®å…¨é¸æŠãƒœã‚¿ãƒ³
                col_tab_btn1, col_tab_btn2 = st.columns([1, 3])
                with col_tab_btn1:
                    if st.button("âœ… å…¨é¸æŠ", key="color_all", help="è‰²èª¿æ•´ã‚’å…¨ã¦ã‚ªãƒ³"):
                        st.session_state['color_select_all'] = True
                        st.rerun()
                with col_tab_btn2:
                    if st.button("âŒ å…¨è§£é™¤", key="color_clear", help="è‰²èª¿æ•´ã‚’å…¨ã¦ã‚ªãƒ•"):
                        st.session_state['color_select_all'] = False
                        st.rerun()
                
                color_select = st.session_state.get('color_select_all', None)
                default_color = False if (select_all == False or color_select == False) else (True if (select_all or color_select) else False)
                
                # æ¨å¥¨è¨­å®šã§ã¯è‰²èª¿æ•´ã¯æ§ãˆã‚ã«
                rec_color = False if recommended else default_color
                
                col1, col2 = st.columns(2)
                with col1:
                    use_saturation_up = st.checkbox("ğŸŒˆ å½©åº¦å¢—åŠ ", value=rec_color, help="è‰²ã‚’é®®ã‚„ã‹ã«", key="aug_sat_up")
                    use_saturation_down = st.checkbox("ğŸŒ«ï¸ å½©åº¦æ¸›å°‘", value=rec_color, help="è‰²ã‚’æ·¡ã", key="aug_sat_down")
                    use_hue_shift = st.checkbox("ğŸ¨ è‰²ç›¸ã‚·ãƒ•ãƒˆ", value=rec_color, help="è‰²åˆã„ã‚’å¤‰æ›´", key="aug_hue")
                with col2:
                    use_temp_warm = st.checkbox("ğŸ”¥ æ¸©åº¦èª¿æ•´(æš–è‰²) ğŸŒŸ", value=rec_color, help="ç…§æ˜æ¡ä»¶ã®å¤‰åŒ–ã«å¯¾å¿œ - AIå­¦ç¿’ã«åŠ¹æœçš„", key="aug_temp_warm")
                    use_temp_cool = st.checkbox("â„ï¸ æ¸©åº¦èª¿æ•´(å¯’è‰²) ğŸŒŸ", value=rec_color, help="ç…§æ˜æ¡ä»¶ã®å¤‰åŒ–ã«å¯¾å¿œ - AIå­¦ç¿’ã«åŠ¹æœçš„", key="aug_temp_cool")
            
            with tab4:
                st.markdown("**ç”»è³ªå‡¦ç† - ãƒã‚¤ã‚ºã‚„ã¼ã‹ã—ã€ã‚·ãƒ£ãƒ¼ãƒ—åŒ–ãªã©ã®å‡¦ç†**")
                
                # ã‚¿ãƒ–ã”ã¨ã®å…¨é¸æŠãƒœã‚¿ãƒ³
                col_tab_btn1, col_tab_btn2 = st.columns([1, 3])
                with col_tab_btn1:
                    if st.button("âœ… å…¨é¸æŠ", key="quality_all", help="ç”»è³ªå‡¦ç†ã‚’å…¨ã¦ã‚ªãƒ³"):
                        st.session_state['quality_select_all'] = True
                        st.rerun()
                with col_tab_btn2:
                    if st.button("âŒ å…¨è§£é™¤", key="quality_clear", help="ç”»è³ªå‡¦ç†ã‚’å…¨ã¦ã‚ªãƒ•"):
                        st.session_state['quality_select_all'] = False
                        st.rerun()
                
                quality_select = st.session_state.get('quality_select_all', None)
                default_quality = False if (select_all == False or quality_select == False) else (True if (select_all or quality_select) else False)
                
                # æ¨å¥¨è¨­å®šã§ã¯é‡è¦ãªç”»è³ªå‡¦ç†ã‚’é¸æŠ
                if recommended:
                    rec_quality = True
                    rec_quality_off = False
                else:
                    rec_quality = default_quality
                    rec_quality_off = default_quality
                
                col1, col2 = st.columns(2)
                with col1:
                    use_noise = st.checkbox("ğŸ“¡ ãƒã‚¤ã‚ºè¿½åŠ ", value=rec_quality, help="ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºã‚’è¿½åŠ ", key="aug_noise")
                    use_blur = st.checkbox("ğŸŒ€ ã¼ã‹ã—", value=rec_quality, help="ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ã¼ã‹ã—ã‚’é©ç”¨", key="aug_blur")
                    use_sharpen = st.checkbox("ğŸ”ª ã‚·ãƒ£ãƒ¼ãƒ—åŒ–", value=rec_quality, help="ã‚¨ãƒƒã‚¸ã‚’å¼·èª¿", key="aug_sharp")
                with col2:
                    use_equalize = st.checkbox("ğŸ“Š ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–", value=rec_quality_off, help="ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’è‡ªå‹•èª¿æ•´", key="aug_eq")
                    use_median = st.checkbox("ğŸ”² ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ ğŸŒŸ", value=rec_quality_off, help="ãƒã‚¤ã‚ºé™¤å» - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ä¿æŒã«åŠ¹æœçš„", key="aug_median")
                    use_bilateral = st.checkbox("ğŸ­ ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ« ğŸŒŸ", value=rec_quality_off, help="ã‚¨ãƒƒã‚¸ä¿å­˜å¹³æ»‘åŒ– - AIå­¦ç¿’ã«åŠ¹æœçš„", key="aug_bilateral")
            
            # ğŸ¯ AIå­¦ç¿’æœ€é©åŒ–ã‚¿ãƒ– (æ–°è¦è¿½åŠ )
            with tab5:
                st.markdown("**AIå­¦ç¿’æœ€é©åŒ– - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒå­¦ç¿’ã«ç‰¹åŒ–ã—ãŸæ‹¡å¼µ ğŸŒŸ**")
                st.info("ã“ã‚Œã‚‰ã®æ‹¡å¼µã¯ã€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®AIå­¦ç¿’ã«ç‰¹ã«åŠ¹æœçš„ã§ã™ã€‚ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§ã€å±€æ‰€çš„ãªç‰¹å¾´æŠ½å‡ºã€ã‚¨ãƒƒã‚¸ä¿å­˜ãªã©ã‚’å¼·åŒ–ã—ã¾ã™ã€‚")
                
                # ã‚¿ãƒ–ã”ã¨ã®å…¨é¸æŠãƒœã‚¿ãƒ³
                col_tab_btn1, col_tab_btn2 = st.columns([1, 3])
                with col_tab_btn1:
                    if st.button("âœ… å…¨é¸æŠ", key="ai_all", help="AIå­¦ç¿’æœ€é©åŒ–ã‚’å…¨ã¦ã‚ªãƒ³"):
                        st.session_state['ai_select_all'] = True
                        st.rerun()
                with col_tab_btn2:
                    if st.button("âŒ å…¨è§£é™¤", key="ai_clear", help="AIå­¦ç¿’æœ€é©åŒ–ã‚’å…¨ã¦ã‚ªãƒ•"):
                        st.session_state['ai_select_all'] = False
                        st.rerun()
                
                ai_select = st.session_state.get('ai_select_all', None)
                default_ai = False if (select_all == False or ai_select == False) else (True if (select_all or ai_select) else False)
                
                col1, col2 = st.columns(2)
                with col1:
                    use_scale_up = st.checkbox("ğŸ“ ã‚¹ã‚±ãƒ¼ãƒ«æ‹¡å¤§ ğŸŒŸ", value=default_ai, help="110%ã«æ‹¡å¤§ - ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§å­¦ç¿’", key="aug_scale_up")
                    use_scale_down = st.checkbox("ğŸ“ ã‚¹ã‚±ãƒ¼ãƒ«ç¸®å° ğŸŒŸ", value=default_ai, help="90%ã«ç¸®å° - ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§å­¦ç¿’", key="aug_scale_down")
                with col2:
                    use_clahe = st.checkbox("ğŸ”† CLAHE ğŸŒŸ", value=default_ai, help="é©å¿œçš„ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ– - å±€æ‰€çš„ãƒ†ã‚¯ã‚¹ãƒãƒ£å¼·èª¿", key="aug_clahe")
                    use_unsharp = st.checkbox("ğŸ” ã‚¢ãƒ³ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ã‚¯ ğŸŒŸ", value=default_ai, help="ã‚¨ãƒƒã‚¸å¼·èª¿ - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã®å¢ƒç•Œæ˜ç¢ºåŒ–", key="aug_unsharp")
            
            # é¸æŠã•ã‚ŒãŸæ‹¡å¼µæ‰‹æ³•ã‚’åé›†ï¼ˆæ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã®ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦å†æ§‹ç¯‰ï¼‰
            augmentation_methods.clear()
            
            # å¹¾ä½•å­¦å¤‰æ›
            if use_flip_h:
                augmentation_methods.append('flip_h')
            if use_flip_v:
                augmentation_methods.append('flip_v')
            if use_rotate_90:
                augmentation_methods.append('rotate_90')
            if use_rotate_180:
                augmentation_methods.append('rotate_180')
            if use_rotate_270:
                augmentation_methods.append('rotate_270')
            if use_rotate_small_cw:
                augmentation_methods.append('rotate_small_cw')
            if use_rotate_small_ccw:
                augmentation_methods.append('rotate_small_ccw')
            
            # æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ
            if use_brightness_up:
                augmentation_methods.append('brightness_up')
            if use_brightness_down:
                augmentation_methods.append('brightness_down')
            if use_contrast_up:
                augmentation_methods.append('contrast_up')
            if use_contrast_down:
                augmentation_methods.append('contrast_down')
            if use_gamma_bright:
                augmentation_methods.append('gamma_bright')
            if use_gamma_dark:
                augmentation_methods.append('gamma_dark')
            
            # è‰²èª¿æ•´
            if use_saturation_up:
                augmentation_methods.append('saturation_up')
            if use_saturation_down:
                augmentation_methods.append('saturation_down')
            if use_hue_shift:
                augmentation_methods.append('hue_shift')
            if use_temp_warm:
                augmentation_methods.append('temp_warm')
            if use_temp_cool:
                augmentation_methods.append('temp_cool')
            
            # ç”»è³ªå‡¦ç†
            if use_noise:
                augmentation_methods.append('noise')
            if use_blur:
                augmentation_methods.append('blur')
            if use_sharpen:
                augmentation_methods.append('sharpen')
            if use_equalize:
                augmentation_methods.append('equalize')
            if use_median:
                augmentation_methods.append('median')
            if use_bilateral:
                augmentation_methods.append('bilateral')
            
            # AIå­¦ç¿’æœ€é©åŒ–
            if use_scale_up:
                augmentation_methods.append('scale_up')
            if use_scale_down:
                augmentation_methods.append('scale_down')
            if use_clahe:
                augmentation_methods.append('clahe')
            if use_unsharp:
                augmentation_methods.append('unsharp')
            
            if augmentation_methods:
                # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨
                original_count = len(high_imgs)
                
                # é¸æŠã•ã‚ŒãŸæ‹¡å¼µæ–¹æ³•ã®æƒ…å ±ã‚’è¡¨ç¤º
                st.info(f"""
                **é¸æŠã•ã‚ŒãŸæ‹¡å¼µæ–¹æ³•: {len(augmentation_methods)}ç¨®é¡**
                
                - å…ƒã®ç”»åƒãƒšã‚¢æ•°: {original_count}çµ„
                - äºˆæƒ³ã•ã‚Œã‚‹æ‹¡å¼µå¾Œ: {original_count * (len(augmentation_methods) + 1)}çµ„ (å…ƒç”»åƒ + æ‹¡å¼µç‰ˆ)
                """)
                
                high_imgs, low_imgs, high_names, low_names = apply_data_augmentation(
                    high_imgs, low_imgs, high_names, low_names, augmentation_methods
                )
                augmented_count = len(high_imgs)
                
                st.success(f"""
                âœ… ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Œäº†
                - å…ƒã®ç”»åƒãƒšã‚¢æ•°: {original_count}çµ„
                - æ‹¡å¼µå¾Œã®ç”»åƒãƒšã‚¢æ•°: {augmented_count}çµ„
                - å¢—åŠ ç‡: {((augmented_count / original_count - 1) * 100):.0f}%
                - ä½¿ç”¨ã—ãŸæ‹¡å¼µæ–¹æ³•: {len(augmentation_methods)}ç¨®é¡
                """)
            else:
                st.warning("âš ï¸ å°‘ãªãã¨ã‚‚1ã¤ã®æ‹¡å¼µæ‰‹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„")
        
        st.markdown("---")
        
        # ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
        if len(high_imgs) < 2:
            st.error(f"""
            âŒ **ç”»åƒãƒšã‚¢æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™**
            
            - æ¤œå‡ºã•ã‚ŒãŸç”»åƒãƒšã‚¢æ•°: **{len(high_imgs)}**
            - å¿…è¦ãªæœ€å°ãƒšã‚¢æ•°: **2**
            
            ğŸ’¡ **è§£æ±ºæ–¹æ³•:**
            1. ãƒ•ã‚©ãƒ«ãƒ€å†…ã«å°‘ãªãã¨ã‚‚**2çµ„ä»¥ä¸Š**ã®ç”»åƒãƒšã‚¢ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„
            2. ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„
               - ä¾‹: `IMG_0001.jpg` ã¨ `IMG_0001_low1.jpg`
               - ä¾‹: `photo1.png` ã¨ `photo1_low1.png`
            3. ã€Œãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºã€ã§æ¤œå‡ºçŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„
            """)
            return
            
        st.success(f"âœ… {len(high_imgs)} çµ„ã®ç”»åƒãƒšã‚¢ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

        # Quick preview first pair (èª¬æ˜ä»˜ã)
        st.subheader("ğŸ“· ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (1æšç›®)")
        st.markdown("""
        **ã“ã‚Œã‹ã‚‰è§£æã™ã‚‹ç”»åƒãƒšã‚¢ã®ä¾‹:**
        - **å·¦ (ä½ç”»è³ª)**: AIãŒã“ã®ç”»åƒã‹ã‚‰é«˜ç”»è³ªç›¸å½“ã®FDã‚’äºˆæ¸¬ã—ã¾ã™
        - **å³ (é«˜ç”»è³ª)**: AIã®äºˆæ¸¬ã®æ­£è§£å€¤ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ (å­¦ç¿’ãƒ»è©•ä¾¡ç”¨)
        
        ğŸ’¡ AIã¯ä½ç”»è³ªç”»åƒã®ç‰¹å¾´ã‚’å­¦ç¿’ã—ã€é«˜ç”»è³ªç›¸å½“ã®æ­£ç¢ºãªãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®šã—ã¾ã™ã€‚
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            st.image(cv2.cvtColor(low_imgs[0], cv2.COLOR_BGR2RGB), caption=f"ä½ç”»è³ª: {low_names[0]}", width=300)
        with col2:
            st.image(cv2.cvtColor(high_imgs[0], cv2.COLOR_BGR2RGB), caption=f"é«˜ç”»è³ª: {high_names[0]}", width=300)

        # Train button
        if st.button("ğŸ”§ AI ã‚’å­¦ç¿’ã—ã¦è§£æã‚’å®Ÿè¡Œ"):
            try:
                st.info("å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
                start = time.time()
                model = train_fd_predictor_fast(low_imgs, high_imgs)
                st.success("å­¦ç¿’å®Œäº†ã—ã¾ã—ãŸã€‚")
                
                # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
                model_path = save_model(model, "trained_fd_model.pkl")
                st.success(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_path}")
                
                # ============================================================
                # ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’æ°¸ç¶šåŒ– - ã‚¢ãƒ—ãƒªå…¨ä½“ã§ä½¿ç”¨å¯èƒ½ã«
                # ============================================================
                st.session_state['persistent_model'] = model
                st.session_state['model_loaded'] = True
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ—¥æ™‚ã‚’å–å¾—
                model_mtime = os.path.getmtime(model_path)
                model_date = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(model_mtime))
                
                st.session_state['model_info'] = {
                    'path': model_path,
                    'loaded_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'trained_at': model_date,
                    'source': 'å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ï¼ˆä»Šå›ã®å­¦ç¿’ï¼‰',
                    'file_size': os.path.getsize(model_path)
                }
                
                st.success("""
                âœ… **ãƒ¢ãƒ‡ãƒ«ã‚’æ°¸ç¶šåŒ–ã—ã¾ã—ãŸ**
                
                **ä¿å­˜å†…å®¹:**
                - ğŸ¤– å­¦ç¿’æ¸ˆã¿AIãƒ¢ãƒ‡ãƒ« â†’ `trained_fd_model.pkl`
                - ğŸ“š å­¦ç¿’å±¥æ­´ â†’ `training_history.json`
                
                **æ¬¡å›èµ·å‹•æ™‚:**
                - âœ… ã“ã®ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•çš„ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã™
                - âœ… å­¦ç¿’å±¥æ­´ãŒå¼•ãç¶™ãŒã‚Œã¾ã™
                - âœ… ã™ãã«æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§è§£æã§ãã¾ã™
                
                ğŸ’¡ ã‚¢ãƒ—ãƒªã‚’é–‰ã˜ã¦ã‚‚ã€ã‚ãªãŸã®AIã®çŸ¥è­˜ã¯ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ï¼
                """)
                
                # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                with open(model_path, 'rb') as f:
                    model_data = f.read()
                st.download_button(
                    label="ğŸ“¥ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=model_data,
                    file_name="trained_fd_model.pkl",
                    mime="application/octet-stream",
                    help="ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¦ã€å¾Œã§æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§ä½¿ç”¨ã§ãã¾ã™"
                )

                # Evaluate & show metrics
                st.info("è§£æãƒ»æ¯”è¼ƒã‚’è¡Œã„ã¾ã™...")
                D_high, D_low, D_pred = evaluate_and_plot(high_imgs, low_imgs, model, use_gpu=use_gpu_checkbox)
                
                # å­¦ç¿’å±¥æ­´ã‚’ä¿å­˜
                training_record = {
                    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'num_pairs': len(high_imgs),
                    'quality_level': quality_level,
                    'augmentation_count': len(augmentation_methods),
                    'augmentation_types': augmentation_methods,
                    'total_samples': len(low_imgs),
                    'model_params': {
                        'n_estimators': 400,
                        'max_depth': 8,
                        'learning_rate': 0.05
                    }
                }
                
                # è©•ä¾¡çµæœã‚’å±¥æ­´ã«è¿½åŠ 
                if 'metrics' in st.session_state:
                    training_record['metrics'] = st.session_state['metrics']
                
                history_path = save_training_history(training_record)
                if history_path:
                    # å­¦ç¿’å±¥æ­´çµ±è¨ˆã‚’æ›´æ–°
                    all_history = load_training_history()
                    st.session_state['history_stats'] = {
                        'total_sessions': len(all_history),
                        'last_trained': training_record['timestamp'],
                        'total_samples': sum(h.get('total_samples', 0) for h in all_history)
                    }
                    
                    st.info(f"""
                    ğŸ“Š **å­¦ç¿’å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ**
                    
                    - ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: `{history_path}`
                    - ğŸ“ ä»Šå›ã®å­¦ç¿’å›æ•°: {len(all_history)}å›ç›®
                    - ğŸ“ˆ ç´¯è¨ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {st.session_state['history_stats']['total_samples']:,}çµ„
                    
                    ğŸ’¾ ã“ã®å±¥æ­´ã¯æ¬¡å›èµ·å‹•æ™‚ã‚‚ä¿æŒã•ã‚Œã¾ã™
                    """)
                
                # âš ï¸ å…¨ãƒ¬ãƒ™ãƒ«ä½¿ç”¨æ™‚ã®è­¦å‘Š
                if len(quality_levels) >= 10:
                    st.warning("""
                    âš ï¸ **å…¨ãƒ¬ãƒ™ãƒ« (low1-10) ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™**
                    
                    **ç¾åœ¨ã®çŠ¶æ³:**
                    - å“è³ªå·®ãŒå¤§ãã™ãã‚‹ãŸã‚ã€MAEãŒæ‚ªåŒ–ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
                    - ä¿¡é ¼åº¦ãŒ70%ä»¥ä¸‹ã«ç•™ã¾ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
                    
                    **æ”¹å–„ç­–:**
                    1. å“è³ªãƒ¬ãƒ™ãƒ«ã‚’ **ã€ŒğŸŸ¡ low4-7 (ä¸­åº¦åŠ£åŒ–)ã€** ã«å¤‰æ›´
                    2. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ **ã€Œãƒã‚¹ã‚¿ãƒ¼è¨­å®š (28ç¨®é¡)ã€** ã«è¨­å®š
                    3. å†å­¦ç¿’ã‚’å®Ÿè¡Œ
                    
                    **æœŸå¾…ã•ã‚Œã‚‹çµæœ:**
                    - MAE: 0.03ä»¥ä¸‹
                    - ä¿¡é ¼åº¦: 85%ä»¥ä¸Š
                    """)
                
                # ============================================================
                # ğŸ¯ AIæ€§èƒ½è©•ä¾¡ã‚’è¡¨ç¤º
                # ============================================================
                if 'metrics' in st.session_state:
                    metrics = st.session_state['metrics']
                    evaluation = evaluate_ai_performance(
                        metrics.get('correlation_pred', 0),
                        metrics.get('improvement', 0),
                        metrics.get('mae_pred', 0)
                    )
                    
                    st.markdown("---")
                    st.subheader("ğŸ¯ AIæ€§èƒ½ç·åˆè©•ä¾¡")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric(
                            label="ç·åˆè©•ä¾¡",
                            value=evaluation['grade'],
                            help=f"ã‚¹ã‚³ã‚¢: {evaluation['score']:.1f}/100"
                        )
                    with col2:
                        st.metric(
                            label="ç›¸é–¢ä¿‚æ•°è©•ä¾¡",
                            value=evaluation['correlation_grade'],
                            delta=f"{metrics.get('correlation_pred', 0):.3f}"
                        )
                    with col3:
                        st.metric(
                            label="æ”¹å–„ç‡",
                            value=f"{metrics.get('improvement', 0):.1f}%",
                            delta="è‰¯å¥½" if metrics.get('improvement', 0) > 50 else "è¦æ”¹å–„"
                        )
                    
                    st.info(f"{evaluation['emoji']} **{evaluation['comment']}**")
                    
                    # MAEãŒé«˜ã„å ´åˆã®è­¦å‘Š
                    if metrics.get('mae_pred', 1.0) > 0.04 and len(quality_levels) >= 10:
                        st.error("""
                        âš ï¸ **MAEãŒé«˜ã„ã§ã™ (0.04ä»¥ä¸Š)**
                        
                        **åŸå› :**
                        - å…¨ãƒ¬ãƒ™ãƒ« (low1-10) ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€å“è³ªå·®ãŒå¤§ãã™ãã¾ã™
                        - low1 (è»½åº¦åŠ£åŒ–) ã¨ low10 (é‡åº¦åŠ£åŒ–) ã§ã¯å¾©å…ƒé›£æ˜“åº¦ãŒç•°ãªã‚Šã¾ã™
                        - AIãŒä¸€è²«ã—ãŸè£œæ­£ãƒ«ãƒ¼ãƒ«ã‚’å­¦ç¿’ã§ãã¦ã„ã¾ã›ã‚“
                        
                        **è§£æ±ºç­–:**
                        1. å“è³ªãƒ¬ãƒ™ãƒ«ã‚’ **ã€ŒğŸŸ¡ low4-7ã€** ã«å¤‰æ›´ã—ã¦å†å­¦ç¿’
                        2. ã¾ãŸã¯ **ã€ŒğŸ”´ low8-10ã€** (é‡åº¦åŠ£åŒ–å°‚é–€) ã‚’é¸æŠ
                        3. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’28ç¨®é¡ (ãƒã‚¹ã‚¿ãƒ¼è¨­å®š) ã«å¢—ã‚„ã™
                        
                        **æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„:**
                        - MAE: 0.04 â†’ 0.02-0.03
                        - ä¿¡é ¼åº¦: 70% â†’ 85%ä»¥ä¸Š
                        """)
                    
                    # è©³ç´°åˆ†æ
                    with st.expander("ğŸ“Š è©³ç´°åˆ†æ"):
                        st.write("### å„è©•ä¾¡é …ç›®ã®ãƒã‚¤ãƒ³ãƒˆ")
                        st.write(f"- **ç›¸é–¢ä¿‚æ•°ã‚¹ã‚³ã‚¢**: {evaluation['details']['corr_points']:.1f}/100")
                        st.write(f"- **æ”¹å–„ç‡ã‚¹ã‚³ã‚¢**: {evaluation['details']['improve_points']:.1f}/100")
                        st.write(f"- **MAEã‚¹ã‚³ã‚¢**: {evaluation['details']['mae_points']:.1f}/100")
                        st.write("")
                        st.write(f"**ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—å¼**: ç›¸é–¢50% + æ”¹å–„ç‡30% + MAE20%")
                        st.write(f"= {evaluation['details']['corr_points']:.1f}Ã—0.5 + {evaluation['details']['improve_points']:.1f}Ã—0.3 + {evaluation['details']['mae_points']:.1f}Ã—0.2")
                        st.write(f"= **{evaluation['score']:.1f}ç‚¹**")
                    
                    # æˆé•·åˆ†æ(è¤‡æ•°å›å­¦ç¿’ã—ã¦ã„ã‚‹å ´åˆ)
                    all_history = load_training_history()
                    if len(all_history) >= 2:
                        growth = analyze_learning_growth(all_history)
                        with st.expander("ğŸ“ˆ å­¦ç¿’æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰"):
                            st.write(f"### {growth['trend']} {growth['trend_emoji']}")
                            st.write(f"**å­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°**: {growth['num_sessions']}å›")
                            st.write(f"**å‰å›ã‹ã‚‰ã®å¤‰åŒ–**:")
                            st.write(f"  - ç›¸é–¢ä¿‚æ•°: {growth['correlation_change']:+.3f}")
                            st.write(f"  - æ”¹å–„ç‡: {growth['improvement_change']:+.1f}%")
                            st.write(f"**æ­´ä»£æœ€é«˜è¨˜éŒ²**:")
                            st.write(f"  - ç›¸é–¢ä¿‚æ•°: {growth['best_correlation']:.3f}")
                            st.write(f"  - æ”¹å–„ç‡: {growth['best_improvement']:.1f}%")
                            st.write("")
                            st.info(f"ğŸ’¡ **æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: {growth['recommendation']}")
                    
                    st.markdown("---")
                
                # çµæœã‚’session_stateã«ä¿å­˜
                st.session_state['analysis_results'] = {
                    'D_high': D_high,
                    'D_low': D_low,
                    'D_pred': D_pred,
                    'high_names': high_names,
                    'low_names': low_names,
                    'model': model,  # ãƒ¢ãƒ‡ãƒ«ã‚‚ä¿å­˜
                    'completed': True
                }
            except ValueError as e:
                st.error(str(e))
                st.stop()
            except Exception as e:
                st.error(f"âŒ **ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:** {str(e)}")
                st.stop()
        
        # çµæœãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¡¨ç¤º
        if 'analysis_results' in st.session_state and st.session_state['analysis_results'].get('completed'):
            results = st.session_state['analysis_results']
            D_high = results['D_high']
            D_low = results['D_low']
            D_pred = results['D_pred']
            high_names = results['high_names']
            low_names = results['low_names']
            
            # show detailed table
            st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ä¸€è¦§")
            
            st.markdown("""
            ### è¡¨ã®å„åˆ—ã®æ„å‘³
            
            - **No.**: ç”»åƒã®ç•ªå·
            - **ç”»åƒå**: å‡¦ç†ã—ãŸç”»åƒã®ãƒ•ã‚¡ã‚¤ãƒ«å
            - **é«˜ç”»è³ªFD**: é«˜ç”»è³ªç”»åƒã‹ã‚‰è¨ˆç®—ã—ãŸæ­£è§£ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ (**ç›®æ¨™å€¤**)
            - **ä½ç”»è³ªFD**: ä½ç”»è³ªç”»åƒã‹ã‚‰ç›´æ¥è¨ˆç®—ã—ãŸFD (**è£œæ­£ãªã—ã€é€šå¸¸ã¯ä¸æ­£ç¢º**)
            - **AIè£œæ­£FD**: AIãŒä½ç”»è³ªã‹ã‚‰äºˆæ¸¬ã—ãŸé«˜ç”»è³ªç›¸å½“ã®FD (**AIè£œæ­£å¾Œ**)
            - **ä½ç”»è³ªèª¤å·®**: |é«˜ç”»è³ªFD - ä½ç”»è³ªFD| = è£œæ­£ãªã—ã®èª¤å·® (å¤§ãã„ã»ã©ä¸æ­£ç¢º)
            - **AIè£œæ­£èª¤å·®**: |é«˜ç”»è³ªFD - AIè£œæ­£FD| = AIè£œæ­£å¾Œã®èª¤å·® (**å°ã•ã„ã»ã©å„ªç§€**)
            - **æ”¹å–„ç‡**: (ä½ç”»è³ªèª¤å·® - AIè£œæ­£èª¤å·®) / ä½ç”»è³ªèª¤å·® Ã— 100% (**é«˜ã„ã»ã©AIãŒåŠ¹æœçš„**)
            
            ğŸ’¡ **è¦‹æ–¹ã®ãƒã‚¤ãƒ³ãƒˆ**: 
            - AIè£œæ­£èª¤å·®ãŒä½ç”»è³ªèª¤å·®ã‚ˆã‚Šå°ã•ã‘ã‚Œã°AIè£œæ­£ãŒæˆåŠŸ
            - æ”¹å–„ç‡ãŒãƒ—ãƒ©ã‚¹ãªã‚‰AIã«ã‚ˆã‚‹æ”¹å–„ã‚ã‚Šã€ãƒã‚¤ãƒŠã‚¹ãªã‚‰æ‚ªåŒ–
            """)
            
            import pandas as pd
            df = pd.DataFrame({
                "No.": range(1, len(D_high)+1),
                "ç”»åƒå": [name.replace('.jpg', '').replace('IMG_', '') for name in high_names],
                "é«˜ç”»è³ªFD": [f"{x:.4f}" if x is not None else "N/A" for x in D_high],
                "ä½ç”»è³ªFD": [f"{x:.4f}" if x is not None else "N/A" for x in D_low],
                "AIè£œæ­£FD": [f"{x:.4f}" if x is not None else "N/A" for x in D_pred],
                "ä½ç”»è³ªèª¤å·®": [f"{abs(h-l):.4f}" if h is not None and l is not None else "N/A" 
                          for h, l in zip(D_high, D_low)],
                "AIè£œæ­£èª¤å·®": [f"{abs(h-p):.4f}" if h is not None and p is not None else "N/A" 
                           for h, p in zip(D_high, D_pred)],
                "æ”¹å–„ç‡": [f"{((abs(h-l)-abs(h-p))/abs(h-l)*100):.1f}%" 
                        if h is not None and l is not None and p is not None and abs(h-l) > 0
                        else "N/A"
                        for h, l, p in zip(D_high, D_low, D_pred)]
            })
            
            # ã‚«ãƒ©ãƒ å¹…ã‚’æŒ‡å®šã—ã¦è¡¨ç¤º
            st.dataframe(
                df,
                use_container_width=True,
                hide_index=True,
                height=350,
                column_config={
                    "No.": st.column_config.NumberColumn("No.", width="small"),
                    "ç”»åƒå": st.column_config.TextColumn("ç”»åƒå", width="medium"),
                    "é«˜ç”»è³ªFD": st.column_config.TextColumn("é«˜ç”»è³ªFD", width="small"),
                    "ä½ç”»è³ªFD": st.column_config.TextColumn("ä½ç”»è³ªFD", width="small"),
                    "AIè£œæ­£FD": st.column_config.TextColumn("AIè£œæ­£FD", width="small"),
                    "ä½ç”»è³ªèª¤å·®": st.column_config.TextColumn("ä½ç”»è³ªèª¤å·®", width="small"),
                    "AIè£œæ­£èª¤å·®": st.column_config.TextColumn("AIè£œæ­£èª¤å·®", width="small"),
                    "æ”¹å–„ç‡": st.column_config.TextColumn("æ”¹å–„ç‡", width="small"),
                }
            )
            
            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
            with st.expander("ğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼ - å…¨ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±"):
                st.markdown("""
                **å„çµ±è¨ˆã®æ„å‘³:**
                - **å¹³å‡**: å…¨ç”»åƒã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®å¹³å‡å€¤
                - **æ¨™æº–åå·®**: ãƒ‡ãƒ¼ã‚¿ã®ã°ã‚‰ã¤ã (å°ã•ã„ã»ã©å‡ä¸€ã€å¤§ãã„ã»ã©å¤šæ§˜)
                - **æœ€å°/æœ€å¤§**: ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²
                
                ğŸ’¡ **æ¯”è¼ƒã®ãƒã‚¤ãƒ³ãƒˆ**: AIè£œæ­£FDã®çµ±è¨ˆãŒé«˜ç”»è³ªFDã«è¿‘ã„ã»ã©ã€AIã®äºˆæ¸¬ãŒæ­£ç¢ºã§ã™ã€‚
                """)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.write("### é«˜ç”»è³ªFDçµ±è¨ˆ")
                    st.caption("(æ­£è§£å€¤)")
                    valid_high = [x for x in D_high if x is not None]
                    st.write(f"**å¹³å‡:** {np.mean(valid_high):.4f}")
                    st.write(f"**æ¨™æº–åå·®:** {np.std(valid_high):.4f}")
                    st.write(f"**æœ€å°:** {np.min(valid_high):.4f}")
                    st.write(f"**æœ€å¤§:** {np.max(valid_high):.4f}")
                
                with col2:
                    st.write("### ä½ç”»è³ªFDçµ±è¨ˆ")
                    st.caption("(è£œæ­£ãªã—)")
                    valid_low = [x for x in D_low if x is not None]
                    st.write(f"**å¹³å‡:** {np.mean(valid_low):.4f}")
                    st.write(f"**æ¨™æº–åå·®:** {np.std(valid_low):.4f}")
                    st.write(f"**æœ€å°:** {np.min(valid_low):.4f}")
                    st.write(f"**æœ€å¤§:** {np.max(valid_low):.4f}")
                
                with col3:
                    st.write("### AIè£œæ­£FDçµ±è¨ˆ")
                    st.caption("(AIäºˆæ¸¬å€¤)")
                    valid_pred = [x for x in D_pred if x is not None]
                    st.write(f"**å¹³å‡:** {np.mean(valid_pred):.4f}")
                    st.write(f"**æ¨™æº–åå·®:** {np.std(valid_pred):.4f}")
                    st.write(f"**æœ€å°:** {np.min(valid_pred):.4f}")
                    st.write(f"**æœ€å¤§:** {np.max(valid_pred):.4f}")

    # ============================================================
    # ğŸŒ¸ é¡”å…¨ä½“åˆ†æãƒ¢ãƒ¼ãƒ‰
    # ============================================================
    elif app_mode == "ğŸŒ¸ é¡”å…¨ä½“åˆ†æãƒ¢ãƒ¼ãƒ‰":
        st.header("ğŸŒ¸ é¡”å…¨ä½“ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«åˆ†æ - éƒ¨ä½åˆ¥è‚Œè©•ä¾¡")
        
        if not SKIN_ANALYSIS_AVAILABLE:
            st.error("""
            âŒ **é¡”åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“**
            
            `skin_analysis.py`ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚
            ã¾ãŸã¯`mediapipe`ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
            
            ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:
            ```
            pip install mediapipe
            ```
            """)
            return
        
        st.markdown("""
        ### ğŸ“¸ é¡”å…¨ä½“ã‚’æ’®å½±ã—ã¦ã€å„éƒ¨ä½ã‚’è‡ªå‹•åˆ†æ
        
        **ã“ã®ãƒ¢ãƒ¼ãƒ‰ã§ã§ãã‚‹ã“ã¨:**
        - ğŸ¯ é¡”ã®è‡ªå‹•æ¤œå‡ºã¨éƒ¨ä½åˆ†å‰²ï¼ˆé¡ã€é ¬ã€é¼»ã€å£å‘¨ã‚Šã€é¡ãªã©ï¼‰
        - ğŸ“Š å„éƒ¨ä½ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒï¼ˆè‚Œã®ã‚­ãƒ¡ç´°ã‹ã•ï¼‰
        - ğŸ” 7ç¨®é¡ã®è‚Œãƒˆãƒ©ãƒ–ãƒ«æ¤œå‡º
          * æ¯›ç©´ã®ç›®ç«‹ã¡
          * ã‚·ãƒ¯
          * è‰²ãƒ ãƒ©ãƒ»ãã™ã¿
          * ãƒ‹ã‚­ãƒ“ãƒ»èµ¤ã¿
          * ã‚¯ãƒï¼ˆç›®ã®ä¸‹ï¼‰
          * ãƒ†ã‚«ãƒª
          * ã‚­ãƒ¡ã®ç²—ã•
        - ğŸ—ºï¸ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã«ã‚ˆã‚‹å¯è¦–åŒ–
        - ğŸ“‹ éƒ¨ä½åˆ¥ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        
        **æ’®å½±ã®ã‚³ãƒ„:**
        - æ­£é¢ã‹ã‚‰é¡”å…¨ä½“ãŒå†™ã‚‹ã‚ˆã†ã«æ’®å½±
        - è‡ªç„¶å…‰ã¾ãŸã¯æ˜ã‚‹ã„å®¤å†…ã§
        - è·é›¢ã¯ç´„30-50cm
        - ç„¡è¡¨æƒ…ã§
        """)
        
        uploaded_file = st.file_uploader(
            "é¡”å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['jpg', 'jpeg', 'png'],
            help="é¡”å…¨ä½“ãŒå†™ã£ãŸç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        
        if uploaded_file:
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = read_bgr_from_buffer(uploaded_file.read())
            
            if image is None:
                st.error("ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return
            
            with st.spinner("ğŸ” é¡”ã‚’æ¤œå‡ºä¸­..."):
                landmarks = detect_face_landmarks(image)
            
            if landmarks is None:
                st.error("""
                âŒ **é¡”ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ**
                
                ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:
                - é¡”å…¨ä½“ãŒå†™ã£ã¦ã„ã‚‹ã‹
                - é¡”ãŒæ­£é¢ã‚’å‘ã„ã¦ã„ã‚‹ã‹
                - ç”»åƒãŒæ˜ã‚‹ã„ã‹
                - é¡”ãŒå¤§ãã™ããŸã‚Šå°ã•ã™ããŸã‚Šã—ãªã„ã‹
                """)
                return
            
            st.success("âœ… é¡”ã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼")
            
            # å„éƒ¨ä½ã‚’æŠ½å‡º
            with st.spinner("ğŸ“ éƒ¨ä½ã‚’åˆ†å‰²ä¸­..."):
                regions = extract_face_regions(image, landmarks)
            
            if not regions:
                st.error("éƒ¨ä½ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
                return
            
            st.success(f"âœ… {len(regions)}ã¤ã®éƒ¨ä½ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
            
            # ã‚¿ãƒ–è¡¨ç¤º
            tab1, tab2, tab3, tab4 = st.tabs([
                "ğŸ“Š ç·åˆè©•ä¾¡",
                "ğŸ—ºï¸ éƒ¨ä½è¡¨ç¤º",
                "ğŸ” è©³ç´°åˆ†æ",
                "ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆ"
            ])
            
            # éƒ¨ä½åˆ¥ã«FDè¨ˆç®—ã¨è‚Œãƒˆãƒ©ãƒ–ãƒ«æ¤œå‡º
            fd_results = {}
            trouble_results = {}
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, (region_name, region_data) in enumerate(regions.items()):
                status_text.text(f"è§£æä¸­: {REGION_NAMES_JP.get(region_name, region_name)}")
                
                region_img = region_data['image']
                
                if region_img is not None and region_img.size > 0:
                    # FDè¨ˆç®—
                    fd_result = calculate_fractal_dimension(region_img)
                    fd_results[region_name] = fd_result['fd']
                    
                    # è‚Œãƒˆãƒ©ãƒ–ãƒ«æ¤œå‡º
                    troubles = detect_skin_troubles(region_img, region_name)
                    # FDå€¤ã‚’ã‚­ãƒ¡ã®ç²—ã•ã‚¹ã‚³ã‚¢ã«åæ˜ 
                    if 'texture_roughness' in troubles:
                        fd_score = min((fd_result['fd'] - 2.0) / 1.0 * 100, 100)
                        troubles['texture_roughness']['score'] = fd_score
                        troubles['texture_roughness']['level'] = (
                            'é«˜' if fd_score > 65 else 'ä¸­' if fd_score > 35 else 'ä½'
                        )
                    
                    trouble_results[region_name] = troubles
                
                progress_bar.progress((idx + 1) / len(regions))
            
            progress_bar.empty()
            status_text.empty()
            
            # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
            if fd_results:
                # FDã‚’100ç‚¹æº€ç‚¹ã‚¹ã‚³ã‚¢ã«å¤‰æ›ï¼ˆ2.0=100ç‚¹, 3.0=0ç‚¹ï¼‰
                scores = {}
                for region, fd in fd_results.items():
                    score = (3.0 - fd) / 1.0 * 100
                    scores[region] = max(0, min(100, score))
                
                # é‡ã¿ä»˜ãå¹³å‡ï¼ˆé¡”ã®é‡è¦éƒ¨ä½ã‚’é‡è¦–ï¼‰
                weights = {
                    'forehead': 0.12,
                    'left_cheek': 0.22,
                    'right_cheek': 0.22,
                    'nose': 0.10,
                    'mouth_area': 0.14,
                    'chin': 0.10,
                    'left_under_eye': 0.05,
                    'right_under_eye': 0.05
                }
                
                overall_score = sum(
                    scores.get(region, 0) * weight
                    for region, weight in weights.items()
                )
                
                # ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¤å®š
                if overall_score >= 85:
                    grade = 'S (éå¸¸ã«è‰¯ã„)'
                    grade_emoji = 'ğŸŒŸ'
                elif overall_score >= 70:
                    grade = 'A (è‰¯ã„)'
                    grade_emoji = 'â­'
                elif overall_score >= 55:
                    grade = 'B (æ™®é€š)'
                    grade_emoji = 'ğŸ”µ'
                elif overall_score >= 40:
                    grade = 'C (ã‚„ã‚„ç²—ã„)'
                    grade_emoji = 'ğŸŸ¡'
                else:
                    grade = 'D (è¦ã‚±ã‚¢)'
                    grade_emoji = 'ğŸ”´'
            
            # Tab 1: ç·åˆè©•ä¾¡
            with tab1:
                st.subheader("ğŸ“Š ç·åˆè©•ä¾¡")
                
                col1, col2, col3 = st.columns([2, 2, 3])
                
                with col1:
                    st.markdown("### å…ƒç”»åƒ")
                    st.image(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), 
                            use_container_width=True)
                
                with col2:
                    st.markdown("### ã‚¹ã‚³ã‚¢")
                    st.metric(
                        "ç·åˆã‚¹ã‚³ã‚¢",
                        f"{overall_score:.1f}/100",
                        delta=None
                    )
                    st.markdown(f"### {grade_emoji} ã‚°ãƒ¬ãƒ¼ãƒ‰")
                    st.markdown(f"## {grade}")
                
                with col3:
                    st.markdown("### éƒ¨ä½åˆ¥ã‚¹ã‚³ã‚¢")
                    for region, score in sorted(scores.items(), key=lambda x: x[1], reverse=True):
                        region_jp = REGION_NAMES_JP.get(region, region)
                        st.progress(score / 100)
                        st.caption(f"{region_jp}: {score:.1f}ç‚¹")
            
            # Tab 2: éƒ¨ä½è¡¨ç¤º
            with tab2:
                st.subheader("ğŸ—ºï¸ æ¤œå‡ºã•ã‚ŒãŸéƒ¨ä½")
                
                # éƒ¨ä½ã‚’2åˆ—ã§è¡¨ç¤º
                cols_per_row = 3
                region_items = list(regions.items())
                
                for i in range(0, len(region_items), cols_per_row):
                    cols = st.columns(cols_per_row)
                    for j, col in enumerate(cols):
                        idx = i + j
                        if idx < len(region_items):
                            region_name, region_data = region_items[idx]
                            region_img = region_data['image']
                            
                            with col:
                                region_jp = REGION_NAMES_JP.get(region_name, region_name)
                                if region_img is not None and region_img.size > 0:
                                    st.image(
                                        cv2.cvtColor(region_img, cv2.COLOR_BGR2RGB),
                                        caption=f"{region_jp}",
                                        use_container_width=True
                                    )
                                    if region_name in fd_results:
                                        st.caption(f"FD: {fd_results[region_name]:.4f}")
                                        st.caption(f"ã‚¹ã‚³ã‚¢: {scores.get(region_name, 0):.1f}ç‚¹")
            
            # Tab 3: è©³ç´°åˆ†æ
            with tab3:
                st.subheader("ğŸ” éƒ¨ä½åˆ¥è©³ç´°åˆ†æ")
                
                for region_name in regions.keys():
                    region_jp = REGION_NAMES_JP.get(region_name, region_name)
                    
                    with st.expander(f"ğŸ“ {region_jp}"):
                        if region_name in fd_results:
                            col1, col2 = st.columns([1, 2])
                            
                            with col1:
                                st.metric("ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ", f"{fd_results[region_name]:.4f}")
                                st.metric("ã‚¹ã‚³ã‚¢", f"{scores.get(region_name, 0):.1f}/100")
                            
                            with col2:
                                if region_name in trouble_results:
                                    troubles = trouble_results[region_name]
                                    
                                    st.markdown("**æ¤œå‡ºã•ã‚ŒãŸè‚Œãƒˆãƒ©ãƒ–ãƒ«:**")
                                    for trouble_key, trouble_data in troubles.items():
                                        trouble_jp = TROUBLE_NAMES_JP.get(trouble_key, trouble_key)
                                        level = trouble_data.get('level', 'ä¸æ˜')
                                        score_val = trouble_data.get('score', 0)
                                        
                                        level_emoji = 'ğŸ”´' if level == 'é«˜' else 'ğŸŸ¡' if level == 'ä¸­' else 'ğŸŸ¢'
                                        st.write(f"{level_emoji} **{trouble_jp}**: {level} ({score_val:.1f})")
            
            # Tab 4: ãƒ¬ãƒãƒ¼ãƒˆ
            with tab4:
                st.subheader("ğŸ“‹ ç·åˆãƒ¬ãƒãƒ¼ãƒˆ")
                
                report = create_trouble_report(trouble_results, fd_results)
                st.markdown(report)
                
                # ãƒ¬ãƒãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
                report_filename = f"skin_analysis_report_{timestamp}.md"
                
                st.download_button(
                    label="ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=report,
                    file_name=report_filename,
                    mime="text/markdown"
                )
    
    # ============================================================
    # ğŸ”¬ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿åé›†ãƒ¢ãƒ¼ãƒ‰
    # ============================================================
    elif app_mode == "ğŸ”¬ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿åé›†":
        st.header("ğŸ”¬ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿åé›† - è‚ŒçŠ¶æ…‹ã¨ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®ç›¸é–¢ç ”ç©¶")
        
        if not EXPERIMENT_ANALYSIS_AVAILABLE:
            st.error("""
            âŒ **å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“**
            
            `experiment_analysis.py`ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚
            """)
            return
        
        st.markdown("""
        ### ğŸ¯ ç ”ç©¶ç›®çš„
        ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¨è‚Œã®ç‰©ç†çš„çŠ¶æ…‹ï¼ˆä¹¾ç‡¥ã€è’ã‚Œã€æ°´åˆ†é‡ãªã©ï¼‰ã®å®šé‡çš„é–¢ä¿‚ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹
        
        **æ¸¬å®šé …ç›®:**
        - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒï¼ˆå®¢è¦³çš„æŒ‡æ¨™ï¼‰
        - è‚ŒçŠ¶æ…‹ã®ä¸»è¦³è©•ä¾¡ï¼ˆè‚Œè’ã‚Œåº¦ã€ä¹¾ç‡¥åº¦ï¼‰
        - å®¢è¦³çš„æ¸¬å®šå€¤ï¼ˆæ°´åˆ†é‡ã€çš®è„‚é‡ãªã©ï¼‰
        - ç’°å¢ƒæ¡ä»¶ï¼ˆæ¸©åº¦ã€æ¹¿åº¦ï¼‰
        
        **ãƒ‡ãƒ¼ã‚¿ã®ä½¿ã„é“:**
        - ç›¸é–¢åˆ†æï¼ˆFDã¨è‚ŒçŠ¶æ…‹ã®é–¢ä¿‚ï¼‰
        - è«–æ–‡ãƒ»ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        - AIäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ”¹å–„
        """)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        data_manager = ExperimentDataManager()
        
        # ã‚¿ãƒ–ã§åˆ†å‰²
        data_tab, history_tab = st.tabs(["ğŸ“ æ–°è¦ãƒ‡ãƒ¼ã‚¿åé›†", "ğŸ“š å±¥æ­´è¡¨ç¤º"])
        
        with data_tab:
            st.subheader("ğŸ“‹ è¢«é¨“è€…æƒ…å ±")
            
            col1, col2 = st.columns(2)
            with col1:
                subject_id = st.text_input("è¢«é¨“è€…ID", placeholder="ä¾‹: S001", help="ä¸€æ„ã®IDã‚’è¨­å®š")
                age = st.number_input("å¹´é½¢", min_value=10, max_value=100, value=25)
                gender = st.selectbox("æ€§åˆ¥", ["å¥³æ€§", "ç”·æ€§", "ãã®ä»–"])
            
            with col2:
                skin_type = st.selectbox("è‚Œè³ª", [
                    "æ™®é€šè‚Œ", "ä¹¾ç‡¥è‚Œ", "è„‚æ€§è‚Œ", "æ··åˆè‚Œ", "æ•æ„Ÿè‚Œ"
                ])
                measurement_date = st.date_input("æ¸¬å®šæ—¥")
                measurement_time = st.time_input("æ¸¬å®šæ™‚åˆ»")
            
            st.markdown("---")
            st.subheader("ğŸŒ¡ï¸ æ¸¬å®šæ¡ä»¶")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                condition = st.selectbox("è‚ŒçŠ¶æ…‹", [
                    "é€šå¸¸çŠ¶æ…‹",
                    "æ´—é¡”ç›´å¾Œï¼ˆ30åˆ†ä»¥å†…ï¼‰",
                    "ä¿æ¹¿ã‚¯ãƒªãƒ¼ãƒ å¡—å¸ƒå¾Œ",
                    "é‹å‹•å¾Œ",
                    "ç¡çœ ä¸è¶³å¾Œ",
                    "ãã®ä»–"
                ])
            with col2:
                temperature = st.number_input("å®¤æ¸© (Â°C)", min_value=10.0, max_value=40.0, value=22.0, step=0.5)
            with col3:
                humidity = st.number_input("æ¹¿åº¦ (%)", min_value=0, max_value=100, value=50)
            
            st.markdown("---")
            st.subheader("ğŸ‘ï¸ è‚ŒçŠ¶æ…‹è©•ä¾¡ï¼ˆç›®è¦–ï¼‰")
            
            st.info("""
            ğŸ’¡ **è©•ä¾¡ã®ãƒã‚¤ãƒ³ãƒˆ:**
            - å®¢è¦³çš„ã«è¦³å¯Ÿã—ã¦è©•ä¾¡ã—ã¦ãã ã•ã„
            - æ¯å›åŒã˜åŸºæº–ã§è©•ä¾¡ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™
            - è¿·ã£ãŸå ´åˆã¯ä¸­é–“ã®å€¤ï¼ˆ3ï¼‰ã‚’é¸æŠ
            """)
            
            col1, col2 = st.columns(2)
            with col1:
                roughness_score = st.slider(
                    "è‚Œè’ã‚Œåº¦",
                    min_value=1, max_value=5, value=3,
                    help="1=éå¸¸ã«æ»‘ã‚‰ã‹, 5=éå¸¸ã«è’ã‚Œã¦ã„ã‚‹"
                )
                st.caption("â­ éå¸¸ã«æ»‘ã‚‰ã‹ â†’ â­â­â­â­â­ éå¸¸ã«è’ã‚Œã¦ã„ã‚‹")
                
                pore_score = st.slider(
                    "æ¯›ç©´ã®ç›®ç«‹ã¡åº¦",
                    min_value=1, max_value=5, value=3,
                    help="1=ç›®ç«‹ãŸãªã„, 5=éå¸¸ã«ç›®ç«‹ã¤"
                )
                
                wrinkle_score = st.slider(
                    "ã‚·ãƒ¯ã®ç›®ç«‹ã¡åº¦",
                    min_value=1, max_value=5, value=3,
                    help="1=ç›®ç«‹ãŸãªã„, 5=éå¸¸ã«ç›®ç«‹ã¤"
                )
            
            with col2:
                dryness_score = st.slider(
                    "ä¹¾ç‡¥åº¦",
                    min_value=1, max_value=5, value=3,
                    help="1=éå¸¸ã«æ½¤ã£ã¦ã„ã‚‹, 5=éå¸¸ã«ä¹¾ç‡¥ã—ã¦ã„ã‚‹"
                )
                st.caption("ğŸ’§ éå¸¸ã«æ½¤ã„ â†’ ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ éå¸¸ã«ä¹¾ç‡¥")
                
                redness_score = st.slider(
                    "èµ¤ã¿ãƒ»ç‚ç—‡",
                    min_value=1, max_value=5, value=3,
                    help="1=ãªã—, 5=å¼·ã„èµ¤ã¿"
                )
                
                dark_circle_score = st.slider(
                    "ã‚¯ãƒã®ç›®ç«‹ã¡åº¦",
                    min_value=1, max_value=5, value=3,
                    help="1=ç›®ç«‹ãŸãªã„, 5=éå¸¸ã«ç›®ç«‹ã¤"
                )
            
            st.markdown("---")
            st.subheader("ğŸ“Š å®¢è¦³çš„æ¸¬å®šå€¤")
            
            col1, col2 = st.columns(2)
            with col1:
                moisture_level = st.number_input(
                    "è‚Œæ°´åˆ†é‡ (%)",
                    min_value=0.0, max_value=100.0, value=40.0, step=0.1,
                    help="è‚Œæ°´åˆ†è¨ˆã§ã®æ¸¬å®šå€¤ï¼ˆæŒã£ã¦ã„ã‚‹å ´åˆï¼‰"
                )
            with col2:
                sebum_level = st.number_input(
                    "çš®è„‚é‡ (ä»»æ„)",
                    min_value=0.0, max_value=100.0, value=50.0, step=0.1,
                    help="çš®è„‚æ¸¬å®šå™¨ã§ã®æ¸¬å®šå€¤ï¼ˆä»»æ„ï¼‰"
                )
            
            st.markdown("---")
            st.subheader("ğŸ“¸ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            
            col1, col2 = st.columns(2)
            with col1:
                left_cheek = st.file_uploader("å·¦é ¬ã®ç”»åƒ", type=['jpg', 'png'], key='left')
            with col2:
                right_cheek = st.file_uploader("å³é ¬ã®ç”»åƒ", type=['jpg', 'png'], key='right')
            
            notes = st.text_area("å‚™è€ƒãƒ»ãƒ¡ãƒ¢", placeholder="ç‰¹è¨˜äº‹é …ãŒã‚ã‚Œã°è¨˜å…¥ï¼ˆä¾‹ï¼šåŒ–ç²§å“ã‚’å¤‰æ›´ã€ä½“èª¿ä¸è‰¯ãªã©ï¼‰")
            
            st.markdown("---")
            
            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒœã‚¿ãƒ³
            if st.button("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜", type="primary", use_container_width=True):
                if not subject_id:
                    st.error("âŒ è¢«é¨“è€…IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                else:
                    with st.spinner("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
                        # ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ãƒˆãƒªä½œæˆ
                        data_entry = {
                            'subject_id': subject_id,
                            'timestamp': f"{measurement_date} {measurement_time}",
                            'age': age,
                            'gender': gender,
                            'skin_type': skin_type,
                            'condition': condition,
                            'temperature': temperature,
                            'humidity': humidity,
                            'roughness_score': roughness_score,
                            'dryness_score': dryness_score,
                            'pore_score': pore_score,
                            'wrinkle_score': wrinkle_score,
                            'redness_score': redness_score,
                            'dark_circle_score': dark_circle_score,
                            'moisture_level': moisture_level,
                            'sebum_level': sebum_level,
                            'notes': notes
                        }
                        
                        # å·¦é ¬ã®FDè¨ˆç®—
                        if left_cheek:
                            left_img = read_bgr_from_buffer(left_cheek.read())
                            if left_img is not None:
                                left_fd_result = calculate_fractal_dimension(left_img)
                                data_entry['left_cheek_fd'] = left_fd_result['fd']
                                data_entry['left_cheek_confidence'] = left_fd_result['confidence']
                        
                        # å³é ¬ã®FDè¨ˆç®—
                        if right_cheek:
                            right_cheek.seek(0)
                            right_img = read_bgr_from_buffer(right_cheek.read())
                            if right_img is not None:
                                right_fd_result = calculate_fractal_dimension(right_img)
                                data_entry['right_cheek_fd'] = right_fd_result['fd']
                                data_entry['right_cheek_confidence'] = right_fd_result['confidence']
                        
                        # å¹³å‡FD
                        if 'left_cheek_fd' in data_entry and 'right_cheek_fd' in data_entry:
                            data_entry['average_fd'] = (data_entry['left_cheek_fd'] + data_entry['right_cheek_fd']) / 2
                        elif 'left_cheek_fd' in data_entry:
                            data_entry['average_fd'] = data_entry['left_cheek_fd']
                        elif 'right_cheek_fd' in data_entry:
                            data_entry['average_fd'] = data_entry['right_cheek_fd']
                        
                        # ä¿å­˜
                        if data_manager.save_data(data_entry):
                            st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                            
                            # çµæœè¡¨ç¤º
                            st.subheader("ğŸ“Š æ¸¬å®šçµæœ")
                            col1, col2, col3 = st.columns(3)
                            
                            if 'left_cheek_fd' in data_entry:
                                with col1:
                                    st.metric("å·¦é ¬ FD", f"{data_entry['left_cheek_fd']:.4f}")
                            
                            if 'right_cheek_fd' in data_entry:
                                with col2:
                                    st.metric("å³é ¬ FD", f"{data_entry['right_cheek_fd']:.4f}")
                            
                            if 'average_fd' in data_entry:
                                with col3:
                                    st.metric("å¹³å‡ FD", f"{data_entry['average_fd']:.4f}")
                        else:
                            st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        with history_tab:
            st.subheader("ğŸ“š åé›†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿")
            
            df = data_manager.load_data()
            
            if df is None or len(df) == 0:
                st.info("ã¾ã ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œæ–°è¦ãƒ‡ãƒ¼ã‚¿åé›†ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦ãã ã•ã„ã€‚")
            else:
                st.success(f"âœ… {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                
                # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ç·æ¸¬å®šå›æ•°", f"{len(df)}å›")
                with col2:
                    st.metric("è¢«é¨“è€…æ•°", f"{df['subject_id'].nunique()}äºº")
                with col3:
                    if 'average_fd' in df.columns:
                        st.metric("FDå€¤ç¯„å›²", f"{df['average_fd'].min():.3f} - {df['average_fd'].max():.3f}")
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
                st.dataframe(df, use_container_width=True, height=400)
                
                # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    "ğŸ“¥ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_data,
                    file_name=f"experimental_data_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )
    
    # ============================================================
    # ğŸ“ˆ ç›¸é–¢åˆ†æãƒ¢ãƒ¼ãƒ‰
    # ============================================================
    elif app_mode == "ğŸ“ˆ ç›¸é–¢åˆ†æ":
        st.header("ğŸ“ˆ ç›¸é–¢åˆ†æ - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¨è‚ŒçŠ¶æ…‹ã®é–¢ä¿‚")
        
        if not EXPERIMENT_ANALYSIS_AVAILABLE:
            st.error("""
            âŒ **ç›¸é–¢åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“**
            
            `experiment_analysis.py`ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚
            """)
            return
        
        st.markdown("""
        ### ğŸ“Š çµ±è¨ˆåˆ†æ
        åé›†ã—ãŸå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¨è‚ŒçŠ¶æ…‹ã®ç›¸é–¢é–¢ä¿‚ã‚’åˆ†æã—ã¾ã™ã€‚
        
        **åˆ†æå†…å®¹:**
        - Pearsonç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—
        - çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®šï¼ˆpå€¤ï¼‰
        - æ•£å¸ƒå›³ã¨å›å¸°ç›´ç·š
        - ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        """)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        data_manager = ExperimentDataManager()
        df = data_manager.load_data()
        
        if df is None or len(df) == 0:
            st.warning("""
            âš ï¸ **åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“**
            
            ã€ŒğŸ”¬ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿åé›†ã€ãƒ¢ãƒ¼ãƒ‰ã§ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦ãã ã•ã„ã€‚
            æœ€ä½ã§ã‚‚3ä»¶ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚
            """)
            return
        
        st.success(f"âœ… {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        
        if len(df) < 3:
            st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚æœ‰æ„ãªç›¸é–¢åˆ†æã«ã¯æœ€ä½3ä»¶ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚")
            return
        
        # ã‚¿ãƒ–ã§åˆ†å‰²
        summary_tab, correlation_tab, scatter_tab, export_tab = st.tabs([
            "ğŸ“‹ ã‚µãƒãƒªãƒ¼",
            "ğŸ”— ç›¸é–¢åˆ†æ",
            "ğŸ“Š æ•£å¸ƒå›³",
            "ğŸ“¥ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"
        ])
        
        with summary_tab:
            st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼")
            
            summary = generate_experiment_summary(df)
            st.markdown(summary)
            
            # åŸºæœ¬çµ±è¨ˆ
            if 'average_fd' in df.columns:
                st.subheader("ğŸ“Š ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®åˆ†å¸ƒ")
                
                fig, ax = plt.subplots(figsize=(10, 5))
                ax.hist(df['average_fd'].dropna(), bins=20, color='steelblue', 
                       edgecolor='darkblue', alpha=0.7)
                ax.set_xlabel('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ', fontsize=12, fontweight='bold')
                ax.set_ylabel('é »åº¦', fontsize=12, fontweight='bold')
                ax.set_title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ', fontsize=14, fontweight='bold')
                ax.grid(axis='y', alpha=0.3)
                st.pyplot(fig)
        
        with correlation_tab:
            st.subheader("ğŸ”— ç›¸é–¢ä¿‚æ•°åˆ†æ")
            
            if 'average_fd' not in df.columns:
                st.error("ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # ç›¸é–¢è¨ˆç®—
            correlations = calculate_correlations(df)
            
            if not correlations:
                st.warning("ç›¸é–¢åˆ†æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            else:
                # ç›¸é–¢ä¿‚æ•°è¡¨
                st.markdown("### ğŸ“‹ ç›¸é–¢ä¿‚æ•°ä¸€è¦§")
                
                corr_data = []
                for name, data in correlations.items():
                    significance = "**" if data['p_value'] < 0.01 else "*" if data['p_value'] < 0.05 else ""
                    corr_data.append({
                        'é …ç›®': name,
                        'ç›¸é–¢ä¿‚æ•° (r)': f"{data['r']:.4f}{significance}",
                        'på€¤': f"{data['p_value']:.6f}",
                        'æœ‰æ„æ€§': 'âœ… æœ‰æ„' if data['significant'] else 'âŒ éæœ‰æ„',
                        'ãƒ‡ãƒ¼ã‚¿æ•°': data['n']
                    })
                
                corr_df = pd.DataFrame(corr_data)
                st.dataframe(corr_df, use_container_width=True, hide_index=True)
                
                st.caption("* p < 0.05, ** p < 0.01")
                
                # è§£é‡ˆã‚¬ã‚¤ãƒ‰
                with st.expander("ğŸ“– ç›¸é–¢ä¿‚æ•°ã®è§£é‡ˆã‚¬ã‚¤ãƒ‰"):
                    st.markdown("""
                    **ç›¸é–¢ä¿‚æ•° (r) ã®å¼·ã•:**
                    - |r| â‰¥ 0.7: å¼·ã„ç›¸é–¢
                    - 0.4 â‰¤ |r| < 0.7: ä¸­ç¨‹åº¦ã®ç›¸é–¢
                    - 0.2 â‰¤ |r| < 0.4: å¼±ã„ç›¸é–¢
                    - |r| < 0.2: ã»ã¼ç›¸é–¢ãªã—
                    
                    **ç¬¦å·ã®æ„å‘³:**
                    - æ­£ã®ç›¸é–¢ (r > 0): ä¸€æ–¹ãŒå¢—ãˆã‚‹ã¨ã‚‚ã†ä¸€æ–¹ã‚‚å¢—ãˆã‚‹
                    - è² ã®ç›¸é–¢ (r < 0): ä¸€æ–¹ãŒå¢—ãˆã‚‹ã¨ã‚‚ã†ä¸€æ–¹ã¯æ¸›ã‚‹
                    
                    **på€¤:**
                    - p < 0.05: çµ±è¨ˆçš„ã«æœ‰æ„ï¼ˆå¶ç„¶ã§ã¯ãªã„å¯èƒ½æ€§ãŒé«˜ã„ï¼‰
                    - p â‰¥ 0.05: çµ±è¨ˆçš„ã«éæœ‰æ„ï¼ˆå¶ç„¶ã®å¯èƒ½æ€§ã‚ã‚Šï¼‰
                    """)
                
                # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
                st.markdown("### ğŸ”¥ ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
                fig = create_correlation_heatmap(correlations)
                st.pyplot(fig)
        
        with scatter_tab:
            st.subheader("ğŸ“Š æ•£å¸ƒå›³åˆ†æ")
            
            if 'average_fd' not in df.columns:
                st.error("ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # æ•£å¸ƒå›³ä½œæˆã™ã‚‹é …ç›®ã‚’é¸æŠ
            scatter_options = {
                'roughness_score': 'è‚Œè’ã‚Œåº¦',
                'dryness_score': 'ä¹¾ç‡¥åº¦',
                'pore_score': 'æ¯›ç©´',
                'wrinkle_score': 'ã‚·ãƒ¯',
                'redness_score': 'èµ¤ã¿',
                'dark_circle_score': 'ã‚¯ãƒ',
                'moisture_level': 'æ°´åˆ†é‡',
                'sebum_level': 'çš®è„‚é‡',
                'age': 'å¹´é½¢'
            }
            
            available_options = {k: v for k, v in scatter_options.items() if k in df.columns}
            
            if not available_options:
                st.warning("æ•£å¸ƒå›³ã‚’ä½œæˆã§ãã‚‹é …ç›®ãŒã‚ã‚Šã¾ã›ã‚“")
            else:
                selected_var = st.selectbox(
                    "æ¯”è¼ƒã™ã‚‹é …ç›®ã‚’é¸æŠ",
                    options=list(available_options.keys()),
                    format_func=lambda x: available_options[x]
                )
                
                fig = create_scatter_plot(
                    df, 
                    selected_var, 
                    'average_fd',
                    available_options[selected_var],
                    'ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ',
                    f'ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ vs {available_options[selected_var]}'
                )
                st.pyplot(fig)
                
                # ã™ã¹ã¦ã®æ•£å¸ƒå›³ã‚’ä¸€æ‹¬è¡¨ç¤º
                if st.checkbox("ã™ã¹ã¦ã®æ•£å¸ƒå›³ã‚’è¡¨ç¤º"):
                    cols_per_row = 2
                    var_items = list(available_options.items())
                    
                    for i in range(0, len(var_items), cols_per_row):
                        cols = st.columns(cols_per_row)
                        for j, col in enumerate(cols):
                            idx = i + j
                            if idx < len(var_items):
                                var_key, var_name = var_items[idx]
                                with col:
                                    fig_small = create_scatter_plot(
                                        df,
                                        var_key,
                                        'average_fd',
                                        var_name,
                                        'FD',
                                        f'FD vs {var_name}'
                                    )
                                    st.pyplot(fig_small)
        
        with export_tab:
            st.subheader("ğŸ“¥ åˆ†æçµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
            
            # ç›¸é–¢åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report_lines = ["# ğŸ“Š ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¨è‚ŒçŠ¶æ…‹ã®ç›¸é–¢åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n"]
            report_lines.append(f"**ä½œæˆæ—¥æ™‚**: {pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            report_lines.append(f"**ãƒ‡ãƒ¼ã‚¿æ•°**: {len(df)}ä»¶\n")
            
            if correlations:
                report_lines.append("\n## ğŸ”— ç›¸é–¢ä¿‚æ•°\n")
                for name, data in sorted(correlations.items(), key=lambda x: abs(x[1]['r']), reverse=True):
                    sig = "**" if data['p_value'] < 0.01 else "*" if data['p_value'] < 0.05 else ""
                    report_lines.append(f"- **{name}**: r = {data['r']:.4f}{sig}, p = {data['p_value']:.6f}, n = {data['n']}")
                
                report_lines.append("\n## ğŸ“‹ è§£é‡ˆ\n")
                strong_corr = [name for name, data in correlations.items() if abs(data['r']) >= 0.7 and data['significant']]
                if strong_corr:
                    report_lines.append("**å¼·ã„ç›¸é–¢ãŒè¦‹ã‚‰ã‚ŒãŸé …ç›®:**")
                    for name in strong_corr:
                        report_lines.append(f"- {name}")
            
            report_text = '\n'.join(report_lines)
            
            st.markdown(report_text)
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            col1, col2 = st.columns(2)
            
            with col1:
                st.download_button(
                    "ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (Markdown)",
                    data=report_text,
                    file_name=f"correlation_report_{pd.Timestamp.now().strftime('%Y%m%d')}.md",
                    mime="text/markdown"
                )
            
            with col2:
                if 'average_fd' in df.columns:
                    # åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§å‡ºåŠ›
                    analysis_df = df[['subject_id', 'timestamp', 'average_fd'] + 
                                    [col for col in df.columns if col.endswith('_score') or col.endswith('_level')]].copy()
                    csv_analysis = analysis_df.to_csv(index=False, encoding='utf-8-sig')
                    
                    st.download_button(
                        "ğŸ“¥ åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (CSV)",
                        data=csv_analysis,
                        file_name=f"analysis_data_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                        mime="text/csv"
                    )

if __name__ == "__main__":
    app()
