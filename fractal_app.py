# fractal_fd_app_optimized.py
# ============================================================
# ä½ç”»è³ªç‰¹åŒ–å‹ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æï¼‹AIè£œæ­£ï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰
# - CuPy ãŒã‚ã‚‹å ´åˆã¯ GPU ã‚’è‡ªå‹•æ¤œå‡ºã—ã¦ä½¿ç”¨
# - ãƒ–ãƒ­ãƒƒã‚¯æ¼”ç®—ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ box-counting ã‚’é«˜é€ŸåŒ–
# - LightGBM ã‚’ä½¿ã£ãŸä½ç”»è³ª->é«˜ç”»è³ªFDäºˆæ¸¬ï¼ˆä¸¦åˆ—åŒ–ï¼‰
# ============================================================

import os
import cv2
import numpy as np
import glob
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, r2_score
from scipy.stats import pearsonr
import streamlit as st
from lightgbm import LGBMRegressor
import time
import pickle

# Try import cupy for GPU acceleration (optional)
USE_CUPY = False
xp = np  # alias for numpy/cupy
try:
    import cupy as cp
    # quick check: is CUDA visible?
    _ = cp.zeros(1)
    USE_CUPY = True
    xp = cp
except Exception:
    USE_CUPY = False
    xp = np

# ============================================================
# Data Augmentation (ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ) - ç”»åƒãŒå°‘ãªã„å ´åˆã®å¯¾ç­–
# ============================================================
def augment_image(img, augmentation_type):
    """
    ç”»åƒã«ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨
    
    Args:
        img: å…¥åŠ›ç”»åƒ (BGR)
        augmentation_type: æ‹¡å¼µã‚¿ã‚¤ãƒ—
    
    Returns:
        æ‹¡å¼µã•ã‚ŒãŸç”»åƒ
    """
    if augmentation_type == 'flip_h':
        # æ°´å¹³åè»¢
        return cv2.flip(img, 1)
    elif augmentation_type == 'flip_v':
        # å‚ç›´åè»¢
        return cv2.flip(img, 0)
    elif augmentation_type == 'rotate_90':
        # 90åº¦å›è»¢
        return cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)
    elif augmentation_type == 'rotate_180':
        # 180åº¦å›è»¢
        return cv2.rotate(img, cv2.ROTATE_180)
    elif augmentation_type == 'rotate_270':
        # 270åº¦å›è»¢
        return cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
    elif augmentation_type == 'brightness_up':
        # æ˜ã‚‹ã•å¢—åŠ 
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 2] = hsv[:, :, 2] * 1.2  # æ˜ã‚‹ã•ã‚’20%å¢—åŠ 
        hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)
        hsv = hsv.astype(np.uint8)
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    elif augmentation_type == 'brightness_down':
        # æ˜ã‚‹ã•æ¸›å°‘
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 2] = hsv[:, :, 2] * 0.8  # æ˜ã‚‹ã•ã‚’20%æ¸›å°‘
        hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)
        hsv = hsv.astype(np.uint8)
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    elif augmentation_type == 'contrast_up':
        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¢—åŠ 
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        l = l.astype(np.float32)
        l = (l - 128) * 1.3 + 128  # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’30%å¢—åŠ 
        l = np.clip(l, 0, 255).astype(np.uint8)
        lab = cv2.merge([l, a, b])
        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    elif augmentation_type == 'contrast_down':
        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆæ¸›å°‘
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        l = l.astype(np.float32)
        l = (l - 128) * 0.7 + 128  # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’30%æ¸›å°‘
        l = np.clip(l, 0, 255).astype(np.uint8)
        lab = cv2.merge([l, a, b])
        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    elif augmentation_type == 'gamma_bright':
        # ã‚¬ãƒ³ãƒè£œæ­£ (æ˜ã‚‹ã)
        gamma = 1.2
        inv_gamma = 1.0 / gamma
        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        return cv2.LUT(img, table)
    elif augmentation_type == 'gamma_dark':
        # ã‚¬ãƒ³ãƒè£œæ­£ (æš—ã)
        gamma = 0.8
        inv_gamma = 1.0 / gamma
        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        return cv2.LUT(img, table)
    elif augmentation_type == 'noise':
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºè¿½åŠ 
        noise = np.random.normal(0, 10, img.shape).astype(np.float32)
        noisy = img.astype(np.float32) + noise
        noisy = np.clip(noisy, 0, 255).astype(np.uint8)
        return noisy
    elif augmentation_type == 'blur':
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ã¼ã‹ã—
        return cv2.GaussianBlur(img, (5, 5), 1.0)
    elif augmentation_type == 'sharpen':
        # ã‚·ãƒ£ãƒ¼ãƒ—åŒ–
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1],
                          [-1,-1,-1]])
        return cv2.filter2D(img, -1, kernel)
    elif augmentation_type == 'saturation_up':
        # å½©åº¦å¢—åŠ 
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 1] = hsv[:, :, 1] * 1.3  # å½©åº¦ã‚’30%å¢—åŠ 
        hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
        hsv = hsv.astype(np.uint8)
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    elif augmentation_type == 'saturation_down':
        # å½©åº¦æ¸›å°‘
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 1] = hsv[:, :, 1] * 0.7  # å½©åº¦ã‚’30%æ¸›å°‘
        hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
        hsv = hsv.astype(np.uint8)
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    elif augmentation_type == 'hue_shift':
        # è‰²ç›¸ã‚·ãƒ•ãƒˆ
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.int16)
        hsv[:, :, 0] = (hsv[:, :, 0] + 10) % 180  # è‰²ç›¸ã‚’10åº¦ã‚·ãƒ•ãƒˆ
        hsv = hsv.astype(np.uint8)
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    elif augmentation_type == 'equalize':
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–
        yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
        yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])
        return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
    
    # ============================================================
    # ğŸ¯ AIå­¦ç¿’ã«ç‰¹ã«æœ‰åŠ¹ãªè¿½åŠ æ‹¡å¼µ (ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒå­¦ç¿’æœ€é©åŒ–)
    # ============================================================
    elif augmentation_type == 'scale_up':
        # ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ› (æ‹¡å¤§ 110%) - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§å­¦ç¿’
        h, w = img.shape[:2]
        new_h, new_w = int(h * 1.1), int(w * 1.1)
        scaled = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        # ä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ—ã§å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
        start_h = (new_h - h) // 2
        start_w = (new_w - w) // 2
        return scaled[start_h:start_h+h, start_w:start_w+w]
    
    elif augmentation_type == 'scale_down':
        # ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ› (ç¸®å° 90%) - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§å­¦ç¿’
        h, w = img.shape[:2]
        new_h, new_w = int(h * 0.9), int(w * 0.9)
        scaled = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã§å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
        pad_h = (h - new_h) // 2
        pad_w = (w - new_w) // 2
        return cv2.copyMakeBorder(scaled, pad_h, h-new_h-pad_h, pad_w, w-new_w-pad_w, 
                                  cv2.BORDER_REFLECT)
    
    elif augmentation_type == 'clahe':
        # CLAHE (é©å¿œçš„ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–) - å±€æ‰€çš„ãªãƒ†ã‚¯ã‚¹ãƒãƒ£å¼·èª¿
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã®è©³ç´°ã‚’ä¿æŒã—ãªãŒã‚‰ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå‘ä¸Š
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        lab = cv2.merge([l, a, b])
        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    
    elif augmentation_type == 'bilateral':
        # ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ - ã‚¨ãƒƒã‚¸ä¿å­˜å¹³æ»‘åŒ–
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã®ã‚¨ãƒƒã‚¸ã‚’ä¿ã¡ãªãŒã‚‰ãƒã‚¤ã‚ºé™¤å»
        return cv2.bilateralFilter(img, 9, 75, 75)
    
    elif augmentation_type == 'median':
        # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ - ãƒã‚¤ã‚ºé™¤å»
        # å¡©èƒ¡æ¤’ãƒã‚¤ã‚ºã«å¼·ãã€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã‚’ä¿æŒ
        return cv2.medianBlur(img, 5)
    
    elif augmentation_type == 'temp_warm':
        # æ¸©åº¦èª¿æ•´ (æš–è‰²åŒ–) - ç…§æ˜æ¡ä»¶ã®å¤‰åŒ–ã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§
        # è‚Œç”»åƒã¯ç…§æ˜ã§è‰²æ¸©åº¦ãŒå¤‰ã‚ã‚‹ãŸã‚é‡è¦
        warm_lut = np.array([[[i, 
                                int(np.clip(i * 0.9, 0, 255)), 
                                int(np.clip(i * 0.8, 0, 255))] 
                              for i in range(256)]], dtype=np.uint8)
        b, g, r = cv2.split(img)
        b = cv2.LUT(b, warm_lut[0, :, 2])
        g = cv2.LUT(g, warm_lut[0, :, 1])
        r = cv2.LUT(r, warm_lut[0, :, 0])
        return cv2.merge([b, g, r])
    
    elif augmentation_type == 'temp_cool':
        # æ¸©åº¦èª¿æ•´ (å¯’è‰²åŒ–) - ç…§æ˜æ¡ä»¶ã®å¤‰åŒ–ã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§
        cool_lut = np.array([[[int(np.clip(i * 0.8, 0, 255)), 
                                int(np.clip(i * 0.9, 0, 255)), 
                                i] 
                              for i in range(256)]], dtype=np.uint8)
        b, g, r = cv2.split(img)
        b = cv2.LUT(b, cool_lut[0, :, 0])
        g = cv2.LUT(g, cool_lut[0, :, 1])
        r = cv2.LUT(r, cool_lut[0, :, 2])
        return cv2.merge([b, g, r])
    
    elif augmentation_type == 'rotate_small_cw':
        # å¾®å°å›è»¢ (æ™‚è¨ˆå›ã‚Š5åº¦) - æ–¹å‘ä¸å¤‰æ€§ã®å­¦ç¿’
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯å›è»¢ã«å¯¾ã—ã¦ä¸å¤‰ã§ã‚ã‚‹ã¹ã
        h, w = img.shape[:2]
        center = (w // 2, h // 2)
        angle = 5
        matrix = cv2.getRotationMatrix2D(center, -angle, 1.0)
        return cv2.warpAffine(img, matrix, (w, h), 
                             flags=cv2.INTER_LINEAR, 
                             borderMode=cv2.BORDER_REFLECT)
    
    elif augmentation_type == 'rotate_small_ccw':
        # å¾®å°å›è»¢ (åæ™‚è¨ˆå›ã‚Š5åº¦) - æ–¹å‘ä¸å¤‰æ€§ã®å­¦ç¿’
        h, w = img.shape[:2]
        center = (w // 2, h // 2)
        angle = -5
        matrix = cv2.getRotationMatrix2D(center, -angle, 1.0)
        return cv2.warpAffine(img, matrix, (w, h), 
                             flags=cv2.INTER_LINEAR, 
                             borderMode=cv2.BORDER_REFLECT)
    
    elif augmentation_type == 'unsharp':
        # ã‚¢ãƒ³ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ã‚¯ - ã‚¨ãƒƒã‚¸å¼·èª¿
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã®å¢ƒç•Œã‚’æ˜ç¢ºåŒ–
        gaussian = cv2.GaussianBlur(img, (0, 0), 2.0)
        unsharp = cv2.addWeighted(img, 1.5, gaussian, -0.5, 0)
        return unsharp
    
    elif augmentation_type == 'crop_zoom':
        # ä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ—&ã‚ºãƒ¼ãƒ  (90%ã‚’æ‹¡å¤§)
        h, w = img.shape[:2]
        crop_size = int(min(h, w) * 0.9)
        start_h = (h - crop_size) // 2
        start_w = (w - crop_size) // 2
        cropped = img[start_h:start_h+crop_size, start_w:start_w+crop_size]
        return cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LINEAR)
    else:
        return img

def apply_data_augmentation(high_imgs, low_imgs, high_names, low_names, augmentation_methods):
    """
    ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨ã—ã¦ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã™
    
    Args:
        high_imgs: é«˜ç”»è³ªç”»åƒãƒªã‚¹ãƒˆ
        low_imgs: ä½ç”»è³ªç”»åƒãƒªã‚¹ãƒˆ
        high_names: é«˜ç”»è³ªç”»åƒåãƒªã‚¹ãƒˆ
        low_names: ä½ç”»è³ªç”»åƒåãƒªã‚¹ãƒˆ
        augmentation_methods: é©ç”¨ã™ã‚‹æ‹¡å¼µæ‰‹æ³•ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        æ‹¡å¼µå¾Œã®ç”»åƒãƒªã‚¹ãƒˆã¨åå‰ãƒªã‚¹ãƒˆ
    """
    augmented_high = high_imgs.copy()
    augmented_low = low_imgs.copy()
    augmented_high_names = high_names.copy()
    augmented_low_names = low_names.copy()
    
    for method in augmentation_methods:
        for high, low, h_name, l_name in zip(high_imgs, low_imgs, high_names, low_names):
            aug_high = augment_image(high, method)
            aug_low = augment_image(low, method)
            augmented_high.append(aug_high)
            augmented_low.append(aug_low)
            augmented_high_names.append(f"{h_name}_{method}")
            augmented_low_names.append(f"{l_name}_{method}")
    
    return augmented_high, augmented_low, augmented_high_names, augmented_low_names


# Helper to move array to xp (cupy or numpy)
def to_xp(arr):
    if USE_CUPY:
        return cp.asarray(arr)
    else:
        return np.asarray(arr)

def to_host(arr):
    if USE_CUPY:
        return cp.asnumpy(arr)
    else:
        return arr

# ------------------------------------------------------------
# Utility: ensure image is color BGR uint8
def read_bgr_from_buffer(buf):
    arr = np.frombuffer(buf, np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    return img

def read_bgr_from_path(filepath):
    """æ—¥æœ¬èªãƒ‘ã‚¹ã«å¯¾å¿œã—ãŸç”»åƒèª­ã¿è¾¼ã¿"""
    try:
        # OpenCVã¯æ—¥æœ¬èªãƒ‘ã‚¹ã‚’ç›´æ¥æ‰±ãˆãªã„ãŸã‚ã€numpyã‚’çµŒç”±
        with open(filepath, 'rb') as f:
            buf = f.read()
        arr = np.frombuffer(buf, np.uint8)
        img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
        return img
    except Exception as e:
        return None

# ============================================================
# Fast vectorized standard-deviation box-counting (ä¸­å·å¼ãƒ™ãƒ¼ã‚¹)
# ============================================================
def fast_fractal_std_boxcount_batched(img_bgr, scales=(2,4,8,16,32,64), use_gpu=None):
    """
    img_bgr: HxWx3 uint8 (OpenCV BGR)
    scales: iterable of block sizes (h)
    use_gpu: None => auto (global USE_CUPY), True/False to force
    returns: D, scales_used, Nh_values (host numpy arrays)
    """
    if use_gpu is None:
        use_gpu = USE_CUPY

    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32)
    H, W = img_gray.shape

    Nh_vals = []
    valid_scales = []
    for h in scales:
        # crop to multiple of h for clean reshaping
        Hc = (H // h) * h
        Wc = (W // h) * h
        if Hc < h or Wc < h:
            continue

        gray_crop = img_gray[:Hc, :Wc]

        # move to xp
        arr = to_xp(gray_crop)

        # reshape to blocks: (Hc//h, h, Wc//h, h) then transpose to (Hc//h, Wc//h, h, h)
        new_shape = (Hc//h, h, Wc//h, h)
        try:
            blocks = arr.reshape(new_shape).transpose(0,2,1,3)
        except Exception:
            # fallback per-block (rare)
            blocks_list = []
            for i in range(0, Hc, h):
                row=[]
                for j in range(0, Wc, h):
                    row.append(arr[i:i+h, j:j+h])
                blocks_list.append(row)
            blocks = to_xp(np.array(blocks_list))

        # compute std over last two axes (h,h) -> shape (Hc//h, Wc//h)
        # note: xp.std uses different dtype; do manually for numerical stability
        mean_blk = blocks.mean(axis=(2,3))
        sq_mean = (blocks**2).mean(axis=(2,3))
        std_blk = xp.sqrt(xp.maximum(0, sq_mean - mean_blk**2))

        # nh per block: sigma/h
        nh = std_blk / float(h)

        # sum across blocks and convert to host
        nh_total = float(to_host(nh.sum()))
        Nh_vals.append(nh_total + 1e-12)
        valid_scales.append(h)

    if len(valid_scales) < 3:
        return None, np.array(scales), np.array([1]*len(scales))

    log_h = np.log(np.array(valid_scales, dtype=np.float64))
    log_Nh = np.log(np.array(Nh_vals, dtype=np.float64))

    # linear fit
    coeffs = np.polyfit(log_h, log_Nh, 1)
    D = abs(coeffs[0])

    return float(D), np.array(valid_scales), np.array(Nh_vals)

# ============================================================
# 3D DBC fast version (vectorized)
# ============================================================
def fast_fractal_3d_dbc(img_bgr, scales=None, max_size=256, use_gpu=None):
    """
    Convert grayscale intensity to height and perform vectorized DBC counting.
    Returns (FD_3d, used_scales, counts)
    """
    if use_gpu is None:
        use_gpu = USE_CUPY

    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32)
    H, W = gray.shape
    # resize for speed
    scale_factor = 1.0
    if max(H, W) > max_size:
        scale_factor = max_size / max(H, W)
        gray = cv2.resize(gray, (int(W*scale_factor), int(H*scale_factor)), interpolation=cv2.INTER_AREA)
        H, W = gray.shape

    if scales is None:
        max_box = max(2, min(H, W)//4)
        scales = []
        s = 2
        while s <= max_box:
            scales.append(s)
            s *= 2
        if len(scales) < 3:
            scales = [2,4,8,16]

    counts = []
    arr_host = gray / 255.0
    arr = to_xp(arr_host)
    for r in scales:
        nh = (H // r)
        nw = (W // r)
        if nh < 1 or nw < 1:
            counts.append(0)
            continue

        Hc = nh * r
        Wc = nw * r
        arr_crop = arr[:Hc, :Wc]
        # shape (nh, r, nw, r) -> (nh, nw, r, r)
        blocks = arr_crop.reshape((nh, r, nw, r)).transpose(0,2,1,3)
        # min and max per block
        bmin = blocks.min(axis=(2,3))
        bmax = blocks.max(axis=(2,3))

        # G as in original (small quantization step): use 1/r to scale
        G = max(0.001, 1.0 / r)
        # l = floor(min/G), k = ceil(max/G)
        l = xp.floor(bmin / G)
        k = xp.ceil(bmax / G)
        # number of boxes per block (k-l)
        nr = (k - l).astype(xp.int32)
        # sum, ensure >=1 per block
        nr = xp.maximum(nr, 1)
        total_nr = int(to_host(nr.sum()))
        counts.append(total_nr)

    # check validity
    valid_sizes = []
    valid_counts = []
    for s,c in zip(scales, counts):
        if c > 0:
            valid_sizes.append(s)
            valid_counts.append(c)
    if len(valid_counts) < 3:
        return None, np.array(scales), np.array(counts)

    log_sizes = np.log(np.array(valid_sizes, dtype=np.float64))
    log_counts = np.log(np.array(valid_counts, dtype=np.float64))
    coeffs = np.polyfit(log_sizes, log_counts, 1)
    slope = coeffs[0]
    # FD = 3 - |slope|
    fd3 = 3.0 - abs(slope)
    fd3 = float(np.clip(fd3, 2.0, 3.0))
    return fd3, np.array(valid_sizes), np.array(valid_counts)

# ============================================================
# Feature extraction (vectorized, batch-friendly)
# ============================================================
def extract_feature_vector(img_bgr, size=256, use_gpu=None):
    if use_gpu is None:
        use_gpu = USE_CUPY
    gray = cv2.cvtColor(cv2.resize(img_bgr, (size, size)), cv2.COLOR_BGR2GRAY).astype(np.float32)
    # move to xp for possible GPU ops
    arr = to_xp(gray)
    mean_val = float(to_host(arr.mean()))
    std_val = float(to_host(arr.std()))
    # Sobel edges
    gx = to_host(cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3))
    gy = to_host(cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3))
    edge_mean = float(np.mean(np.sqrt(gx**2 + gy**2)))
    noise_level = float(np.mean(np.abs(gray - cv2.GaussianBlur(gray, (3,3), 1))))
    # entropy
    probs, _ = np.histogram(gray.flatten(), bins=256, range=(0,255), density=True)
    probs = probs + 1e-12
    entropy = -np.sum(probs * np.log2(probs))
    return [mean_val, std_val, edge_mean, noise_level, entropy]

# ============================================================
# Train FD predictor (low->high) using LightGBM (fast, parallel)
# ============================================================
def train_fd_predictor_fast(low_imgs, high_imgs, n_estimators=400, max_depth=8):
    # ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
    if len(low_imgs) < 2 or len(high_imgs) < 2:
        raise ValueError(
            f"âŒ **å­¦ç¿’ã«å¿…è¦ãªç”»åƒãƒšã‚¢æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™**\n\n"
            f"- æ¤œå‡ºã•ã‚ŒãŸç”»åƒãƒšã‚¢æ•°: {len(low_imgs)}\n"
            f"- å¿…è¦ãªæœ€å°ãƒšã‚¢æ•°: 2\n\n"
            f"ğŸ’¡ **è§£æ±ºæ–¹æ³•:**\n"
            f"1. ãƒ•ã‚©ãƒ«ãƒ€å†…ã«å°‘ãªãã¨ã‚‚2çµ„ä»¥ä¸Šã®ç”»åƒãƒšã‚¢ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n"
            f"2. ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„\n"
            f"   - ä¾‹: `IMG_0001.jpg` ã¨ `IMG_0001_low1.jpg`\n"
            f"3. ç”»åƒãŒæ­£ã—ãèª­ã¿è¾¼ã‚ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
        )
    
    X = []
    y = []
    for low, high in zip(low_imgs, high_imgs):
        feat = extract_feature_vector(low)
        X.append(feat)
        D_high, *_ = fast_fractal_std_boxcount_batched(high, use_gpu=False)  # computing target on CPU for stability
        if D_high is None:
            # fallback to classic fractal_dimension naive
            D_high, *_ = fractal_dimension_naive(high)
        y.append(D_high)
    X = np.array(X, dtype=np.float32)
    y = np.array(y, dtype=np.float32)
    model = LGBMRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=0.05, n_jobs=-1)
    model.fit(X, y)
    return model

# ============================================================
# Model Save/Load (ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿)
# ============================================================
def save_model(model, filepath="trained_fd_model.pkl"):
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
    with open(filepath, 'wb') as f:
        pickle.dump(model, f)
    return filepath

def load_model(filepath="trained_fd_model.pkl"):
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    if not os.path.exists(filepath):
        return None
    with open(filepath, 'rb') as f:
        model = pickle.load(f)
    return model

def predict_fd_from_low_quality(low_img, model):
    """
    ä½ç”»è³ªç”»åƒã ã‘ã‹ã‚‰é«˜ç”»è³ªç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’äºˆæ¸¬
    
    Args:
        low_img: ä½ç”»è³ªç”»åƒ (BGR)
        model: å­¦ç¿’æ¸ˆã¿LightGBMãƒ¢ãƒ‡ãƒ«
    
    Returns:
        äºˆæ¸¬ã•ã‚ŒãŸãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
    """
    feat = extract_feature_vector(low_img)
    D_pred = float(model.predict([feat])[0])
    return D_pred

# ============================================================
# ä¿¡é ¼åº¦è¨ˆç®—æ©Ÿèƒ½ (Confidence Scoring)
# ============================================================
def calculate_prediction_confidence(low_img, model, predicted_fd):
    """
    äºˆæ¸¬å€¤ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—
    
    ä¿¡é ¼åº¦æŒ‡æ¨™:
    1. ç‰¹å¾´é‡å“è³ªã‚¹ã‚³ã‚¢ (0-100): å…¥åŠ›ç”»åƒã®å“è³ªè©•ä¾¡
    2. ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦ (0-100): äºˆæ¸¬ã®å®‰å®šæ€§
    3. ç·åˆä¿¡é ¼åº¦ (0-100): å…¨ä½“çš„ãªä¿¡é ¼æ€§
    
    Args:
        low_img: ä½ç”»è³ªç”»åƒ
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        predicted_fd: äºˆæ¸¬ã•ã‚ŒãŸFDå€¤
    
    Returns:
        dict: ä¿¡é ¼åº¦æƒ…å ±
    """
    feat = extract_feature_vector(low_img)
    
    # 1. ç‰¹å¾´é‡å“è³ªã‚¹ã‚³ã‚¢ (Feature Quality Score)
    # ã‚¨ãƒƒã‚¸å¼·åº¦ã€ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‹ã‚‰è©•ä¾¡
    mean_val, std_val, edge_strength, noise_level, entropy = feat
    
    # ã‚¨ãƒƒã‚¸å¼·åº¦ãŒé«˜ã„ = æ˜ç¢ºãªæ§‹é€  = è‰¯ã„ (0-40ç‚¹)
    edge_score = min(edge_strength / 30.0 * 40, 40)
    
    # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ãŒä½ã„ = è‰¯ã„ (0-30ç‚¹)
    noise_score = max(30 - noise_level / 10.0 * 30, 0)
    
    # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒé©åº¦ (5-7ãŒç†æƒ³) = è‰¯ã„ (0-30ç‚¹)
    entropy_diff = abs(entropy - 6.0)
    entropy_score = max(30 - entropy_diff * 10, 0)
    
    feature_quality = edge_score + noise_score + entropy_score
    feature_quality = np.clip(feature_quality, 0, 100)
    
    # 2. ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦ (Model Confidence)
    # äºˆæ¸¬å€¤ãŒå¦¥å½“ãªç¯„å›²å†…ã‹ (2.0-3.0)
    if 2.0 <= predicted_fd <= 3.0:
        range_score = 50
    elif 1.9 <= predicted_fd <= 3.1:
        range_score = 30
    else:
        range_score = 10
    
    # äºˆæ¸¬å€¤ã®å®‰å®šæ€§ (LightGBMã®å ´åˆã€æœ¨ã®äºˆæ¸¬ã®ã°ã‚‰ã¤ãã‚’æ¨å®š)
    # ç°¡æ˜“ç‰ˆ: äºˆæ¸¬å€¤ãŒæ¥µç«¯ã§ãªã„ã»ã©é«˜ã‚¹ã‚³ã‚¢
    stability_score = 50 - abs(predicted_fd - 2.5) * 20
    stability_score = np.clip(stability_score, 0, 50)
    
    model_confidence = range_score + stability_score
    model_confidence = np.clip(model_confidence, 0, 100)
    
    # 3. ç·åˆä¿¡é ¼åº¦ (Overall Confidence)
    # ç‰¹å¾´é‡å“è³ª 60%, ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦ 40%
    overall_confidence = feature_quality * 0.6 + model_confidence * 0.4
    overall_confidence = np.clip(overall_confidence, 0, 100)
    
    # ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
    if overall_confidence >= 80:
        confidence_level = "éå¸¸ã«é«˜ã„"
        level_emoji = "ğŸŸ¢"
        level_color = "success"
    elif overall_confidence >= 60:
        confidence_level = "é«˜ã„"
        level_emoji = "ğŸ”µ"
        level_color = "info"
    elif overall_confidence >= 40:
        confidence_level = "ä¸­ç¨‹åº¦"
        level_emoji = "ğŸŸ¡"
        level_color = "warning"
    else:
        confidence_level = "ä½ã„"
        level_emoji = "ğŸ”´"
        level_color = "error"
    
    # äºˆæ¸¬åŒºé–“ã®æ¨å®š (ç°¡æ˜“ç‰ˆ)
    # ä¿¡é ¼åº¦ãŒä½ã„ã»ã©åŒºé–“ãŒåºƒã„
    uncertainty = (100 - overall_confidence) / 100 * 0.1
    lower_bound = predicted_fd - uncertainty
    upper_bound = predicted_fd + uncertainty
    
    return {
        'overall_confidence': overall_confidence,
        'feature_quality': feature_quality,
        'model_confidence': model_confidence,
        'confidence_level': confidence_level,
        'level_emoji': level_emoji,
        'level_color': level_color,
        'lower_bound': lower_bound,
        'upper_bound': upper_bound,
        'uncertainty': uncertainty,
        'feature_details': {
            'edge_strength': edge_strength,
            'noise_level': noise_level,
            'entropy': entropy,
            'edge_score': edge_score,
            'noise_score': noise_score,
            'entropy_score': entropy_score
        }
    }

# fallback naive fractal (simple binary box count) used only if needed
def fractal_dimension_naive(img_bgr, scales=(2,4,8,16,32)):
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    H, W = gray.shape
    Nh = []
    valid_scales = []
    for s in scales:
        Hc = (H // s) * s
        Wc = (W // s) * s
        if Hc < s or Wc < s:
            continue
        cropped = gray[:Hc, :Wc]
        blocks = (cropped.reshape(Hc//s, s, Wc//s, s).mean(axis=(1,3)) > 127).astype(np.int32)
        Nh.append(blocks.sum() + 1e-9)
        valid_scales.append(s)
    if len(valid_scales) < 3:
        return None, np.array(scales), np.array([1]*len(scales))
    log_h = np.log(np.array(valid_scales))
    log_Nh = np.log(np.array(Nh))
    coeffs = np.polyfit(log_h, log_Nh, 1)
    return float(abs(coeffs[0])), np.array(valid_scales), np.array(Nh)

# ============================================================
# Evaluate pairs and show metrics & plots
# ============================================================
def evaluate_and_plot(high_imgs, low_imgs, model, use_gpu=None):
    if use_gpu is None:
        use_gpu = USE_CUPY

    D_high_list = []
    D_low_list = []
    D_pred_list = []
    t0 = time.time()
    for high, low in zip(high_imgs, low_imgs):
        # compute FD (fast vectorized)
        D_high, *_ = fast_fractal_std_boxcount_batched(high, use_gpu=use_gpu)
        D_low, *_ = fast_fractal_std_boxcount_batched(low, use_gpu=use_gpu)
        # predicted FD
        feat = extract_feature_vector(low)
        D_pred = float(model.predict([feat])[0])
        D_high_list.append(D_high)
        D_low_list.append(D_low)
        D_pred_list.append(D_pred)
    t1 = time.time()

    D_high_arr = np.array(D_high_list, dtype=np.float32)
    D_low_arr = np.array(D_low_list, dtype=np.float32)
    D_pred_arr = np.array(D_pred_list, dtype=np.float32)

    # metrics
    valid_mask = ~np.isnan(D_high_arr) & ~np.isnan(D_low_arr) & ~np.isnan(D_pred_arr)
    if valid_mask.sum() < 2:
        st.warning("è§£æå¯èƒ½ãªé«˜ç”»è³ªFDãŒå°‘ãªã„ãŸã‚è©•ä¾¡ã§ãã¾ã›ã‚“ã€‚")
        return D_high_list, D_low_list, D_pred_list

    # å®‰å…¨ã«ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
    r_low = 0.0
    r_pred = 0.0
    
    try:
        # æ¨™æº–åå·®ãŒ0ã®å ´åˆã¯nanã«ãªã‚‹ã®ã§å¯¾ç­–
        std_low = np.std(D_low_arr[valid_mask])
        std_high = np.std(D_high_arr[valid_mask])
        std_pred = np.std(D_pred_arr[valid_mask])
        
        if std_low > 1e-10 and std_high > 1e-10:
            r_low_val, _ = pearsonr(D_high_arr[valid_mask], D_low_arr[valid_mask])
            # nanãƒã‚§ãƒƒã‚¯
            if not np.isnan(r_low_val):
                r_low = r_low_val
            else:
                st.warning("âš ï¸ ä½ç”»è³ªã®ç›¸é–¢ä¿‚æ•°ãŒnanã§ã™(æ¨™æº–åå·®ãŒ0ã«è¿‘ã„)")
        else:
            st.warning(f"âš ï¸ ä½ç”»è³ªFDã®åˆ†æ•£ãŒ0ã«è¿‘ã„ãŸã‚ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ (std_low={std_low:.6f}, std_high={std_high:.6f})")
        
        if std_pred > 1e-10 and std_high > 1e-10:
            r_pred_val, _ = pearsonr(D_high_arr[valid_mask], D_pred_arr[valid_mask])
            # nanãƒã‚§ãƒƒã‚¯
            if not np.isnan(r_pred_val):
                r_pred = r_pred_val
            else:
                st.warning("âš ï¸ AIè£œæ­£ã®ç›¸é–¢ä¿‚æ•°ãŒnanã§ã™(æ¨™æº–åå·®ãŒ0ã«è¿‘ã„)")
                st.info(f"AIäºˆæ¸¬å€¤ã®çµ±è¨ˆ: å¹³å‡={np.mean(D_pred_arr[valid_mask]):.4f}, æ¨™æº–åå·®={std_pred:.6f}")
        else:
            st.warning(f"âš ï¸ AIäºˆæ¸¬å€¤ã®åˆ†æ•£ãŒ0ã«è¿‘ã„ãŸã‚ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ (std_pred={std_pred:.6f}, std_high={std_high:.6f})")
            st.error("ğŸ”´ **å•é¡Œ**: AIãŒå…¨ã¦åŒã˜å€¤(ã¾ãŸã¯ã»ã¼åŒã˜å€¤)ã‚’äºˆæ¸¬ã—ã¦ã„ã¾ã™!")
            st.info("ğŸ’¡ **åŸå› **: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ä¸è¶³ã€ã¾ãŸã¯ç‰¹å¾´é‡ãŒåŠ¹æœçš„ã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    except Exception as e:
        st.error(f"ç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        r_low = 0.0
        r_pred = 0.0
    
    mae_low = mean_absolute_error(D_high_arr[valid_mask], D_low_arr[valid_mask])
    mae_pred = mean_absolute_error(D_high_arr[valid_mask], D_pred_arr[valid_mask])
    
    try:
        r2_val = r2_score(D_high_arr[valid_mask], D_pred_arr[valid_mask])
        if not np.isnan(r2_val) and not np.isinf(r2_val):
            r2 = r2_val
        else:
            r2 = 0.0
            st.warning("âš ï¸ RÂ²ã‚¹ã‚³ã‚¢ãŒnanã¾ãŸã¯infã§ã™")
    except Exception as e:
        st.error(f"RÂ²ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        r2 = 0.0
    
    # æ”¹å–„åº¦ã®è¨ˆç®—
    improvement = ((mae_low - mae_pred) / mae_low) * 100 if mae_low > 0 else 0
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    with st.expander("ğŸ” è¨ˆç®—å€¤ã®è©³ç´° (ãƒ‡ãƒãƒƒã‚°ç”¨)"):
        st.write("### åŸºæœ¬çµ±è¨ˆ")
        st.write(f"**ç›¸é–¢ä¿‚æ•° (ä½ç”»è³ª):** r_low = {r_low}")
        st.write(f"**ç›¸é–¢ä¿‚æ•° (AIè£œæ­£):** r_pred = {r_pred}")
        st.write(f"**MAE (ä½ç”»è³ª):** mae_low = {mae_low}")
        st.write(f"**MAE (AIè£œæ­£):** mae_pred = {mae_pred}")
        st.write(f"**RÂ² ã‚¹ã‚³ã‚¢:** r2 = {r2}")
        st.write(f"**æ”¹å–„åº¦:** {improvement}%")
        st.write(f"**æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«æ•°:** {valid_mask.sum()} / {len(D_high_arr)}")
        
        st.write("### AIäºˆæ¸¬å€¤ã®åˆ†æ")
        st.write(f"**äºˆæ¸¬å€¤ã®å¹³å‡:** {np.mean(D_pred_arr[valid_mask]):.4f}")
        st.write(f"**äºˆæ¸¬å€¤ã®æ¨™æº–åå·®:** {np.std(D_pred_arr[valid_mask]):.4f}")
        st.write(f"**äºˆæ¸¬å€¤ã®æœ€å°å€¤:** {np.min(D_pred_arr[valid_mask]):.4f}")
        st.write(f"**äºˆæ¸¬å€¤ã®æœ€å¤§å€¤:** {np.max(D_pred_arr[valid_mask]):.4f}")
        st.write(f"**äºˆæ¸¬å€¤ã®ç¯„å›²:** {np.max(D_pred_arr[valid_mask]) - np.min(D_pred_arr[valid_mask]):.4f}")
        
        st.write("### é«˜ç”»è³ªFDã®åˆ†æ")
        st.write(f"**é«˜ç”»è³ªã®å¹³å‡:** {np.mean(D_high_arr[valid_mask]):.4f}")
        st.write(f"**é«˜ç”»è³ªã®æ¨™æº–åå·®:** {np.std(D_high_arr[valid_mask]):.4f}")
        st.write(f"**é«˜ç”»è³ªã®æœ€å°å€¤:** {np.min(D_high_arr[valid_mask]):.4f}")
        st.write(f"**é«˜ç”»è³ªã®æœ€å¤§å€¤:** {np.max(D_high_arr[valid_mask]):.4f}")
        
        # RÂ²ãŒ0ã«ãªã‚‹ç†ç”±ã‚’èª¬æ˜
        if r2 <= 0.01:
            st.error("âš ï¸ **RÂ²ã‚¹ã‚³ã‚¢ãŒ0ã«è¿‘ã„ç†ç”±:**")
            if np.std(D_pred_arr[valid_mask]) < 0.001:
                st.write("- AIãŒ**ã»ã¼åŒã˜å€¤**ã°ã‹ã‚Šäºˆæ¸¬ã—ã¦ã„ã¾ã™(äºˆæ¸¬å€¤ã®æ¨™æº–åå·®ãŒ0ã«è¿‘ã„)")
                st.write("- ã“ã‚Œã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ä¸è¶³ã€ã¾ãŸã¯ç‰¹å¾´é‡ãŒåŠ¹æœçš„ã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            else:
                st.write("- AIã®äºˆæ¸¬ãŒæ­£è§£å€¤ã¨å…¨ãç›¸é–¢ã—ã¦ã„ã¾ã›ã‚“")
                st.write("- ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒé©åˆ‡ã«è¡Œã‚ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")

    # è©•ä¾¡æŒ‡æ¨™ã‚’è¦‹ã‚„ã™ãè¡¨ç¤º
    st.subheader("ğŸ“Š AIæ€§èƒ½è©•ä¾¡")
    st.markdown("""
    **å„æŒ‡æ¨™ã®æ„å‘³:**
    - ğŸ¯ **æ”¹å–„åº¦**: ä½ç”»è³ªã®èª¤å·®ã‹ã‚‰ã©ã‚Œã ã‘æ”¹å–„ã—ãŸã‹ (é«˜ã„ã»ã©è‰¯ã„)
    - ğŸ“ˆ **ç›¸é–¢ä¿‚æ•°**: äºˆæ¸¬å€¤ã¨æ­£è§£å€¤ã®ä¸€è‡´åº¦ (1.0ã§å®Œå…¨ä¸€è‡´ã€0ã§ç„¡ç›¸é–¢)
    - ğŸ“‰ **MAE**: å¹³å‡çµ¶å¯¾èª¤å·® (å°ã•ã„ã»ã©æ­£ç¢º)
    - ğŸ”¢ **RÂ²**: ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ› (1.0ã§å®Œç’§ã€0ä»¥ä¸‹ã§ãƒ©ãƒ³ãƒ€ãƒ ä»¥ä¸‹)
    """)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric(
            label="ğŸ¯ æ”¹å–„åº¦",
            value=f"{improvement:.1f}%",
            delta=f"{mae_low-mae_pred:.4f}",
            help="ä½ç”»è³ªã‹ã‚‰AIè£œæ­£ã§ã©ã‚Œã ã‘èª¤å·®ãŒæ¸›ã£ãŸã‹ã€‚æ­£ã®å€¤ã¯æ”¹å–„ã€è² ã®å€¤ã¯æ‚ªåŒ–ã‚’æ„å‘³ã—ã¾ã™ã€‚"
        )
        if improvement > 50:
            st.success("âœ… å¤§å¹…æ”¹å–„")
        elif improvement > 20:
            st.info("ğŸ‘ è‰¯å¥½ãªæ”¹å–„")
        elif improvement > 0:
            st.warning("âš ï¸ ã‚ãšã‹ãªæ”¹å–„")
        else:
            st.error("âŒ æ”¹å–„ãªã—")
            
    with col2:
        # nanãƒã‚§ãƒƒã‚¯
        r_pred_display = "N/A" if np.isnan(r_pred) else f"{r_pred:.4f}"
        r_low_safe = 0.0 if np.isnan(r_low) else r_low
        r_pred_safe = 0.0 if np.isnan(r_pred) else r_pred
        delta_r = r_pred_safe - r_low_safe
        
        st.metric(
            label="ğŸ“ˆ ç›¸é–¢ä¿‚æ•° (AI)",
            value=r_pred_display,
            delta=f"+{delta_r:.4f}" if delta_r > 0 else f"{delta_r:.4f}" if not np.isnan(delta_r) else "N/A",
            help="AIè£œæ­£å¾Œã®å€¤ã¨é«˜ç”»è³ªFDã®ç›¸é–¢ã€‚1.0ã«è¿‘ã„ã»ã©äºˆæ¸¬ãŒæ­£ç¢ºã§ã™ã€‚"
        )
        
        if np.isnan(r_pred):
            st.error("âŒ è¨ˆç®—ä¸å¯ (nanã‚¨ãƒ©ãƒ¼)")
        elif r_pred > 0.9:
            st.success("âœ… éå¸¸ã«é«˜ã„ç›¸é–¢")
        elif r_pred > 0.7:
            st.info("ğŸ‘ è‰¯å¥½ãªç›¸é–¢")
        elif r_pred > 0.5:
            st.warning("âš ï¸ ä¸­ç¨‹åº¦ã®ç›¸é–¢")
        else:
            st.error("âŒ ä½ã„ç›¸é–¢")
            
    with col3:
        # nanãƒã‚§ãƒƒã‚¯
        mae_display = "N/A" if np.isnan(mae_pred) else f"{mae_pred:.4f}"
        mae_low_safe = mae_low if not np.isnan(mae_low) else 0.0
        mae_pred_safe = mae_pred if not np.isnan(mae_pred) else 0.0
        delta_mae = mae_low_safe - mae_pred_safe
        
        st.metric(
            label="ğŸ“‰ MAE (AIè£œæ­£)",
            value=mae_display,
            delta=f"-{delta_mae:.4f}" if not np.isnan(delta_mae) else "N/A",
            delta_color="inverse",
            help="AIè£œæ­£å¾Œã®å¹³å‡çµ¶å¯¾èª¤å·®ã€‚å°ã•ã„ã»ã©æ­£ç¢ºãªäºˆæ¸¬ã§ã™ã€‚"
        )
        
        if np.isnan(mae_pred):
            st.error("âŒ è¨ˆç®—ä¸å¯ (nanã‚¨ãƒ©ãƒ¼)")
        elif mae_pred < 0.01:
            st.success("âœ… éå¸¸ã«æ­£ç¢º")
        elif mae_pred < 0.05:
            st.info("ğŸ‘ è‰¯å¥½ãªç²¾åº¦")
        elif mae_pred < 0.1:
            st.warning("âš ï¸ ä¸­ç¨‹åº¦ã®ç²¾åº¦")
        else:
            st.error("âŒ ä½ã„ç²¾åº¦")
            
    with col4:
        # nanãƒã‚§ãƒƒã‚¯
        r2_display = "N/A" if (np.isnan(r2) or np.isinf(r2)) else f"{r2:.4f}"
        st.metric(
            label="ğŸ”¢ R-squared",
            value=r2_display,
            help=f"æ±ºå®šä¿‚æ•°ã€‚ãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ãƒ¼ã‚¿ã‚’ã©ã‚Œã ã‘èª¬æ˜ã§ãã‚‹ã‹ã€‚1.0ã§å®Œç’§ã€0ä»¥ä¸‹ã¯ãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ä»¥ä¸‹ã§ã™ã€‚"
        )
        
        if np.isnan(r2) or np.isinf(r2):
            st.error("âŒ è¨ˆç®—ä¸å¯ (nanã¾ãŸã¯infã‚¨ãƒ©ãƒ¼)")
        elif r2 > 0.8:
            st.success("âœ… å„ªã‚ŒãŸãƒ¢ãƒ‡ãƒ«")
        elif r2 > 0.5:
            st.info("ğŸ‘ è‰¯å¥½ãªãƒ¢ãƒ‡ãƒ«")
        elif r2 > 0.2:
            st.warning("âš ï¸ æ”¹å–„ã®ä½™åœ°ã‚ã‚Š")
        else:
            st.error("âŒ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ä¸è¶³")
    
    # ğŸ” è‡ªå‹•è¨ºæ–­ã¨æ”¹å–„ææ¡ˆ
    st.markdown("---")
    st.subheader("ğŸ” çµæœã®è¨ºæ–­ã¨æ”¹å–„ææ¡ˆ")
    
    problems = []
    suggestions = []
    
    # è¨ºæ–­1: æ”¹å–„åº¦
    if improvement < 0:
        problems.append("âŒ **æ”¹å–„åº¦ãŒè² **: AIãŒä½ç”»è³ªã‚ˆã‚Šã‚‚æ‚ªã„äºˆæ¸¬ã‚’ã—ã¦ã„ã¾ã™")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã™ (ç¾åœ¨: {}çµ„ â†’ æ¨å¥¨: 20çµ„ä»¥ä¸Š)".format(len(high_imgs)))
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ç•°ãªã‚‹å“è³ªãƒ¬ãƒ™ãƒ« (low2, low3) ã‚’è©¦ã™")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ã‚ˆã‚Šå¤šæ§˜ãªã‚·ãƒ¼ãƒ³ãƒ»è¢«å†™ä½“ã®ç”»åƒã‚’è¿½åŠ ")
    elif improvement < 20:
        problems.append("âš ï¸ **æ”¹å–„åº¦ãŒä½ã„**: AIè£œæ­£ã®åŠ¹æœãŒé™å®šçš„ã§ã™")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ç”»åƒã®å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™ (ç•°ãªã‚‹ã‚·ãƒ¼ãƒ³ãƒ»è¢«å†™ä½“)")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ã‚ˆã‚Šä½å“è³ªãªç”»åƒãƒ¬ãƒ™ãƒ« (low2, low3) ã‚’è©¦ã™")
    
    # è¨ºæ–­2: ç›¸é–¢ä¿‚æ•°
    if np.isnan(r_pred) or r_pred <= 0.0:
        problems.append("âŒ **ç›¸é–¢ä¿‚æ•°ãŒ0ã¾ãŸã¯N/A**: AIãŒæœ‰åŠ¹ãªäºˆæ¸¬ã‚’ã—ã¦ã„ã¾ã›ã‚“")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ç”»åƒãƒšã‚¢æ•°ã‚’å¤§å¹…ã«å¢—ã‚„ã™ (æ¨å¥¨: 30çµ„ä»¥ä¸Š)")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: é«˜ç”»è³ªã¨ä½ç”»è³ªã®å·®ãŒæ˜ç¢ºãªãƒšã‚¢ã‚’ä½¿ç”¨")
    elif r_pred < 0.5:
        problems.append("âš ï¸ **ç›¸é–¢ä¿‚æ•°ãŒä½ã„**: äºˆæ¸¬ç²¾åº¦ãŒä¸ååˆ†ã§ã™")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ã‚ˆã‚Šå¤šãã®ç”»åƒãƒšã‚¢ã§å­¦ç¿’ (æ¨å¥¨: 15çµ„ä»¥ä¸Š)")
    
    # è¨ºæ–­3: RÂ²ã‚¹ã‚³ã‚¢
    if r2 <= 0:
        problems.append("âŒ **RÂ²ã‚¹ã‚³ã‚¢ãŒ0ä»¥ä¸‹**: ãƒ¢ãƒ‡ãƒ«ãŒãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ä»¥ä¸‹ã®æ€§èƒ½")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®è³ªã‚’è¦‹ç›´ã™ (åŒã˜ã‚ˆã†ãªç”»åƒã°ã‹ã‚Šã«ãªã£ã¦ã„ãªã„ã‹)")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã™")
    elif r2 < 0.3:
        problems.append("âš ï¸ **RÂ²ã‚¹ã‚³ã‚¢ãŒä½ã„**: ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ›ãŒä¸è¶³")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™")
    
    # è¨ºæ–­4: MAE
    if mae_pred > 0.1:
        problems.append("âš ï¸ **MAEãŒå¤§ãã„**: äºˆæ¸¬èª¤å·®ãŒå¤§ãã„ã§ã™")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ã‚ˆã‚Šå¤šãã®ã‚µãƒ³ãƒ—ãƒ«ã§å­¦ç¿’")
    
    # è¨ºæ–­5: ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§
    if len(high_imgs) < 10:
        problems.append(f"âš ï¸ **ç”»åƒãƒšã‚¢æ•°ãŒå°‘ãªã„**: ç¾åœ¨{len(high_imgs)}çµ„ (æ¨å¥¨: 10çµ„ä»¥ä¸Š)")
        suggestions.append("ğŸ“Œ **å¯¾ç­–**: ã‚ˆã‚Šå¤šãã®ç”»åƒãƒšã‚¢ã‚’è¿½åŠ ã—ã¦ãã ã•ã„")
    
    # çµæœè¡¨ç¤º
    if problems:
        st.warning("### âš ï¸ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ")
        for problem in problems:
            st.markdown(problem)
        
        st.info("### ğŸ’¡ æ¨å¥¨ã•ã‚Œã‚‹æ”¹å–„ç­–")
        for suggestion in suggestions:
            st.markdown(suggestion)
        
        # å…·ä½“çš„ãªæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
        st.success("""
        ### ğŸ“ æ¬¡ã«è©¦ã™ã“ã¨ (å„ªå…ˆé †ä½é †)
        
        1. **ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã™**
           - ç›®æ¨™: 20çµ„ä»¥ä¸Š (ç¾åœ¨: {}çµ„)
           - ã‚ˆã‚Šå¤šæ§˜ãªã‚·ãƒ¼ãƒ³ãƒ»è¢«å†™ä½“ã‚’å«ã‚ã‚‹
        
        2. **å“è³ªãƒ¬ãƒ™ãƒ«ã‚’å¤‰æ›´**
           - ç¾åœ¨ä½¿ç”¨ä¸­ã®ãƒ¬ãƒ™ãƒ«ã§åŠ¹æœãŒè–„ã„å ´åˆ
           - low1 â†’ low2 â†’ low3 ã®é †ã«è©¦ã™
        
        3. **ç”»åƒã®è³ªã‚’ç¢ºèª**
           - é«˜ç”»è³ªã¨ä½ç”»è³ªã®å·®ãŒæ˜ç¢ºã‹
           - åŒã˜ã‚ˆã†ãªç”»åƒã°ã‹ã‚Šã«ãªã£ã¦ã„ãªã„ã‹
        
        4. **ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™**
           - ç•°ãªã‚‹ç…§æ˜æ¡ä»¶
           - ç•°ãªã‚‹è¢«å†™ä½“
           - ç•°ãªã‚‹ã‚¢ãƒ³ã‚°ãƒ«
        """.format(len(high_imgs)))
    else:
        st.success("""
        ### âœ… è‰¯å¥½ãªçµæœã§ã™!
        
        ç¾åœ¨ã®è¨­å®šã§ååˆ†ãªæ€§èƒ½ãŒå‡ºã¦ã„ã¾ã™ã€‚
        
        **ã•ã‚‰ã«æ”¹å–„ã—ãŸã„å ´åˆ:**
        - ã‚ˆã‚Šå¤šãã®ç”»åƒãƒšã‚¢ã‚’è¿½åŠ  (ç²¾åº¦å‘ä¸Š)
        - ç•°ãªã‚‹å“è³ªãƒ¬ãƒ™ãƒ«ã‚’è©¦ã™ (æ±ç”¨æ€§å‘ä¸Š)
        """)
    
    st.markdown("---")
    
    # æ¯”è¼ƒè¡¨ (è©³ç´°èª¬æ˜ä»˜ã)
    st.subheader("ğŸ“‹ ä½ç”»è³ª vs AIè£œæ­£ æ¯”è¼ƒ")
    st.markdown("""
    **ã“ã®è¡¨ã®è¦‹æ–¹:**
    - **ä½ç”»è³ª(è£œæ­£ãªã—)**: ä½ç”»è³ªç”»åƒã‹ã‚‰ç›´æ¥è¨ˆç®—ã—ãŸãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ€§èƒ½
    - **AIè£œæ­£å¾Œ**: AIãŒä½ç”»è³ªç”»åƒã‹ã‚‰é«˜ç”»è³ªç›¸å½“ã®FDã‚’äºˆæ¸¬ã—ãŸçµæœ
    - **æ”¹å–„**: AIè£œæ­£ã«ã‚ˆã£ã¦ã©ã‚Œã ã‘æ€§èƒ½ãŒå‘ä¸Šã—ãŸã‹ (ãƒ—ãƒ©ã‚¹ã¯æ”¹å–„ã€ãƒã‚¤ãƒŠã‚¹ã¯æ‚ªåŒ–)
    """)
    
    import pandas as pd
    comparison_df = pd.DataFrame({
        "æŒ‡æ¨™": ["ç›¸é–¢ä¿‚æ•° (r)", "å¹³å‡çµ¶å¯¾èª¤å·® (MAE)", "R-squared", "å‡¦ç†æ™‚é–“"],
        "ä½ç”»è³ª(è£œæ­£ãªã—)": [f"{r_low:.4f}", f"{mae_low:.4f}", "-", "-"],
        "AIè£œæ­£å¾Œ": [f"{r_pred:.4f}", f"{mae_pred:.4f}", f"{r2:.4f}", f"{t1-t0:.2f}ç§’"],
        "æ”¹å–„": [
            f"+{r_pred-r_low:.4f}" if r_pred > r_low else f"{r_pred-r_low:.4f}",
            f"-{mae_low-mae_pred:.4f}" if mae_pred < mae_low else f"+{mae_pred-mae_low:.4f}",
            "-",
            "-"
        ]
    })
    
    # è¡¨ã‚’è¦‹ã‚„ã™ãè¡¨ç¤º
    st.dataframe(
        comparison_df, 
        use_container_width=True, 
        hide_index=True,
        column_config={
            "æŒ‡æ¨™": st.column_config.TextColumn("æŒ‡æ¨™", width="medium"),
            "ä½ç”»è³ª(è£œæ­£ãªã—)": st.column_config.TextColumn("ä½ç”»è³ª(è£œæ­£ãªã—)", width="medium"),
            "AIè£œæ­£å¾Œ": st.column_config.TextColumn("AIè£œæ­£å¾Œ", width="medium"),
            "æ”¹å–„": st.column_config.TextColumn("æ”¹å–„", width="medium"),
        }
    )

    # scatter plot (è©³ç´°èª¬æ˜ä»˜ã)
    st.subheader("ğŸ“ˆ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ æ¯”è¼ƒã‚°ãƒ©ãƒ•")
    
    st.markdown("""
    ### ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹
    
    **æ¨ªè»¸ (Xè»¸)**: é«˜ç”»è³ªãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ = **æ­£è§£å€¤** (ç›®æ¨™ã¨ã™ã‚‹å€¤)
    
    **ç¸¦è»¸ (Yè»¸)**: äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ = ä½ç”»è³ªã‹ã‚‰æ¨å®šã—ãŸå€¤
    
    **ğŸ”µ é’ã„ä¸¸**: ä½ç”»è³ªç”»åƒã‹ã‚‰ç›´æ¥è¨ˆç®—ã—ãŸFD (è£œæ­£ãªã—)
    - æ­£è§£å€¤ã‹ã‚‰å¤§ãããšã‚Œã¦ã„ã‚‹ = ä½ç”»è³ªã§ã¯æ­£ç¢ºã«æ¸¬å®šã§ããªã„
    
    **ğŸ”º èµ¤ã„ä¸‰è§’**: AIãŒä½ç”»è³ªã‹ã‚‰äºˆæ¸¬ã—ãŸFD (AIè£œæ­£å¾Œ)
    - é»’ã„ç‚¹ç·šã«è¿‘ã„ã»ã© = é«˜ç”»è³ªç›¸å½“ã®æ­£ç¢ºãªå€¤ã‚’äºˆæ¸¬ã§ãã¦ã„ã‚‹
    
    **âš« é»’ã„ç‚¹ç·š**: å®Œå…¨ä¸€è‡´ãƒ©ã‚¤ãƒ³ (äºˆæ¸¬=æ­£è§£ã¨ãªã‚‹ç†æƒ³çš„ãªçŠ¶æ…‹)
    - ã“ã®ç·šä¸Šã«ã‚ã‚Œã°å®Œç’§ãªäºˆæ¸¬
    
    **ç†æƒ³çš„ãªçµæœ**: èµ¤ã„ä¸‰è§’ãŒé»’ã„ç‚¹ç·šã«æ²¿ã£ã¦ä¸¦ã³ã€é’ã„ä¸¸ã‚ˆã‚Šã‚‚ç‚¹ç·šã«è¿‘ã„
    """)
    
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š(æ–‡å­—åŒ–ã‘å¯¾ç­–)
    try:
        import matplotlib
        matplotlib.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'sans-serif']
        matplotlib.rcParams['axes.unicode_minus'] = False
    except:
        pass
    
    # ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºã‚’å°ã•ãèª¿æ•´
    fig = plt.figure(figsize=(7,5))
    
    # ä½ç”»è³ªã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    plt.scatter(D_high_arr, D_low_arr, 
                label='ä½ç”»è³ª (è£œæ­£ãªã—)', 
                alpha=0.6, s=80, c='#1f77b4', 
                edgecolors='darkblue', linewidth=1.2)
    
    # AIè£œæ­£ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    plt.scatter(D_high_arr, D_pred_arr, 
                label='AIè£œæ­£å¾Œ', 
                alpha=0.9, s=100, c='#ff7f0e', 
                marker='^', edgecolors='darkred', linewidth=1.2)
    
    # ç†æƒ³çš„ãªä¸€è‡´ãƒ©ã‚¤ãƒ³
    plt.plot([2.0,3.0],[2.0,3.0],'k--', linewidth=1.5, label='å®Œå…¨ä¸€è‡´ãƒ©ã‚¤ãƒ³', alpha=0.5)
    
    plt.xlabel('é«˜ç”»è³ªãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ (æ­£è§£å€¤)', fontsize=11, fontweight='bold')
    plt.ylabel('äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ', fontsize=11, fontweight='bold')
    plt.title(f'AIè£œæ­£åŠ¹æœ\nç›¸é–¢: {r_pred:.4f} | MAE: {mae_pred:.4f} | RÂ²: {r2:.4f}', 
              fontsize=12, fontweight='bold', pad=15)
    plt.legend(fontsize=9, loc='upper left', framealpha=0.9)
    plt.grid(True, alpha=0.3, linestyle='--')
    plt.tick_params(labelsize=10)
    
    # è»¸ã®ç¯„å›²ã‚’è‡ªå‹•èª¿æ•´
    all_vals = np.concatenate([D_high_arr, D_low_arr, D_pred_arr])
    vmin, vmax = np.nanmin(all_vals), np.nanmax(all_vals)
    margin = (vmax - vmin) * 0.1
    plt.xlim(vmin - margin, vmax + margin)
    plt.ylim(vmin - margin, vmax + margin)
    
    plt.tight_layout()
    
    # ã‚°ãƒ©ãƒ•ã‚’ä¸­å¤®å¯„ã›ã§è¡¨ç¤º (ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆ)
    col_left, col_center, col_right = st.columns([1, 3, 1])
    with col_center:
        st.pyplot(fig, use_container_width=False)
    plt.close(fig)

    return D_high_list, D_low_list, D_pred_list

# ============================================================
# Streamlit app
# ============================================================
def app():
    st.set_page_config(layout="wide", page_title="é«˜é€Ÿãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æï¼ˆGPUæœ€é©åŒ–ç‰ˆï¼‰")
    st.title("ğŸš€ é«˜é€Ÿãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æ + AIè£œæ­£ï¼ˆGPU æœ€é©åŒ–ç‰ˆï¼‰")
    st.markdown("CuPy ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ GPU ã‚’è‡ªå‹•ã§ä½¿ã„ã¾ã™ã€‚ç„¡ã‘ã‚Œã° CPU (NumPy) ã§å‡¦ç†ã—ã¾ã™ã€‚")

    # ============================================================
    # ğŸ”„ è‡ªå‹•ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æ©Ÿèƒ½ - ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«å®Ÿè¡Œ
    # ============================================================
    if 'model_loaded' not in st.session_state:
        st.session_state['model_loaded'] = False
        st.session_state['persistent_model'] = None
        st.session_state['model_info'] = None
        
        # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¢ã™
        default_model_path = "trained_fd_model.pkl"
        if os.path.exists(default_model_path):
            try:
                model = load_model(default_model_path)
                st.session_state['persistent_model'] = model
                st.session_state['model_loaded'] = True
                st.session_state['model_info'] = {
                    'path': default_model_path,
                    'loaded_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'source': 'è‡ªå‹•èª­ã¿è¾¼ã¿'
                }
            except Exception as e:
                pass  # èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯ç„¡è¦–

    gpu_auto = USE_CUPY
    st.sidebar.header("è¨­å®š")
    st.sidebar.write(f"GPU åˆ©ç”¨å¯èƒ½: {USE_CUPY}")
    use_gpu_checkbox = st.sidebar.checkbox("GPU ã‚’ä½¿ã†(è‡ªå‹•åˆ¤å®š)", value=USE_CUPY)
    st.sidebar.write("â€» GPU ãŒç„¡ã„å ´åˆã¯è‡ªå‹•çš„ã« CPU ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
    
    # ============================================================
    # ğŸ“Š ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã‚’è¡¨ç¤º
    # ============================================================
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹")
    if st.session_state.get('model_loaded', False):
        model_info = st.session_state.get('model_info', {})
        st.sidebar.success("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æ¸ˆã¿")
        st.sidebar.write(f"ğŸ“ {model_info.get('source', 'ä¸æ˜')}")
        st.sidebar.write(f"ğŸ•’ {model_info.get('loaded_at', 'ä¸æ˜')}")
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ãƒœã‚¿ãƒ³
        if st.sidebar.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆ"):
            st.session_state['persistent_model'] = None
            st.session_state['model_loaded'] = False
            st.session_state['model_info'] = None
            st.rerun()
    else:
        st.sidebar.warning("âš ï¸ ãƒ¢ãƒ‡ãƒ«æœªèª­ã¿è¾¼ã¿")
        st.sidebar.write("å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’ã™ã‚‹ã‹ã€")
        st.sidebar.write("æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    # æ”¹å–„æ–¹æ³•ã‚¬ã‚¤ãƒ‰
    with st.sidebar.expander("ğŸ’¡ çµæœã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•"):
        st.markdown("""
        ### ğŸ¯ è‰¯ã„çµæœã‚’å¾—ã‚‹ãŸã‚ã®ãƒã‚¤ãƒ³ãƒˆ
        
        #### 1ï¸âƒ£ **ç”»åƒã®è³ªã¨å¤šæ§˜æ€§**
        - âœ… **æœ€ä½ã§ã‚‚10çµ„ä»¥ä¸Š**ã®ç”»åƒãƒšã‚¢ã‚’ç”¨æ„
        - âœ… **ç•°ãªã‚‹è¢«å†™ä½“ãƒ»ã‚·ãƒ¼ãƒ³**ã‚’å«ã‚ã‚‹
        - âœ… é«˜ç”»è³ªã¨ä½ç”»è³ªã®**å·®ãŒæ˜ç¢º**ãªãƒšã‚¢ã‚’ä½¿ç”¨
        - ğŸ”„ **ç”»åƒãŒå°‘ãªã„å ´åˆ**: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ©Ÿèƒ½ã‚’ä½¿ç”¨
        
        #### 2ï¸âƒ£ **ç”»è³ªãƒ¬ãƒ™ãƒ«ã®é¸æŠ**
        - ğŸ“Œ `low1` (æœ€ã‚‚é«˜å“è³ª) â†’ å·®ãŒå°ã•ã„
        - ğŸ“Œ `low2` (ä¸­ç¨‹åº¦) â†’ **æ¨å¥¨**
        - ğŸ“Œ `low3` (æœ€ã‚‚ä½å“è³ª) â†’ å·®ãŒå¤§ãã„
        
        **ğŸ’¡ ãƒ’ãƒ³ãƒˆ**: ã¾ãš `low2` ã‚’è©¦ã—ã¦ã€çµæœãŒæ‚ªã‘ã‚Œã° `low3` ã‚’è©¦ã—ã¦ãã ã•ã„
        
        #### 3ï¸âƒ£ **ç”»åƒãŒè¶³ã‚Šãªã„å ´åˆã®å¯¾ç­–**
        
        **ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ (Data Augmentation) ã‚’ä½¿ç”¨**
        - ã‚¢ãƒ—ãƒªå†…ã§è‡ªå‹•çš„ã«ç”»åƒã‚’å¢—ã‚„ã›ã¾ã™
        - æ°´å¹³åè»¢ã€å›è»¢ã€æ˜ã‚‹ã•èª¿æ•´ãªã©
        - ä¾‹: 5çµ„ â†’ æ‹¡å¼µå¾Œ 15çµ„ä»¥ä¸Š
        
        **ğŸ“¸ è¿½åŠ ã®ç”»åƒã‚’ç”¨æ„**
        - ç•°ãªã‚‹è§’åº¦ã‹ã‚‰æ’®å½±
        - ç•°ãªã‚‹ç…§æ˜æ¡ä»¶ã§æ’®å½±
        - ç•°ãªã‚‹è¢«å†™ä½“ã‚’è¿½åŠ 
        
        **âš ï¸ æœ€ä½é™å¿…è¦ãªæšæ•°**
        - å­¦ç¿’ã«ã¯æœ€ä½2çµ„å¿…è¦
        - æ¨å¥¨: 10çµ„ä»¥ä¸Š (æ‹¡å¼µå‰)
        - ç†æƒ³: 20çµ„ä»¥ä¸Š
        
        #### 4ï¸âƒ£ **æ”¹å–„åº¦ãŒä½ã„/è² ã®å ´åˆ**
        - âŒ **åŸå› **: ç”»åƒã®å¤šæ§˜æ€§ä¸è¶³
        - âœ… **å¯¾ç­–1**: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’å¢—ã‚„ã™
        - âœ… **å¯¾ç­–2**: ç•°ãªã‚‹å“è³ªãƒ¬ãƒ™ãƒ« (low2, low3) ã‚’è©¦ã™
        - âœ… **å¯¾ç­–3**: ç•°ãªã‚‹ã‚·ãƒ¼ãƒ³ã®ç”»åƒã‚’è¿½åŠ 
        
        #### 5ï¸âƒ£ **ç›¸é–¢ä¿‚æ•°ãŒ0.0ã¾ãŸã¯N/Aã®å ´åˆ**
        - âŒ **åŸå› **: AIãŒåŒã˜å€¤ã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹
        - âœ… **å¯¾ç­–1**: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã§ç”»åƒã®å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™
        - âœ… **å¯¾ç­–2**: ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã™ (20çµ„ä»¥ä¸Šæ¨å¥¨)
        - âœ… **å¯¾ç­–3**: ç•°ãªã‚‹å“è³ªãƒ¬ãƒ™ãƒ«ã‚’è©¦ã™
        
        #### 6ï¸âƒ£ **RÂ²ã‚¹ã‚³ã‚¢ãŒ0ä»¥ä¸‹ã®å ´åˆ**
        - âŒ **åŸå› **: ãƒ¢ãƒ‡ãƒ«ãŒãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ä»¥ä¸‹
        - âœ… **å¯¾ç­–**: ä¸Šè¨˜1ã€œ4ã‚’å…¨ã¦å®Ÿæ–½
        
        ---
        
        ### ğŸ“Š è‰¯ã„çµæœã®ç›®å®‰
        - âœ… **æ”¹å–„åº¦**: 30%ä»¥ä¸Š
        - âœ… **ç›¸é–¢ä¿‚æ•° (AI)**: 0.7ä»¥ä¸Š
        - âœ… **MAE (AIè£œæ­£)**: 0.05ä»¥ä¸‹
        - âœ… **RÂ²ã‚¹ã‚³ã‚¢**: 0.5ä»¥ä¸Š
        """)
    
    st.sidebar.markdown("---")

    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    st.sidebar.header("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰")
    app_mode = st.sidebar.radio(
        "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
        ["ğŸ“ å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ (ç”»åƒãƒšã‚¢ãŒå¿…è¦)", "ğŸ”® æ¨è«–ãƒ¢ãƒ¼ãƒ‰ (ä½ç”»è³ªç”»åƒã®ã¿ã§äºˆæ¸¬)"],
        help="å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰: é«˜ç”»è³ª+ä½ç”»è³ªãƒšã‚¢ã§AIã‚’å­¦ç¿’\næ¨è«–ãƒ¢ãƒ¼ãƒ‰: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ä½ç”»è³ªç”»åƒã‹ã‚‰äºˆæ¸¬"
    )
    
    st.sidebar.markdown("---")

    # æ¨è«–ãƒ¢ãƒ¼ãƒ‰
    if app_mode == "ğŸ”® æ¨è«–ãƒ¢ãƒ¼ãƒ‰ (ä½ç”»è³ªç”»åƒã®ã¿ã§äºˆæ¸¬)":
        st.header("ğŸ”® æ¨è«–ãƒ¢ãƒ¼ãƒ‰ - ä½ç”»è³ªç”»åƒã ã‘ã§é«˜å“è³ªFDã‚’äºˆæ¸¬")
        
        st.markdown("""
        ### ã“ã®ãƒ¢ãƒ¼ãƒ‰ã«ã¤ã„ã¦
        
        **å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€ä½ç”»è³ªã®è‚Œç”»åƒã ã‘ã‹ã‚‰é«˜å“è³ªç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’äºˆæ¸¬ã—ã¾ã™ã€‚**
        
        #### ğŸ“‹ ä½¿ã„æ–¹
        1. ã¾ãšã€Œå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã€ã§ç”»åƒãƒšã‚¢ã‚’ä½¿ã£ã¦AIã‚’å­¦ç¿’
        2. ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        3. ã“ã®ãƒ¢ãƒ¼ãƒ‰ã§ä½ç”»è³ªç”»åƒã ã‘ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        4. **AIãŒè‡ªå‹•çš„ã«é«˜å“è³ªç›¸å½“ã®FDã‚’äºˆæ¸¬**
        
        #### âœ¨ ãƒ¡ãƒªãƒƒãƒˆ
        - ä½ç”»è³ªç”»åƒã ã‘ã§OK (é«˜ç”»è³ªç”»åƒä¸è¦)
        - é«˜é€Ÿå‡¦ç†
        - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯å†åˆ©ç”¨å¯èƒ½
        """)
        
        # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        st.subheader("ğŸ“‚ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿")
        
        # æ°¸ç¶šåŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèª
        if st.session_state.get('model_loaded', False):
            model = st.session_state['persistent_model']
            model_info = st.session_state.get('model_info', {})
            st.success(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æ¸ˆã¿ ({model_info.get('source', 'ä¸æ˜')})")
            
            st.info(f"""
            **ãƒ¢ãƒ‡ãƒ«æƒ…å ±:**
            - ç¨®é¡: {type(model).__name__}
            - æ¨å®šå™¨æ•°: {model.n_estimators if hasattr(model, 'n_estimators') else 'N/A'}
            - æœ€å¤§æ·±åº¦: {model.max_depth if hasattr(model, 'max_depth') else 'N/A'}
            - èª­ã¿è¾¼ã¿æ—¥æ™‚: {model_info.get('loaded_at', 'ä¸æ˜')}
            """)
        else:
            model = None
            st.warning("âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # è¿½åŠ ã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ©Ÿèƒ½
        with st.expander("ğŸ“¤ åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"):
            model_file = st.file_uploader(
                "å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (.pkl)",
                type=['pkl'],
                help="å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã§ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                key="inference_model_uploader"
            )
            
            if model_file is not None:
                try:
                    new_model = pickle.load(model_file)
                    st.success("âœ… æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ!")
                    
                    # æ°¸ç¶šåŒ–
                    st.session_state['persistent_model'] = new_model
                    st.session_state['model_loaded'] = True
                    st.session_state['model_info'] = {
                        'path': model_file.name,
                        'loaded_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                        'source': 'ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'
                    }
                    
                    st.info(f"""
                    **æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«æƒ…å ±:**
                    - ç¨®é¡: {type(new_model).__name__}
                    - æ¨å®šå™¨æ•°: {new_model.n_estimators if hasattr(new_model, 'n_estimators') else 'N/A'}
                    - æœ€å¤§æ·±åº¦: {new_model.max_depth if hasattr(new_model, 'max_depth') else 'N/A'}
                    """)
                    
                    model = new_model
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        
        if model is not None:
            # ä½ç”»è³ªç”»åƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            st.subheader("ğŸ“¤ ä½ç”»è³ªç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            
            st.success("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚äºˆæ¸¬ã®æº–å‚™å®Œäº†!")
            
            low_quality_imgs = st.file_uploader(
                "ä½ç”»è³ªã®è‚Œç”»åƒ",
                type=['png', 'jpg', 'jpeg'],
                accept_multiple_files=True,
                help="ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’äºˆæ¸¬ã—ãŸã„ä½ç”»è³ªç”»åƒ",
                key="inference_image_uploader"
            )
            
            if low_quality_imgs:
                st.success(f"âœ… {len(low_quality_imgs)}æšã®ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                
                # äºˆæ¸¬å®Ÿè¡Œãƒœã‚¿ãƒ³
                if st.button("ğŸ”® ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’äºˆæ¸¬"):
                    st.info("äºˆæ¸¬ã‚’é–‹å§‹ã—ã¾ã™...")
                    
                    results = []
                    progress_bar = st.progress(0)
                    
                    for idx, img_file in enumerate(low_quality_imgs):
                        # ç”»åƒèª­ã¿è¾¼ã¿
                        img = read_bgr_from_buffer(img_file.read())
                        
                        if img is not None:
                            # äºˆæ¸¬
                            predicted_fd = predict_fd_from_low_quality(img, model)
                            
                            # ä¿¡é ¼åº¦è¨ˆç®—
                            confidence_info = calculate_prediction_confidence(img, model, predicted_fd)
                            
                            results.append({
                                'filename': img_file.name,
                                'predicted_fd': predicted_fd,
                                'image': img,
                                'confidence': confidence_info
                            })
                        
                        progress_bar.progress((idx + 1) / len(low_quality_imgs))
                    
                    st.success("âœ… äºˆæ¸¬å®Œäº†!")
                    
                    # çµæœè¡¨ç¤º
                    st.subheader("ğŸ“Š äºˆæ¸¬çµæœã¨ä¿¡é ¼åº¦")
                    
                    st.markdown("""
                    **äºˆæ¸¬ã•ã‚ŒãŸãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¨ä¿¡é ¼åº¦:**
                    - **äºˆæ¸¬FD**: AIãŒæ¨å®šã—ãŸé«˜ç”»è³ªç›¸å½“ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
                    - **ä¿¡é ¼åº¦**: äºˆæ¸¬å€¤ã®ä¿¡é ¼æ€§ (0-100%)
                    - **äºˆæ¸¬åŒºé–“**: äºˆæ¸¬å€¤ã®æ¨å®šç¯„å›²
                    
                    ğŸ’¡ **ä¿¡é ¼åº¦ãŒé«˜ã„ã»ã©ã€äºˆæ¸¬å€¤ã®ç²¾åº¦ãŒé«˜ã„ã¨æœŸå¾…ã§ãã¾ã™**
                    """)
                    
                    # çµæœãƒ†ãƒ¼ãƒ–ãƒ« (ä¿¡é ¼åº¦ä»˜ã)
                    import pandas as pd
                    df = pd.DataFrame({
                        "No.": range(1, len(results) + 1),
                        "ç”»åƒå": [r['filename'] for r in results],
                        "äºˆæ¸¬FD": [f"{r['predicted_fd']:.4f}" for r in results],
                        "ä¿¡é ¼åº¦": [f"{r['confidence']['overall_confidence']:.1f}%" for r in results],
                        "ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«": [f"{r['confidence']['level_emoji']} {r['confidence']['confidence_level']}" for r in results],
                        "äºˆæ¸¬åŒºé–“": [f"{r['confidence']['lower_bound']:.4f} - {r['confidence']['upper_bound']:.4f}" for r in results]
                    })
                    
                    st.dataframe(df, use_container_width=True, hide_index=True)
                    
                    # çµ±è¨ˆæƒ…å ±
                    predicted_fds = [r['predicted_fd'] for r in results]
                    avg_confidence = np.mean([r['confidence']['overall_confidence'] for r in results])
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.info(f"""
                        **äºˆæ¸¬å€¤ã®çµ±è¨ˆ:**
                        - å¹³å‡FD: {np.mean(predicted_fds):.4f}
                        - æ¨™æº–åå·®: {np.std(predicted_fds):.4f}
                        - æœ€å°å€¤: {np.min(predicted_fds):.4f}
                        - æœ€å¤§å€¤: {np.max(predicted_fds):.4f}
                        """)
                    
                    with col2:
                        st.info(f"""
                        **ä¿¡é ¼åº¦ã®çµ±è¨ˆ:**
                        - å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.1f}%
                        - é«˜ä¿¡é ¼åº¦(â‰¥80%): {sum(1 for r in results if r['confidence']['overall_confidence'] >= 80)}æš
                        - ä¸­ä¿¡é ¼åº¦(60-80%): {sum(1 for r in results if 60 <= r['confidence']['overall_confidence'] < 80)}æš
                        - ä½ä¿¡é ¼åº¦(<60%): {sum(1 for r in results if r['confidence']['overall_confidence'] < 60)}æš
                        """)
                    
                    # è©³ç´°ãªä¿¡é ¼åº¦æƒ…å ± (å±•é–‹å¯èƒ½)
                    with st.expander("ğŸ” ä¿¡é ¼åº¦ã®è©³ç´°æƒ…å ±"):
                        st.markdown("""
                        ### ä¿¡é ¼åº¦ã®è¨ˆç®—æ–¹æ³•
                        
                        **ç·åˆä¿¡é ¼åº¦**ã¯ä»¥ä¸‹ã®2ã¤ã®è¦ç´ ã‹ã‚‰è¨ˆç®—ã•ã‚Œã¾ã™:
                        
                        1. **ç‰¹å¾´é‡å“è³ªã‚¹ã‚³ã‚¢ (60%ã®é‡ã¿)**
                           - ã‚¨ãƒƒã‚¸å¼·åº¦: ç”»åƒã®æ§‹é€ ãŒæ˜ç¢ºã‹
                           - ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: ãƒã‚¤ã‚ºãŒå°‘ãªã„ã‹
                           - ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: æƒ…å ±é‡ãŒé©åˆ‡ã‹
                        
                        2. **ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦ (40%ã®é‡ã¿)**
                           - ç¯„å›²å¦¥å½“æ€§: äºˆæ¸¬å€¤ãŒæ­£å¸¸ç¯„å›²å†…ã‹ (2.0-3.0)
                           - äºˆæ¸¬å®‰å®šæ€§: äºˆæ¸¬å€¤ãŒæ¥µç«¯ã§ãªã„ã‹
                        
                        **ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«:**
                        - ğŸŸ¢ éå¸¸ã«é«˜ã„ (80%ä»¥ä¸Š): äºˆæ¸¬å€¤ã¯éå¸¸ã«ä¿¡é ¼ã§ãã‚‹
                        - ğŸ”µ é«˜ã„ (60-80%): äºˆæ¸¬å€¤ã¯ä¿¡é ¼ã§ãã‚‹
                        - ğŸŸ¡ ä¸­ç¨‹åº¦ (40-60%): äºˆæ¸¬å€¤ã¯å‚è€ƒç¨‹åº¦
                        - ğŸ”´ ä½ã„ (40%æœªæº€): äºˆæ¸¬å€¤ã¯æ…é‡ã«æ‰±ã†ã¹ã
                        """)
                        
                        # å„ç”»åƒã®è©³ç´°
                        for idx, result in enumerate(results):
                            conf = result['confidence']
                            st.markdown(f"---")
                            st.markdown(f"### {idx+1}. {result['filename']}")
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric(
                                    "ç·åˆä¿¡é ¼åº¦",
                                    f"{conf['overall_confidence']:.1f}%",
                                    delta=None
                                )
                            with col2:
                                st.metric(
                                    "ç‰¹å¾´é‡å“è³ª",
                                    f"{conf['feature_quality']:.1f}%"
                                )
                            with col3:
                                st.metric(
                                    "ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦",
                                    f"{conf['model_confidence']:.1f}%"
                                )
                            
                            # ç‰¹å¾´é‡ã®è©³ç´°
                            feat_details = conf['feature_details']
                            st.write(f"""
                            **ç‰¹å¾´é‡ã®è©³ç´°:**
                            - ã‚¨ãƒƒã‚¸å¼·åº¦: {feat_details['edge_strength']:.2f} (ã‚¹ã‚³ã‚¢: {feat_details['edge_score']:.1f}/40)
                            - ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {feat_details['noise_level']:.2f} (ã‚¹ã‚³ã‚¢: {feat_details['noise_score']:.1f}/30)
                            - ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {feat_details['entropy']:.2f} (ã‚¹ã‚³ã‚¢: {feat_details['entropy_score']:.1f}/30)
                            """)
                    
                    # ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ä¿¡é ¼åº¦ä»˜ã)
                    st.subheader("ğŸ“· ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ä¸Šä½3æš)")
                    cols = st.columns(min(3, len(results)))
                    for idx, result in enumerate(results[:3]):
                        with cols[idx]:
                            conf = result['confidence']
                            st.image(
                                cv2.cvtColor(result['image'], cv2.COLOR_BGR2RGB),
                                caption=f"{result['filename']}",
                                use_container_width=True
                            )
                            st.markdown(f"""
                            **FD:** {result['predicted_fd']:.4f}  
                            **ä¿¡é ¼åº¦:** {conf['level_emoji']} {conf['overall_confidence']:.1f}%  
                            **åŒºé–“:** {conf['lower_bound']:.4f} - {conf['upper_bound']:.4f}
                            """)
                    
                    # CSVå‡ºåŠ› (ä¿¡é ¼åº¦æƒ…å ±å«ã‚€)
                    csv = df.to_csv(index=False).encode('utf-8-sig')
                    st.download_button(
                        label="ğŸ“¥ çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ä¿¡é ¼åº¦å«ã‚€)",
                        data=csv,
                        file_name="predicted_fractal_dimensions_with_confidence.csv",
                        mime="text/csv"
                    )
        
        return  # æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã¯ã“ã“ã§çµ‚äº†

    # ============================================================
    # å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ (æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰)
    # ============================================================
    st.header("ğŸ“ å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ - AIã‚’å­¦ç¿’ã•ã›ã‚‹")
    
    # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆã¯é€šçŸ¥
    if st.session_state.get('model_loaded', False):
        model_info = st.session_state.get('model_info', {})
        st.info(f"""
        â„¹ï¸ æ—¢ã«ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ ({model_info.get('source', 'ä¸æ˜')})
        
        - ã“ã®ã¾ã¾æ–°ã—ãå­¦ç¿’ã™ã‚‹ã¨ã€**æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã¯ä¸Šæ›¸ã**ã•ã‚Œã¾ã™
        - æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä¿æŒã—ãŸã„å ´åˆã¯ã€å…ˆã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„
        - æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã‚Œã°ã€æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã§ãã¾ã™
        """)
    
    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    mode = st.radio(
        "ç”»åƒèª­ã¿è¾¼ã¿ãƒ¢ãƒ¼ãƒ‰",
        ["ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è‡ªå‹•ãƒšã‚¢ãƒªãƒ³ã‚°", "ğŸ“¤ æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"],
        help="ãƒ•ã‚©ãƒ«ãƒ€ãƒ¢ãƒ¼ãƒ‰: åŒã˜åå‰ã®ç”»åƒã‚’è‡ªå‹•çš„ã«ãƒšã‚¢ãƒªãƒ³ã‚°\næ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰: å€‹åˆ¥ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
    )

    if mode == "ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è‡ªå‹•ãƒšã‚¢ãƒªãƒ³ã‚°":
        st.markdown("""
        ### ãƒ•ã‚©ãƒ«ãƒ€é¸æŠã‚¬ã‚¤ãƒ‰
        ç”»åƒãƒšã‚¢ã®æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³:
        1. **IMG_XXX.jpg + IMG_XXX_low1.jpg** å½¢å¼ (ä¾‹: `E:\\é ¬ç”»åƒã€€ç”»è³ªåˆ¥\\ç”»è³ªåˆ¥ï¼¿é ¬ç”»åƒ`)
        2. **é«˜ç”»è³ª/ä½ç”»è³ªãƒ•ã‚©ãƒ«ãƒ€åˆ†é›¢** å½¢å¼ (ä»Šå¾Œå¯¾å¿œäºˆå®š)
        3. **ãã®ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³** - æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã‚’ã”åˆ©ç”¨ãã ã•ã„
        """)
        
        folder_path = st.text_input(
            "ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹",
            value=r"E:\é ¬ç”»åƒã€€ç”»è³ªåˆ¥\ç”»è³ªåˆ¥ï¼¿é ¬ç”»åƒ",
            help="é«˜ç”»è³ªã¨ä½ç”»è³ªã®ç”»åƒãŒå…¥ã£ãŸãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
        )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠ
        col1, col2 = st.columns(2)
        with col1:
            file_pattern = st.selectbox(
                "ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³",
                ["IMG_*.jpg", "*.jpg", "*.png", "ã‚«ã‚¹ã‚¿ãƒ "],
                help="æ¤œå‡ºã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³"
            )
            if file_pattern == "ã‚«ã‚¹ã‚¿ãƒ ":
                file_pattern = st.text_input("ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³", value="*.jpg")
        
        with col2:
            quality_level = st.selectbox(
                "ä½ç”»è³ªãƒ¬ãƒ™ãƒ«ã‚’é¸æŠ",
                ["low1", "low2", "low3", "ã‚«ã‚¹ã‚¿ãƒ "],
                help="æ¯”è¼ƒã™ã‚‹ä½ç”»è³ªãƒ¬ãƒ™ãƒ«ã‚’é¸æŠ (low1ãŒæœ€ã‚‚é«˜å“è³ªã€low3ãŒæœ€ã‚‚ä½å“è³ª)"
            )
            if quality_level == "ã‚«ã‚¹ã‚¿ãƒ ":
                quality_level = st.text_input("ã‚«ã‚¹ã‚¿ãƒ ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹", value="low1")
        
        if folder_path and os.path.exists(folder_path):
            # ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç”»åƒãƒšã‚¢ã‚’è‡ªå‹•æ¤œå‡º
            all_files = sorted(glob.glob(os.path.join(folder_path, file_pattern)))
            
            # é«˜ç”»è³ªç”»åƒã‚’æ¤œå‡º(_lowãŒã¤ã„ã¦ã„ãªã„ã‚‚ã®)
            high_files = [f for f in all_files if f"_{quality_level}" not in os.path.basename(f) 
                          and not any(f"_low{i}" in os.path.basename(f) for i in ["1", "2", "3"])]
            
            if len(all_files) > 0:
                st.info(f"ğŸ“‚ æ¤œå‡ºã•ã‚ŒãŸå…¨ç”»åƒ: {len(all_files)}æš")
            
            if len(high_files) > 0:
                st.success(f"âœ… {len(high_files)}æšã®é«˜ç”»è³ªç”»åƒã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
                
                # ãƒ‡ãƒãƒƒã‚°: æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¡¨ç¤º
                with st.expander("ğŸ” æ¤œå‡ºã•ã‚ŒãŸç”»åƒãƒ‘ã‚¹ (ãƒ‡ãƒãƒƒã‚°æƒ…å ±)"):
                    st.write(f"**ãƒ•ã‚©ãƒ«ãƒ€:** {folder_path}")
                    st.write(f"**ãƒ‘ã‚¿ãƒ¼ãƒ³:** {file_pattern}")
                    st.write(f"**å…¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°:** {len(all_files)}")
                    st.write(f"**é«˜ç”»è³ªãƒ•ã‚¡ã‚¤ãƒ«æ•°:** {len(high_files)}")
                    st.write(f"**é«˜ç”»è³ªä¾‹:** {os.path.basename(high_files[0]) if high_files else 'ãªã—'}")
                    if len(high_files) > 1:
                        st.write(f"**ä»–ã®ä¾‹:** {', '.join([os.path.basename(f) for f in high_files[1:min(4, len(high_files))]])}")
                
                # å¯¾å¿œã™ã‚‹ä½ç”»è³ªç”»åƒã‚’æ¤œç´¢
                low_files = []
                missing_files = []
                for hf in high_files:
                    base_name = os.path.splitext(os.path.basename(hf))[0]
                    ext = os.path.splitext(os.path.basename(hf))[1]
                    low_file = os.path.join(folder_path, f"{base_name}_{quality_level}{ext}")
                    if os.path.exists(low_file):
                        low_files.append(low_file)
                    else:
                        missing_files.append(f"{base_name}_{quality_level}{ext}")
                
                # ãƒ‡ãƒãƒƒã‚°: ä½ç”»è³ªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚‚è¡¨ç¤º
                if low_files:
                    with st.expander("ğŸ” ãƒšã‚¢ç”»åƒãƒ‘ã‚¹ (ãƒ‡ãƒãƒƒã‚°æƒ…å ±)"):
                        st.write(f"**ä½ç”»è³ªãƒ•ã‚¡ã‚¤ãƒ«æ•°:** {len(low_files)}")
                        st.write(f"**ä½ç”»è³ªä¾‹:** {os.path.basename(low_files[0])}")
                        if missing_files:
                            st.warning(f"**è¦‹ã¤ã‹ã‚‰ãªã„ãƒ•ã‚¡ã‚¤ãƒ«:** {len(missing_files)}ä»¶")
                            st.write(f"ä¾‹: {', '.join(missing_files[:3])}")
                
                if len(low_files) == len(high_files):
                    st.success(f"âœ… {len(low_files)}çµ„ã®å®Œå…¨ãªãƒšã‚¢ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
                    
                    # ç”»åƒã‚’èª­ã¿è¾¼ã¿
                    uploaded_high = high_files
                    uploaded_low = low_files
                    auto_mode = True
                else:
                    st.error(f"âŒ ãƒšã‚¢ãŒä¸å®Œå…¨ã§ã™ (é«˜ç”»è³ª: {len(high_files)}æš, ä½ç”»è³ª: {len(low_files)}æš)")
                    if len(low_files) > 0:
                        st.warning(f"ä¸€éƒ¨ã®ãƒšã‚¢ã®ã¿ä½¿ç”¨ã—ã¾ã™ã‹? (å®Œå…¨ãªãƒšã‚¢: {len(low_files)}çµ„)")
                        if st.checkbox("ä¸å®Œå…¨ã§ã‚‚ç¶šè¡Œã™ã‚‹"):
                            # å®Œå…¨ãªãƒšã‚¢ã®ã¿ä½¿ç”¨
                            valid_high = []
                            valid_low = []
                            for hf in high_files:
                                base_name = os.path.splitext(os.path.basename(hf))[0]
                                ext = os.path.splitext(os.path.basename(hf))[1]
                                low_file = os.path.join(folder_path, f"{base_name}_{quality_level}{ext}")
                                if os.path.exists(low_file):
                                    valid_high.append(hf)
                                    valid_low.append(low_file)
                            uploaded_high = valid_high
                            uploaded_low = valid_low
                            auto_mode = True
                            st.info(f"âœ… {len(valid_high)}çµ„ã®å®Œå…¨ãªãƒšã‚¢ã‚’ä½¿ç”¨ã—ã¾ã™")
                        else:
                            uploaded_high = None
                            uploaded_low = None
                            auto_mode = False
                    else:
                        uploaded_high = None
                        uploaded_low = None
                        auto_mode = False
            else:
                st.warning(f"âš ï¸ ãƒ•ã‚©ãƒ«ãƒ€å†…ã«'{file_pattern}'ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                uploaded_high = None
                uploaded_low = None
                auto_mode = False
        elif folder_path:
            st.error(f"âŒ **ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ãŒç„¡åŠ¹ã§ã™**")
            st.info(f"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹: `{folder_path}`")
            st.info(f"ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
            # ãƒ‘ã‚¹ã®å­˜åœ¨ç¢ºèªã®è©³ç´°
            parent_dir = os.path.dirname(folder_path)
            if os.path.exists(parent_dir):
                st.warning(f"è¦ªãƒ•ã‚©ãƒ«ãƒ€ã¯å­˜åœ¨ã—ã¾ã™: `{parent_dir}`")
                # è¦ªãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ã‚’è¡¨ç¤º
                try:
                    subdirs = [d for d in os.listdir(parent_dir) if os.path.isdir(os.path.join(parent_dir, d))]
                    if subdirs:
                        st.info(f"åˆ©ç”¨å¯èƒ½ãªã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€: {', '.join(subdirs[:5])}")
                except:
                    pass
            else:
                st.error(f"è¦ªãƒ•ã‚©ãƒ«ãƒ€ã‚‚å­˜åœ¨ã—ã¾ã›ã‚“: `{parent_dir}`")
            
            uploaded_high = None
            uploaded_low = None
            auto_mode = False
        else:
            st.info("ğŸ‘† ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            uploaded_high = None
            uploaded_low = None
            auto_mode = False
    else:
        uploaded_high = st.file_uploader("é«˜ç”»è³ªç”»åƒã‚’ãƒšã‚¢ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰(åŒæšæ•°)", type=['png','jpg','jpeg'], accept_multiple_files=True)
        uploaded_low = st.file_uploader("ä½ç”»è³ªç”»åƒã‚’ãƒšã‚¢ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰(åŒæšæ•°)", type=['png','jpg','jpeg'], accept_multiple_files=True)
        auto_mode = False


    if uploaded_high and uploaded_low:
        if not auto_mode and len(uploaded_high) != len(uploaded_low):
            st.error("é«˜ç”»è³ªã¨ä½ç”»è³ªã®æšæ•°ã‚’æƒãˆã¦ãã ã•ã„(ãƒšã‚¢ã§è§£æã—ã¾ã™)ã€‚")
            return

        # read images
        if auto_mode:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿(æ—¥æœ¬èªãƒ‘ã‚¹å¯¾å¿œ)
            high_imgs = []
            low_imgs = []
            failed_files = []
            
            for hf, lf in zip(uploaded_high, uploaded_low):
                h_img = read_bgr_from_path(hf)
                l_img = read_bgr_from_path(lf)
                
                if h_img is None:
                    failed_files.append(f"é«˜ç”»è³ª: {os.path.basename(hf)}")
                if l_img is None:
                    failed_files.append(f"ä½ç”»è³ª: {os.path.basename(lf)}")
                
                if h_img is not None and l_img is not None:
                    high_imgs.append(h_img)
                    low_imgs.append(l_img)
            
            if failed_files:
                st.error(f"ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ:\n" + "\n".join(failed_files[:5]))
                if len(failed_files) > 5:
                    st.error(f"...ä»– {len(failed_files)-5} ä»¶")
                return
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
            high_names = [os.path.basename(f) for f in uploaded_high]
            low_names = [os.path.basename(f) for f in uploaded_low]
        else:
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            high_imgs = [read_bgr_from_buffer(f.read()) for f in uploaded_high]
            low_imgs = [read_bgr_from_buffer(f.read()) for f in uploaded_low]
            high_names = [f.name for f in uploaded_high]
            low_names = [f.name for f in uploaded_low]

        if len(high_imgs) == 0:
            st.error("âŒ ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.markdown("---")
        st.subheader("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ (Data Augmentation)")
        
        if len(high_imgs) < 10:
            st.warning(f"""
            âš ï¸ **ç”»åƒãƒšã‚¢æ•°ãŒå°‘ãªã„ã§ã™** (ç¾åœ¨: {len(high_imgs)}çµ„)
            
            ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€å°‘ãªã„ç”»åƒã‹ã‚‰å¤šãã®å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚
            """)
        
        st.markdown("""
        **ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨ã¯ï¼Ÿ**
        
        ç”»åƒã«å¤‰æ›ã‚’åŠ ãˆã¦å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¢—ã‚„ã™æ‰‹æ³•ã§ã™ã€‚ç”»åƒãŒå°‘ãªã„å ´åˆã«æœ‰åŠ¹ã§ã™ã€‚
        
        **ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªå¤‰æ› (å…¨28ç¨®é¡):**
        
        **ğŸ”„ å¹¾ä½•å­¦å¤‰æ› (7ç¨®é¡)**
        - æ°´å¹³åè»¢ã€å‚ç›´åè»¢
        - 90åº¦å›è»¢ã€180åº¦å›è»¢ã€270åº¦å›è»¢
        - å¾®å°å›è»¢ (Â±5åº¦) - æ–¹å‘ä¸å¤‰æ€§å­¦ç¿’
        
        **ğŸ’¡ æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ (6ç¨®é¡)**
        - æ˜ã‚‹ã•å¢—åŠ /æ¸›å°‘
        - ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¢—åŠ /æ¸›å°‘
        - ã‚¬ãƒ³ãƒè£œæ­£ (æ˜ã‚‹ã/æš—ã)
        
        **ğŸ¨ è‰²èª¿æ•´ (5ç¨®é¡)**
        - å½©åº¦å¢—åŠ /æ¸›å°‘
        - è‰²ç›¸ã‚·ãƒ•ãƒˆ
        - æ¸©åº¦èª¿æ•´ (æš–è‰²/å¯’è‰²) - ç…§æ˜æ¡ä»¶å¯¾å¿œ ğŸŒŸ
        
        **ğŸ”§ ç”»è³ªå‡¦ç† (6ç¨®é¡)**
        - ãƒã‚¤ã‚ºè¿½åŠ ã€ã¼ã‹ã—
        - ã‚·ãƒ£ãƒ¼ãƒ—åŒ–ã€ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–
        - ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã€ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ ğŸŒŸ
        
        **ğŸ¯ AIå­¦ç¿’æœ€é©åŒ– (4ç¨®é¡) - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒå­¦ç¿’ã«ç‰¹åŒ– ğŸŒŸ**
        - ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ› (æ‹¡å¤§/ç¸®å°) - ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§å­¦ç¿’
        - CLAHE - å±€æ‰€çš„ãƒ†ã‚¯ã‚¹ãƒãƒ£å¼·èª¿
        - ã‚¢ãƒ³ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ã‚¯ - ã‚¨ãƒƒã‚¸å¼·èª¿
        
        **ğŸŒŸ = AIå­¦ç¿’ã«ç‰¹ã«åŠ¹æœçš„**
        
        **æ³¨æ„**: æ‹¡å¼µã«ã‚ˆã‚Šå‡¦ç†æ™‚é–“ãŒå¢—åŠ ã—ã¾ã™
        """)
        
        use_augmentation = st.checkbox(
            "ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½¿ç”¨ã™ã‚‹",
            value=len(high_imgs) < 10,
            help="ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨ç”»åƒãƒšã‚¢æ•°ã‚’å¢—ã‚„ã—ã¾ã™ã€‚ç”»åƒãŒ10çµ„æœªæº€ã®å ´åˆã«æ¨å¥¨"
        )
        
        if use_augmentation:
            st.info("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚ªãƒ—ã‚·ãƒ§ãƒ³ - ä½¿ç”¨ã™ã‚‹å¤‰æ›ã‚’é¸æŠ")
            
            # ============================================================
            # ğŸ¯ å…¨é¸æŠãƒœã‚¿ãƒ³æ©Ÿèƒ½
            # ============================================================
            col_btn1, col_btn2, col_btn3 = st.columns([2, 2, 3])
            with col_btn1:
                if st.button("âœ… å…¨ã¦é¸æŠ", use_container_width=True, help="å…¨ã¦ã®æ‹¡å¼µæ©Ÿèƒ½ã‚’ã‚ªãƒ³ã«ã—ã¾ã™", type="primary"):
                    st.session_state['select_all_augmentation'] = True
                    # ã‚¿ãƒ–ã”ã¨ã®çŠ¶æ…‹ã‚‚ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.pop('geo_select_all', None)
                    st.session_state.pop('bright_select_all', None)
                    st.session_state.pop('color_select_all', None)
                    st.session_state.pop('quality_select_all', None)
                    st.session_state.pop('ai_select_all', None)
                    st.rerun()
            with col_btn2:
                if st.button("âŒ å…¨ã¦è§£é™¤", use_container_width=True, help="å…¨ã¦ã®æ‹¡å¼µæ©Ÿèƒ½ã‚’ã‚ªãƒ•ã«ã—ã¾ã™"):
                    st.session_state['select_all_augmentation'] = False
                    # ã‚¿ãƒ–ã”ã¨ã®çŠ¶æ…‹ã‚‚ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.pop('geo_select_all', None)
                    st.session_state.pop('bright_select_all', None)
                    st.session_state.pop('color_select_all', None)
                    st.session_state.pop('quality_select_all', None)
                    st.session_state.pop('ai_select_all', None)
                    st.rerun()
            with col_btn3:
                # ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¡¨ç¤º
                select_all_state = st.session_state.get('select_all_augmentation', None)
                if select_all_state == True:
                    st.success("âœ… å…¨é¸æŠä¸­ (28ç¨®é¡)")
                elif select_all_state == False:
                    st.warning("å…¨è§£é™¤ä¸­")
            
            # å…¨é¸æŠ/è§£é™¤ã®çŠ¶æ…‹ã‚’å–å¾—
            select_all = st.session_state.get('select_all_augmentation', None)
            
            # ã‚¿ãƒ–ã§åˆ†é¡ - 5ã¤ã®ã‚¿ãƒ–ã«æ‹¡å¼µ
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "ğŸ”„ å¹¾ä½•å­¦å¤‰æ›", 
                "ğŸ’¡ æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ", 
                "ğŸ¨ è‰²èª¿æ•´", 
                "ğŸ”§ ç”»è³ªå‡¦ç†",
                "ğŸ¯ AIå­¦ç¿’æœ€é©åŒ– ğŸŒŸ"
            ])
            
            with tab1:
                st.markdown("**å¹¾ä½•å­¦å¤‰æ› - ç”»åƒã®å‘ãã‚„è§’åº¦ã‚’å¤‰æ›´**")
                
                # ã‚¿ãƒ–ã”ã¨ã®å…¨é¸æŠãƒœã‚¿ãƒ³
                col_tab_btn1, col_tab_btn2 = st.columns([1, 3])
                with col_tab_btn1:
                    if st.button("âœ… å…¨é¸æŠ", key="geo_all", help="å¹¾ä½•å­¦å¤‰æ›ã‚’å…¨ã¦ã‚ªãƒ³"):
                        st.session_state['geo_select_all'] = True
                        st.rerun()
                with col_tab_btn2:
                    if st.button("âŒ å…¨è§£é™¤", key="geo_clear", help="å¹¾ä½•å­¦å¤‰æ›ã‚’å…¨ã¦ã‚ªãƒ•"):
                        st.session_state['geo_select_all'] = False
                        st.rerun()
                
                geo_select = st.session_state.get('geo_select_all', None)
                default_geo = True if (select_all or geo_select) else (False if (select_all == False or geo_select == False) else True)
                default_geo_off = False if (select_all == False or geo_select == False) else (True if (select_all or geo_select) else False)
                
                col1, col2 = st.columns(2)
                with col1:
                    use_flip_h = st.checkbox("ğŸ”„ æ°´å¹³åè»¢ (å·¦å³åè»¢)", value=default_geo, help="ç”»åƒã‚’å·¦å³åè»¢", key="aug_flip_h")
                    use_flip_v = st.checkbox("ğŸ”ƒ å‚ç›´åè»¢ (ä¸Šä¸‹åè»¢)", value=default_geo_off, help="ç”»åƒã‚’ä¸Šä¸‹åè»¢", key="aug_flip_v")
                    use_rotate_90 = st.checkbox("â†©ï¸ 90åº¦å›è»¢", value=default_geo, help="æ™‚è¨ˆå›ã‚Šã«90åº¦å›è»¢", key="aug_rot90")
                    use_rotate_180 = st.checkbox("ğŸ” 180åº¦å›è»¢", value=default_geo_off, help="180åº¦å›è»¢", key="aug_rot180")
                with col2:
                    use_rotate_270 = st.checkbox("â†ªï¸ 270åº¦å›è»¢", value=default_geo_off, help="æ™‚è¨ˆå›ã‚Šã«270åº¦å›è»¢", key="aug_rot270")
                    use_rotate_small_cw = st.checkbox("ğŸ”„ å¾®å°å›è»¢(+5Â°) ğŸŒŸ", value=default_geo_off, help="æ™‚è¨ˆå›ã‚Šã«5åº¦å›è»¢ - æ–¹å‘ä¸å¤‰æ€§å­¦ç¿’ã«åŠ¹æœçš„", key="aug_rot_small_cw")
                    use_rotate_small_ccw = st.checkbox("ğŸ”„ å¾®å°å›è»¢(-5Â°) ğŸŒŸ", value=default_geo_off, help="åæ™‚è¨ˆå›ã‚Šã«5åº¦å›è»¢ - æ–¹å‘ä¸å¤‰æ€§å­¦ç¿’ã«åŠ¹æœçš„", key="aug_rot_small_ccw")
            
            with tab2:
                st.markdown("**æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ - ç”»åƒã®æ˜ã‚‹ã•ã‚„ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’èª¿æ•´**")
                
                # ã‚¿ãƒ–ã”ã¨ã®å…¨é¸æŠãƒœã‚¿ãƒ³
                col_tab_btn1, col_tab_btn2 = st.columns([1, 3])
                with col_tab_btn1:
                    if st.button("âœ… å…¨é¸æŠ", key="bright_all", help="æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å…¨ã¦ã‚ªãƒ³"):
                        st.session_state['bright_select_all'] = True
                        st.rerun()
                with col_tab_btn2:
                    if st.button("âŒ å…¨è§£é™¤", key="bright_clear", help="æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å…¨ã¦ã‚ªãƒ•"):
                        st.session_state['bright_select_all'] = False
                        st.rerun()
                
                bright_select = st.session_state.get('bright_select_all', None)
                default_bright = False if (select_all == False or bright_select == False) else (True if (select_all or bright_select) else False)
                
                col1, col2 = st.columns(2)
                with col1:
                    use_brightness_up = st.checkbox("â˜€ï¸ æ˜ã‚‹ã•å¢—åŠ  (+20%)", value=default_bright, help="ç”»åƒã‚’20%æ˜ã‚‹ã", key="aug_br_up")
                    use_brightness_down = st.checkbox("ğŸŒ™ æ˜ã‚‹ã•æ¸›å°‘ (-20%)", value=default_bright, help="ç”»åƒã‚’20%æš—ã", key="aug_br_down")
                    use_contrast_up = st.checkbox("ğŸ“ˆ ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¢—åŠ ", value=default_bright, help="ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·ã", key="aug_cont_up")
                with col2:
                    use_contrast_down = st.checkbox("ğŸ“‰ ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆæ¸›å°‘", value=default_bright, help="ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼±ã", key="aug_cont_down")
                    use_gamma_bright = st.checkbox("âœ¨ ã‚¬ãƒ³ãƒè£œæ­£ (æ˜ã‚‹ã)", value=default_bright, help="ã‚¬ãƒ³ãƒè£œæ­£ã§æ˜ã‚‹ã", key="aug_gamma_br")
                    use_gamma_dark = st.checkbox("ğŸŒ‘ ã‚¬ãƒ³ãƒè£œæ­£ (æš—ã)", value=default_bright, help="ã‚¬ãƒ³ãƒè£œæ­£ã§æš—ã", key="aug_gamma_dk")
            
            with tab3:
                st.markdown("**è‰²èª¿æ•´ - ç”»åƒã®è‰²åˆã„ã‚„å½©åº¦ã‚’å¤‰æ›´**")
                
                # ã‚¿ãƒ–ã”ã¨ã®å…¨é¸æŠãƒœã‚¿ãƒ³
                col_tab_btn1, col_tab_btn2 = st.columns([1, 3])
                with col_tab_btn1:
                    if st.button("âœ… å…¨é¸æŠ", key="color_all", help="è‰²èª¿æ•´ã‚’å…¨ã¦ã‚ªãƒ³"):
                        st.session_state['color_select_all'] = True
                        st.rerun()
                with col_tab_btn2:
                    if st.button("âŒ å…¨è§£é™¤", key="color_clear", help="è‰²èª¿æ•´ã‚’å…¨ã¦ã‚ªãƒ•"):
                        st.session_state['color_select_all'] = False
                        st.rerun()
                
                color_select = st.session_state.get('color_select_all', None)
                default_color = False if (select_all == False or color_select == False) else (True if (select_all or color_select) else False)
                
                col1, col2 = st.columns(2)
                with col1:
                    use_saturation_up = st.checkbox("ğŸŒˆ å½©åº¦å¢—åŠ ", value=default_color, help="è‰²ã‚’é®®ã‚„ã‹ã«", key="aug_sat_up")
                    use_saturation_down = st.checkbox("ğŸŒ«ï¸ å½©åº¦æ¸›å°‘", value=default_color, help="è‰²ã‚’æ·¡ã", key="aug_sat_down")
                    use_hue_shift = st.checkbox("ğŸ¨ è‰²ç›¸ã‚·ãƒ•ãƒˆ", value=default_color, help="è‰²åˆã„ã‚’å¤‰æ›´", key="aug_hue")
                with col2:
                    use_temp_warm = st.checkbox("ğŸ”¥ æ¸©åº¦èª¿æ•´(æš–è‰²) ğŸŒŸ", value=default_color, help="ç…§æ˜æ¡ä»¶ã®å¤‰åŒ–ã«å¯¾å¿œ - AIå­¦ç¿’ã«åŠ¹æœçš„", key="aug_temp_warm")
                    use_temp_cool = st.checkbox("â„ï¸ æ¸©åº¦èª¿æ•´(å¯’è‰²) ğŸŒŸ", value=default_color, help="ç…§æ˜æ¡ä»¶ã®å¤‰åŒ–ã«å¯¾å¿œ - AIå­¦ç¿’ã«åŠ¹æœçš„", key="aug_temp_cool")
            
            with tab4:
                st.markdown("**ç”»è³ªå‡¦ç† - ãƒã‚¤ã‚ºã‚„ã¼ã‹ã—ã€ã‚·ãƒ£ãƒ¼ãƒ—åŒ–ãªã©ã®å‡¦ç†**")
                
                # ã‚¿ãƒ–ã”ã¨ã®å…¨é¸æŠãƒœã‚¿ãƒ³
                col_tab_btn1, col_tab_btn2 = st.columns([1, 3])
                with col_tab_btn1:
                    if st.button("âœ… å…¨é¸æŠ", key="quality_all", help="ç”»è³ªå‡¦ç†ã‚’å…¨ã¦ã‚ªãƒ³"):
                        st.session_state['quality_select_all'] = True
                        st.rerun()
                with col_tab_btn2:
                    if st.button("âŒ å…¨è§£é™¤", key="quality_clear", help="ç”»è³ªå‡¦ç†ã‚’å…¨ã¦ã‚ªãƒ•"):
                        st.session_state['quality_select_all'] = False
                        st.rerun()
                
                quality_select = st.session_state.get('quality_select_all', None)
                default_quality = False if (select_all == False or quality_select == False) else (True if (select_all or quality_select) else False)
                
                col1, col2 = st.columns(2)
                with col1:
                    use_noise = st.checkbox("ğŸ“¡ ãƒã‚¤ã‚ºè¿½åŠ ", value=default_quality, help="ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºã‚’è¿½åŠ ", key="aug_noise")
                    use_blur = st.checkbox("ğŸŒ€ ã¼ã‹ã—", value=default_quality, help="ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ã¼ã‹ã—ã‚’é©ç”¨", key="aug_blur")
                    use_sharpen = st.checkbox("ğŸ”ª ã‚·ãƒ£ãƒ¼ãƒ—åŒ–", value=default_quality, help="ã‚¨ãƒƒã‚¸ã‚’å¼·èª¿", key="aug_sharp")
                with col2:
                    use_equalize = st.checkbox("ğŸ“Š ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–", value=default_quality, help="ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’è‡ªå‹•èª¿æ•´", key="aug_eq")
                    use_median = st.checkbox("ğŸ”² ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ ğŸŒŸ", value=default_quality, help="ãƒã‚¤ã‚ºé™¤å» - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ä¿æŒã«åŠ¹æœçš„", key="aug_median")
                    use_bilateral = st.checkbox("ğŸ­ ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ« ğŸŒŸ", value=default_quality, help="ã‚¨ãƒƒã‚¸ä¿å­˜å¹³æ»‘åŒ– - AIå­¦ç¿’ã«åŠ¹æœçš„", key="aug_bilateral")
            
            # ğŸ¯ AIå­¦ç¿’æœ€é©åŒ–ã‚¿ãƒ– (æ–°è¦è¿½åŠ )
            with tab5:
                st.markdown("**AIå­¦ç¿’æœ€é©åŒ– - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒå­¦ç¿’ã«ç‰¹åŒ–ã—ãŸæ‹¡å¼µ ğŸŒŸ**")
                st.info("ã“ã‚Œã‚‰ã®æ‹¡å¼µã¯ã€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®AIå­¦ç¿’ã«ç‰¹ã«åŠ¹æœçš„ã§ã™ã€‚ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§ã€å±€æ‰€çš„ãªç‰¹å¾´æŠ½å‡ºã€ã‚¨ãƒƒã‚¸ä¿å­˜ãªã©ã‚’å¼·åŒ–ã—ã¾ã™ã€‚")
                
                # ã‚¿ãƒ–ã”ã¨ã®å…¨é¸æŠãƒœã‚¿ãƒ³
                col_tab_btn1, col_tab_btn2 = st.columns([1, 3])
                with col_tab_btn1:
                    if st.button("âœ… å…¨é¸æŠ", key="ai_all", help="AIå­¦ç¿’æœ€é©åŒ–ã‚’å…¨ã¦ã‚ªãƒ³"):
                        st.session_state['ai_select_all'] = True
                        st.rerun()
                with col_tab_btn2:
                    if st.button("âŒ å…¨è§£é™¤", key="ai_clear", help="AIå­¦ç¿’æœ€é©åŒ–ã‚’å…¨ã¦ã‚ªãƒ•"):
                        st.session_state['ai_select_all'] = False
                        st.rerun()
                
                ai_select = st.session_state.get('ai_select_all', None)
                default_ai = False if (select_all == False or ai_select == False) else (True if (select_all or ai_select) else False)
                
                col1, col2 = st.columns(2)
                with col1:
                    use_scale_up = st.checkbox("ğŸ“ ã‚¹ã‚±ãƒ¼ãƒ«æ‹¡å¤§ ğŸŒŸ", value=default_ai, help="110%ã«æ‹¡å¤§ - ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§å­¦ç¿’", key="aug_scale_up")
                    use_scale_down = st.checkbox("ğŸ“ ã‚¹ã‚±ãƒ¼ãƒ«ç¸®å° ğŸŒŸ", value=default_ai, help="90%ã«ç¸®å° - ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§å­¦ç¿’", key="aug_scale_down")
                with col2:
                    use_clahe = st.checkbox("ğŸ”† CLAHE ğŸŒŸ", value=default_ai, help="é©å¿œçš„ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ– - å±€æ‰€çš„ãƒ†ã‚¯ã‚¹ãƒãƒ£å¼·èª¿", key="aug_clahe")
                    use_unsharp = st.checkbox("ğŸ” ã‚¢ãƒ³ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ã‚¯ ğŸŒŸ", value=default_ai, help="ã‚¨ãƒƒã‚¸å¼·èª¿ - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ§‹é€ ã®å¢ƒç•Œæ˜ç¢ºåŒ–", key="aug_unsharp")
            
            # é¸æŠã•ã‚ŒãŸæ‹¡å¼µæ‰‹æ³•ã‚’åé›†
            augmentation_methods = []
            
            # å¹¾ä½•å­¦å¤‰æ›
            if use_flip_h:
                augmentation_methods.append('flip_h')
            if use_flip_v:
                augmentation_methods.append('flip_v')
            if use_rotate_90:
                augmentation_methods.append('rotate_90')
            if use_rotate_180:
                augmentation_methods.append('rotate_180')
            if use_rotate_270:
                augmentation_methods.append('rotate_270')
            if use_rotate_small_cw:
                augmentation_methods.append('rotate_small_cw')
            if use_rotate_small_ccw:
                augmentation_methods.append('rotate_small_ccw')
            
            # æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ
            if use_brightness_up:
                augmentation_methods.append('brightness_up')
            if use_brightness_down:
                augmentation_methods.append('brightness_down')
            if use_contrast_up:
                augmentation_methods.append('contrast_up')
            if use_contrast_down:
                augmentation_methods.append('contrast_down')
            if use_gamma_bright:
                augmentation_methods.append('gamma_bright')
            if use_gamma_dark:
                augmentation_methods.append('gamma_dark')
            
            # è‰²èª¿æ•´
            if use_saturation_up:
                augmentation_methods.append('saturation_up')
            if use_saturation_down:
                augmentation_methods.append('saturation_down')
            if use_hue_shift:
                augmentation_methods.append('hue_shift')
            if use_temp_warm:
                augmentation_methods.append('temp_warm')
            if use_temp_cool:
                augmentation_methods.append('temp_cool')
            
            # ç”»è³ªå‡¦ç†
            if use_noise:
                augmentation_methods.append('noise')
            if use_blur:
                augmentation_methods.append('blur')
            if use_sharpen:
                augmentation_methods.append('sharpen')
            if use_equalize:
                augmentation_methods.append('equalize')
            if use_median:
                augmentation_methods.append('median')
            if use_bilateral:
                augmentation_methods.append('bilateral')
            
            # AIå­¦ç¿’æœ€é©åŒ–
            if use_scale_up:
                augmentation_methods.append('scale_up')
            if use_scale_down:
                augmentation_methods.append('scale_down')
            if use_clahe:
                augmentation_methods.append('clahe')
            if use_unsharp:
                augmentation_methods.append('unsharp')
            
            if augmentation_methods:
                # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨
                original_count = len(high_imgs)
                
                # é¸æŠã•ã‚ŒãŸæ‹¡å¼µæ–¹æ³•ã®æƒ…å ±ã‚’è¡¨ç¤º
                st.info(f"""
                **é¸æŠã•ã‚ŒãŸæ‹¡å¼µæ–¹æ³•: {len(augmentation_methods)}ç¨®é¡**
                
                - å…ƒã®ç”»åƒãƒšã‚¢æ•°: {original_count}çµ„
                - äºˆæƒ³ã•ã‚Œã‚‹æ‹¡å¼µå¾Œ: {original_count * (len(augmentation_methods) + 1)}çµ„ (å…ƒç”»åƒ + æ‹¡å¼µç‰ˆ)
                """)
                
                high_imgs, low_imgs, high_names, low_names = apply_data_augmentation(
                    high_imgs, low_imgs, high_names, low_names, augmentation_methods
                )
                augmented_count = len(high_imgs)
                
                st.success(f"""
                âœ… ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Œäº†
                - å…ƒã®ç”»åƒãƒšã‚¢æ•°: {original_count}çµ„
                - æ‹¡å¼µå¾Œã®ç”»åƒãƒšã‚¢æ•°: {augmented_count}çµ„
                - å¢—åŠ ç‡: {((augmented_count / original_count - 1) * 100):.0f}%
                - ä½¿ç”¨ã—ãŸæ‹¡å¼µæ–¹æ³•: {len(augmentation_methods)}ç¨®é¡
                """)
            else:
                st.warning("âš ï¸ å°‘ãªãã¨ã‚‚1ã¤ã®æ‹¡å¼µæ‰‹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„")
        
        st.markdown("---")
        
        # ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
        if len(high_imgs) < 2:
            st.error(f"""
            âŒ **ç”»åƒãƒšã‚¢æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™**
            
            - æ¤œå‡ºã•ã‚ŒãŸç”»åƒãƒšã‚¢æ•°: **{len(high_imgs)}**
            - å¿…è¦ãªæœ€å°ãƒšã‚¢æ•°: **2**
            
            ğŸ’¡ **è§£æ±ºæ–¹æ³•:**
            1. ãƒ•ã‚©ãƒ«ãƒ€å†…ã«å°‘ãªãã¨ã‚‚**2çµ„ä»¥ä¸Š**ã®ç”»åƒãƒšã‚¢ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„
            2. ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„
               - ä¾‹: `IMG_0001.jpg` ã¨ `IMG_0001_low1.jpg`
               - ä¾‹: `photo1.png` ã¨ `photo1_low1.png`
            3. ã€Œãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºã€ã§æ¤œå‡ºçŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„
            """)
            return
            
        st.success(f"âœ… {len(high_imgs)} çµ„ã®ç”»åƒãƒšã‚¢ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

        # Quick preview first pair (èª¬æ˜ä»˜ã)
        st.subheader("ğŸ“· ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (1æšç›®)")
        st.markdown("""
        **ã“ã‚Œã‹ã‚‰è§£æã™ã‚‹ç”»åƒãƒšã‚¢ã®ä¾‹:**
        - **å·¦ (ä½ç”»è³ª)**: AIãŒã“ã®ç”»åƒã‹ã‚‰é«˜ç”»è³ªç›¸å½“ã®FDã‚’äºˆæ¸¬ã—ã¾ã™
        - **å³ (é«˜ç”»è³ª)**: AIã®äºˆæ¸¬ã®æ­£è§£å€¤ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ (å­¦ç¿’ãƒ»è©•ä¾¡ç”¨)
        
        ğŸ’¡ AIã¯ä½ç”»è³ªç”»åƒã®ç‰¹å¾´ã‚’å­¦ç¿’ã—ã€é«˜ç”»è³ªç›¸å½“ã®æ­£ç¢ºãªãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®šã—ã¾ã™ã€‚
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            st.image(cv2.cvtColor(low_imgs[0], cv2.COLOR_BGR2RGB), caption=f"ä½ç”»è³ª: {low_names[0]}", width=300)
        with col2:
            st.image(cv2.cvtColor(high_imgs[0], cv2.COLOR_BGR2RGB), caption=f"é«˜ç”»è³ª: {high_names[0]}", width=300)

        # Train button
        if st.button("ğŸ”§ AI ã‚’å­¦ç¿’ã—ã¦è§£æã‚’å®Ÿè¡Œ"):
            try:
                st.info("å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
                start = time.time()
                model = train_fd_predictor_fast(low_imgs, high_imgs)
                st.success("å­¦ç¿’å®Œäº†ã—ã¾ã—ãŸã€‚")
                
                # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
                model_path = save_model(model, "trained_fd_model.pkl")
                st.success(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_path}")
                
                # ============================================================
                # ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’æ°¸ç¶šåŒ– - ã‚¢ãƒ—ãƒªå…¨ä½“ã§ä½¿ç”¨å¯èƒ½ã«
                # ============================================================
                st.session_state['persistent_model'] = model
                st.session_state['model_loaded'] = True
                st.session_state['model_info'] = {
                    'path': model_path,
                    'loaded_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'source': 'å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰'
                }
                st.info("âœ… ãƒ¢ãƒ‡ãƒ«ã‚’æ°¸ç¶šåŒ–ã—ã¾ã—ãŸã€‚æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚ä½¿ç”¨ã§ãã¾ã™ã€‚")
                
                # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                with open(model_path, 'rb') as f:
                    model_data = f.read()
                st.download_button(
                    label="ğŸ“¥ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=model_data,
                    file_name="trained_fd_model.pkl",
                    mime="application/octet-stream",
                    help="ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¦ã€å¾Œã§æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§ä½¿ç”¨ã§ãã¾ã™"
                )

                # Evaluate & show metrics
                st.info("è§£æãƒ»æ¯”è¼ƒã‚’è¡Œã„ã¾ã™...")
                D_high, D_low, D_pred = evaluate_and_plot(high_imgs, low_imgs, model, use_gpu=use_gpu_checkbox)
                
                # çµæœã‚’session_stateã«ä¿å­˜
                st.session_state['analysis_results'] = {
                    'D_high': D_high,
                    'D_low': D_low,
                    'D_pred': D_pred,
                    'high_names': high_names,
                    'low_names': low_names,
                    'model': model,  # ãƒ¢ãƒ‡ãƒ«ã‚‚ä¿å­˜
                    'completed': True
                }
            except ValueError as e:
                st.error(str(e))
                st.stop()
            except Exception as e:
                st.error(f"âŒ **ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:** {str(e)}")
                st.stop()
        
        # çµæœãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¡¨ç¤º
        if 'analysis_results' in st.session_state and st.session_state['analysis_results'].get('completed'):
            results = st.session_state['analysis_results']
            D_high = results['D_high']
            D_low = results['D_low']
            D_pred = results['D_pred']
            high_names = results['high_names']
            low_names = results['low_names']
            
            # show detailed table
            st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ä¸€è¦§")
            
            st.markdown("""
            ### è¡¨ã®å„åˆ—ã®æ„å‘³
            
            - **No.**: ç”»åƒã®ç•ªå·
            - **ç”»åƒå**: å‡¦ç†ã—ãŸç”»åƒã®ãƒ•ã‚¡ã‚¤ãƒ«å
            - **é«˜ç”»è³ªFD**: é«˜ç”»è³ªç”»åƒã‹ã‚‰è¨ˆç®—ã—ãŸæ­£è§£ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ (**ç›®æ¨™å€¤**)
            - **ä½ç”»è³ªFD**: ä½ç”»è³ªç”»åƒã‹ã‚‰ç›´æ¥è¨ˆç®—ã—ãŸFD (**è£œæ­£ãªã—ã€é€šå¸¸ã¯ä¸æ­£ç¢º**)
            - **AIè£œæ­£FD**: AIãŒä½ç”»è³ªã‹ã‚‰äºˆæ¸¬ã—ãŸé«˜ç”»è³ªç›¸å½“ã®FD (**AIè£œæ­£å¾Œ**)
            - **ä½ç”»è³ªèª¤å·®**: |é«˜ç”»è³ªFD - ä½ç”»è³ªFD| = è£œæ­£ãªã—ã®èª¤å·® (å¤§ãã„ã»ã©ä¸æ­£ç¢º)
            - **AIè£œæ­£èª¤å·®**: |é«˜ç”»è³ªFD - AIè£œæ­£FD| = AIè£œæ­£å¾Œã®èª¤å·® (**å°ã•ã„ã»ã©å„ªç§€**)
            - **æ”¹å–„ç‡**: (ä½ç”»è³ªèª¤å·® - AIè£œæ­£èª¤å·®) / ä½ç”»è³ªèª¤å·® Ã— 100% (**é«˜ã„ã»ã©AIãŒåŠ¹æœçš„**)
            
            ğŸ’¡ **è¦‹æ–¹ã®ãƒã‚¤ãƒ³ãƒˆ**: 
            - AIè£œæ­£èª¤å·®ãŒä½ç”»è³ªèª¤å·®ã‚ˆã‚Šå°ã•ã‘ã‚Œã°AIè£œæ­£ãŒæˆåŠŸ
            - æ”¹å–„ç‡ãŒãƒ—ãƒ©ã‚¹ãªã‚‰AIã«ã‚ˆã‚‹æ”¹å–„ã‚ã‚Šã€ãƒã‚¤ãƒŠã‚¹ãªã‚‰æ‚ªåŒ–
            """)
            
            import pandas as pd
            df = pd.DataFrame({
                "No.": range(1, len(D_high)+1),
                "ç”»åƒå": [name.replace('.jpg', '').replace('IMG_', '') for name in high_names],
                "é«˜ç”»è³ªFD": [f"{x:.4f}" if x is not None else "N/A" for x in D_high],
                "ä½ç”»è³ªFD": [f"{x:.4f}" if x is not None else "N/A" for x in D_low],
                "AIè£œæ­£FD": [f"{x:.4f}" if x is not None else "N/A" for x in D_pred],
                "ä½ç”»è³ªèª¤å·®": [f"{abs(h-l):.4f}" if h is not None and l is not None else "N/A" 
                          for h, l in zip(D_high, D_low)],
                "AIè£œæ­£èª¤å·®": [f"{abs(h-p):.4f}" if h is not None and p is not None else "N/A" 
                           for h, p in zip(D_high, D_pred)],
                "æ”¹å–„ç‡": [f"{((abs(h-l)-abs(h-p))/abs(h-l)*100):.1f}%" 
                        if h is not None and l is not None and p is not None and abs(h-l) > 0
                        else "N/A"
                        for h, l, p in zip(D_high, D_low, D_pred)]
            })
            
            # ã‚«ãƒ©ãƒ å¹…ã‚’æŒ‡å®šã—ã¦è¡¨ç¤º
            st.dataframe(
                df,
                use_container_width=True,
                hide_index=True,
                height=350,
                column_config={
                    "No.": st.column_config.NumberColumn("No.", width="small"),
                    "ç”»åƒå": st.column_config.TextColumn("ç”»åƒå", width="medium"),
                    "é«˜ç”»è³ªFD": st.column_config.TextColumn("é«˜ç”»è³ªFD", width="small"),
                    "ä½ç”»è³ªFD": st.column_config.TextColumn("ä½ç”»è³ªFD", width="small"),
                    "AIè£œæ­£FD": st.column_config.TextColumn("AIè£œæ­£FD", width="small"),
                    "ä½ç”»è³ªèª¤å·®": st.column_config.TextColumn("ä½ç”»è³ªèª¤å·®", width="small"),
                    "AIè£œæ­£èª¤å·®": st.column_config.TextColumn("AIè£œæ­£èª¤å·®", width="small"),
                    "æ”¹å–„ç‡": st.column_config.TextColumn("æ”¹å–„ç‡", width="small"),
                }
            )
            
            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
            with st.expander("ğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼ - å…¨ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±"):
                st.markdown("""
                **å„çµ±è¨ˆã®æ„å‘³:**
                - **å¹³å‡**: å…¨ç”»åƒã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®å¹³å‡å€¤
                - **æ¨™æº–åå·®**: ãƒ‡ãƒ¼ã‚¿ã®ã°ã‚‰ã¤ã (å°ã•ã„ã»ã©å‡ä¸€ã€å¤§ãã„ã»ã©å¤šæ§˜)
                - **æœ€å°/æœ€å¤§**: ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²
                
                ğŸ’¡ **æ¯”è¼ƒã®ãƒã‚¤ãƒ³ãƒˆ**: AIè£œæ­£FDã®çµ±è¨ˆãŒé«˜ç”»è³ªFDã«è¿‘ã„ã»ã©ã€AIã®äºˆæ¸¬ãŒæ­£ç¢ºã§ã™ã€‚
                """)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.write("### é«˜ç”»è³ªFDçµ±è¨ˆ")
                    st.caption("(æ­£è§£å€¤)")
                    valid_high = [x for x in D_high if x is not None]
                    st.write(f"**å¹³å‡:** {np.mean(valid_high):.4f}")
                    st.write(f"**æ¨™æº–åå·®:** {np.std(valid_high):.4f}")
                    st.write(f"**æœ€å°:** {np.min(valid_high):.4f}")
                    st.write(f"**æœ€å¤§:** {np.max(valid_high):.4f}")
                
                with col2:
                    st.write("### ä½ç”»è³ªFDçµ±è¨ˆ")
                    st.caption("(è£œæ­£ãªã—)")
                    valid_low = [x for x in D_low if x is not None]
                    st.write(f"**å¹³å‡:** {np.mean(valid_low):.4f}")
                    st.write(f"**æ¨™æº–åå·®:** {np.std(valid_low):.4f}")
                    st.write(f"**æœ€å°:** {np.min(valid_low):.4f}")
                    st.write(f"**æœ€å¤§:** {np.max(valid_low):.4f}")
                
                with col3:
                    st.write("### AIè£œæ­£FDçµ±è¨ˆ")
                    st.caption("(AIäºˆæ¸¬å€¤)")
                    valid_pred = [x for x in D_pred if x is not None]
                    st.write(f"**å¹³å‡:** {np.mean(valid_pred):.4f}")
                    st.write(f"**æ¨™æº–åå·®:** {np.std(valid_pred):.4f}")
                    st.write(f"**æœ€å°:** {np.min(valid_pred):.4f}")
                    st.write(f"**æœ€å¤§:** {np.max(valid_pred):.4f}")

    else:
        st.info("ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ãƒ¢ãƒ¼ãƒ‰: ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’å…¥åŠ›ã™ã‚‹ã¨è‡ªå‹•çš„ã«ç”»åƒãƒšã‚¢ã‚’æ¤œå‡ºã—ã¾ã™\nğŸ“¤ æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰: é«˜ç”»è³ªã¨ä½ç”»è³ªã®ãƒšã‚¢ç”»åƒã‚’åŒæ•°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    app()
