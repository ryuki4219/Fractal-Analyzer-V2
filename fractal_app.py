import streamlit as st
import cv2
<<<<<<< Updated upstream
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
from datetime import datetime
import io
import base64

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Meiryo']
plt.rcParams['axes.unicode_minus'] = False
=======
from PIL import Image
import io
import os
import base64
from datetime import datetime
import joblib
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, accuracy_score
import matplotlib.pyplot as plt
from skimage import filters, color
from skimage.feature import canny

# matplotlibã§æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®šï¼ˆæ–‡å­—åŒ–ã‘å¯¾ç­–ï¼‰
import matplotlib
matplotlib.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False  # ãƒã‚¤ãƒŠã‚¹è¨˜å·ã®æ–‡å­—åŒ–ã‘å¯¾ç­–
>>>>>>> Stashed changes

# ----------------------------
# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé–¢æ•°
# ----------------------------
def augment_image(image):
    """ç”»åƒã‚’å›è»¢ãƒ»åè»¢ã—ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™"""
    augmented = [image]
    # 90åº¦å›è»¢
    augmented.append(cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE))
    # 180åº¦å›è»¢
    augmented.append(cv2.rotate(image, cv2.ROTATE_180))
    # 270åº¦å›è»¢
    augmented.append(cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE))
    # æ°´å¹³åè»¢
    augmented.append(cv2.flip(image, 1))
    # å‚ç›´åè»¢
    augmented.append(cv2.flip(image, 0))
    return augmented

<<<<<<< Updated upstream
# ----------------------------
# AIè£œå®Œãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå¯¾å¿œï¼‰
# ----------------------------
def train_image_enhancer(low_quality_images, high_quality_images, use_augmentation=True):
    X, y = [], []
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®é©ç”¨
    if use_augmentation:
        aug_low, aug_high = [], []
        for low, high in zip(low_quality_images, high_quality_images):
            aug_low.extend(augment_image(low))
            aug_high.extend(augment_image(high))
        low_quality_images = aug_low
        high_quality_images = aug_high
    
    for low, high in zip(low_quality_images, high_quality_images):
        low_flat = low.flatten() / 255.0
        high_flat = high.flatten() / 255.0
        X.append(low_flat)
        y.append(high_flat)
    
    X = np.array(X)
    y = np.array(y)
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    if len(X) > 1:
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    else:
        X_train, X_test, y_train, y_test = X, X, y, y
    
    model = RandomForestRegressor(n_estimators=50, max_depth=15, random_state=42)
    model.fit(X_train, y_train)
    
    # ç²¾åº¦è©•ä¾¡
    if len(X_test) > 0:
        score = model.score(X_test, y_test)
    else:
        score = 0.0
    
    return model, score

def enhance_image(model, low_quality_image):
    low_flat = low_quality_image.flatten() / 255.0
    pred = model.predict([low_flat])[0]
    enhanced = np.clip(pred * 255, 0, 255).reshape(low_quality_image.shape).astype(np.uint8)
    return enhanced

# ----------------------------
# ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ(ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆæ³•ãƒ»é–¾å€¤èª¿æ•´å¯¾å¿œ)
# ----------------------------
def fractal_dimension(image, threshold_value=128, use_otsu=False):
    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # é–¾å€¤å‡¦ç†
    if use_otsu:
        threshold_value, binary = cv2.threshold(image_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    else:
        _, binary = cv2.threshold(image_gray, threshold_value, 255, cv2.THRESH_BINARY)

    sizes = 2 ** np.arange(1, 8)
    counts = []
    for size in sizes:
        resized = cv2.resize(binary, (binary.shape[1] // size, binary.shape[0] // size))
        count = np.sum(resized > 0)
        counts.append(count)

    # ç•°å¸¸æ¤œå‡º
    if all(c == 0 for c in counts) or all(c == counts[0] for c in counts):
        return None, sizes, counts, binary, threshold_value  # ç„¡åŠ¹ãªçµæœ
    
    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)
    fractal_dim = -coeffs[0]
    
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    if fractal_dim < 0 or fractal_dim > 3:
        return None, sizes, counts, binary, threshold_value  # ç„¡åŠ¹ãªçµæœ
    
    return fractal_dim, sizes, counts, binary, threshold_value

# ----------------------------
# 3Dã‚°ãƒ©ãƒ•ç”Ÿæˆï¼ˆå›³ã‚’è¿”ã™ï¼‰
# ----------------------------
def generate_3d_surface(binary_image):
    h, w = binary_image.shape
    X, Y = np.meshgrid(np.arange(w), np.arange(h))
    Z = binary_image.astype(np.float32) / 255.0 * 10  # æ˜åº¦ã‚’é«˜ã•ã«å¤‰æ›
    fig = plt.figure(figsize=(8, 6))
    ax = fig.add_subplot(111, projection='3d')
    ax.plot_surface(X, Y, Z, cmap='viridis', linewidth=0, antialiased=False)
    ax.set_title("3D ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¡¨é¢ (æ˜åº¦ãƒ™ãƒ¼ã‚¹)")
    return fig

# ----------------------------
# ç©ºé–“å æœ‰ç‡ã®è¨ˆç®—ï¼ˆé»’ãƒ»ç™½ï¼‰
# ----------------------------
def calculate_occupancy(binary_image):
    total = binary_image.size
    white = np.sum(binary_image == 255)
    black = total - white
    return black / total * 100, white / total * 100

# ----------------------------
# ç”»åƒä¿å­˜ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ----------------------------
def save_image_to_bytes(image):
    """OpenCVç”»åƒã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›"""
    is_success, buffer = cv2.imencode(".png", image)
    return buffer.tobytes() if is_success else None

def fig_to_bytes(fig):
    """matplotlibã®figureã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›"""
    buf = io.BytesIO()
    fig.savefig(buf, format='png', bbox_inches='tight')
    buf.seek(0)
    return buf.getvalue()

# ----------------------------
# CSVå‡ºåŠ›é–¢æ•°
# ----------------------------
def create_results_csv(results_data):
    """è§£æçµæœã‚’CSVå½¢å¼ã§å‡ºåŠ›"""
    df = pd.DataFrame([results_data])
    return df.to_csv(index=False).encode('utf-8-sig')

# ----------------------------
# Streamlitã‚¢ãƒ—ãƒªæœ¬ä½“
# ----------------------------
st.title("ğŸ§  ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æï¼‹AIç”»åƒè£œå®Œã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚ªãƒ—ã‚·ãƒ§ãƒ³
    use_augmentation = st.checkbox("ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½¿ç”¨", value=True, 
                                   help="å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å›è»¢ãƒ»åè»¢ã—ã¦6å€ã«å¢—ã‚„ã—ã¾ã™")
    
    # é–¾å€¤è¨­å®š
    st.subheader("äºŒå€¤åŒ–è¨­å®š")
    use_otsu = st.checkbox("å¤§æ´¥ã®äºŒå€¤åŒ–ã‚’ä½¿ç”¨", value=False,
                          help="è‡ªå‹•ã§æœ€é©ãªé–¾å€¤ã‚’è¨ˆç®—ã—ã¾ã™")
    
    threshold_value = 128
    if not use_otsu:
        threshold_value = st.slider("æ‰‹å‹•é–¾å€¤", 0, 255, 128,
                                   help="äºŒå€¤åŒ–ã®é–¾å€¤ã‚’æ‰‹å‹•ã§è¨­å®šã—ã¾ã™")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
col1, col2 = st.columns(2)
with col1:
    uploaded_low = st.file_uploader("ğŸ“ ä½ç”»è³ªç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "bmp"])
=======
@st.cache_data
def load_image_from_bytes(bytes_data: bytes) -> np.ndarray:
    # ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ BGR(OpenCV) ç”»åƒã‚’è¿”ã™ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰
    img = Image.open(io.BytesIO(bytes_data)).convert('RGB')
    arr = np.array(img)[:, :, ::-1].copy()  # RGB->BGR
    return arr

def load_image_bytes(file) -> np.ndarray:
    # Streamlit ã® UploadedFile ã‹ã‚‰ BGR(OpenCV) ç”»åƒã‚’è¿”ã™
    bytes_data = file.read()
    return load_image_from_bytes(bytes_data)


@st.cache_data
def resize_image(img: np.ndarray, max_side: float):
    # æœ€é•·è¾ºãŒ max_side ã‚’è¶…ãˆã‚‹å ´åˆãƒªã‚µã‚¤ã‚ºã™ã‚‹
    h, w = img.shape[:2]
    scale = 1.0
    if max(h, w) > max_side and max_side > 0:
        scale = max_side / max(h, w)
        new_w = int(w * scale)
        new_h = int(h * scale)
        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return img, scale


@st.cache_data
def binarize_image_gray(gray: np.ndarray, thresh: float):
    # thresh ã¯ 0..255 ã®å®Ÿæ•°å€¤ã€‚ã“ã“ã§ã¯å›ºå®šé–¾å€¤ã«ã‚ˆã‚‹äºŒå€¤åŒ–
    _, bw = cv2.threshold(gray.astype('uint8'), thresh, 255, cv2.THRESH_BINARY)
    return bw


def adaptive_binarize(gray: np.ndarray, block_size: int = 11, c: int = 2):
    # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³é©å¿œé–¾å€¤ï¼ˆãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºã¯å¥‡æ•°ï¼‰
    if block_size % 2 == 0:
        block_size += 1
    block_size = max(3, block_size)
    bw = cv2.adaptiveThreshold(gray.astype('uint8'), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, block_size, c)
    return bw


def apply_gamma_correction(img: np.ndarray, gamma: float) -> np.ndarray:
    if gamma <= 0:
        return img
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(256)]).astype('uint8')
    return cv2.LUT(img, table)


def apply_brightness_offset(img: np.ndarray, beta: float) -> np.ndarray:
    if beta == 0:
        return img
    adjusted = cv2.convertScaleAbs(img, alpha=1.0, beta=beta)
    return adjusted


def apply_saturation_adjustment(img: np.ndarray, factor: float) -> np.ndarray:
    if np.isclose(factor, 1.0):
        return img
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV).astype(np.float32)
    hsv[:, :, 1] = np.clip(hsv[:, :, 1] * factor, 0, 255)
    adjusted = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
    return adjusted


def image_to_base64_png(img: np.ndarray) -> str:
    success, buffer = cv2.imencode('.png', img)
    if not success:
        return ''
    return base64.b64encode(buffer).decode('utf-8')


def build_html_report(run_timestamp: datetime, run_settings: dict, summary_df: pd.DataFrame, detail_records: list[dict]) -> str:
    timestamp_str = run_timestamp.strftime('%Y-%m-%d %H:%M:%S')
    summary_html = summary_df.to_html(index=False, classes='summary-table', float_format=lambda x: f'{x:.4f}' if isinstance(x, (int, float, np.floating)) else x)

    styles = """
    <style>
    body { font-family: 'Segoe UI', sans-serif; margin: 2rem; background-color: #f9fafb; color: #1f2933; }
    h1 { color: #0f4c81; }
    h2 { color: #1f2933; margin-top: 2rem; }
    .meta, .summary { background: #ffffff; padding: 1.5rem; border-radius: 12px; box-shadow: 0 10px 25px rgba(15,76,129,0.08); margin-bottom: 2rem; }
    .meta ul { list-style: none; padding-left: 0; }
    .meta li { margin-bottom: 0.4rem; }
    .images { display: flex; flex-wrap: wrap; gap: 1rem; }
    .images figure { flex: 1 1 200px; text-align: center; background: #f1f5f9; padding: 1rem; border-radius: 12px; }
    .images img { max-width: 100%; border-radius: 8px; box-shadow: 0 10px 20px rgba(15,76,129,0.15); }
    .badge { display: inline-block; padding: 0.2rem 0.6rem; border-radius: 999px; font-size: 0.85rem; margin-right: 0.4rem; }
    .badge-ok { background: #d1fae5; color: #047857; }
    .badge-ng { background: #fee2e2; color: #b91c1c; }
    .summary-table { width: 100%; border-collapse: collapse; }
    .summary-table th, .summary-table td { border: 1px solid #d1d5db; padding: 0.6rem; text-align: center; }
    .summary-table th { background: #e5f0ff; }
    .card { background: #ffffff; padding: 1.5rem; border-radius: 12px; box-shadow: 0 12px 30px rgba(15,76,129,0.10); margin-bottom: 2rem; }
    .metrics { margin-top: 1rem; }
    .metrics table { width: 100%; border-collapse: collapse; }
    .metrics th, .metrics td { border: 1px solid #e5e7eb; padding: 0.5rem; }
    .metrics th { background: #f3f4f6; text-align: left; }
    footer { text-align: center; color: #6b7280; margin-top: 3rem; font-size: 0.85rem; }
    </style>
    """

    meta_items = ''.join(
        f"<li><strong>{key}</strong>: {value}</li>" for key, value in run_settings.items()
    )

    detail_sections = []
    for record in detail_records:
        status_badge = '<span class="badge badge-ok">æ­£å¸¸</span>' if not record['fail_flag'] else '<span class="badge badge-ng">ç•°å¸¸</span>'
        reasons = record['fail_reasons'] if record['fail_reasons'] else 'ç‰¹è¨˜äº‹é …ãªã—'
        pred_fractal = record['pred_fractal'] if record['pred_fractal'] is not None else 'N/A'
        pred_occupancy = record['pred_occupancy'] if record['pred_occupancy'] is not None else 'N/A'
        detail_sections.append(f"""
        <section class="card">
            <h2>{record['filename']} {status_badge}</h2>
            <div class="images">
                <figure>
                    <img src="data:image/png;base64,{record['original_b64']}" alt="Original">
                    <figcaption>å…ƒç”»åƒï¼ˆãƒªã‚µã‚¤ã‚ºå¾Œï¼‰</figcaption>
                </figure>
                <figure>
                    <img src="data:image/png;base64,{record['processed_b64']}" alt="Preprocessed">
                    <figcaption>å‰å‡¦ç†å¾Œç”»åƒ</figcaption>
                </figure>
                <figure>
                    <img src="data:image/png;base64,{record['binary_b64']}" alt="Binary">
                    <figcaption>äºŒå€¤åŒ–ç”»åƒ</figcaption>
                </figure>
            </div>
            <div class="metrics">
                <table>
                    <tr><th>ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ</th><td>{record['fractal']:.4f}</td></tr>
                    <tr><th>ç©ºé–“å æœ‰ç‡</th><td>{record['occupancy']*100:.2f}%</td></tr>
                    <tr><th>äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ</th><td>{pred_fractal}</td></tr>
                    <tr><th>äºˆæ¸¬ç©ºé–“å æœ‰ç‡</th><td>{pred_occupancy}</td></tr>
                    <tr><th>é–¾å€¤æ–¹å¼</th><td>{record['threshold_mode']}</td></tr>
                    <tr><th>é–¾å€¤å€¤</th><td>{record['threshold_value'] if record['threshold_value'] is not None else 'N/A'}</td></tr>
                    <tr><th>é©å¿œé–¾å€¤ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º</th><td>{record['adaptive_block_size'] if record['adaptive_block_size'] is not None else 'N/A'}</td></tr>
                    <tr><th>é©å¿œé–¾å€¤Cå€¤</th><td>{record['adaptive_c'] if record['adaptive_c'] is not None else 'N/A'}</td></tr>
                    <tr><th>è¼åº¦è£œæ­£</th><td>{'ON' if record['gamma_applied'] else 'OFF'} / Î³={record['gamma_value'] if record['gamma_value'] is not None else '1.0'} / Î²={record['brightness_offset'] if record['brightness_offset'] is not None else 0}</td></tr>
                    <tr><th>å½©åº¦è£œæ­£</th><td>{'ON' if record['saturation_applied'] else 'OFF'} / å€ç‡={record['saturation_factor'] if record['saturation_factor'] is not None else 1.0}</td></tr>
                    <tr><th>ãƒ¡ãƒ¢</th><td>{reasons}</td></tr>
                </table>
            </div>
        </section>
        """)

    html = f"""
    <!DOCTYPE html>
    <html lang="ja">
    <head>
        <meta charset="UTF-8">
        <title>ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æãƒ¬ãƒãƒ¼ãƒˆ</title>
        {styles}
    </head>
    <body>
        <h1>ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æãƒ¬ãƒãƒ¼ãƒˆ</h1>
        <section class="meta">
            <h2>è§£æãƒ¡ã‚¿æƒ…å ±</h2>
            <ul>
                <li><strong>ç”Ÿæˆæ—¥æ™‚</strong>: {timestamp_str}</li>
                {meta_items}
            </ul>
        </section>
        <section class="summary">
            <h2>è§£æçµæœã‚µãƒãƒª</h2>
            {summary_html}
        </section>
        {''.join(detail_sections)}
        <footer>ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ : ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ç”»åƒè§£æã‚¢ãƒ—ãƒª</footer>
    </body>
    </html>
    """
    return html


@st.cache_data
def boxcount_fractal_dim(bw: np.ndarray, sizes=None):
    # ç™½(255) ã‚’å¯¾è±¡ã«ç®±ã²ãï¼ˆbox-countingæ³•ï¼‰ã§ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®š
    # bw: äºŒå€¤ç”»åƒï¼ˆ0 or 255ï¼‰
    # sizes: list of box sizes to use (pixels)
    S = bw.shape
    if sizes is None:
        max_dim = max(S)
        min_dim = min(S)
        # ç®±ã‚µã‚¤ã‚ºã¯ 2^k ç³»åˆ—ã§ç”Ÿæˆï¼ˆæœ€å°3ãƒã‚¤ãƒ³ãƒˆç¢ºä¿ï¼‰
        if min_dim >= 8:
            sizes = np.array([2 ** i for i in range(1, int(np.log2(min_dim)) + 1)])
        else:
            sizes = np.array([1, 2, 4])
        sizes = sizes[sizes <= min_dim]
        if len(sizes) < 2:
            sizes = np.array([1, 2, 4, 8])
    counts = []
    for size in sizes:
        # ç”»åƒã‚’ size x size ã®ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²ã—ã¦ã€ç™½ãŒå«ã¾ã‚Œã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ•°ãˆã‚‹
        nx = int(np.ceil(S[1] / size))
        ny = int(np.ceil(S[0] / size))
        count = 0
        for i in range(ny):
            for j in range(nx):
                y0 = i * size
                x0 = j * size
                block = bw[y0:y0 + size, x0:x0 + size]
                if np.any(block > 0):
                    count += 1
        counts.append(count)
    sizes = np.array(sizes, dtype=float)
    counts = np.array(counts, dtype=float)
    # fractal dimension D is slope of log(count) vs log(1/size)
    # linear regression via least squares
    # ã‚¼ãƒ­ã‚„è² ã®å€¤ã‚’é™¤å¤–
    valid_mask = (counts > 0) & (sizes > 0)
    if np.sum(valid_mask) < 2:
        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒ2ã¤æœªæº€ã®å ´åˆã¯ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’è¨ˆç®—ã§ããªã„
        return 0.0, sizes, counts
    
    sizes_valid = sizes[valid_mask]
    counts_valid = counts[valid_mask]
    
    logs = np.log(counts_valid)
    loginv = np.log(1.0 / sizes_valid)
    
    # å˜ç´”ãªç·šå½¢å›å¸°
    A = np.vstack([loginv, np.ones_like(loginv)]).T
    try:
        m, c = np.linalg.lstsq(A, logs, rcond=None)[0]
    except Exception:
        m = 0.0
    return float(m), sizes, counts


@st.cache_data
def compute_spatial_occupancy(bw: np.ndarray):
    # ç™½ï¼ˆ255ï¼‰ãŒå ã‚ã‚‹å‰²åˆ
    total = bw.size
    white = np.count_nonzero(bw > 0)
    return float(white / total)


@st.cache_data
def extract_features_from_image(img_bgr: np.ndarray, bw: np.ndarray, fractal_dim: float):
    # ã‚·ãƒ³ãƒ—ãƒ«ãªç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    mean_int = float(np.mean(gray))
    std_int = float(np.std(gray))
    edge = canny(gray / 255.0)
    edge_density = float(np.count_nonzero(edge) / edge.size)
    occupancy = compute_spatial_occupancy(bw)
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè‡ªèº«ã‚‚ç‰¹å¾´ã¨ã—ã¦å«ã‚ã‚‹
    return np.array([mean_int, std_int, edge_density, occupancy, fractal_dim], dtype=float)

# --- æ°¸ç¶šåŒ–ãƒ•ã‚¡ã‚¤ãƒ« & ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– ----------------------------------------
MODEL_PATH = 'model_joblib.pkl'
SCALER_PATH = 'scaler_joblib.pkl'
CLASS_PATH = 'classifier_joblib.pkl'
EXCEL_PATH = 'results.xlsx'
TRAIN_CSV = 'train_data.csv'

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰é–¢æ•°
@st.cache_resource
def load_models():
    models = {}
    if os.path.exists(MODEL_PATH) and os.path.exists(SCALER_PATH):
        try:
            models['reg'] = joblib.load(MODEL_PATH)
            models['scaler'] = joblib.load(SCALER_PATH)
        except Exception:
            models = {}
    if os.path.exists(CLASS_PATH):
        try:
            models['clf'] = joblib.load(CLASS_PATH)
        except Exception:
            pass
    return models


def save_models(reg, scaler, clf=None):
    joblib.dump(reg, MODEL_PATH)
    joblib.dump(scaler, SCALER_PATH)
    if clf is not None:
        joblib.dump(clf, CLASS_PATH)

# --- ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šæ‰±ã„ --------------------------------------

def append_to_train_csv(features, y_reg, is_valid):
    # features: 1d array, y_reg: dict {'fractal':..., 'occupancy':...}
    cols = ['mean_int', 'std_int', 'edge_density', 'occupancy', 'fractal_dim_feature',
            'target_fractal', 'target_occupancy', 'is_valid']
    row = list(features) + [y_reg['fractal'], y_reg['occupancy'], int(is_valid)]
    df = pd.DataFrame([row], columns=cols)
    if os.path.exists(TRAIN_CSV):
        df.to_csv(TRAIN_CSV, mode='a', header=False, index=False)
    else:
        df.to_csv(TRAIN_CSV, index=False)


@st.cache_data(ttl=1)  # 1ç§’é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒè¿½åŠ ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚çŸ­ã‚ï¼‰
def load_train_data():
    if os.path.exists(TRAIN_CSV):
        return pd.read_csv(TRAIN_CSV)
    else:
        return None

# --- Streamlit UI -------------------------------------------------------

st.set_page_config(layout='wide', page_title='ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ç”»åƒè§£æã‚¢ãƒ—ãƒª')
st.title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã‚’ç”¨ã„ãŸç”»åƒè§£æã‚¢ãƒ—ãƒª')

st.sidebar.header('å…¥åŠ›ã¨è§£ææ¡ä»¶')
uploaded_files = st.sidebar.file_uploader('ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰', type=['png','jpg','jpeg','bmp','tif','tiff'], accept_multiple_files=True)

st.sidebar.markdown('---')
st.sidebar.subheader('å‰å‡¦ç†ï¼ˆä»»æ„ï¼‰')
enable_brightness = st.sidebar.checkbox('è¼åº¦è£œæ­£ã‚’æœ‰åŠ¹åŒ–', value=False)
if enable_brightness:
    gamma_value = st.sidebar.slider('ã‚¬ãƒ³ãƒå€¤', min_value=0.10, max_value=3.0, value=1.0, step=0.05)
    brightness_offset = st.sidebar.slider('æ˜ã‚‹ã•èª¿æ•´ (Î²)', min_value=-100, max_value=100, value=0, step=1)
else:
    gamma_value = 1.0
    brightness_offset = 0

enable_saturation = st.sidebar.checkbox('å½©åº¦è£œæ­£ã‚’æœ‰åŠ¹åŒ–', value=False)
if enable_saturation:
    saturation_factor = st.sidebar.slider('å½©åº¦å€ç‡', min_value=0.5, max_value=2.0, value=1.0, step=0.05)
else:
    saturation_factor = 1.0

st.sidebar.markdown('---')
st.sidebar.subheader('äºŒå€¤åŒ–ãƒ»è§£ææ¡ä»¶')

if 'threshold_value' not in st.session_state:
    st.session_state['threshold_value'] = 128.0
if 'threshold_slider' not in st.session_state:
    st.session_state['threshold_slider'] = st.session_state['threshold_value']
if 'threshold_number' not in st.session_state:
    st.session_state['threshold_number'] = st.session_state['threshold_value']
if 'max_side_value' not in st.session_state:
    st.session_state['max_side_value'] = 1024.0
if 'max_side_slider' not in st.session_state:
    st.session_state['max_side_slider'] = st.session_state['max_side_value']
if 'max_side_number' not in st.session_state:
    st.session_state['max_side_number'] = st.session_state['max_side_value']
if 'adaptive_block_size' not in st.session_state:
    st.session_state['adaptive_block_size'] = 11
if 'adaptive_c' not in st.session_state:
    st.session_state['adaptive_c'] = 2


def _sync_threshold_from_slider():
    st.session_state['threshold_value'] = float(st.session_state['threshold_slider'])
    st.session_state['threshold_number'] = st.session_state['threshold_value']


def _sync_threshold_from_number():
    st.session_state['threshold_value'] = float(st.session_state['threshold_number'])
    st.session_state['threshold_slider'] = st.session_state['threshold_value']


def _sync_max_side_from_slider():
    st.session_state['max_side_value'] = float(st.session_state['max_side_slider'])
    st.session_state['max_side_number'] = st.session_state['max_side_value']


def _sync_max_side_from_number():
    st.session_state['max_side_value'] = float(st.session_state['max_side_number'])
    st.session_state['max_side_slider'] = st.session_state['max_side_value']


binarize_mode = st.sidebar.radio('äºŒå€¤åŒ–æ–¹å¼', ['å›ºå®šé–¾å€¤', 'é©å¿œé–¾å€¤'], index=0)

if binarize_mode == 'å›ºå®šé–¾å€¤':
    st.sidebar.slider('äºŒå€¤åŒ–é–¾å€¤ (ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼)', min_value=0.0, max_value=255.0, key='threshold_slider', value=float(st.session_state['threshold_value']), step=1.0, on_change=_sync_threshold_from_slider)
    st.sidebar.number_input('äºŒå€¤åŒ–é–¾å€¤ (æ•°å€¤å…¥åŠ›)', min_value=0.0, max_value=255.0, key='threshold_number', step=0.1, value=st.session_state['threshold_value'], on_change=_sync_threshold_from_number)
    thresh_value = float(st.session_state['threshold_value'])
    adaptive_block_size = None
    adaptive_c = None
else:
    adaptive_block_size = st.sidebar.slider('é©å¿œé–¾å€¤ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º (å¥‡æ•°)', min_value=3, max_value=51, step=2, value=int(st.session_state['adaptive_block_size']))
    st.session_state['adaptive_block_size'] = adaptive_block_size
    adaptive_c = st.sidebar.slider('é©å¿œé–¾å€¤ C å€¤', min_value=-20, max_value=20, value=int(st.session_state['adaptive_c']))
    st.session_state['adaptive_c'] = adaptive_c
    thresh_value = None

st.sidebar.slider('ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º (ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼)', min_value=0.0, max_value=6000.0, key='max_side_slider', value=float(st.session_state['max_side_value']), step=10.0, on_change=_sync_max_side_from_slider)
st.sidebar.number_input('ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º (æ•°å€¤å…¥åŠ›)', min_value=0.0, max_value=10000.0, key='max_side_number', step=10.0, value=st.session_state['max_side_value'], on_change=_sync_max_side_from_number)
max_side = float(st.session_state['max_side_value'])

st.sidebar.markdown('---')
# å­¦ç¿’ãƒœã‚¿ãƒ³
do_train_now = st.sidebar.button('å­¦ç¿’ã‚’å®Ÿè¡Œï¼ˆä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ï¼‰')
# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
models = load_models()

# è§£æ/å­¦ç¿’ç”¨ã®è¡¨ç¤ºé ˜åŸŸ
col1, col2 = st.columns([2,1])

with col1:
    st.header('è§£æçµæœ')
    if uploaded_files is not None and len(uploaded_files) > 0:
        results_list = []  # Excel/å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”¨
        summary_records = []  # è¡¨ç¤ºãƒ»ä¿å­˜ç”¨
        detail_records = []  # HTMLãƒ¬ãƒãƒ¼ãƒˆç”¨
        run_timestamp = datetime.now()

        for file in uploaded_files:
            st.subheader(f'ãƒ•ã‚¡ã‚¤ãƒ«: {file.name}')
            file_bytes = file.getvalue()
            if file_bytes is None or len(file_bytes) == 0:
                st.error('ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚')
                continue

            original_bgr = load_image_from_bytes(file_bytes)
            resized_bgr, scale = resize_image(original_bgr, max_side)

            processed_bgr = resized_bgr.copy()
            preprocessing_steps = []
            if enable_brightness:
                processed_bgr = apply_gamma_correction(processed_bgr, gamma_value)
                processed_bgr = apply_brightness_offset(processed_bgr, brightness_offset)
                preprocessing_steps.append(f'è¼åº¦è£œæ­£ (Î³={gamma_value:.2f}, Î²={brightness_offset})')
            if enable_saturation:
                processed_bgr = apply_saturation_adjustment(processed_bgr, saturation_factor)
                preprocessing_steps.append(f'å½©åº¦è£œæ­£ (Ã—{saturation_factor:.2f})')
            if not preprocessing_steps:
                preprocessing_steps.append('å‰å‡¦ç†ãªã—')

            gray = cv2.cvtColor(processed_bgr, cv2.COLOR_BGR2GRAY)

            if binarize_mode == 'å›ºå®šé–¾å€¤':
                bw = binarize_image_gray(gray, thresh_value)
                threshold_info = f'å›ºå®šé–¾å€¤: {thresh_value:.2f}'
                adaptive_bs = None
                adaptive_c_value = None
            else:
                adaptive_bs = adaptive_block_size
                adaptive_c_value = adaptive_c
                bw = adaptive_binarize(gray, adaptive_bs, adaptive_c_value)
                threshold_info = f'é©å¿œé–¾å€¤: block={adaptive_bs}, C={adaptive_c_value}'

            fractal_d, sizes, counts = boxcount_fractal_dim(bw)
            occupancy = compute_spatial_occupancy(bw)

            fail_flag = False
            fail_reasons: list[str] = []
            if occupancy < 0.01:
                fail_flag = True
                fail_reasons.append('ã»ã¨ã‚“ã©ç™½ãŒç„¡ã„(å æœ‰ç‡ <1%)')
            if occupancy > 0.99:
                fail_flag = True
                fail_reasons.append('ã»ã¨ã‚“ã©ç™½ã§åŸ‹ã¾ã£ã¦ã„ã‚‹(å æœ‰ç‡ >99%)')
            if not (-5.0 < fractal_d < 5.0):
                fail_flag = True
                fail_reasons.append(f'ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãŒç•°å¸¸å€¤:{fractal_d:.3f}')

            feat = extract_features_from_image(processed_bgr, bw, fractal_d)

            pred = None
            if 'reg' in models and 'scaler' in models:
                try:
                    Xs = models['scaler'].transform(feat.reshape(1, -1))
                    ypred = models['reg'].predict(Xs)[0]
                    if isinstance(ypred, (list, tuple, np.ndarray)) and len(ypred) >= 2:
                        pred = {'fractal': float(ypred[0]), 'occupancy': float(ypred[1])}
                    else:
                        pred = {'fractal': float(ypred), 'occupancy': None}
                except Exception as e:
                    st.warning(f'äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}')

            st.caption('å‡¦ç†ãƒ•ãƒ­ãƒ¼: ç”»åƒå…¥åŠ› â†’ å‰å‡¦ç† â†’ äºŒå€¤åŒ– â†’ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æ â†’ å¯è¦–åŒ–ãƒ»ä¿å­˜')

            st.subheader('ğŸ“Š è§£æçµæœ')
            metric_col1, metric_col2 = st.columns(2)
            with metric_col1:
                st.metric(
                    label='ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ',
                    value=f'{fractal_d:.4f}',
                    help='ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯ç”»åƒãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¤‡é›‘ã•ã‚’è¡¨ã™æŒ‡æ¨™ã§ã™'
                )
            with metric_col2:
                st.metric(
                    label='ç©ºé–“å æœ‰ç‡ï¼ˆç™½ãƒ”ã‚¯ã‚»ãƒ«ï¼‰',
                    value=f'{occupancy*100:.2f}%',
                    help='ç™½ãƒ”ã‚¯ã‚»ãƒ«ãŒå ã‚ã‚‹å‰²åˆã‚’ç¤ºã—ã¾ã™'
                )

            if pred is not None:
                st.write('**ğŸ¤– å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å€¤**')
                pred_col1, pred_col2 = st.columns(2)
                with pred_col1:
                    delta_fractal = None if pred['fractal'] is None else fractal_d - pred['fractal']
                    st.metric(
                        label='äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ',
                        value=f"{pred['fractal']:.4f}" if pred['fractal'] is not None else 'N/A',
                        delta=f'{delta_fractal:.4f}' if delta_fractal is not None else None,
                        delta_color='off'
                    )
                with pred_col2:
                    if pred['occupancy'] is not None:
                        delta_occupancy = (occupancy - pred['occupancy']) * 100
                        st.metric(
                            label='äºˆæ¸¬ç©ºé–“å æœ‰ç‡',
                            value=f"{pred['occupancy']*100:.2f}%",
                            delta=f'{delta_occupancy:.2f}%' if delta_occupancy is not None else None,
                            delta_color='off'
                        )

            preprocessing_text = '\n'.join([f'- {step}' for step in preprocessing_steps])
            st.markdown(f'**å‰å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—**\n{preprocessing_text}')
            st.markdown(f'**äºŒå€¤åŒ–æ¡ä»¶**: {threshold_info}')

            if fail_flag:
                st.warning('âš ï¸ è‡ªå‹•æ¤œçŸ¥: å¤±æ•—ã¨åˆ¤å®šã•ã‚Œã¾ã—ãŸã€‚ç†ç”±: ' + '; '.join(fail_reasons))
            else:
                st.success('âœ… è‡ªå‹•æ¤œçŸ¥: æ­£å¸¸ã¨åˆ¤å®š')

            st.divider()

            col_img1, col_img2, col_img3 = st.columns(3)
            with col_img1:
                st.subheader('å…ƒç”»åƒï¼ˆãƒªã‚µã‚¤ã‚ºå¾Œï¼‰')
                st.image(cv2.cvtColor(resized_bgr, cv2.COLOR_BGR2RGB), use_container_width=True)
            with col_img2:
                st.subheader('å‰å‡¦ç†å¾Œç”»åƒ')
                st.image(cv2.cvtColor(processed_bgr, cv2.COLOR_BGR2RGB), use_container_width=True)
            with col_img3:
                st.subheader('äºŒå€¤åŒ–ç”»åƒ')
                st.image(bw, use_container_width=True, clamp=True)

            st.subheader('ğŸ“ˆ ã‚°ãƒ©ãƒ•è¡¨ç¤º')
            graph_col1, graph_col2 = st.columns(2)
            with graph_col1:
                fig1, ax1 = plt.subplots()
                ax1.plot(np.log(1.0 / sizes), np.log(counts), marker='o', linewidth=2, markersize=8)
                ax1.set_xlabel('log(1/size)')
                ax1.set_ylabel('log(count)')
                ax1.set_title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æã‚°ãƒ©ãƒ•')
                ax1.grid(True, alpha=0.3)
                st.pyplot(fig1)
                plt.close(fig1)
            with graph_col2:
                fig2, ax2 = plt.subplots()
                colors = ['white', 'black']
                wedgeprops = {'edgecolor': 'gray', 'linewidth': 1}
                ax2.pie([occupancy, 1 - occupancy], labels=['ç™½ãƒ”ã‚¯ã‚»ãƒ«', 'é»’ãƒ”ã‚¯ã‚»ãƒ«'], autopct='%1.1f%%', colors=colors, wedgeprops=wedgeprops, startangle=90)
                ax2.set_title('ç©ºé–“å æœ‰ç‡ï¼ˆç™½ãƒ”ã‚¯ã‚»ãƒ« vs é»’ãƒ”ã‚¯ã‚»ãƒ«ï¼‰')
                st.pyplot(fig2)
                plt.close(fig2)

            if pred is not None:
                st.subheader('ğŸ” äºˆæ¸¬ vs å®Ÿæ¸¬ã®æ¯”è¼ƒ')
                compare_col1, compare_col2 = st.columns(2)
                with compare_col1:
                    fig3, ax3 = plt.subplots()
                    ax3.plot([0, 1], [fractal_d, pred['fractal']], marker='o', linewidth=2, markersize=10)
                    ax3.set_xticks([0, 1])
                    ax3.set_xticklabels(['å®Ÿæ¸¬', 'äºˆæ¸¬'])
                    ax3.set_ylabel('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ')
                    ax3.set_title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¯”è¼ƒ')
                    ax3.grid(True, alpha=0.3)
                    st.pyplot(fig3)
                    plt.close(fig3)
                with compare_col2:
                    if pred['occupancy'] is not None:
                        fig4, ax4 = plt.subplots()
                        ax4.plot([0, 1], [occupancy, pred['occupancy']], marker='o', linewidth=2, markersize=10)
                        ax4.set_xticks([0, 1])
                        ax4.set_xticklabels(['å®Ÿæ¸¬', 'äºˆæ¸¬'])
                        ax4.set_ylabel('å æœ‰ç‡')
                        ax4.set_title('ç©ºé–“å æœ‰ç‡ã®æ¯”è¼ƒ')
                        ax4.grid(True, alpha=0.3)
                        st.pyplot(fig4)
                        plt.close(fig4)

            rec = {
                'filename': file.name,
                'fractal': fractal_d,
                'occupancy': occupancy,
                'pred_fractal': pred['fractal'] if pred is not None else None,
                'pred_occupancy': pred['occupancy'] if (pred is not None and pred['occupancy'] is not None) else None,
                'is_valid': int(not fail_flag)
            }
            results_list.append(rec)

            summary_records.append({
                'ãƒ•ã‚¡ã‚¤ãƒ«å': file.name,
                'ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ': fractal_d,
                'ç©ºé–“å æœ‰ç‡(%)': occupancy * 100,
                'äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ': rec['pred_fractal'],
                'äºˆæ¸¬ç©ºé–“å æœ‰ç‡(%)': rec['pred_occupancy'] * 100 if rec['pred_occupancy'] is not None else None,
                'é–¾å€¤æ–¹å¼': binarize_mode,
                'é–¾å€¤å€¤': thresh_value if thresh_value is not None else None,
                'é©å¿œãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º': adaptive_bs,
                'é©å¿œCå€¤': adaptive_c_value,
                'ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º': max_side,
                'è¼åº¦è£œæ­£': 'ON' if enable_brightness else 'OFF',
                'å½©åº¦è£œæ­£': 'ON' if enable_saturation else 'OFF',
                'ç•°å¸¸åˆ¤å®š': 'æ­£å¸¸' if not fail_flag else 'å¤±æ•—',
                'ç•°å¸¸ç†ç”±': '; '.join(fail_reasons) if fail_reasons else ''
            })

            detail_records.append({
                'filename': file.name,
                'fractal': fractal_d,
                'occupancy': occupancy,
                'pred_fractal': rec['pred_fractal'],
                'pred_occupancy': rec['pred_occupancy'],
                'fail_flag': fail_flag,
                'fail_reasons': '; '.join(fail_reasons) if fail_reasons else '',
                'threshold_mode': binarize_mode,
                'threshold_value': thresh_value,
                'adaptive_block_size': adaptive_bs,
                'adaptive_c': adaptive_c_value,
                'gamma_applied': enable_brightness,
                'gamma_value': gamma_value if enable_brightness else None,
                'brightness_offset': brightness_offset if enable_brightness else None,
                'saturation_applied': enable_saturation,
                'saturation_factor': saturation_factor if enable_saturation else None,
                'original_b64': image_to_base64_png(resized_bgr),
                'processed_b64': image_to_base64_png(processed_bgr),
                'binary_b64': image_to_base64_png(bw)
            })

            append_to_train_csv(feat, {'fractal': fractal_d, 'occupancy': occupancy}, not fail_flag)

            st.markdown('---')

        if summary_records:
            summary_df = pd.DataFrame(summary_records)
            st.subheader('ğŸ“‹ è§£æã‚µãƒãƒªï¼ˆæ•°å€¤ä¸€è¦§ï¼‰')
            st.dataframe(summary_df, use_container_width=True)

            csv_data = summary_df.to_csv(index=False).encode('utf-8-sig')
            csv_filename = f'fractal_results_{run_timestamp.strftime("%Y%m%d_%H%M%S")}.csv'
            st.download_button('CSVã¨ã—ã¦ä¿å­˜', data=csv_data, file_name=csv_filename, mime='text/csv')

            run_settings = {
                'äºŒå€¤åŒ–æ–¹å¼': binarize_mode,
                'å›ºå®šé–¾å€¤': f'{thresh_value:.2f}' if thresh_value is not None else 'N/A',
                'é©å¿œãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º': adaptive_block_size if binarize_mode == 'é©å¿œé–¾å€¤' else 'N/A',
                'é©å¿œCå€¤': adaptive_c if binarize_mode == 'é©å¿œé–¾å€¤' else 'N/A',
                'ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º(px)': max_side,
                'è¼åº¦è£œæ­£': 'ON' if enable_brightness else 'OFF',
                'å½©åº¦è£œæ­£': 'ON' if enable_saturation else 'OFF'
            }
            html_report = build_html_report(run_timestamp, run_settings, summary_df, detail_records)
            html_filename = f'fractal_report_{run_timestamp.strftime("%Y%m%d_%H%M%S")}.html'
            st.download_button('HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ', data=html_report.encode('utf-8'), file_name=html_filename, mime='text/html')

        if len(results_list) >= 2:
            df_results = pd.DataFrame(results_list)
            if os.path.exists(EXCEL_PATH):
                with pd.ExcelWriter(EXCEL_PATH, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:
                    sheet_name = pd.Timestamp.now().strftime('run_%Y%m%d_%H%M%S')
                    df_results.to_excel(writer, sheet_name=sheet_name, index=False)
                st.info(f'è§£æçµæœã‚’æ—¢å­˜Excel ({EXCEL_PATH}) ã«è¿½è¨˜ã—ã¾ã—ãŸã€‚')
            else:
                df_results.to_excel(EXCEL_PATH, sheet_name='run', index=False)
                st.info(f'è§£æçµæœã‚’æ–°è¦Excel ({EXCEL_PATH}) ã«ä¿å­˜ã—ã¾ã—ãŸã€‚')

        train_df = load_train_data()
        if train_df is not None:
            st.sidebar.write(f'å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(train_df)}')
        else:
            st.sidebar.write('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚')

>>>>>>> Stashed changes
with col2:
    uploaded_high = st.file_uploader("ğŸ“ é«˜ç”»è³ªç”»åƒ(å­¦ç¿’ç”¨)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "bmp"])

if uploaded_low is not None:
    low_img = cv2.imdecode(np.frombuffer(uploaded_low.read(), np.uint8), cv2.IMREAD_COLOR)
    
    st.markdown("---")
    
    # AIç”»åƒè£œå®Œ
    enhanced_img = None
    model_score = None
    
    if uploaded_high is not None:
        high_img = cv2.imdecode(np.frombuffer(uploaded_high.read(), np.uint8), cv2.IMREAD_COLOR)
        
        with st.spinner('ğŸ¤– AIå­¦ç¿’ä¸­...'):
            model, model_score = train_image_enhancer([low_img], [high_img], use_augmentation)
            enhanced_img = enhance_image(model, low_img)
        
        st.success(f"âœ… å­¦ç¿’å®Œäº†ï¼ ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: {model_score:.3f}")
        
        # ç”»åƒæ¯”è¼ƒè¡¨ç¤º
        st.subheader("ğŸ“Š ç”»åƒæ¯”è¼ƒ")
        img_cols = st.columns(3)
        with img_cols[0]:
            st.image(cv2.cvtColor(low_img, cv2.COLOR_BGR2RGB), caption="ä½ç”»è³ª", use_container_width=True)
        with img_cols[1]:
            st.image(cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB), caption="AIè£œå®Œå¾Œ", use_container_width=True)
        with img_cols[2]:
            st.image(cv2.cvtColor(high_img, cv2.COLOR_BGR2RGB), caption="é«˜ç”»è³ª(æ­£è§£)", use_container_width=True)
        
        target_img = enhanced_img
    else:
        st.warning("âš ï¸ é«˜ç”»è³ªç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è£œå®Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        target_img = low_img
    
    st.markdown("---")
    
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æ
    st.subheader("ğŸ“ˆ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ")
    
    with st.spinner('ğŸ” è§£æä¸­...'):
        fd, sizes, counts, binary, used_threshold = fractal_dimension(target_img, threshold_value, use_otsu)
    
    # ç•°å¸¸æ¤œå‡º
    if fd is None:
        st.error("âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”»åƒã‚„é–¾å€¤ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¡¨ç¤º
    col_fd1, col_fd2 = st.columns(2)
    with col_fd1:
        st.metric("ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ", f"{fd:.4f}")
    with col_fd2:
        st.metric("ä½¿ç”¨ã—ãŸé–¾å€¤", f"{used_threshold}")
    
    # ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆã‚°ãƒ©ãƒ•
    fig_boxcount, ax = plt.subplots(figsize=(8, 5))
    ax.plot(np.log(sizes), np.log(counts), marker="o", linewidth=2, markersize=8)
    ax.set_xlabel("log(ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º)")
    ax.set_ylabel("log(ã‚«ã‚¦ãƒ³ãƒˆæ•°)")
    ax.set_title("ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆæ³•ã«ã‚ˆã‚‹ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ")
    ax.grid(True, alpha=0.3)
    st.pyplot(fig_boxcount)
    
    # äºŒå€¤åŒ–ç”»åƒè¡¨ç¤º
    st.subheader("ğŸ–¼ï¸ äºŒå€¤åŒ–ç”»åƒ")
    st.image(binary, caption="äºŒå€¤åŒ–çµæœ", use_container_width=True, clamp=True)
    
    # 3Dã‚°ãƒ©ãƒ•å‡ºåŠ›
    st.subheader("ğŸŒ 3D ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¡¨é¢")
    fig_3d = generate_3d_surface(binary)
    st.pyplot(fig_3d)
    
    # ç©ºé–“å æœ‰ç‡
    black_rate, white_rate = calculate_occupancy(binary)
    
    st.subheader("ğŸ“Š ç©ºé–“å æœ‰ç‡")
    col_occ1, col_occ2 = st.columns(2)
    with col_occ1:
        st.metric("é»’ãƒ”ã‚¯ã‚»ãƒ«", f"{black_rate:.2f}%")
    with col_occ2:
        st.metric("ç™½ãƒ”ã‚¯ã‚»ãƒ«", f"{white_rate:.2f}%")
    
    # å††ã‚°ãƒ©ãƒ•
    fig_pie, ax_pie = plt.subplots(figsize=(6, 6))
    ax_pie.pie([black_rate, white_rate], labels=["é»’", "ç™½"], autopct="%.1f%%", 
               startangle=90, colors=['#2c3e50', '#ecf0f1'])
    ax_pie.set_title("ç©ºé–“å æœ‰ç‡ã®åˆ†å¸ƒ")
    st.pyplot(fig_pie)
    
    st.markdown("---")
    
    # çµæœã®ä¿å­˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ’¾ çµæœã®ä¿å­˜")
    
    # CSVãƒ‡ãƒ¼ã‚¿ä½œæˆ
    results_data = {
        "è§£ææ—¥æ™‚": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ": fd,
        "é–¾å€¤": used_threshold,
        "å¤§æ´¥æ³•ä½¿ç”¨": use_otsu,
        "é»’ãƒ”ã‚¯ã‚»ãƒ«ç‡(%)": black_rate,
        "ç™½ãƒ”ã‚¯ã‚»ãƒ«ç‡(%)": white_rate,
        "ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ": use_augmentation,
        "ãƒ¢ãƒ‡ãƒ«ç²¾åº¦": model_score if model_score else "N/A"
    }
    
    csv_data = create_results_csv(results_data)
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    download_cols = st.columns(4)
    
    with download_cols[0]:
        st.download_button(
            label="ğŸ“„ CSVå‡ºåŠ›",
            data=csv_data,
            file_name=f"fractal_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with download_cols[1]:
        if enhanced_img is not None:
            img_bytes = save_image_to_bytes(enhanced_img)
            if img_bytes:
                st.download_button(
                    label="ğŸ–¼ï¸ è£œå®Œç”»åƒ",
                    data=img_bytes,
                    file_name=f"enhanced_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                    mime="image/png"
                )
    
    with download_cols[2]:
        graph_bytes = fig_to_bytes(fig_boxcount)
        st.download_button(
            label="ğŸ“Š ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆ",
            data=graph_bytes,
            file_name=f"boxcount_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
            mime="image/png"
        )
    
    with download_cols[3]:
        graph_3d_bytes = fig_to_bytes(fig_3d)
        st.download_button(
            label="ğŸŒ 3Dã‚°ãƒ©ãƒ•",
            data=graph_3d_bytes,
            file_name=f"3d_surface_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
            mime="image/png"
        )

else:
    st.info("ğŸ‘† ä½ç”»è³ªç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray; font-size: 12px;'>
    <p>ğŸ”¬ Fractal Analyzer V2 with AI Enhancement | Powered by Streamlit & OpenCV</p>
</div>
""", unsafe_allow_html=True)
