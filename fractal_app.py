import streamlit as st
import cv2
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
from datetime import datetime
import io
import base64

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Meiryo']
plt.rcParams['axes.unicode_minus'] = False

# ----------------------------
# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé–¢æ•°
# ----------------------------
def augment_image(image):
    """ç”»åƒã‚’å›è»¢ãƒ»åè»¢ã—ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™"""
    augmented = [image]
    # 90åº¦å›è»¢
    augmented.append(cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE))
    # 180åº¦å›è»¢
    augmented.append(cv2.rotate(image, cv2.ROTATE_180))
    # 270åº¦å›è»¢
    augmented.append(cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE))
    # æ°´å¹³åè»¢
    augmented.append(cv2.flip(image, 1))
    # å‚ç›´åè»¢
    augmented.append(cv2.flip(image, 0))
    return augmented

# ----------------------------
# AIè£œå®Œãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå¯¾å¿œï¼‰
# ----------------------------
def train_image_enhancer(low_quality_images, high_quality_images, use_augmentation=True):
    X, y = [], []
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®é©ç”¨
    if use_augmentation:
        aug_low, aug_high = [], []
        for low, high in zip(low_quality_images, high_quality_images):
            aug_low.extend(augment_image(low))
            aug_high.extend(augment_image(high))
        low_quality_images = aug_low
        high_quality_images = aug_high
    
    for low, high in zip(low_quality_images, high_quality_images):
        low_flat = low.flatten() / 255.0
        high_flat = high.flatten() / 255.0
        X.append(low_flat)
        y.append(high_flat)
    
    X = np.array(X)
    y = np.array(y)
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    if len(X) > 1:
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    else:
        X_train, X_test, y_train, y_test = X, X, y, y
    
    model = RandomForestRegressor(n_estimators=50, max_depth=15, random_state=42)
    model.fit(X_train, y_train)
    
    # ç²¾åº¦è©•ä¾¡
    if len(X_test) > 0:
        score = model.score(X_test, y_test)
    else:
        score = 0.0
    
    return model, score

def enhance_image(model, low_quality_image):
    low_flat = low_quality_image.flatten() / 255.0
    pred = model.predict([low_flat])[0]
    enhanced = np.clip(pred * 255, 0, 255).reshape(low_quality_image.shape).astype(np.uint8)
    return enhanced

# ----------------------------
# ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ(ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆæ³•ãƒ»é–¾å€¤èª¿æ•´å¯¾å¿œ)
# ----------------------------
def fractal_dimension(image, threshold_value=128, use_otsu=False):
    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # é–¾å€¤å‡¦ç†
    if use_otsu:
        threshold_value, binary = cv2.threshold(image_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    else:
        _, binary = cv2.threshold(image_gray, threshold_value, 255, cv2.THRESH_BINARY)

    sizes = 2 ** np.arange(1, 8)
    counts = []
    for size in sizes:
        resized = cv2.resize(binary, (binary.shape[1] // size, binary.shape[0] // size))
        count = np.sum(resized > 0)
        counts.append(count)

    # ç•°å¸¸æ¤œå‡º
    if all(c == 0 for c in counts) or all(c == counts[0] for c in counts):
        return None, sizes, counts, binary, threshold_value  # ç„¡åŠ¹ãªçµæœ
    
    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)
    fractal_dim = -coeffs[0]
    
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    if fractal_dim < 0 or fractal_dim > 3:
        return None, sizes, counts, binary, threshold_value  # ç„¡åŠ¹ãªçµæœ
    
    return fractal_dim, sizes, counts, binary, threshold_value

# ----------------------------
# 3Dã‚°ãƒ©ãƒ•ç”Ÿæˆï¼ˆå›³ã‚’è¿”ã™ï¼‰
# ----------------------------
def generate_3d_surface(binary_image):
    h, w = binary_image.shape
    X, Y = np.meshgrid(np.arange(w), np.arange(h))
    Z = binary_image.astype(np.float32) / 255.0 * 10  # æ˜åº¦ã‚’é«˜ã•ã«å¤‰æ›
    fig = plt.figure(figsize=(8, 6))
    ax = fig.add_subplot(111, projection='3d')
    ax.plot_surface(X, Y, Z, cmap='viridis', linewidth=0, antialiased=False)
    ax.set_title("3D ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¡¨é¢ (æ˜åº¦ãƒ™ãƒ¼ã‚¹)")
    return fig

# ----------------------------
# ç©ºé–“å æœ‰ç‡ã®è¨ˆç®—ï¼ˆé»’ãƒ»ç™½ï¼‰
# ----------------------------
def calculate_occupancy(binary_image):
    total = binary_image.size
    white = np.sum(binary_image == 255)
    black = total - white
    return black / total * 100, white / total * 100

# ----------------------------
# ç”»åƒä¿å­˜ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ----------------------------
def save_image_to_bytes(image):
    """OpenCVç”»åƒã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›"""
    is_success, buffer = cv2.imencode(".png", image)
    return buffer.tobytes() if is_success else None

def fig_to_bytes(fig):
    """matplotlibã®figureã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›"""
    buf = io.BytesIO()
    fig.savefig(buf, format='png', bbox_inches='tight')
    buf.seek(0)
    return buf.getvalue()

# ----------------------------
# CSVå‡ºåŠ›é–¢æ•°
# ----------------------------
def create_results_csv(results_data):
    """è§£æçµæœã‚’CSVå½¢å¼ã§å‡ºåŠ›"""
    df = pd.DataFrame([results_data])
    return df.to_csv(index=False).encode('utf-8-sig')

# ----------------------------
# Streamlitã‚¢ãƒ—ãƒªæœ¬ä½“
# ----------------------------
st.title("ğŸ§  ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æï¼‹AIç”»åƒè£œå®Œã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚ªãƒ—ã‚·ãƒ§ãƒ³
    use_augmentation = st.checkbox("ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½¿ç”¨", value=True, 
                                   help="å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å›è»¢ãƒ»åè»¢ã—ã¦6å€ã«å¢—ã‚„ã—ã¾ã™")
    
    # é–¾å€¤è¨­å®š
    st.subheader("äºŒå€¤åŒ–è¨­å®š")
    use_otsu = st.checkbox("å¤§æ´¥ã®äºŒå€¤åŒ–ã‚’ä½¿ç”¨", value=False,
                          help="è‡ªå‹•ã§æœ€é©ãªé–¾å€¤ã‚’è¨ˆç®—ã—ã¾ã™")
    
    threshold_value = 128
    if not use_otsu:
        threshold_value = st.slider("æ‰‹å‹•é–¾å€¤", 0, 255, 128,
                                   help="äºŒå€¤åŒ–ã®é–¾å€¤ã‚’æ‰‹å‹•ã§è¨­å®šã—ã¾ã™")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
col1, col2 = st.columns(2)
with col1:
    uploaded_low = st.file_uploader("ğŸ“ ä½ç”»è³ªç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "bmp"])
with col2:
    uploaded_high = st.file_uploader("ğŸ“ é«˜ç”»è³ªç”»åƒ(å­¦ç¿’ç”¨)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "bmp"])

if uploaded_low is not None:
    low_img = cv2.imdecode(np.frombuffer(uploaded_low.read(), np.uint8), cv2.IMREAD_COLOR)
    
    st.markdown("---")
    
    # AIç”»åƒè£œå®Œ
    enhanced_img = None
    model_score = None
    
    if uploaded_high is not None:
        high_img = cv2.imdecode(np.frombuffer(uploaded_high.read(), np.uint8), cv2.IMREAD_COLOR)
        
        with st.spinner('ğŸ¤– AIå­¦ç¿’ä¸­...'):
            model, model_score = train_image_enhancer([low_img], [high_img], use_augmentation)
            enhanced_img = enhance_image(model, low_img)
        
        st.success(f"âœ… å­¦ç¿’å®Œäº†ï¼ ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: {model_score:.3f}")
        
        # ç”»åƒæ¯”è¼ƒè¡¨ç¤º
        st.subheader("ğŸ“Š ç”»åƒæ¯”è¼ƒ")
        img_cols = st.columns(3)
        with img_cols[0]:
            st.image(cv2.cvtColor(low_img, cv2.COLOR_BGR2RGB), caption="ä½ç”»è³ª", use_container_width=True)
        with img_cols[1]:
            st.image(cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB), caption="AIè£œå®Œå¾Œ", use_container_width=True)
        with img_cols[2]:
            st.image(cv2.cvtColor(high_img, cv2.COLOR_BGR2RGB), caption="é«˜ç”»è³ª(æ­£è§£)", use_container_width=True)
        
        target_img = enhanced_img
    else:
        st.warning("âš ï¸ é«˜ç”»è³ªç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è£œå®Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        target_img = low_img
    
    st.markdown("---")
    
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æ
    st.subheader("ğŸ“ˆ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ")
    
    with st.spinner('ğŸ” è§£æä¸­...'):
        fd, sizes, counts, binary, used_threshold = fractal_dimension(target_img, threshold_value, use_otsu)
    
    # ç•°å¸¸æ¤œå‡º
    if fd is None:
        st.error("âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”»åƒã‚„é–¾å€¤ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¡¨ç¤º
    col_fd1, col_fd2 = st.columns(2)
    with col_fd1:
        st.metric("ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ", f"{fd:.4f}")
    with col_fd2:
        st.metric("ä½¿ç”¨ã—ãŸé–¾å€¤", f"{used_threshold}")
    
    # ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆã‚°ãƒ©ãƒ•
    fig_boxcount, ax = plt.subplots(figsize=(8, 5))
    ax.plot(np.log(sizes), np.log(counts), marker="o", linewidth=2, markersize=8)
    ax.set_xlabel("log(ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º)")
    ax.set_ylabel("log(ã‚«ã‚¦ãƒ³ãƒˆæ•°)")
    ax.set_title("ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆæ³•ã«ã‚ˆã‚‹ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ")
    ax.grid(True, alpha=0.3)
    st.pyplot(fig_boxcount)
    
    # äºŒå€¤åŒ–ç”»åƒè¡¨ç¤º
    st.subheader("ğŸ–¼ï¸ äºŒå€¤åŒ–ç”»åƒ")
    st.image(binary, caption="äºŒå€¤åŒ–çµæœ", use_container_width=True, clamp=True)
    
    # 3Dã‚°ãƒ©ãƒ•å‡ºåŠ›
    st.subheader("ğŸŒ 3D ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¡¨é¢")
    fig_3d = generate_3d_surface(binary)
    st.pyplot(fig_3d)
    
    # ç©ºé–“å æœ‰ç‡
    black_rate, white_rate = calculate_occupancy(binary)
    
    st.subheader("ğŸ“Š ç©ºé–“å æœ‰ç‡")
    col_occ1, col_occ2 = st.columns(2)
    with col_occ1:
        st.metric("é»’ãƒ”ã‚¯ã‚»ãƒ«", f"{black_rate:.2f}%")
    with col_occ2:
        st.metric("ç™½ãƒ”ã‚¯ã‚»ãƒ«", f"{white_rate:.2f}%")
    
    # å††ã‚°ãƒ©ãƒ•
    fig_pie, ax_pie = plt.subplots(figsize=(6, 6))
    ax_pie.pie([black_rate, white_rate], labels=["é»’", "ç™½"], autopct="%.1f%%", 
               startangle=90, colors=['#2c3e50', '#ecf0f1'])
    ax_pie.set_title("ç©ºé–“å æœ‰ç‡ã®åˆ†å¸ƒ")
    st.pyplot(fig_pie)
    
    st.markdown("---")
    
    # çµæœã®ä¿å­˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ’¾ çµæœã®ä¿å­˜")
    
    # CSVãƒ‡ãƒ¼ã‚¿ä½œæˆ
    results_data = {
        "è§£ææ—¥æ™‚": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ": fd,
        "é–¾å€¤": used_threshold,
        "å¤§æ´¥æ³•ä½¿ç”¨": use_otsu,
        "é»’ãƒ”ã‚¯ã‚»ãƒ«ç‡(%)": black_rate,
        "ç™½ãƒ”ã‚¯ã‚»ãƒ«ç‡(%)": white_rate,
        "ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ": use_augmentation,
        "ãƒ¢ãƒ‡ãƒ«ç²¾åº¦": model_score if model_score else "N/A"
    }
    
    csv_data = create_results_csv(results_data)
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    download_cols = st.columns(4)
    
    with download_cols[0]:
        st.download_button(
            label="ğŸ“„ CSVå‡ºåŠ›",
            data=csv_data,
            file_name=f"fractal_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with download_cols[1]:
        if enhanced_img is not None:
            img_bytes = save_image_to_bytes(enhanced_img)
            if img_bytes:
                st.download_button(
                    label="ğŸ–¼ï¸ è£œå®Œç”»åƒ",
                    data=img_bytes,
                    file_name=f"enhanced_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                    mime="image/png"
                )
    
    with download_cols[2]:
        graph_bytes = fig_to_bytes(fig_boxcount)
        st.download_button(
            label="ğŸ“Š ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆ",
            data=graph_bytes,
            file_name=f"boxcount_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
            mime="image/png"
        )
    
    with download_cols[3]:
        graph_3d_bytes = fig_to_bytes(fig_3d)
        st.download_button(
            label="ğŸŒ 3Dã‚°ãƒ©ãƒ•",
            data=graph_3d_bytes,
            file_name=f"3d_surface_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
            mime="image/png"
        )

else:
    st.info("ğŸ‘† ä½ç”»è³ªç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray; font-size: 12px;'>
    <p>ğŸ”¬ Fractal Analyzer V2 with AI Enhancement | Powered by Streamlit & OpenCV</p>
</div>
""", unsafe_allow_html=True)
