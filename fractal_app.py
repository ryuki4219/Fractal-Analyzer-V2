"""
Streamlit ã‚¢ãƒ—ãƒª: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã‚’ç”¨ã„ãŸç”»åƒè§£æã‚¢ãƒ—ãƒª
æ©Ÿèƒ½:
- é–¾å€¤ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼/æ•°å€¤å…¥åŠ›ï¼‰ã¨ãƒªã‚µã‚¤ã‚ºä¸Šé™ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼/æ•°å€¤å…¥åŠ›ï¼‰ã®2æ–¹å¼ã‚’ç”¨æ„
- ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã§å‡ºåŠ›ã€ç©ºé–“å æœ‰ç‡ã¯å††ã‚°ãƒ©ãƒ•ã§å‡ºåŠ›
- å­¦ç¿’æ©Ÿèƒ½: è§£æçµæœï¼ˆæœ‰åŠ¹/å¤±æ•—ï¼‰ã‚’å­¦ç¿’ã—ã€äºˆæ¸¬çµæœã¨æ¯”è¼ƒè¡¨ç¤º
- ç•°å¸¸å€¤ãƒ»ç•°å¸¸ãªäºŒå€¤åŒ–ã®è‡ªå‹•æ¤œçŸ¥ï¼ˆå¤±æ•—æ‰±ã„ï¼‰ -> å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
- ãƒ•ã‚©ãƒ«ãƒ€å†…ç”»åƒã‚’ä¸€æ‹¬è§£æï¼ˆStreamlitã®ä»•æ§˜ä¸Šã€è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§å¯¾å¿œï¼‰
- 2æšä»¥ä¸Šè§£ææ™‚ã€è‡ªå‹•ã§Excelã«çµæœã‚’ä¿å­˜ãƒ»è¿½è¨˜
- å­¦ç¿’ä»¶æ•°ã®è¡¨ç¤ºã€è§£æç²¾åº¦ï¼ˆMAEãªã©ï¼‰ã®è¡¨ç¤º

ä½¿ã„æ–¹:
1) å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install -r requirements.txt
2) å®Ÿè¡Œ: streamlit run fractal_app.py

ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›:
- å­¦ç¿’ãƒ¢ãƒ‡ãƒ«: model_joblib.pkl
- ã‚¹ã‚±ãƒ¼ãƒ©: scaler_joblib.pkl
- çµæœExcel: results.xlsx

æ³¨æ„: æœ¬ä¾‹ã¯å­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç°¡æ½”åŒ–ã—ã¦ã„ã¾ã™ã€‚ç”¨é€”ã«å¿œã˜ã¦ç‰¹å¾´é‡ã‚„ãƒ¢ãƒ‡ãƒ«ã‚’æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚
"""

import streamlit as st
import numpy as np
import pandas as pd
import cv2
from PIL import Image
import io
import os
import base64
from datetime import datetime
import joblib
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, accuracy_score
import matplotlib.pyplot as plt
from skimage import filters, color
from skimage.feature import canny

# matplotlibã§æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®šï¼ˆæ–‡å­—åŒ–ã‘å¯¾ç­–ï¼‰
import matplotlib
matplotlib.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False  # ãƒã‚¤ãƒŠã‚¹è¨˜å·ã®æ–‡å­—åŒ–ã‘å¯¾ç­–

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° -------------------------------------------------

@st.cache_data
def load_image_from_bytes(bytes_data: bytes) -> np.ndarray:
    # ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ BGR(OpenCV) ç”»åƒã‚’è¿”ã™ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰
    img = Image.open(io.BytesIO(bytes_data)).convert('RGB')
    arr = np.array(img)[:, :, ::-1].copy()  # RGB->BGR
    return arr

def load_image_bytes(file) -> np.ndarray:
    # Streamlit ã® UploadedFile ã‹ã‚‰ BGR(OpenCV) ç”»åƒã‚’è¿”ã™
    bytes_data = file.read()
    return load_image_from_bytes(bytes_data)


@st.cache_data
def resize_image(img: np.ndarray, max_side: float):
    # æœ€é•·è¾ºãŒ max_side ã‚’è¶…ãˆã‚‹å ´åˆãƒªã‚µã‚¤ã‚ºã™ã‚‹
    h, w = img.shape[:2]
    scale = 1.0
    if max(h, w) > max_side and max_side > 0:
        scale = max_side / max(h, w)
        new_w = int(w * scale)
        new_h = int(h * scale)
        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return img, scale


@st.cache_data
def binarize_image_gray(gray: np.ndarray, thresh: float):
    # thresh ã¯ 0..255 ã®å®Ÿæ•°å€¤ã€‚ã“ã“ã§ã¯å›ºå®šé–¾å€¤ã«ã‚ˆã‚‹äºŒå€¤åŒ–
    _, bw = cv2.threshold(gray.astype('uint8'), thresh, 255, cv2.THRESH_BINARY)
    return bw


def adaptive_binarize(gray: np.ndarray, block_size: int = 11, c: int = 2):
    # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³é©å¿œé–¾å€¤ï¼ˆãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºã¯å¥‡æ•°ï¼‰
    if block_size % 2 == 0:
        block_size += 1
    block_size = max(3, block_size)
    bw = cv2.adaptiveThreshold(gray.astype('uint8'), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, block_size, c)
    return bw


def apply_gamma_correction(img: np.ndarray, gamma: float) -> np.ndarray:
    if gamma <= 0:
        return img
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(256)]).astype('uint8')
    return cv2.LUT(img, table)


def apply_brightness_offset(img: np.ndarray, beta: float) -> np.ndarray:
    if beta == 0:
        return img
    adjusted = cv2.convertScaleAbs(img, alpha=1.0, beta=beta)
    return adjusted


def apply_saturation_adjustment(img: np.ndarray, factor: float) -> np.ndarray:
    if np.isclose(factor, 1.0):
        return img
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV).astype(np.float32)
    hsv[:, :, 1] = np.clip(hsv[:, :, 1] * factor, 0, 255)
    adjusted = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
    return adjusted


def image_to_base64_png(img: np.ndarray) -> str:
    success, buffer = cv2.imencode('.png', img)
    if not success:
        return ''
    return base64.b64encode(buffer).decode('utf-8')


def build_html_report(run_timestamp: datetime, run_settings: dict, summary_df: pd.DataFrame, detail_records: list[dict]) -> str:
    timestamp_str = run_timestamp.strftime('%Y-%m-%d %H:%M:%S')
    summary_html = summary_df.to_html(index=False, classes='summary-table', float_format=lambda x: f'{x:.4f}' if isinstance(x, (int, float, np.floating)) else x)

    styles = """
    <style>
    body { font-family: 'Segoe UI', sans-serif; margin: 2rem; background-color: #f9fafb; color: #1f2933; }
    h1 { color: #0f4c81; }
    h2 { color: #1f2933; margin-top: 2rem; }
    .meta, .summary { background: #ffffff; padding: 1.5rem; border-radius: 12px; box-shadow: 0 10px 25px rgba(15,76,129,0.08); margin-bottom: 2rem; }
    .meta ul { list-style: none; padding-left: 0; }
    .meta li { margin-bottom: 0.4rem; }
    .images { display: flex; flex-wrap: wrap; gap: 1rem; }
    .images figure { flex: 1 1 200px; text-align: center; background: #f1f5f9; padding: 1rem; border-radius: 12px; }
    .images img { max-width: 100%; border-radius: 8px; box-shadow: 0 10px 20px rgba(15,76,129,0.15); }
    .badge { display: inline-block; padding: 0.2rem 0.6rem; border-radius: 999px; font-size: 0.85rem; margin-right: 0.4rem; }
    .badge-ok { background: #d1fae5; color: #047857; }
    .badge-ng { background: #fee2e2; color: #b91c1c; }
    .summary-table { width: 100%; border-collapse: collapse; }
    .summary-table th, .summary-table td { border: 1px solid #d1d5db; padding: 0.6rem; text-align: center; }
    .summary-table th { background: #e5f0ff; }
    .card { background: #ffffff; padding: 1.5rem; border-radius: 12px; box-shadow: 0 12px 30px rgba(15,76,129,0.10); margin-bottom: 2rem; }
    .metrics { margin-top: 1rem; }
    .metrics table { width: 100%; border-collapse: collapse; }
    .metrics th, .metrics td { border: 1px solid #e5e7eb; padding: 0.5rem; }
    .metrics th { background: #f3f4f6; text-align: left; }
    footer { text-align: center; color: #6b7280; margin-top: 3rem; font-size: 0.85rem; }
    </style>
    """

    meta_items = ''.join(
        f"<li><strong>{key}</strong>: {value}</li>" for key, value in run_settings.items()
    )

    detail_sections = []
    for record in detail_records:
        status_badge = '<span class="badge badge-ok">æ­£å¸¸</span>' if not record['fail_flag'] else '<span class="badge badge-ng">ç•°å¸¸</span>'
        reasons = record['fail_reasons'] if record['fail_reasons'] else 'ç‰¹è¨˜äº‹é …ãªã—'
        pred_fractal = record['pred_fractal'] if record['pred_fractal'] is not None else 'N/A'
        pred_occupancy = record['pred_occupancy'] if record['pred_occupancy'] is not None else 'N/A'
        detail_sections.append(f"""
        <section class="card">
            <h2>{record['filename']} {status_badge}</h2>
            <div class="images">
                <figure>
                    <img src="data:image/png;base64,{record['original_b64']}" alt="Original">
                    <figcaption>å…ƒç”»åƒï¼ˆãƒªã‚µã‚¤ã‚ºå¾Œï¼‰</figcaption>
                </figure>
                <figure>
                    <img src="data:image/png;base64,{record['processed_b64']}" alt="Preprocessed">
                    <figcaption>å‰å‡¦ç†å¾Œç”»åƒ</figcaption>
                </figure>
                <figure>
                    <img src="data:image/png;base64,{record['binary_b64']}" alt="Binary">
                    <figcaption>äºŒå€¤åŒ–ç”»åƒ</figcaption>
                </figure>
            </div>
            <div class="metrics">
                <table>
                    <tr><th>ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ</th><td>{record['fractal']:.4f}</td></tr>
                    <tr><th>ç©ºé–“å æœ‰ç‡</th><td>{record['occupancy']*100:.2f}%</td></tr>
                    <tr><th>äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ</th><td>{pred_fractal}</td></tr>
                    <tr><th>äºˆæ¸¬ç©ºé–“å æœ‰ç‡</th><td>{pred_occupancy}</td></tr>
                    <tr><th>é–¾å€¤æ–¹å¼</th><td>{record['threshold_mode']}</td></tr>
                    <tr><th>é–¾å€¤å€¤</th><td>{record['threshold_value'] if record['threshold_value'] is not None else 'N/A'}</td></tr>
                    <tr><th>é©å¿œé–¾å€¤ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º</th><td>{record['adaptive_block_size'] if record['adaptive_block_size'] is not None else 'N/A'}</td></tr>
                    <tr><th>é©å¿œé–¾å€¤Cå€¤</th><td>{record['adaptive_c'] if record['adaptive_c'] is not None else 'N/A'}</td></tr>
                    <tr><th>è¼åº¦è£œæ­£</th><td>{'ON' if record['gamma_applied'] else 'OFF'} / Î³={record['gamma_value'] if record['gamma_value'] is not None else '1.0'} / Î²={record['brightness_offset'] if record['brightness_offset'] is not None else 0}</td></tr>
                    <tr><th>å½©åº¦è£œæ­£</th><td>{'ON' if record['saturation_applied'] else 'OFF'} / å€ç‡={record['saturation_factor'] if record['saturation_factor'] is not None else 1.0}</td></tr>
                    <tr><th>ãƒ¡ãƒ¢</th><td>{reasons}</td></tr>
                </table>
            </div>
        </section>
        """)

    html = f"""
    <!DOCTYPE html>
    <html lang="ja">
    <head>
        <meta charset="UTF-8">
        <title>ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æãƒ¬ãƒãƒ¼ãƒˆ</title>
        {styles}
    </head>
    <body>
        <h1>ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æãƒ¬ãƒãƒ¼ãƒˆ</h1>
        <section class="meta">
            <h2>è§£æãƒ¡ã‚¿æƒ…å ±</h2>
            <ul>
                <li><strong>ç”Ÿæˆæ—¥æ™‚</strong>: {timestamp_str}</li>
                {meta_items}
            </ul>
        </section>
        <section class="summary">
            <h2>è§£æçµæœã‚µãƒãƒª</h2>
            {summary_html}
        </section>
        {''.join(detail_sections)}
        <footer>ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ : ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ç”»åƒè§£æã‚¢ãƒ—ãƒª</footer>
    </body>
    </html>
    """
    return html


@st.cache_data
def boxcount_fractal_dim(bw: np.ndarray, sizes=None):
    # ç™½(255) ã‚’å¯¾è±¡ã«ç®±ã²ãï¼ˆbox-countingæ³•ï¼‰ã§ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’æ¨å®š
    # bw: äºŒå€¤ç”»åƒï¼ˆ0 or 255ï¼‰
    # sizes: list of box sizes to use (pixels)
    S = bw.shape
    if sizes is None:
        max_dim = max(S)
        min_dim = min(S)
        # ç®±ã‚µã‚¤ã‚ºã¯ 2^k ç³»åˆ—ã§ç”Ÿæˆï¼ˆæœ€å°3ãƒã‚¤ãƒ³ãƒˆç¢ºä¿ï¼‰
        if min_dim >= 8:
            sizes = np.array([2 ** i for i in range(1, int(np.log2(min_dim)) + 1)])
        else:
            sizes = np.array([1, 2, 4])
        sizes = sizes[sizes <= min_dim]
        if len(sizes) < 2:
            sizes = np.array([1, 2, 4, 8])
    counts = []
    for size in sizes:
        # ç”»åƒã‚’ size x size ã®ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²ã—ã¦ã€ç™½ãŒå«ã¾ã‚Œã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ•°ãˆã‚‹
        nx = int(np.ceil(S[1] / size))
        ny = int(np.ceil(S[0] / size))
        count = 0
        for i in range(ny):
            for j in range(nx):
                y0 = i * size
                x0 = j * size
                block = bw[y0:y0 + size, x0:x0 + size]
                if np.any(block > 0):
                    count += 1
        counts.append(count)
    sizes = np.array(sizes, dtype=float)
    counts = np.array(counts, dtype=float)
    # fractal dimension D is slope of log(count) vs log(1/size)
    # linear regression via least squares
    # ã‚¼ãƒ­ã‚„è² ã®å€¤ã‚’é™¤å¤–
    valid_mask = (counts > 0) & (sizes > 0)
    if np.sum(valid_mask) < 2:
        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒ2ã¤æœªæº€ã®å ´åˆã¯ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’è¨ˆç®—ã§ããªã„
        return 0.0, sizes, counts
    
    sizes_valid = sizes[valid_mask]
    counts_valid = counts[valid_mask]
    
    logs = np.log(counts_valid)
    loginv = np.log(1.0 / sizes_valid)
    
    # å˜ç´”ãªç·šå½¢å›å¸°
    A = np.vstack([loginv, np.ones_like(loginv)]).T
    try:
        m, c = np.linalg.lstsq(A, logs, rcond=None)[0]
    except Exception:
        m = 0.0
    return float(m), sizes, counts


@st.cache_data
def compute_spatial_occupancy(bw: np.ndarray):
    # ç™½ï¼ˆ255ï¼‰ãŒå ã‚ã‚‹å‰²åˆ
    total = bw.size
    white = np.count_nonzero(bw > 0)
    return float(white / total)


@st.cache_data
def extract_features_from_image(img_bgr: np.ndarray, bw: np.ndarray, fractal_dim: float):
    # ã‚·ãƒ³ãƒ—ãƒ«ãªç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    mean_int = float(np.mean(gray))
    std_int = float(np.std(gray))
    edge = canny(gray / 255.0)
    edge_density = float(np.count_nonzero(edge) / edge.size)
    occupancy = compute_spatial_occupancy(bw)
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè‡ªèº«ã‚‚ç‰¹å¾´ã¨ã—ã¦å«ã‚ã‚‹
    return np.array([mean_int, std_int, edge_density, occupancy, fractal_dim], dtype=float)

# --- æ°¸ç¶šåŒ–ãƒ•ã‚¡ã‚¤ãƒ« & ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– ----------------------------------------
MODEL_PATH = 'model_joblib.pkl'
SCALER_PATH = 'scaler_joblib.pkl'
CLASS_PATH = 'classifier_joblib.pkl'
EXCEL_PATH = 'results.xlsx'
TRAIN_CSV = 'train_data.csv'

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰é–¢æ•°
@st.cache_resource
def load_models():
    models = {}
    if os.path.exists(MODEL_PATH) and os.path.exists(SCALER_PATH):
        try:
            models['reg'] = joblib.load(MODEL_PATH)
            models['scaler'] = joblib.load(SCALER_PATH)
        except Exception:
            models = {}
    if os.path.exists(CLASS_PATH):
        try:
            models['clf'] = joblib.load(CLASS_PATH)
        except Exception:
            pass
    return models


def save_models(reg, scaler, clf=None):
    joblib.dump(reg, MODEL_PATH)
    joblib.dump(scaler, SCALER_PATH)
    if clf is not None:
        joblib.dump(clf, CLASS_PATH)

# --- ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šæ‰±ã„ --------------------------------------

def append_to_train_csv(features, y_reg, is_valid):
    # features: 1d array, y_reg: dict {'fractal':..., 'occupancy':...}
    cols = ['mean_int', 'std_int', 'edge_density', 'occupancy', 'fractal_dim_feature',
            'target_fractal', 'target_occupancy', 'is_valid']
    row = list(features) + [y_reg['fractal'], y_reg['occupancy'], int(is_valid)]
    df = pd.DataFrame([row], columns=cols)
    if os.path.exists(TRAIN_CSV):
        df.to_csv(TRAIN_CSV, mode='a', header=False, index=False)
    else:
        df.to_csv(TRAIN_CSV, index=False)


@st.cache_data(ttl=1)  # 1ç§’é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒè¿½åŠ ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚çŸ­ã‚ï¼‰
def load_train_data():
    if os.path.exists(TRAIN_CSV):
        return pd.read_csv(TRAIN_CSV)
    else:
        return None

# --- Streamlit UI -------------------------------------------------------

st.set_page_config(layout='wide', page_title='ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ç”»åƒè§£æã‚¢ãƒ—ãƒª')
st.title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã‚’ç”¨ã„ãŸç”»åƒè§£æã‚¢ãƒ—ãƒª')

st.sidebar.header('å…¥åŠ›ã¨è§£ææ¡ä»¶')
uploaded_files = st.sidebar.file_uploader('ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰', type=['png','jpg','jpeg','bmp','tif','tiff'], accept_multiple_files=True)

st.sidebar.markdown('---')
st.sidebar.subheader('å‰å‡¦ç†ï¼ˆä»»æ„ï¼‰')
enable_brightness = st.sidebar.checkbox('è¼åº¦è£œæ­£ã‚’æœ‰åŠ¹åŒ–', value=False)
if enable_brightness:
    gamma_value = st.sidebar.slider('ã‚¬ãƒ³ãƒå€¤', min_value=0.10, max_value=3.0, value=1.0, step=0.05)
    brightness_offset = st.sidebar.slider('æ˜ã‚‹ã•èª¿æ•´ (Î²)', min_value=-100, max_value=100, value=0, step=1)
else:
    gamma_value = 1.0
    brightness_offset = 0

enable_saturation = st.sidebar.checkbox('å½©åº¦è£œæ­£ã‚’æœ‰åŠ¹åŒ–', value=False)
if enable_saturation:
    saturation_factor = st.sidebar.slider('å½©åº¦å€ç‡', min_value=0.5, max_value=2.0, value=1.0, step=0.05)
else:
    saturation_factor = 1.0

st.sidebar.markdown('---')
st.sidebar.subheader('äºŒå€¤åŒ–ãƒ»è§£ææ¡ä»¶')

if 'threshold_value' not in st.session_state:
    st.session_state['threshold_value'] = 128.0
if 'threshold_slider' not in st.session_state:
    st.session_state['threshold_slider'] = st.session_state['threshold_value']
if 'threshold_number' not in st.session_state:
    st.session_state['threshold_number'] = st.session_state['threshold_value']
if 'max_side_value' not in st.session_state:
    st.session_state['max_side_value'] = 1024.0
if 'max_side_slider' not in st.session_state:
    st.session_state['max_side_slider'] = st.session_state['max_side_value']
if 'max_side_number' not in st.session_state:
    st.session_state['max_side_number'] = st.session_state['max_side_value']
if 'adaptive_block_size' not in st.session_state:
    st.session_state['adaptive_block_size'] = 11
if 'adaptive_c' not in st.session_state:
    st.session_state['adaptive_c'] = 2


def _sync_threshold_from_slider():
    st.session_state['threshold_value'] = float(st.session_state['threshold_slider'])
    st.session_state['threshold_number'] = st.session_state['threshold_value']


def _sync_threshold_from_number():
    st.session_state['threshold_value'] = float(st.session_state['threshold_number'])
    st.session_state['threshold_slider'] = st.session_state['threshold_value']


def _sync_max_side_from_slider():
    st.session_state['max_side_value'] = float(st.session_state['max_side_slider'])
    st.session_state['max_side_number'] = st.session_state['max_side_value']


def _sync_max_side_from_number():
    st.session_state['max_side_value'] = float(st.session_state['max_side_number'])
    st.session_state['max_side_slider'] = st.session_state['max_side_value']


binarize_mode = st.sidebar.radio('äºŒå€¤åŒ–æ–¹å¼', ['å›ºå®šé–¾å€¤', 'é©å¿œé–¾å€¤'], index=0)

if binarize_mode == 'å›ºå®šé–¾å€¤':
    st.sidebar.slider('äºŒå€¤åŒ–é–¾å€¤ (ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼)', min_value=0.0, max_value=255.0, key='threshold_slider', value=float(st.session_state['threshold_value']), step=1.0, on_change=_sync_threshold_from_slider)
    st.sidebar.number_input('äºŒå€¤åŒ–é–¾å€¤ (æ•°å€¤å…¥åŠ›)', min_value=0.0, max_value=255.0, key='threshold_number', step=0.1, value=st.session_state['threshold_value'], on_change=_sync_threshold_from_number)
    thresh_value = float(st.session_state['threshold_value'])
    adaptive_block_size = None
    adaptive_c = None
else:
    adaptive_block_size = st.sidebar.slider('é©å¿œé–¾å€¤ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º (å¥‡æ•°)', min_value=3, max_value=51, step=2, value=int(st.session_state['adaptive_block_size']))
    st.session_state['adaptive_block_size'] = adaptive_block_size
    adaptive_c = st.sidebar.slider('é©å¿œé–¾å€¤ C å€¤', min_value=-20, max_value=20, value=int(st.session_state['adaptive_c']))
    st.session_state['adaptive_c'] = adaptive_c
    thresh_value = None

st.sidebar.slider('ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º (ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼)', min_value=0.0, max_value=6000.0, key='max_side_slider', value=float(st.session_state['max_side_value']), step=10.0, on_change=_sync_max_side_from_slider)
st.sidebar.number_input('ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º (æ•°å€¤å…¥åŠ›)', min_value=0.0, max_value=10000.0, key='max_side_number', step=10.0, value=st.session_state['max_side_value'], on_change=_sync_max_side_from_number)
max_side = float(st.session_state['max_side_value'])

st.sidebar.markdown('---')
# å­¦ç¿’ãƒœã‚¿ãƒ³
do_train_now = st.sidebar.button('å­¦ç¿’ã‚’å®Ÿè¡Œï¼ˆä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ï¼‰')
# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
models = load_models()

# è§£æ/å­¦ç¿’ç”¨ã®è¡¨ç¤ºé ˜åŸŸ
col1, col2 = st.columns([2,1])

with col1:
    st.header('è§£æçµæœ')
    if uploaded_files is not None and len(uploaded_files) > 0:
        results_list = []  # Excel/å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”¨
        summary_records = []  # è¡¨ç¤ºãƒ»ä¿å­˜ç”¨
        detail_records = []  # HTMLãƒ¬ãƒãƒ¼ãƒˆç”¨
        run_timestamp = datetime.now()

        for file in uploaded_files:
            st.subheader(f'ãƒ•ã‚¡ã‚¤ãƒ«: {file.name}')
            file_bytes = file.getvalue()
            if file_bytes is None or len(file_bytes) == 0:
                st.error('ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚')
                continue

            original_bgr = load_image_from_bytes(file_bytes)
            resized_bgr, scale = resize_image(original_bgr, max_side)

            processed_bgr = resized_bgr.copy()
            preprocessing_steps = []
            if enable_brightness:
                processed_bgr = apply_gamma_correction(processed_bgr, gamma_value)
                processed_bgr = apply_brightness_offset(processed_bgr, brightness_offset)
                preprocessing_steps.append(f'è¼åº¦è£œæ­£ (Î³={gamma_value:.2f}, Î²={brightness_offset})')
            if enable_saturation:
                processed_bgr = apply_saturation_adjustment(processed_bgr, saturation_factor)
                preprocessing_steps.append(f'å½©åº¦è£œæ­£ (Ã—{saturation_factor:.2f})')
            if not preprocessing_steps:
                preprocessing_steps.append('å‰å‡¦ç†ãªã—')

            gray = cv2.cvtColor(processed_bgr, cv2.COLOR_BGR2GRAY)

            if binarize_mode == 'å›ºå®šé–¾å€¤':
                bw = binarize_image_gray(gray, thresh_value)
                threshold_info = f'å›ºå®šé–¾å€¤: {thresh_value:.2f}'
                adaptive_bs = None
                adaptive_c_value = None
            else:
                adaptive_bs = adaptive_block_size
                adaptive_c_value = adaptive_c
                bw = adaptive_binarize(gray, adaptive_bs, adaptive_c_value)
                threshold_info = f'é©å¿œé–¾å€¤: block={adaptive_bs}, C={adaptive_c_value}'

            fractal_d, sizes, counts = boxcount_fractal_dim(bw)
            occupancy = compute_spatial_occupancy(bw)

            fail_flag = False
            fail_reasons: list[str] = []
            if occupancy < 0.01:
                fail_flag = True
                fail_reasons.append('ã»ã¨ã‚“ã©ç™½ãŒç„¡ã„(å æœ‰ç‡ <1%)')
            if occupancy > 0.99:
                fail_flag = True
                fail_reasons.append('ã»ã¨ã‚“ã©ç™½ã§åŸ‹ã¾ã£ã¦ã„ã‚‹(å æœ‰ç‡ >99%)')
            if not (-5.0 < fractal_d < 5.0):
                fail_flag = True
                fail_reasons.append(f'ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãŒç•°å¸¸å€¤:{fractal_d:.3f}')

            feat = extract_features_from_image(processed_bgr, bw, fractal_d)

            pred = None
            if 'reg' in models and 'scaler' in models:
                try:
                    Xs = models['scaler'].transform(feat.reshape(1, -1))
                    ypred = models['reg'].predict(Xs)[0]
                    if isinstance(ypred, (list, tuple, np.ndarray)) and len(ypred) >= 2:
                        pred = {'fractal': float(ypred[0]), 'occupancy': float(ypred[1])}
                    else:
                        pred = {'fractal': float(ypred), 'occupancy': None}
                except Exception as e:
                    st.warning(f'äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}')

            st.caption('å‡¦ç†ãƒ•ãƒ­ãƒ¼: ç”»åƒå…¥åŠ› â†’ å‰å‡¦ç† â†’ äºŒå€¤åŒ– â†’ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æ â†’ å¯è¦–åŒ–ãƒ»ä¿å­˜')

            st.subheader('ğŸ“Š è§£æçµæœ')
            metric_col1, metric_col2 = st.columns(2)
            with metric_col1:
                st.metric(
                    label='ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ',
                    value=f'{fractal_d:.4f}',
                    help='ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¯ç”»åƒãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¤‡é›‘ã•ã‚’è¡¨ã™æŒ‡æ¨™ã§ã™'
                )
            with metric_col2:
                st.metric(
                    label='ç©ºé–“å æœ‰ç‡ï¼ˆç™½ãƒ”ã‚¯ã‚»ãƒ«ï¼‰',
                    value=f'{occupancy*100:.2f}%',
                    help='ç™½ãƒ”ã‚¯ã‚»ãƒ«ãŒå ã‚ã‚‹å‰²åˆã‚’ç¤ºã—ã¾ã™'
                )

            if pred is not None:
                st.write('**ğŸ¤– å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å€¤**')
                pred_col1, pred_col2 = st.columns(2)
                with pred_col1:
                    delta_fractal = None if pred['fractal'] is None else fractal_d - pred['fractal']
                    st.metric(
                        label='äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ',
                        value=f"{pred['fractal']:.4f}" if pred['fractal'] is not None else 'N/A',
                        delta=f'{delta_fractal:.4f}' if delta_fractal is not None else None,
                        delta_color='off'
                    )
                with pred_col2:
                    if pred['occupancy'] is not None:
                        delta_occupancy = (occupancy - pred['occupancy']) * 100
                        st.metric(
                            label='äºˆæ¸¬ç©ºé–“å æœ‰ç‡',
                            value=f"{pred['occupancy']*100:.2f}%",
                            delta=f'{delta_occupancy:.2f}%' if delta_occupancy is not None else None,
                            delta_color='off'
                        )

            preprocessing_text = '\n'.join([f'- {step}' for step in preprocessing_steps])
            st.markdown(f'**å‰å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—**\n{preprocessing_text}')
            st.markdown(f'**äºŒå€¤åŒ–æ¡ä»¶**: {threshold_info}')

            if fail_flag:
                st.warning('âš ï¸ è‡ªå‹•æ¤œçŸ¥: å¤±æ•—ã¨åˆ¤å®šã•ã‚Œã¾ã—ãŸã€‚ç†ç”±: ' + '; '.join(fail_reasons))
            else:
                st.success('âœ… è‡ªå‹•æ¤œçŸ¥: æ­£å¸¸ã¨åˆ¤å®š')

            st.divider()

            col_img1, col_img2, col_img3 = st.columns(3)
            with col_img1:
                st.subheader('å…ƒç”»åƒï¼ˆãƒªã‚µã‚¤ã‚ºå¾Œï¼‰')
                st.image(cv2.cvtColor(resized_bgr, cv2.COLOR_BGR2RGB), use_container_width=True)
            with col_img2:
                st.subheader('å‰å‡¦ç†å¾Œç”»åƒ')
                st.image(cv2.cvtColor(processed_bgr, cv2.COLOR_BGR2RGB), use_container_width=True)
            with col_img3:
                st.subheader('äºŒå€¤åŒ–ç”»åƒ')
                st.image(bw, use_container_width=True, clamp=True)

            st.subheader('ğŸ“ˆ ã‚°ãƒ©ãƒ•è¡¨ç¤º')
            graph_col1, graph_col2 = st.columns(2)
            with graph_col1:
                fig1, ax1 = plt.subplots()
                ax1.plot(np.log(1.0 / sizes), np.log(counts), marker='o', linewidth=2, markersize=8)
                ax1.set_xlabel('log(1/size)')
                ax1.set_ylabel('log(count)')
                ax1.set_title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æã‚°ãƒ©ãƒ•')
                ax1.grid(True, alpha=0.3)
                st.pyplot(fig1)
                plt.close(fig1)
            with graph_col2:
                fig2, ax2 = plt.subplots()
                colors = ['white', 'black']
                wedgeprops = {'edgecolor': 'gray', 'linewidth': 1}
                ax2.pie([occupancy, 1 - occupancy], labels=['ç™½ãƒ”ã‚¯ã‚»ãƒ«', 'é»’ãƒ”ã‚¯ã‚»ãƒ«'], autopct='%1.1f%%', colors=colors, wedgeprops=wedgeprops, startangle=90)
                ax2.set_title('ç©ºé–“å æœ‰ç‡ï¼ˆç™½ãƒ”ã‚¯ã‚»ãƒ« vs é»’ãƒ”ã‚¯ã‚»ãƒ«ï¼‰')
                st.pyplot(fig2)
                plt.close(fig2)

            if pred is not None:
                st.subheader('ğŸ” äºˆæ¸¬ vs å®Ÿæ¸¬ã®æ¯”è¼ƒ')
                compare_col1, compare_col2 = st.columns(2)
                with compare_col1:
                    fig3, ax3 = plt.subplots()
                    ax3.plot([0, 1], [fractal_d, pred['fractal']], marker='o', linewidth=2, markersize=10)
                    ax3.set_xticks([0, 1])
                    ax3.set_xticklabels(['å®Ÿæ¸¬', 'äºˆæ¸¬'])
                    ax3.set_ylabel('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ')
                    ax3.set_title('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¯”è¼ƒ')
                    ax3.grid(True, alpha=0.3)
                    st.pyplot(fig3)
                    plt.close(fig3)
                with compare_col2:
                    if pred['occupancy'] is not None:
                        fig4, ax4 = plt.subplots()
                        ax4.plot([0, 1], [occupancy, pred['occupancy']], marker='o', linewidth=2, markersize=10)
                        ax4.set_xticks([0, 1])
                        ax4.set_xticklabels(['å®Ÿæ¸¬', 'äºˆæ¸¬'])
                        ax4.set_ylabel('å æœ‰ç‡')
                        ax4.set_title('ç©ºé–“å æœ‰ç‡ã®æ¯”è¼ƒ')
                        ax4.grid(True, alpha=0.3)
                        st.pyplot(fig4)
                        plt.close(fig4)

            rec = {
                'filename': file.name,
                'fractal': fractal_d,
                'occupancy': occupancy,
                'pred_fractal': pred['fractal'] if pred is not None else None,
                'pred_occupancy': pred['occupancy'] if (pred is not None and pred['occupancy'] is not None) else None,
                'is_valid': int(not fail_flag)
            }
            results_list.append(rec)

            summary_records.append({
                'ãƒ•ã‚¡ã‚¤ãƒ«å': file.name,
                'ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ': fractal_d,
                'ç©ºé–“å æœ‰ç‡(%)': occupancy * 100,
                'äºˆæ¸¬ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ': rec['pred_fractal'],
                'äºˆæ¸¬ç©ºé–“å æœ‰ç‡(%)': rec['pred_occupancy'] * 100 if rec['pred_occupancy'] is not None else None,
                'é–¾å€¤æ–¹å¼': binarize_mode,
                'é–¾å€¤å€¤': thresh_value if thresh_value is not None else None,
                'é©å¿œãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º': adaptive_bs,
                'é©å¿œCå€¤': adaptive_c_value,
                'ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º': max_side,
                'è¼åº¦è£œæ­£': 'ON' if enable_brightness else 'OFF',
                'å½©åº¦è£œæ­£': 'ON' if enable_saturation else 'OFF',
                'ç•°å¸¸åˆ¤å®š': 'æ­£å¸¸' if not fail_flag else 'å¤±æ•—',
                'ç•°å¸¸ç†ç”±': '; '.join(fail_reasons) if fail_reasons else ''
            })

            detail_records.append({
                'filename': file.name,
                'fractal': fractal_d,
                'occupancy': occupancy,
                'pred_fractal': rec['pred_fractal'],
                'pred_occupancy': rec['pred_occupancy'],
                'fail_flag': fail_flag,
                'fail_reasons': '; '.join(fail_reasons) if fail_reasons else '',
                'threshold_mode': binarize_mode,
                'threshold_value': thresh_value,
                'adaptive_block_size': adaptive_bs,
                'adaptive_c': adaptive_c_value,
                'gamma_applied': enable_brightness,
                'gamma_value': gamma_value if enable_brightness else None,
                'brightness_offset': brightness_offset if enable_brightness else None,
                'saturation_applied': enable_saturation,
                'saturation_factor': saturation_factor if enable_saturation else None,
                'original_b64': image_to_base64_png(resized_bgr),
                'processed_b64': image_to_base64_png(processed_bgr),
                'binary_b64': image_to_base64_png(bw)
            })

            append_to_train_csv(feat, {'fractal': fractal_d, 'occupancy': occupancy}, not fail_flag)

            st.markdown('---')

        if summary_records:
            summary_df = pd.DataFrame(summary_records)
            st.subheader('ğŸ“‹ è§£æã‚µãƒãƒªï¼ˆæ•°å€¤ä¸€è¦§ï¼‰')
            st.dataframe(summary_df, use_container_width=True)

            csv_data = summary_df.to_csv(index=False).encode('utf-8-sig')
            csv_filename = f'fractal_results_{run_timestamp.strftime("%Y%m%d_%H%M%S")}.csv'
            st.download_button('CSVã¨ã—ã¦ä¿å­˜', data=csv_data, file_name=csv_filename, mime='text/csv')

            run_settings = {
                'äºŒå€¤åŒ–æ–¹å¼': binarize_mode,
                'å›ºå®šé–¾å€¤': f'{thresh_value:.2f}' if thresh_value is not None else 'N/A',
                'é©å¿œãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º': adaptive_block_size if binarize_mode == 'é©å¿œé–¾å€¤' else 'N/A',
                'é©å¿œCå€¤': adaptive_c if binarize_mode == 'é©å¿œé–¾å€¤' else 'N/A',
                'ãƒªã‚µã‚¤ã‚ºæœ€å¤§è¾º(px)': max_side,
                'è¼åº¦è£œæ­£': 'ON' if enable_brightness else 'OFF',
                'å½©åº¦è£œæ­£': 'ON' if enable_saturation else 'OFF'
            }
            html_report = build_html_report(run_timestamp, run_settings, summary_df, detail_records)
            html_filename = f'fractal_report_{run_timestamp.strftime("%Y%m%d_%H%M%S")}.html'
            st.download_button('HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ', data=html_report.encode('utf-8'), file_name=html_filename, mime='text/html')

        if len(results_list) >= 2:
            df_results = pd.DataFrame(results_list)
            if os.path.exists(EXCEL_PATH):
                with pd.ExcelWriter(EXCEL_PATH, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:
                    sheet_name = pd.Timestamp.now().strftime('run_%Y%m%d_%H%M%S')
                    df_results.to_excel(writer, sheet_name=sheet_name, index=False)
                st.info(f'è§£æçµæœã‚’æ—¢å­˜Excel ({EXCEL_PATH}) ã«è¿½è¨˜ã—ã¾ã—ãŸã€‚')
            else:
                df_results.to_excel(EXCEL_PATH, sheet_name='run', index=False)
                st.info(f'è§£æçµæœã‚’æ–°è¦Excel ({EXCEL_PATH}) ã«ä¿å­˜ã—ã¾ã—ãŸã€‚')

        train_df = load_train_data()
        if train_df is not None:
            st.sidebar.write(f'å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(train_df)}')
        else:
            st.sidebar.write('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚')

with col2:
    st.header('å­¦ç¿’ / ãƒ¢ãƒ‡ãƒ«')
    st.write('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»å†å­¦ç¿’ã‚’è¡Œãˆã¾ã™ã€‚')

    train_df = load_train_data()
    if train_df is None:
        st.info('ã¾ã å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚è§£æã‚’æ•°å›è¡Œã†ã¨è‡ªå‹•çš„ã«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒè“„ç©ã•ã‚Œã¾ã™ã€‚')
    else:
        st.write('å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­5è¡Œ:')
        st.dataframe(train_df.head())

        # å­¦ç¿’å®Ÿè¡Œ
        if do_train_now:
            st.write('å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...')
            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ç”¨æ„
            X = train_df[['mean_int','std_int','edge_density','occupancy','fractal_dim_feature']].values
            y_fractal = train_df['target_fractal'].values
            y_occupancy = train_df['target_occupancy'].values
            y_valid = train_df['is_valid'].values

            scaler = StandardScaler()
            Xs = scaler.fit_transform(X)

            # å›å¸°: 2å‡ºåŠ›ã‚’åŒæ™‚ã«å­¦ç¿’ã™ã‚‹ãŸã‚ã€å˜ç´”ã«æ¨ªã«çµåˆ
            Y_reg = np.vstack([y_fractal, y_occupancy]).T
            reg = RandomForestRegressor(n_estimators=100, random_state=42)
            try:
                reg.fit(Xs, Y_reg)
                st.success('å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚')
            except Exception as e:
                st.error('å›å¸°å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ:' + str(e))
                reg = None

            # åˆ†é¡: æœ‰åŠ¹/ç„¡åŠ¹åˆ¤å®š
            clf = RandomForestClassifier(n_estimators=100, random_state=42)
            try:
                clf.fit(Xs, y_valid)
                st.success('åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚')
            except Exception as e:
                st.error('åˆ†é¡å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ:' + str(e))
                clf = None

            # ä¿å­˜
            if reg is not None:
                save_models(reg, scaler, clf)
                st.info('ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ (model_joblib.pkl, scaler_joblib.pkl)ã€‚')

            # ç°¡æ˜“è©•ä¾¡: ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç„¡ã—ã®å­¦å†…è©•ä¾¡
            if reg is not None:
                ypred = reg.predict(Xs)
                mae_fractal = mean_absolute_error(y_fractal, ypred[:,0])
                mae_occ = mean_absolute_error(y_occupancy, ypred[:,1])
                st.write(f'å­¦å†…è©•ä¾¡ MAE - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«: {mae_fractal:.4f}, å æœ‰ç‡: {mae_occ:.4f}')
            if clf is not None:
                ypredc = clf.predict(Xs)
                acc = accuracy_score(y_valid, ypredc)
                st.write(f'åˆ†é¡ãƒ¢ãƒ‡ãƒ« å­¦å†…ç²¾åº¦: {acc:.3f} (æ­£ç­”ç‡)')

    # æ‰‹å‹•ã§å†å­¦ç¿’ã—ãŸã„å ´åˆã®ãƒœã‚¿ãƒ³
    if st.button('ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿ç›´ã™ï¼ˆä¿å­˜æ¸ˆã¿ã‚’ãƒ­ãƒ¼ãƒ‰ï¼‰'):
        models2 = load_models()
        if 'reg' in models2:
            st.success('ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚')
        else:
            st.error('ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚')

st.sidebar.markdown('---')
st.sidebar.write('å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:')
st.sidebar.write(EXCEL_PATH)
st.sidebar.write(MODEL_PATH)
st.sidebar.write(TRAIN_CSV)

st.write('\n')
st.write('---')
st.write('æ³¨æ„: æœ¬ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã‚µãƒ³ãƒ—ãƒ«å®Ÿè£…ã§ã™ã€‚ç”»åƒã‚µã‚¤ã‚ºã€ç‰¹å¾´é‡ã€ç•°å¸¸åˆ¤å®šåŸºæº–ã€ãƒ¢ãƒ‡ãƒ«é¸å®šã¯ç”¨é€”ã«å¿œã˜ã¦èª¿æ•´ã—ã¦ãã ã•ã„ã€‚')