import streamlit as st
import cv2
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
from datetime import datetime
import io
import base64
from scipy import ndimage

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Meiryo']
plt.rcParams['axes.unicode_minus'] = False

# ----------------------------
# è‚Œè³ªè©•ä¾¡ã®åŸºæº–å€¤
# ----------------------------
SKIN_FD_IDEAL_MIN = 2.4  # ç†æƒ³çš„ãªè‚Œã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒä¸‹é™
SKIN_FD_IDEAL_MAX = 2.8  # ç†æƒ³çš„ãªè‚Œã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒä¸Šé™

# ----------------------------
# ãƒ‘ãƒƒãƒç‰¹å¾´é‡æŠ½å‡ºï¼ˆæ•™å¸«ã‚ã‚Šå­¦ç¿’ã®æ”¹å–„ï¼‰
# ----------------------------
def extract_patch_features(patch):
    """
    ãƒ‘ãƒƒãƒã‹ã‚‰å¤šæ§˜ãªç‰¹å¾´é‡ã‚’æŠ½å‡º
    å˜ç´”ãªãƒ”ã‚¯ã‚»ãƒ«å€¤ã ã‘ã§ãªãã€ã‚¨ãƒƒã‚¸ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ãªã©ã‚‚å«ã‚ã‚‹
    """
    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–
    if len(patch.shape) == 3:
        gray = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)
    else:
        gray = patch
    
    # æ­£è¦åŒ–
    normalized = gray.astype(np.float32) / 255.0
    
    # 1. ãƒ”ã‚¯ã‚»ãƒ«å€¤ï¼ˆåŸºæœ¬ï¼‰
    pixel_features = normalized.flatten()
    
    # 2. ã‚¨ãƒƒã‚¸æ¤œå‡ºï¼ˆSobelï¼‰
    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
    edge_features = (edge_magnitude / 255.0).flatten()
    
    # 3. ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ï¼ˆè©³ç´°åº¦ï¼‰
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    laplacian_features = (np.abs(laplacian) / 255.0).flatten()
    
    # 4. çµ±è¨ˆçš„ç‰¹å¾´
    stats = np.array([
        np.mean(normalized),
        np.std(normalized),
        np.min(normalized),
        np.max(normalized)
    ])
    
    # ã™ã¹ã¦ã®ç‰¹å¾´ã‚’çµåˆ
    features = np.concatenate([
        pixel_features,
        edge_features[:len(pixel_features)//4],  # ã‚µã‚¤ã‚ºå‰Šæ¸›
        laplacian_features[:len(pixel_features)//4],  # ã‚µã‚¤ã‚ºå‰Šæ¸›
        stats
    ])
    
    return features

# ----------------------------
# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé–¢æ•°ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
# ----------------------------
def augment_image(image):
    """ç”»åƒã‚’å›è»¢ã—ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚å›è»¢ã®ã¿ï¼‰"""
    augmented = [image]
    
    # 90åº¦å›è»¢ï¼ˆ4æ–¹å‘ï¼‰
    augmented.append(cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE))
    augmented.append(cv2.rotate(image, cv2.ROTATE_180))
    augmented.append(cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE))
    
    return augmented

# ----------------------------
# åŠ£åŒ–ç”»åƒç”Ÿæˆé–¢æ•°ï¼ˆåŒæ–¹å‘å­¦ç¿’ç”¨ï¼‰
# ----------------------------
def generate_degraded_image(high_quality_image):
    """
    é«˜ç”»è³ªç”»åƒã‹ã‚‰ä½ç”»è³ªç”»åƒã‚’ç”Ÿæˆï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µç”¨ï¼‰
    è¤‡æ•°ã®åŠ£åŒ–æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ãƒªã‚¢ãƒ«ãªåŠ£åŒ–ã‚’å†ç¾
    """
    degraded_images = []
    
    # 1. ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ï¼ˆè»½åº¦ï¼‰
    blur1 = cv2.GaussianBlur(high_quality_image, (3, 3), 0.5)
    degraded_images.append(blur1)
    
    # 2. ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ï¼ˆä¸­åº¦ï¼‰
    blur2 = cv2.GaussianBlur(high_quality_image, (5, 5), 1.0)
    degraded_images.append(blur2)
    
    # 3. ãƒã‚¤ã‚ºè¿½åŠ ï¼ˆè»½åº¦ï¼‰
    noise = np.random.normal(0, 5, high_quality_image.shape).astype(np.float32)
    noisy = np.clip(high_quality_image.astype(np.float32) + noise, 0, 255).astype(np.uint8)
    degraded_images.append(noisy)
    
    # 4. JPEGåœ§ç¸®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå“è³ª80ï¼‰
    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 80]
    success, encoded_img = cv2.imencode('.jpg', high_quality_image, encode_param)
    if success:
        jpeg_compressed = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)
        if jpeg_compressed is not None:
            degraded_images.append(jpeg_compressed)
    
    # 5. ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°+ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    h, w = high_quality_image.shape[:2]
    if h > 2 and w > 2:  # ã‚µã‚¤ã‚ºãŒååˆ†å¤§ãã„å ´åˆã®ã¿
        downsampled = cv2.resize(high_quality_image, (w//2, h//2), interpolation=cv2.INTER_LINEAR)
        upsampled = cv2.resize(downsampled, (w, h), interpolation=cv2.INTER_LINEAR)
        degraded_images.append(upsampled)
    
    return degraded_images

def generate_enhanced_image(low_quality_image):
    """
    ä½ç”»è³ªç”»åƒã‹ã‚‰ç–‘ä¼¼çš„ãªé«˜ç”»è³ªç”»åƒã‚’ç”Ÿæˆï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µç”¨ï¼‰
    ã‚·ãƒ£ãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ã‚„ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ã§å“è³ªå‘ä¸Šã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    """
    enhanced_images = []
    
    # 1. ã‚¢ãƒ³ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ã‚¯ï¼ˆè»½åº¦ï¼‰
    gaussian = cv2.GaussianBlur(low_quality_image, (0, 0), 2.0)
    unsharp = cv2.addWeighted(low_quality_image, 1.5, gaussian, -0.5, 0)
    enhanced_images.append(unsharp)
    
    # 2. ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–ï¼ˆã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–ï¼‰
    lab = cv2.cvtColor(low_quality_image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    l_eq = clahe.apply(l)
    enhanced = cv2.merge([l_eq, a, b])
    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
    enhanced_images.append(enhanced)
    
    # 3. ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆãƒã‚¤ã‚ºé™¤å»ã—ã¤ã¤ã‚¨ãƒƒã‚¸ä¿å­˜ï¼‰
    bilateral = cv2.bilateralFilter(low_quality_image, 9, 75, 75)
    enhanced_images.append(bilateral)
    
    return enhanced_images

# ----------------------------
# ç”»åƒã‚µã‚¤ã‚ºçµ±ä¸€é–¢æ•°
# ----------------------------
def align_image_sizes(low_img, high_img, mode='larger'):
    """
    ä½ç”»è³ªã¨é«˜ç”»è³ªã®ç”»åƒã‚µã‚¤ã‚ºã‚’çµ±ä¸€ã™ã‚‹
    mode: 'larger' = å¤§ãã„æ–¹ã«åˆã‚ã›ã‚‹ï¼ˆæ¨å¥¨ï¼‰
          'smaller' = å°ã•ã„æ–¹ã«åˆã‚ã›ã‚‹
          'high' = é«˜ç”»è³ªç”»åƒã«åˆã‚ã›ã‚‹
          'low' = ä½ç”»è³ªç”»åƒã«åˆã‚ã›ã‚‹
    """
    low_h, low_w = low_img.shape[:2]
    high_h, high_w = high_img.shape[:2]
    
    # ã‚µã‚¤ã‚ºãŒåŒã˜å ´åˆã¯ãã®ã¾ã¾è¿”ã™
    if (low_h, low_w) == (high_h, high_w):
        return low_img, high_img
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚µã‚¤ã‚ºã‚’æ±ºå®š
    if mode == 'larger':
        target_h = max(low_h, high_h)
        target_w = max(low_w, high_w)
    elif mode == 'smaller':
        target_h = min(low_h, high_h)
        target_w = min(low_w, high_w)
    elif mode == 'high':
        target_h, target_w = high_h, high_w
    elif mode == 'low':
        target_h, target_w = low_h, low_w
    else:
        target_h = max(low_h, high_h)
        target_w = max(low_w, high_w)
    
    # ãƒªã‚µã‚¤ã‚º
    aligned_low = low_img
    aligned_high = high_img
    
    if (low_h, low_w) != (target_h, target_w):
        aligned_low = cv2.resize(low_img, (target_w, target_h), interpolation=cv2.INTER_LANCZOS4)
    
    if (high_h, high_w) != (target_h, target_w):
        aligned_high = cv2.resize(high_img, (target_w, target_h), interpolation=cv2.INTER_LANCZOS4)
    
    return aligned_low, aligned_high

# ----------------------------
# AIè£œå®Œãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ï¼ˆç•°ãªã‚‹ã‚µã‚¤ã‚ºå¯¾å¿œç‰ˆï¼‰
# ----------------------------
def train_image_enhancer(low_quality_images, high_quality_images, use_augmentation=True, 
                        max_size=384, n_trees=20, max_depth_val=10, align_mode='larger'):
    """
    åŒæ–¹å‘å­¦ç¿’ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãªç”»åƒè£œæ­£ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    
    ã€åŒæ–¹å‘å­¦ç¿’ã®ä»•çµ„ã¿ã€‘
    1. ä½ç”»è³ªâ†’é«˜ç”»è³ªï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ï¼‰
    2. é«˜ç”»è³ªâ†’åŠ£åŒ–â†’é«˜ç”»è³ªï¼ˆé€†å¤‰æ›å­¦ç¿’ï¼‰
    3. ä½ç”»è³ªâ†’ç–‘ä¼¼é«˜ç”»è³ªï¼ˆè‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ï¼‰
    
    ã“ã‚Œã«ã‚ˆã‚Šã€AIãŒåŠ£åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã¨å¾©å…ƒãƒ—ãƒ­ã‚»ã‚¹ã®ä¸¡æ–¹ã‚’å­¦ç¿’ã—ã€
    ã‚ˆã‚Šæ­£ç¢ºã§æ±ç”¨çš„ãªè£œæ­£ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚
    """
    X, y = [], []
    trained_shape = None
    patch_size = 16  # ãƒ‘ãƒƒãƒã‚µã‚¤ã‚ºï¼ˆ16Ã—16ã§ç´°ã‹ãè£œæ­£ï¼‰
    
    # ç”»åƒã‚µã‚¤ã‚ºã®çµ±ä¸€ã¨æœ€é©åŒ–
    resized_low, resized_high = [], []
    for low, high in zip(low_quality_images, high_quality_images):
        # ã‚µã‚¤ã‚ºã‚’çµ±ä¸€
        low, high = align_image_sizes(low, high, mode=align_mode)
        
        # max_sizeã«åã¾ã‚‹ã‚ˆã†ã«ãƒªã‚µã‚¤ã‚º
        h, w = low.shape[:2]
        if max(h, w) > max_size:
            scale = max_size / max(h, w)
            new_size = (int(w * scale), int(h * scale))
            low = cv2.resize(low, new_size, interpolation=cv2.INTER_LANCZOS4)
            high = cv2.resize(high, new_size, interpolation=cv2.INTER_LANCZOS4)
        
        if trained_shape is None:
            trained_shape = low.shape
        
        resized_low.append(low)
        resized_high.append(high)
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
    if use_augmentation:
        aug_low, aug_high = [], []
        for low, high in zip(resized_low, resized_high):
            aug_low.extend(augment_image(low))
            aug_high.extend(augment_image(high))
        resized_low = aug_low
        resized_high = aug_high
    
    # åŒæ–¹å‘å­¦ç¿’: é«˜ç”»è³ªâ†’ä½ç”»è³ªã€ä½ç”»è³ªâ†’é«˜ç”»è³ªã®ä¸¡æ–¹å‘ã‚’å­¦ç¿’
    bidirectional_low, bidirectional_high = [], []
    
    # å…ƒã®ãƒšã‚¢æ•°ã‚’è¨˜éŒ²
    original_pair_count = len(resized_low)
    
    # å…ƒã®ãƒšã‚¢ï¼ˆä½â†’é«˜ï¼‰
    bidirectional_low.extend(resized_low)
    bidirectional_high.extend(resized_high)
    
    # é€†æ–¹å‘ãƒšã‚¢1: é«˜ç”»è³ªã‹ã‚‰åŠ£åŒ–ç”»åƒã‚’ç”Ÿæˆï¼ˆé«˜â†’ä½ï¼‰
    degraded_count = 0
    for high in resized_high:
        degraded_list = generate_degraded_image(high)
        for degraded in degraded_list:
            bidirectional_low.append(degraded)
            bidirectional_high.append(high)  # åŠ£åŒ–â†’å…ƒã®é«˜ç”»è³ª
            degraded_count += 1
    
    # é€†æ–¹å‘ãƒšã‚¢2: ä½ç”»è³ªã‹ã‚‰ç–‘ä¼¼é«˜ç”»è³ªã‚’ç”Ÿæˆï¼ˆä½â†’ç–‘ä¼¼é«˜ï¼‰
    enhanced_count = 0
    for low in resized_low:
        enhanced_list = generate_enhanced_image(low)
        for enhanced in enhanced_list:
            bidirectional_low.append(low)
            bidirectional_high.append(enhanced)  # ä½ç”»è³ªâ†’ç–‘ä¼¼é«˜ç”»è³ª
            enhanced_count += 1
    
    # åŒæ–¹å‘å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ç½®ãæ›ãˆ
    resized_low = bidirectional_low
    resized_high = bidirectional_high
    
    # ç·ç”»åƒãƒšã‚¢æ•°
    total_image_pairs = len(resized_low)
    
    # ãƒ‘ãƒƒãƒãƒ™ãƒ¼ã‚¹ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    patch_count = 0
    for low, high in zip(resized_low, resized_high):
        h, w = low.shape[:2]
        stride = patch_size  # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ãªã—ï¼ˆé«˜é€ŸåŒ–ï¼‰
        
        for i in range(0, h - patch_size + 1, stride):
            for j in range(0, w - patch_size + 1, stride):
                # ãƒ‘ãƒƒãƒã‚’æŠ½å‡º
                low_patch = low[i:i+patch_size, j:j+patch_size]
                high_patch = high[i:i+patch_size, j:j+patch_size]
                
                if low_patch.shape[:2] != (patch_size, patch_size):
                    continue
                
                # æ­£è¦åŒ–ã—ã¦å¹³å¦åŒ– + ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆç²¾åº¦å‘ä¸Šï¼‰
                low_flat = low_patch.flatten().astype(np.float32) / 255.0
                high_flat = high_patch.flatten().astype(np.float32) / 255.0
                
                # ã‚¨ãƒƒã‚¸æ¤œå‡ºï¼ˆSobelï¼‰ã§è¿½åŠ ç‰¹å¾´é‡ï¼ˆè»½é‡ï¼‰
                gray_low = cv2.cvtColor(low_patch, cv2.COLOR_BGR2GRAY)
                sobel_x = cv2.Sobel(gray_low, cv2.CV_32F, 1, 0, ksize=3)
                sobel_y = cv2.Sobel(gray_low, cv2.CV_32F, 0, 1, ksize=3)
                
                # ã‚¨ãƒƒã‚¸å¼·åº¦ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼å€¤ï¼‰
                edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2).mean() / 255.0
                
                # çµ±è¨ˆç‰¹å¾´é‡ï¼ˆå¹³å‡ã€æ¨™æº–åå·®ï¼‰
                mean_val = np.mean(low_patch, axis=(0, 1)) / 255.0
                std_val = np.std(low_patch, axis=(0, 1)) / 255.0
                
                # å…¨ç‰¹å¾´é‡ã‚’çµåˆï¼ˆãƒ”ã‚¯ã‚»ãƒ«å€¤ + ã‚¨ãƒƒã‚¸å¼·åº¦ + çµ±è¨ˆï¼‰
                features = np.concatenate([low_flat, [edge_magnitude], mean_val, std_val])
                
                X.append(features)
                y.append(high_flat)
                patch_count += 1
    
    if len(X) == 0:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç”»åƒå…¨ä½“ã§å­¦ç¿’
        for low, high in zip(resized_low, resized_high):
            low_flat = low.flatten().astype(np.float32) / 255.0
            high_flat = high.flatten().astype(np.float32) / 255.0
            X.append(low_flat)
            y.append(high_flat)
        patch_count = len(X)
    
    X = np.array(X, dtype=np.float32)
    y = np.array(y, dtype=np.float32)
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    if len(X) > 1:
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    else:
        X_train, X_test, y_train, y_test = X, X, y, y
    
    # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã§å­¦ç¿’ï¼ˆæœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
    # é«˜é€ŸåŒ–ã¨ç²¾åº¦å‘ä¸Šã®ãƒãƒ©ãƒ³ã‚¹
    n_estimators_val = min(n_trees, 50)
    use_oob = len(X_train) > 100 and n_estimators_val >= 10  # OOBã¯ååˆ†ãªãƒ‡ãƒ¼ã‚¿ã¨æœ¨ãŒã‚ã‚‹å ´åˆã®ã¿
    
    model = RandomForestRegressor(
        n_estimators=n_estimators_val,
        max_depth=max_depth_val,
        min_samples_split=10,  # åˆ†å‰²ã«å¿…è¦ãªæœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¢—ã‚„ã—ã¦éå­¦ç¿’ã‚’é˜²ã
        min_samples_leaf=4,    # è‘‰ãƒãƒ¼ãƒ‰ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¢—ã‚„ã—ã¦æ±åŒ–æ€§èƒ½å‘ä¸Š
        max_features='sqrt',   # ç‰¹å¾´é‡ã®ã‚µãƒ–ã‚»ãƒƒãƒˆé¸æŠã§å¤šæ§˜æ€§å‘ä¸Š
        random_state=42,
        n_jobs=-1,             # å…¨CPUã‚³ã‚¢ã‚’ä½¿ç”¨
        warm_start=False,
        bootstrap=True,        # ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æ±åŒ–æ€§èƒ½å‘ä¸Š
        oob_score=use_oob      # Out-of-Bagè©•ä¾¡ï¼ˆæ¡ä»¶ä»˜ãï¼‰
    )
    model.fit(X_train, y_train)
    
    # ç²¾åº¦è©•ä¾¡
    score = model.score(X_test, y_test) if len(X_test) > 0 else 0.0
    
    # ãƒ¢ãƒ‡ãƒ«ã«å¿…è¦ãªæƒ…å ±ã‚’ä¿å­˜
    model.trained_shape = trained_shape
    model.patch_size = patch_size
    
    # å­¦ç¿’ã«ä½¿ç”¨ã—ãŸç”»åƒãƒšã‚¢æ•°ï¼ˆåŒæ–¹å‘å­¦ç¿’ã«ã‚ˆã‚‹å¢—åŠ ã‚’åæ˜ ï¼‰
    # total_image_pairs ã¯æ—¢ã«å®šç¾©æ¸ˆã¿
    
    return model, score, patch_count, total_image_pairs

def enhance_image(model, low_quality_image, max_size=384):
    """
    ãƒ‘ãƒƒãƒãƒ™ãƒ¼ã‚¹ã§ç”»åƒã‚’è£œæ­£
    """
    # å…ƒã®ã‚µã‚¤ã‚ºã‚’ä¿å­˜
    original_shape = low_quality_image.shape
    h, w = original_shape[:2]
    
    # ãƒ‘ãƒƒãƒã‚µã‚¤ã‚ºã‚’å–å¾—
    patch_size = getattr(model, 'patch_size', 32)
    
    # å­¦ç¿’æ™‚ã¨åŒã˜ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
    if hasattr(model, 'trained_shape') and model.trained_shape is not None:
        target_shape = model.trained_shape
        resized_image = cv2.resize(low_quality_image, 
                                   (target_shape[1], target_shape[0]), 
                                   interpolation=cv2.INTER_LANCZOS4)
    else:
        resized_image = low_quality_image.copy()
        if max(h, w) > max_size:
            scale = max_size / max(h, w)
            new_size = (int(w * scale), int(h * scale))
            resized_image = cv2.resize(low_quality_image, new_size, interpolation=cv2.INTER_LANCZOS4)
    
    # ãƒ‘ãƒƒãƒãƒ™ãƒ¼ã‚¹ã§äºˆæ¸¬
    h_resized, w_resized = resized_image.shape[:2]
    enhanced = np.zeros((h_resized, w_resized, 3), dtype=np.float32)
    count_map = np.zeros((h_resized, w_resized, 3), dtype=np.float32)
    
    stride = patch_size  # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ãªã—ï¼ˆé«˜é€ŸåŒ–ï¼‰
    
    for i in range(0, h_resized - patch_size + 1, stride):
        for j in range(0, w_resized - patch_size + 1, stride):
            # ãƒ‘ãƒƒãƒã‚’æŠ½å‡º
            patch = resized_image[i:i+patch_size, j:j+patch_size]
            
            if patch.shape[:2] != (patch_size, patch_size):
                continue
            
            # æ­£è¦åŒ–ã—ã¦å¹³å¦åŒ– + ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜ï¼‰
            patch_flat = patch.flatten().astype(np.float32) / 255.0
            
            # ã‚¨ãƒƒã‚¸æ¤œå‡ºï¼ˆSobelï¼‰
            gray_patch = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)
            sobel_x = cv2.Sobel(gray_patch, cv2.CV_32F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(gray_patch, cv2.CV_32F, 0, 1, ksize=3)
            
            # ã‚¨ãƒƒã‚¸å¼·åº¦ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼å€¤ï¼‰
            edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2).mean() / 255.0
            
            # çµ±è¨ˆç‰¹å¾´é‡
            mean_val = np.mean(patch, axis=(0, 1)) / 255.0
            std_val = np.std(patch, axis=(0, 1)) / 255.0
            
            # å…¨ç‰¹å¾´é‡ã‚’çµåˆ
            features = np.concatenate([patch_flat, [edge_magnitude], mean_val, std_val])
            
            # äºˆæ¸¬
            predicted_flat = model.predict([features])[0]
            
            # ãƒ‘ãƒƒãƒã‚µã‚¤ã‚ºã«å¾©å…ƒ
            predicted_patch = (predicted_flat.reshape(patch_size, patch_size, 3) * 255).astype(np.float32)
            
            # åŠ ç®—ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—éƒ¨åˆ†ã¯å¹³å‡åŒ–ï¼‰
            enhanced[i:i+patch_size, j:j+patch_size] += predicted_patch
            count_map[i:i+patch_size, j:j+patch_size] += 1
    
    # å¢ƒç•Œéƒ¨åˆ†ã®å‡¦ç†
    for i in range(0, h_resized, patch_size):
        for j in range(0, w_resized, patch_size):
            if i + patch_size > h_resized or j + patch_size > w_resized:
                i_end = min(i + patch_size, h_resized)
                j_end = min(j + patch_size, w_resized)
                
                if count_map[i, j, 0] == 0:  # æœªå‡¦ç†ã®éƒ¨åˆ†
                    # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦äºˆæ¸¬
                    patch = resized_image[i:i_end, j:j_end]
                    if patch.shape[0] < patch_size or patch.shape[1] < patch_size:
                        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                        padded = np.zeros((patch_size, patch_size, 3), dtype=np.uint8)
                        padded[:patch.shape[0], :patch.shape[1]] = patch
                        
                        # ç‰¹å¾´é‡æŠ½å‡ºï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜ï¼‰
                        patch_flat = padded.flatten().astype(np.float32) / 255.0
                        gray_padded = cv2.cvtColor(padded, cv2.COLOR_BGR2GRAY)
                        sobel_x = cv2.Sobel(gray_padded, cv2.CV_32F, 1, 0, ksize=3)
                        sobel_y = cv2.Sobel(gray_padded, cv2.CV_32F, 0, 1, ksize=3)
                        edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2).mean() / 255.0
                        mean_val = np.mean(padded, axis=(0, 1)) / 255.0
                        std_val = np.std(padded, axis=(0, 1)) / 255.0
                        features = np.concatenate([patch_flat, [edge_magnitude], mean_val, std_val])
                        
                        predicted_flat = model.predict([features])[0]
                        predicted_patch = (predicted_flat.reshape(patch_size, patch_size, 3) * 255).astype(np.float32)
                        
                        # æœ‰åŠ¹ãªéƒ¨åˆ†ã ã‘ã‚³ãƒ”ãƒ¼
                        enhanced[i:i_end, j:j_end] = predicted_patch[:i_end-i, :j_end-j]
                        count_map[i:i_end, j:j_end] = 1
    
    # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—éƒ¨åˆ†ã‚’å¹³å‡åŒ–
    count_map[count_map == 0] = 1  # ã‚¼ãƒ­é™¤ç®—ã‚’é˜²ã
    enhanced = enhanced / count_map
    enhanced = np.clip(enhanced, 0, 255).astype(np.uint8)
    
    # å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
    if enhanced.shape != original_shape:
        enhanced = cv2.resize(enhanced, (w, h), interpolation=cv2.INTER_LANCZOS4)
    
    return enhanced

# ----------------------------
# AIè£œæ­£ã®è©•ä¾¡é–¢æ•°
# ----------------------------
def evaluate_ai_correction(fd_low, fd_enhanced, fd_high):
    """
    AIè£œæ­£ã®ç²¾åº¦ã‚’è©•ä¾¡
    low: ä½ç”»è³ªã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
    enhanced: AIè£œæ­£å¾Œã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
    high: é«˜ç”»è³ªã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
    """
    if fd_low is None or fd_enhanced is None or fd_high is None:
        return None, "è©•ä¾¡ä¸å¯"
    
    # æ”¹å–„åº¦: ä½ç”»è³ªã‹ã‚‰è£œæ­£å¾Œã¸ã®å¤‰åŒ–
    improvement = abs(fd_enhanced - fd_low)
    
    # ç›®æ¨™ã¨ã®å·®: è£œæ­£å¾Œã¨é«˜ç”»è³ªã®å·®
    target_diff = abs(fd_enhanced - fd_high)
    
    # ä½ç”»è³ªã¨é«˜ç”»è³ªã®å·®
    original_diff = abs(fd_high - fd_low)
    
    # æ”¹å–„ç‡: ã©ã‚Œã ã‘ç›®æ¨™ã«è¿‘ã¥ã„ãŸã‹
    if original_diff > 0:
        improvement_rate = (1 - target_diff / original_diff) * 100
    else:
        improvement_rate = 100.0
    
    # è©•ä¾¡ãƒ©ãƒ³ã‚¯
    if improvement_rate >= 90:
        rank = "S (å„ªç§€)"
        color = "ğŸŸ¢"
    elif improvement_rate >= 75:
        rank = "A (è‰¯å¥½)"
        color = "ğŸ”µ"
    elif improvement_rate >= 60:
        rank = "B (æ™®é€š)"
        color = "ğŸŸ¡"
    elif improvement_rate >= 40:
        rank = "C (è¦æ”¹å–„)"
        color = "ğŸŸ "
    else:
        rank = "D (ä¸è‰¯)"
        color = "ğŸ”´"
    
    evaluation = {
        "improvement_rate": improvement_rate,
        "rank": rank,
        "color": color,
        "improvement": improvement,
        "target_diff": target_diff,
        "original_diff": original_diff
    }
    
    return evaluation, f"{color} ãƒ©ãƒ³ã‚¯: {rank}"

# ----------------------------
# 3Dè¡¨é¢å‡¹å‡¸è§£æï¼ˆè‚Œè³ªç”¨ï¼‰
# ----------------------------
def calculate_surface_roughness(image):
    """
    3Dè¡¨é¢ã®å‡¹å‡¸ã‚’è§£æ
    è‚Œã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ï¼ˆæ¯›ç©´ã€ã‚·ãƒ¯ã€ã‚­ãƒ¡ï¼‰ã‚’å®šé‡åŒ–
    """
    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    # é«˜ã•ãƒãƒƒãƒ—ã¨ã—ã¦æ‰±ã†ï¼ˆè¼åº¦ã‚’é«˜ã•ã«å¤‰æ›ï¼‰
    height_map = gray.astype(np.float32)
    
    # è¡¨é¢ç²—ã•ã®è¨ˆç®—
    # 1. æ¨™æº–åå·®ï¼ˆå…¨ä½“çš„ãªå‡¹å‡¸ï¼‰
    roughness_std = np.std(height_map)
    
    # 2. å¹³å‡çµ¶å¯¾åå·®
    roughness_mad = np.mean(np.abs(height_map - np.mean(height_map)))
    
    # 3. å‹¾é…ãƒ™ãƒ¼ã‚¹ã®ç²—ã•ï¼ˆæ€¥å³»ã•ï¼‰
    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
    roughness_gradient = np.mean(gradient_magnitude)
    
    # 4. ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ï¼ˆå±€æ‰€çš„ãªå¤‰åŒ–ï¼‰
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    roughness_laplacian = np.var(laplacian)
    
    return {
        "std": roughness_std,
        "mad": roughness_mad,
        "gradient": roughness_gradient,
        "laplacian": roughness_laplacian
    }

# ----------------------------
# 3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒï¼ˆè‚Œè³ªè§£æç”¨ï¼‰
# ----------------------------
def fractal_dimension_3d_surface(image, max_size=256):
    """
    3Dè¡¨é¢ã¨ã—ã¦ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’è¨ˆç®—
    è‚Œè³ªè©•ä¾¡ã«é©ã—ãŸæ‰‹æ³•ï¼ˆDifferential Box Countingæ³•ï¼‰
    ç†æƒ³çš„ãªè‚Œ: 2.4~2.8
    """
    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    # ã‚µã‚¤ã‚ºèª¿æ•´ï¼ˆ2ã®ç´¯ä¹—ã«è¿‘ã„ã‚µã‚¤ã‚ºã«ï¼‰
    h, w = gray.shape
    if max(h, w) > max_size:
        scale = max_size / max(h, w)
        new_size = (int(w * scale), int(h * scale))
        gray = cv2.resize(gray, new_size, interpolation=cv2.INTER_LANCZOS4)
    
    h, w = gray.shape
    
    # Differential Box Counting (DBC) æ³•ã®å®Ÿè£…
    # ç”»åƒã®è¼åº¦å€¤ã‚’é«˜ã•ã¨ã—ã¦æ‰±ã†
    height_map = gray.astype(np.float64)
    
    # ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºï¼‰ã®è¨­å®š
    min_box_size = 2
    max_box_size = min(h, w) // 4
    box_sizes = []
    box_size = min_box_size
    while box_size <= max_box_size:
        box_sizes.append(box_size)
        box_size *= 2
    
    if len(box_sizes) < 3:
        box_sizes = [2, 4, 8, 16]
    
    counts = []
    
    for r in box_sizes:
        # r x r ã®ã‚°ãƒªãƒƒãƒ‰ã«åˆ†å‰²
        n_h = h // r
        n_w = w // r
        
        if n_h < 1 or n_w < 1:
            continue
        
        # ã“ã®ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®ç·ãƒœãƒƒã‚¯ã‚¹æ•°
        nr = 0
        
        # é«˜ã•æ–¹å‘ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆæ”¹å–„ç‰ˆï¼‰
        # ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºrã«å¿œã˜ã¦ã€é«˜ã•æ–¹å‘ã®ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚’è¨­å®š
        # rãŒå°ã•ã„ã»ã©ç´°ã‹ãã€rãŒå¤§ãã„ã»ã©ç²—ã
        # æ­£è¦åŒ–ï¼š0-1ã®ç¯„å›²ã«ã‚¹ã‚±ãƒ¼ãƒ«
        height_map_normalized = height_map / 255.0
        G = max(0.001, 1.0 / r)  # é«˜ã•æ–¹å‘ã®ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º
        
        for i in range(n_h):
            for j in range(n_w):
                # r x r ã®ã‚°ãƒªãƒƒãƒ‰ã‚»ãƒ«ã‚’å–å¾—
                grid = height_map_normalized[i*r:(i+1)*r, j*r:(j+1)*r]
                
                if grid.size == 0:
                    continue
                
                # ã‚°ãƒªãƒƒãƒ‰å†…ã®æœ€å°ãƒ»æœ€å¤§é«˜ã•
                min_height = np.min(grid)
                max_height = np.max(grid)
                
                # é«˜ã•æ–¹å‘ã®ãƒœãƒƒã‚¯ã‚¹ä½ç½®ã‚’è¨ˆç®—
                l = int(np.floor(min_height / G))
                k = int(np.ceil(max_height / G))
                
                # ã“ã®ã‚°ãƒªãƒƒãƒ‰ãŒå ã‚ã‚‹3Dãƒœãƒƒã‚¯ã‚¹ã®æ•°
                # æœ€å°ã§ã‚‚1ã¤ã¯ã‚«ã‚¦ãƒ³ãƒˆ
                nr += max(1, k - l)
        
        if nr > 0:
            counts.append(nr)
    
    # box_sizes ã¨ counts ã®é•·ã•ã‚’æƒãˆã‚‹
    valid_sizes = box_sizes[:len(counts)]
    valid_counts = counts
    
    # ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    if len(valid_sizes) < 3 or len(valid_counts) < 3:
        # ãƒ‡ãƒ¼ã‚¿ä¸è¶³
        return None, np.array([2, 4, 8]), np.array([1, 1, 1])
    
    # ã™ã¹ã¦ã®ã‚«ã‚¦ãƒ³ãƒˆãŒæ­£ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    if any(c <= 0 for c in valid_counts):
        return None, np.array(valid_sizes), np.array(valid_counts)
    
    # å¯¾æ•°å¤‰æ›
    log_sizes = np.log(np.array(valid_sizes, dtype=np.float64))
    log_counts = np.log(np.array(valid_counts, dtype=np.float64))
    
    # NaN/Inf ãƒã‚§ãƒƒã‚¯
    if np.any(~np.isfinite(log_sizes)) or np.any(~np.isfinite(log_counts)):
        return None, np.array(valid_sizes), np.array(valid_counts)
    
    # ç·šå½¢å›å¸°ã§ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’è¨ˆç®—
    # DBCæ³•ã®æ­£ã—ã„å®šç¾©:
    # Nr(r) = ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºrã§ã®3Dãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆæ•°
    # ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºãŒå°ã•ã„ã»ã©ã€ç´°ã‹ãæ¸¬å®šã§ãã‚‹ã®ã§å¤šãã®ãƒœãƒƒã‚¯ã‚¹ãŒå¿…è¦
    # ã¤ã¾ã‚Š: rå° â†’ Nrå¤§, rå¤§ â†’ Nrå° ï¼ˆè² ã®ç›¸é–¢ï¼‰
    # log(Nr) vs log(r) ã®é–¢ä¿‚: log(Nr) = a * log(r) + b
    # å‚¾ã a ã¯è² ã«ãªã‚‹ã®ãŒæ­£å¸¸
    # 3Dè¡¨é¢ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ D = 3 + a (aã¯è² ãªã®ã§å®Ÿè³ª 3 - |a|)
    
    coeffs = np.polyfit(log_sizes, log_counts, 1)
    slope = coeffs[0]
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆå¯èƒ½ï¼‰
    # print(f"DBCæ³• - ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º: {valid_sizes}")
    # print(f"DBCæ³• - ã‚«ã‚¦ãƒ³ãƒˆæ•°: {valid_counts}")
    # print(f"DBCæ³• - å‚¾ã: {slope:.4f}")
    
    # DBCæ³•ã§ã®3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®è¨ˆç®—
    if slope < 0:
        # æ­£å¸¸ãªå‚¾å‘ï¼šãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºå¢—åŠ â†’ã‚«ã‚¦ãƒ³ãƒˆæ¸›å°‘
        # FD = 3 + slope (slope < 0 ãªã®ã§å®Ÿè³ª 3 - |slope|)
        # ä¾‹: slope = -0.5 â†’ FD = 2.5 (å¥åº·ãªè‚Œ)
        # ä¾‹: slope = -0.8 â†’ FD = 2.2 (æ»‘ã‚‰ã‹)
        # ä¾‹: slope = -0.3 â†’ FD = 2.7 (ç²—ã„)
        fractal_dim_3d = 3.0 + slope
    else:
        # ç•°å¸¸ãªå‚¾å‘ï¼šæ­£ã®å‚¾ãï¼ˆç†è«–çš„ã«ã¯ã‚ã‚Šãˆãªã„ï¼‰
        # ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        fractal_dim_3d = 3.0 - slope
    
    # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼š2.0ï½3.0ã®ç¯„å›²ã«åã‚ã‚‹
    # å¥åº·ãªè‚Œã®å…¸å‹çš„ãªç¯„å›²ã¯ 2.4ï½2.8
    fractal_dim_3d = np.clip(fractal_dim_3d, 2.0, 3.0)
    
    return fractal_dim_3d, np.array(valid_sizes), np.array(valid_counts)

# ----------------------------
# 3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚°ãƒ©ãƒ•
# ----------------------------
def plot_3d_fractal_analysis(box_sizes, counts, fd_3d):
    """3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®è§£æã‚°ãƒ©ãƒ•"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # FDãŒNoneã®å ´åˆã®ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
    if fd_3d is None or fd_3d == 0:
        ax1.text(0.5, 0.5, 'è¨ˆç®—ã‚¨ãƒ©ãƒ¼\næœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“', 
                ha='center', va='center', transform=ax1.transAxes, fontsize=14, color='red')
        ax2.text(0.5, 0.5, 'è¨ˆç®—ã‚¨ãƒ©ãƒ¼', 
                ha='center', va='center', transform=ax2.transAxes, fontsize=14, color='red')
        return fig
    
    # å·¦: å¯¾æ•°ãƒ—ãƒ­ãƒƒãƒˆ
    # ãƒã‚¹ã‚¯ã•ã‚ŒãŸå€¤ã‚’é™¤å¤–
    try:
        valid_mask = ~np.ma.getmaskarray(counts)
    except:
        # ãƒã‚¹ã‚¯ãŒãªã„å ´åˆ
        valid_mask = np.ones(len(counts), dtype=bool)
    
    if not np.any(valid_mask):
        # ã™ã¹ã¦ãƒã‚¹ã‚¯ã•ã‚Œã¦ã„ã‚‹å ´åˆ
        ax1.text(0.5, 0.5, 'ãƒ‡ãƒ¼ã‚¿ãªã—', ha='center', va='center', 
                transform=ax1.transAxes, fontsize=14)
        log_sizes = np.array([])
        log_counts = np.array([])
    else:
        valid_sizes = np.asarray(box_sizes)[valid_mask]
        valid_counts = np.asarray(counts)[valid_mask]
        log_sizes = np.log(valid_sizes)
        log_counts = np.log(valid_counts)
    
    # ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿æç”»
    if len(log_sizes) > 0 and len(log_counts) > 0:
        ax1.scatter(log_sizes, log_counts, s=100, color='#e74c3c', zorder=5, 
                   edgecolors='white', linewidth=2, label='å®Ÿæ¸¬å€¤')
        
        # å›å¸°ç›´ç·š
        if len(log_sizes) >= 2:
            coeffs = np.polyfit(log_sizes, log_counts, 1)
            fit_line = coeffs[0] * log_sizes + coeffs[1]
            ax1.plot(log_sizes, fit_line, '--', color='#3498db', linewidth=2, label='å›å¸°ç›´ç·š')
    
    ax1.set_xlabel('log(ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º r)', fontsize=11, fontweight='bold')
    ax1.set_ylabel('log(3Dãƒœãƒƒã‚¯ã‚¹æ•° Nr)', fontsize=11, fontweight='bold')
    ax1.set_title(f'3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ (DBCæ³•)\nFD = {fd_3d:.4f}', 
                 fontsize=12, fontweight='bold', pad=15)
    ax1.grid(True, alpha=0.3, linestyle='--')
    if len(log_sizes) > 0:
        ax1.legend(fontsize=9, loc='best')
    
    # å‚¾ãã®æƒ…å ±ã‚’è¡¨ç¤º
    if len(log_sizes) >= 2:
        coeffs = np.polyfit(log_sizes, log_counts, 1)
        slope = coeffs[0]
        ax1.text(0.05, 0.95, f'å‚¾ã: {slope:.3f}\nFD = 3 - |å‚¾ã|', 
                transform=ax1.transAxes, fontsize=9, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    # å³: ç†æƒ³ç¯„å›²ã¨ã®æ¯”è¼ƒ
    categories = ['ç¾åœ¨ã®å€¤', 'ç†æƒ³ç¯„å›²\n(ä¸‹é™)', 'ç†æƒ³ç¯„å›²\n(ä¸Šé™)']
    values = [fd_3d, SKIN_FD_IDEAL_MIN, SKIN_FD_IDEAL_MAX]
    colors_bar = ['#3498db', '#2ecc71', '#2ecc71']
    
    bars = ax2.bar(categories, values, color=colors_bar, alpha=0.7, edgecolor='white', linewidth=2)
    
    # ç†æƒ³ç¯„å›²ã‚’å¼·èª¿
    ax2.axhspan(SKIN_FD_IDEAL_MIN, SKIN_FD_IDEAL_MAX, alpha=0.2, color='green', 
               label='ç†æƒ³ç¯„å›² (2.4-2.8)')
    
    # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
    for bar, val in zip(bars, values):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    ax2.set_ylabel('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ', fontsize=11, fontweight='bold')
    ax2.set_title('è‚Œè³ªåŸºæº–ã¨ã®æ¯”è¼ƒ', fontsize=12, fontweight='bold', pad=15)
    ax2.set_ylim(min(values) - 0.3, max(values) + 0.3)
    ax2.legend(fontsize=9, loc='upper right')
    ax2.grid(True, alpha=0.3, axis='y', linestyle='--')
    
    plt.tight_layout()
    return fig

# ----------------------------
# è¡¨é¢ç²—ã•å¯è¦–åŒ–
# ----------------------------
def plot_surface_roughness(image, roughness):
    """è¡¨é¢ã®å‡¹å‡¸ã‚’å¯è¦–åŒ–"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    fig, axes = plt.subplots(2, 2, figsize=(10, 8))
    
    # å…ƒç”»åƒ
    axes[0, 0].imshow(gray, cmap='gray')
    axes[0, 0].set_title('å…ƒç”»åƒï¼ˆã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰', fontsize=10, fontweight='bold')
    axes[0, 0].axis('off')
    
    # å‹¾é…ãƒãƒƒãƒ—ï¼ˆå‡¹å‡¸ã®æ€¥å³»ã•ï¼‰
    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    gradient = np.sqrt(grad_x**2 + grad_y**2)
    im1 = axes[0, 1].imshow(gradient, cmap='hot')
    axes[0, 1].set_title(f'å‹¾é…ãƒãƒƒãƒ— (å‡¹å‡¸ã®æ€¥å³»ã•)\nå¹³å‡: {roughness["gradient"]:.2f}', 
                        fontsize=10, fontweight='bold')
    axes[0, 1].axis('off')
    plt.colorbar(im1, ax=axes[0, 1], fraction=0.046)
    
    # ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ï¼ˆå±€æ‰€çš„ãªå¤‰åŒ–ï¼‰
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    im2 = axes[1, 0].imshow(np.abs(laplacian), cmap='viridis')
    axes[1, 0].set_title(f'ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ (å±€æ‰€å¤‰åŒ–)\nåˆ†æ•£: {roughness["laplacian"]:.2f}', 
                        fontsize=10, fontweight='bold')
    axes[1, 0].axis('off')
    plt.colorbar(im2, ax=axes[1, 0], fraction=0.046)
    
    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    axes[1, 1].hist(gray.ravel(), bins=50, color='#3498db', alpha=0.7, edgecolor='black')
    axes[1, 1].axvline(np.mean(gray), color='red', linestyle='--', linewidth=2, label='å¹³å‡')
    axes[1, 1].set_xlabel('è¼åº¦å€¤', fontsize=10)
    axes[1, 1].set_ylabel('é »åº¦', fontsize=10)
    axes[1, 1].set_title(f'è¼åº¦åˆ†å¸ƒ\næ¨™æº–åå·®: {roughness["std"]:.2f}', 
                        fontsize=10, fontweight='bold')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

# ----------------------------
# è‚Œè³ªè©•ä¾¡é–¢æ•°
# ----------------------------
def evaluate_skin_quality(fd_3d, roughness):
    """
    3Dãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã¨è¡¨é¢ç²—ã•ã‹ã‚‰è‚Œè³ªã‚’è©•ä¾¡
    ç†æƒ³çš„ãªè‚Œ: FD 2.4~2.8
    """
    if fd_3d is None:
        return None, "è©•ä¾¡ä¸å¯"
    
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã«ã‚ˆã‚‹è©•ä¾¡
    if SKIN_FD_IDEAL_MIN <= fd_3d <= SKIN_FD_IDEAL_MAX:
        fd_score = 100
        fd_comment = "ç†æƒ³çš„"
        fd_color = "ğŸŸ¢"
    elif fd_3d < SKIN_FD_IDEAL_MIN:
        # ä½ã™ãã‚‹ï¼šæ»‘ã‚‰ã‹ã™ãã‚‹ï¼ˆä¸è‡ªç„¶ï¼‰
        diff = SKIN_FD_IDEAL_MIN - fd_3d
        fd_score = max(0, 100 - diff * 100)
        fd_comment = "æ»‘ã‚‰ã‹ã™ãã‚‹"
        fd_color = "ğŸŸ¡"
    else:
        # é«˜ã™ãã‚‹ï¼šç²—ã„ï¼ˆè‚Œè’ã‚Œï¼‰
        diff = fd_3d - SKIN_FD_IDEAL_MAX
        fd_score = max(0, 100 - diff * 50)
        if fd_3d > 3.0:
            fd_comment = "ç²—ã„ï¼ˆè‚Œè’ã‚Œï¼‰"
            fd_color = "ğŸ”´"
        else:
            fd_comment = "ã‚„ã‚„ç²—ã„"
            fd_color = "ğŸŸ "
    
    # è¡¨é¢ç²—ã•ã«ã‚ˆã‚‹è©•ä¾¡
    roughness_score = 100 - min(100, roughness['std'] / 2.55)
    
    # ç·åˆè©•ä¾¡
    total_score = (fd_score * 0.7 + roughness_score * 0.3)
    
    # ãƒ©ãƒ³ã‚¯ä»˜ã‘
    if total_score >= 90:
        rank = "S (éå¸¸ã«è‰¯ã„)"
        rank_color = "ğŸŸ¢"
    elif total_score >= 75:
        rank = "A (è‰¯ã„)"
        rank_color = "ğŸ”µ"
    elif total_score >= 60:
        rank = "B (æ™®é€š)"
        rank_color = "ğŸŸ¡"
    elif total_score >= 40:
        rank = "C (ã‚„ã‚„æ‚ªã„)"
        rank_color = "ğŸŸ "
    else:
        rank = "D (æ‚ªã„)"
        rank_color = "ğŸ”´"
    
    evaluation = {
        "fd_3d": fd_3d,
        "fd_score": fd_score,
        "fd_comment": fd_comment,
        "fd_color": fd_color,
        "roughness_score": roughness_score,
        "total_score": total_score,
        "rank": rank,
        "rank_color": rank_color,
        "in_ideal_range": SKIN_FD_IDEAL_MIN <= fd_3d <= SKIN_FD_IDEAL_MAX
    }
    
    return evaluation, f"{rank_color} {rank}"

# ----------------------------
# ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ(ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆæ³•ãƒ»é–¾å€¤èª¿æ•´å¯¾å¿œãƒ»é«˜é€ŸåŒ–ç‰ˆ)
# ----------------------------
def fractal_dimension(image, threshold_value=128, use_otsu=False, max_size=512):
    # ç”»åƒã‚µã‚¤ã‚ºã‚’åˆ¶é™ï¼ˆé«˜é€ŸåŒ–ï¼‰
    h, w = image.shape[:2]
    if max(h, w) > max_size:
        scale = max_size / max(h, w)
        new_size = (int(w * scale), int(h * scale))
        image = cv2.resize(image, new_size)
    
    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # é–¾å€¤å‡¦ç†
    if use_otsu:
        threshold_value, binary = cv2.threshold(image_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    else:
        _, binary = cv2.threshold(image_gray, threshold_value, 255, cv2.THRESH_BINARY)

    # ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›ï¼ˆ8æ®µéšâ†’6æ®µéšï¼‰
    sizes = 2 ** np.arange(1, 7)
    counts = []
    for size in sizes:
        resized = cv2.resize(binary, (binary.shape[1] // size, binary.shape[0] // size))
        count = np.sum(resized > 0)
        counts.append(count)

    # 0ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–
    valid_sizes = []
    valid_counts = []
    for size, count in zip(sizes, counts):
        if count > 0:
            valid_sizes.append(size)
            valid_counts.append(count)
    
    # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
    if len(valid_sizes) < 3:
        return None, sizes, counts, binary, threshold_value
    
    # ç•°å¸¸æ¤œå‡ºï¼ˆã™ã¹ã¦åŒã˜å€¤ï¼‰
    if all(c == valid_counts[0] for c in valid_counts):
        return None, sizes, counts, binary, threshold_value  # ç„¡åŠ¹ãªçµæœ
    
    coeffs = np.polyfit(np.log(valid_sizes), np.log(valid_counts), 1)
    fractal_dim = -coeffs[0]
    
    # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    if fractal_dim < 0 or fractal_dim > 3:
        return None, sizes, counts, binary, threshold_value  # ç„¡åŠ¹ãªçµæœ
    
    return fractal_dim, sizes, counts, binary, threshold_value

# ----------------------------
# ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒæ¯”è¼ƒã‚°ãƒ©ãƒ•ï¼ˆç·šã‚°ãƒ©ãƒ•ï¼‰
# ----------------------------
def plot_fractal_comparison(fd_low, fd_enhanced, fd_high):
    """3ã¤ã®ç”»åƒã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’ç·šã‚°ãƒ©ãƒ•ã§æ¯”è¼ƒ"""
    fig, ax = plt.subplots(figsize=(8, 5))
    
    # Noneå€¤ã®ãƒã‚§ãƒƒã‚¯
    if None in [fd_low, fd_enhanced, fd_high]:
        ax.text(0.5, 0.5, 'è¨ˆç®—ã‚¨ãƒ©ãƒ¼\nãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ', 
                ha='center', va='center', transform=ax.transAxes, fontsize=14, color='red')
        return fig
    
    categories = ['ä½ç”»è³ª', 'AIè£œæ­£å¾Œ', 'é«˜ç”»è³ª\n(ç›®æ¨™)']
    values = [fd_low, fd_enhanced, fd_high]
    colors = ['#e74c3c', '#3498db', '#2ecc71']
    
    # NaN/Infãƒã‚§ãƒƒã‚¯
    if any(not np.isfinite(v) for v in values):
        ax.text(0.5, 0.5, 'è¨ˆç®—ã‚¨ãƒ©ãƒ¼\nç„¡åŠ¹ãªå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™', 
                ha='center', va='center', transform=ax.transAxes, fontsize=14, color='red')
        return fig
    
    # ç·šã‚°ãƒ©ãƒ•
    ax.plot(categories, values, marker='o', linewidth=3, markersize=12, color='#34495e')
    
    # å„ç‚¹ã«è‰²ã‚’ã¤ã‘ã‚‹
    for i, (cat, val, color) in enumerate(zip(categories, values, colors)):
        ax.scatter(i, val, s=200, color=color, zorder=5, edgecolors='white', linewidth=2)
        ax.text(i, val + 0.05, f'{val:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    # æ”¹å–„ã®çŸ¢å°
    if fd_enhanced > fd_low:
        ax.annotate('', xy=(1, fd_enhanced), xytext=(0, fd_low),
                   arrowprops=dict(arrowstyle='->', color='green', lw=2, alpha=0.5))
        ax.text(0.5, (fd_low + fd_enhanced) / 2, 'æ”¹å–„â†‘', ha='center', color='green', fontweight='bold')
    elif fd_enhanced < fd_low:
        ax.annotate('', xy=(1, fd_enhanced), xytext=(0, fd_low),
                   arrowprops=dict(arrowstyle='->', color='red', lw=2, alpha=0.5))
        ax.text(0.5, (fd_low + fd_enhanced) / 2, 'ä½ä¸‹â†“', ha='center', color='red', fontweight='bold')
    
    ax.set_ylabel('ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ', fontsize=12, fontweight='bold')
    ax.set_title('ç”»åƒå“è³ªã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒæ¯”è¼ƒ', fontsize=14, fontweight='bold', pad=20)
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.set_ylim(min(values) - 0.2, max(values) + 0.2)
    
    return fig

# ----------------------------
# 3Dã‚°ãƒ©ãƒ•ç”Ÿæˆï¼ˆå›³ã‚’è¿”ã™ãƒ»é«˜é€ŸåŒ–ç‰ˆãƒ»ã‚µã‚¤ã‚ºèª¿æ•´ï¼‰
# ----------------------------
def generate_3d_surface(binary_image, max_resolution=128):
    h, w = binary_image.shape
    
    # è§£åƒåº¦ã‚’åˆ¶é™ï¼ˆé«˜é€ŸåŒ–ï¼‰
    if max(h, w) > max_resolution:
        scale = max_resolution / max(h, w)
        new_size = (int(w * scale), int(h * scale))
        binary_image = cv2.resize(binary_image, new_size)
        h, w = binary_image.shape
    
    X, Y = np.meshgrid(np.arange(w), np.arange(h))
    Z = binary_image.astype(np.float32) / 255.0 * 10  # æ˜åº¦ã‚’é«˜ã•ã«å¤‰æ›
    fig = plt.figure(figsize=(7, 5))  # ã‚µã‚¤ã‚ºç¸®å°: 8,6 â†’ 7,5
    ax = fig.add_subplot(111, projection='3d')
    ax.plot_surface(X, Y, Z, cmap='viridis', linewidth=0, antialiased=False)
    ax.set_title("3D ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¡¨é¢ (æ˜åº¦ãƒ™ãƒ¼ã‚¹)", fontsize=12, pad=10)
    ax.set_xlabel('X', fontsize=9)
    ax.set_ylabel('Y', fontsize=9)
    ax.set_zlabel('æ˜åº¦', fontsize=9)
    return fig

# ----------------------------
# ç©ºé–“å æœ‰ç‡ã®è¨ˆç®—ï¼ˆé»’ãƒ»ç™½ï¼‰
# ----------------------------
def calculate_occupancy(binary_image):
    total = binary_image.size
    white = np.sum(binary_image == 255)
    black = total - white
    return black / total * 100, white / total * 100

# ----------------------------
# ç”»åƒä¿å­˜ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ----------------------------
def save_image_to_bytes(image):
    """OpenCVç”»åƒã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›"""
    is_success, buffer = cv2.imencode(".png", image)
    return buffer.tobytes() if is_success else None

def fig_to_bytes(fig):
    """matplotlibã®figureã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›"""
    buf = io.BytesIO()
    fig.savefig(buf, format='png', bbox_inches='tight')
    buf.seek(0)
    return buf.getvalue()

# ----------------------------
# CSVå‡ºåŠ›é–¢æ•°
# ----------------------------
def create_results_csv(results_data):
    """è§£æçµæœã‚’CSVå½¢å¼ã§å‡ºåŠ›"""
    df = pd.DataFrame([results_data])
    return df.to_csv(index=False).encode('utf-8-sig')

# ----------------------------
# Streamlitã‚¢ãƒ—ãƒªæœ¬ä½“
# ----------------------------
st.title("ğŸ§  è‚Œè³ªåˆ†æã‚·ã‚¹ãƒ†ãƒ  - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ Ã— AIè£œæ­£")
st.markdown("**3Dè¡¨é¢è§£æã¨2Dãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã«ã‚ˆã‚‹ç·åˆçš„ãªè‚Œè³ªè©•ä¾¡**")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è‚Œè³ªåˆ†æè¨­å®š")
    
    st.markdown("""
    **ğŸ“‹ åˆ†æã®æµã‚Œ:**
    1. ä½ç”»è³ªç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    2. ï¼ˆä»»æ„ï¼‰é«˜ç”»è³ªç”»åƒã§å­¦ç¿’
    3. 3D+2Dä¸¡æ–¹ã§è‡ªå‹•è§£æ
    4. ç·åˆçš„ãªè‚Œè³ªè©•ä¾¡
    """)
    
    st.markdown("---")
    
    # AIå­¦ç¿’ã®ç²¾åº¦ãƒ»é€Ÿåº¦è¨­å®š
    st.subheader("ğŸ¤– AIå­¦ç¿’è¨­å®š")
    quality_mode = st.radio(
        "ç²¾åº¦ãƒ»é€Ÿåº¦ãƒãƒ©ãƒ³ã‚¹",
        ["âš¡ é«˜é€Ÿï¼ˆä½ç²¾åº¦ï¼‰", "âš–ï¸ ãƒãƒ©ãƒ³ã‚¹ï¼ˆæ¨å¥¨ï¼‰", "ğŸ¯ é«˜ç²¾åº¦ï¼ˆä½é€Ÿï¼‰"],
        index=1,
        help="å­¦ç¿’æ™‚é–“ã¨ç²¾åº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’é¸æŠ"
    )
    
    # ãƒ¢ãƒ¼ãƒ‰åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    if quality_mode == "âš¡ é«˜é€Ÿï¼ˆä½ç²¾åº¦ï¼‰":
        max_size, n_trees, max_depth_val = 256, 10, 5
        speed_text = "ç´„15ç§’ | ç²¾åº¦: ä¸­"
    elif quality_mode == "âš–ï¸ ãƒãƒ©ãƒ³ã‚¹ï¼ˆæ¨å¥¨ï¼‰":
        max_size, n_trees, max_depth_val = 384, 20, 10
        speed_text = "ç´„30ç§’ | ç²¾åº¦: é«˜"
    else:  # é«˜ç²¾åº¦
        max_size, n_trees, max_depth_val = 512, 50, 15
        speed_text = "ç´„90ç§’ | ç²¾åº¦: æœ€é«˜"
    
    st.caption(f"â±ï¸ äºˆæƒ³å‡¦ç†æ™‚é–“: {speed_text}")
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚ªãƒ—ã‚·ãƒ§ãƒ³
    use_augmentation = st.checkbox("ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½¿ç”¨", value=True, 
                                   help="å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å›è»¢ãƒ»åè»¢ã—ã¦3å€ã«å¢—ã‚„ã—ã¾ã™")
    
    # ç”»åƒã‚µã‚¤ã‚ºçµ±ä¸€è¨­å®š
    st.caption("ğŸ“ ç”»åƒã‚µã‚¤ã‚ºçµ±ä¸€")
    size_align_mode = st.selectbox(
        "ã‚µã‚¤ã‚ºãŒç•°ãªã‚‹å ´åˆ",
        ["ğŸ”¼ å¤§ãã„æ–¹ã«åˆã‚ã›ã‚‹ï¼ˆæ¨å¥¨ï¼‰", "ğŸ”½ å°ã•ã„æ–¹ã«åˆã‚ã›ã‚‹", "ğŸ“· é«˜ç”»è³ªã«åˆã‚ã›ã‚‹", "ğŸ“± ä½ç”»è³ªã«åˆã‚ã›ã‚‹"],
        index=0,
        help="ä½ç”»è³ªã¨é«˜ç”»è³ªã®ç”»åƒã‚µã‚¤ã‚ºãŒç•°ãªã‚‹å ´åˆã®å‡¦ç†æ–¹æ³•"
    )
    
    # ãƒ¢ãƒ¼ãƒ‰å¤‰æ›
    if "å¤§ãã„æ–¹" in size_align_mode:
        align_mode = "larger"
    elif "å°ã•ã„æ–¹" in size_align_mode:
        align_mode = "smaller"
    elif "é«˜ç”»è³ª" in size_align_mode:
        align_mode = "high"
    else:
        align_mode = "low"
    
    st.markdown("---")
    
    # è‚Œè³ªåŸºæº–ã®èª¬æ˜
    st.subheader("ğŸ“Š ç†æƒ³çš„ãªè‚Œã®åŸºæº–")
    st.markdown(f"""
    **3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ:**
    - ç†æƒ³ç¯„å›²: {SKIN_FD_IDEAL_MIN} ~ {SKIN_FD_IDEAL_MAX}
    - ã“ã®ç¯„å›²å†…: æ»‘ã‚‰ã‹ã§å¥åº·çš„ãªè‚Œ
    - ç¯„å›²å¤–: å‡¹å‡¸ãŒå¤šã„orå°‘ãªã„
    
    **è©•ä¾¡ãƒ©ãƒ³ã‚¯:**
    - S (90ç‚¹ä»¥ä¸Š): å„ªç§€
    - A (80-90ç‚¹): è‰¯å¥½
    - B (70-80ç‚¹): æ™®é€š
    - C (60-70ç‚¹): è¦æ”¹å–„
    - D (60ç‚¹æœªæº€): ä¸è‰¯
    """)
    
    st.markdown("---")
    
    # è§£æãƒ¢ãƒ¼ãƒ‰é¸æŠï¼ˆè‚Œåˆ†æç”¨ã«3D+2Dã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    st.subheader("ğŸ”¬ è§£æãƒ¢ãƒ¼ãƒ‰")
    analysis_mode = st.radio(
        "è§£ææ‰‹æ³•ã‚’é¸æŠ",
        ["ï¿½ ä¸¡æ–¹å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼šè‚Œåˆ†æç”¨ï¼‰", "ï¿½ğŸ”² 2Dè§£æã®ã¿", "ğŸŒ 3Dè¡¨é¢è§£æã®ã¿"],
        index=0,
        help="è‚Œåˆ†æã«ã¯3D+2Dã®ä¸¡æ–¹å®Ÿè¡Œã‚’æ¨å¥¨ | 2D: é€šå¸¸ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æ | 3D: è¡¨é¢å‡¹å‡¸ã‚’è€ƒæ…®ã—ãŸè‚Œè³ªè§£æ"
    )
    
    st.markdown("---")
    
    # é–¾å€¤è¨­å®šï¼ˆ2Dè§£æç”¨ï¼‰
    if "2D" in analysis_mode or "ä¸¡æ–¹" in analysis_mode:
        st.subheader("äºŒå€¤åŒ–è¨­å®šï¼ˆ2Dè§£æç”¨ï¼‰")
        use_otsu = st.checkbox("å¤§æ´¥ã®äºŒå€¤åŒ–ã‚’ä½¿ç”¨", value=False,
                              help="è‡ªå‹•ã§æœ€é©ãªé–¾å€¤ã‚’è¨ˆç®—ã—ã¾ã™")
        
        threshold_value = 128
        if not use_otsu:
            threshold_value = st.slider("æ‰‹å‹•é–¾å€¤", 0, 255, 128,
                                       help="äºŒå€¤åŒ–ã®é–¾å€¤ã‚’æ‰‹å‹•ã§è¨­å®šã—ã¾ã™")
    else:
        use_otsu = False
        threshold_value = 128

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
st.markdown("### ğŸ“¸ è‚Œç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: åŒã˜éƒ¨ä½ã®ç•°ãªã‚‹è§£åƒåº¦ã®ç”»åƒã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€AIå­¦ç¿’ã«ã‚ˆã‚Šé«˜ç²¾åº¦ãªåˆ†æãŒå¯èƒ½ã§ã™")
col1, col2 = st.columns(2)
with col1:
    uploaded_low = st.file_uploader("ğŸ“ ä½ç”»è³ªç”»åƒï¼ˆåˆ†æå¯¾è±¡ï¼‰", type=["jpg", "png", "bmp"], 
                                    help="åˆ†æã—ãŸã„è‚Œç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
with col2:
    uploaded_high = st.file_uploader("ğŸ“ é«˜ç”»è³ªç”»åƒï¼ˆå­¦ç¿’ç”¨ãƒ»ä»»æ„ï¼‰", type=["jpg", "png", "bmp"],
                                     help="åŒã˜éƒ¨ä½ã®é«˜ç”»è³ªç”»åƒãŒã‚ã‚‹ã¨ã€AIãŒå­¦ç¿’ã—ã¦è£œæ­£ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™")

if uploaded_low is not None:
    low_img = cv2.imdecode(np.frombuffer(uploaded_low.read(), np.uint8), cv2.IMREAD_COLOR)
    
    st.markdown("---")
    
    # ç”»åƒã‚µã‚¤ã‚ºæƒ…å ±ã‚’è¡¨ç¤º
    st.info(f"ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {low_img.shape[1]} Ã— {low_img.shape[0]} px | è§£æãƒ¢ãƒ¼ãƒ‰: 3D+2Dä¸¡æ–¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰")
    
    # AIç”»åƒè£œå®Œ
    enhanced_img = None
    model_score = None
    
    if uploaded_high is not None:
        high_img = cv2.imdecode(np.frombuffer(uploaded_high.read(), np.uint8), cv2.IMREAD_COLOR)
        
        # ç”»åƒã‚µã‚¤ã‚ºã®æ¯”è¼ƒè¡¨ç¤º
        low_size = f"{low_img.shape[1]}Ã—{low_img.shape[0]}"
        high_size = f"{high_img.shape[1]}Ã—{high_img.shape[0]}"
        
        size_col1, size_col2, size_col3 = st.columns(3)
        with size_col1:
            st.metric("ğŸ“± ä½ç”»è³ª", low_size)
        with size_col2:
            if low_img.shape[:2] != high_img.shape[:2]:
                st.warning("âš ï¸ ã‚µã‚¤ã‚ºä¸ä¸€è‡´")
                st.caption(f"â†’ {align_mode}ãƒ¢ãƒ¼ãƒ‰ã§çµ±ä¸€")
            else:
                st.success("âœ… ã‚µã‚¤ã‚ºä¸€è‡´")
        with size_col3:
            st.metric("ğŸ“· é«˜ç”»è³ª", high_size)
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text(f'ğŸ¤– åŒæ–¹å‘å­¦ç¿’æº–å‚™ä¸­... ({quality_mode})')
        progress_bar.progress(20)
        
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ¼ãƒ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å­¦ç¿’
        model, model_score, training_count, original_count = train_image_enhancer(
            [low_img], [high_img], 
            use_augmentation=use_augmentation,
            max_size=max_size,
            n_trees=n_trees,
            max_depth_val=max_depth_val,
            align_mode=align_mode
        )
        progress_bar.progress(70)
        
        status_text.text('ğŸ–¼ï¸ ç”»åƒè£œå®Œä¸­...')
        enhanced_img = enhance_image(model, low_img, max_size=max_size)
        progress_bar.progress(100)
        
        status_text.empty()
        progress_bar.empty()
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°ã¨ç²¾åº¦ã‚’è¡¨ç¤º
        metric_cols = st.columns(4)
        with metric_cols[0]:
            st.metric("ğŸ–¼ï¸ å­¦ç¿’ç”»åƒãƒšã‚¢æ•°", f"{original_count} çµ„")
        with metric_cols[1]:
            st.metric("ğŸ“š å­¦ç¿’ãƒ‘ãƒƒãƒæ•°", f"{training_count} å€‹")
        with metric_cols[2]:
            st.metric("ğŸ¯ ãƒ¢ãƒ‡ãƒ«ç²¾åº¦", f"{model_score:.3f}")
        with metric_cols[3]:
            st.metric("âš™ï¸ å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰", quality_mode)
        
        st.success(f"âœ… å­¦ç¿’å®Œäº†!")
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°æƒ…å ±
        with st.expander("ğŸ“– å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°"):
            st.markdown(f"""
            **åŒæ–¹å‘å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ§‹æˆ:**
            - å…ƒç”»åƒãƒšã‚¢: 1çµ„ï¼ˆä½ç”»è³ªâ†’é«˜ç”»è³ªï¼‰
            - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ: 4å€ï¼ˆå›è»¢ï¼‰
            - åŠ£åŒ–ç”»åƒç”Ÿæˆ: é«˜ç”»è³ªã‹ã‚‰æœ€å¤§5ãƒ‘ã‚¿ãƒ¼ãƒ³
            - ç–‘ä¼¼é«˜ç”»è³ªç”Ÿæˆ: ä½ç”»è³ªã‹ã‚‰3ãƒ‘ã‚¿ãƒ¼ãƒ³
            
            **æœ€çµ‚çš„ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿:**
            - ç·ç”»åƒãƒšã‚¢æ•°: **{original_count}çµ„**
            - ç·ãƒ‘ãƒƒãƒæ•°: **{training_count}å€‹**
            - ãƒ‘ãƒƒãƒã‚µã‚¤ã‚º: 32Ã—32ãƒ”ã‚¯ã‚»ãƒ«
            - ç‰¹å¾´é‡æ¬¡å…ƒæ•°: 3,079æ¬¡å…ƒï¼ˆãƒ”ã‚¯ã‚»ãƒ«+ã‚¨ãƒƒã‚¸+çµ±è¨ˆï¼‰
            """)
        
        # ç”»åƒæ¯”è¼ƒè¡¨ç¤º
        st.subheader("ğŸ“Š ç”»åƒæ¯”è¼ƒ")
        img_cols = st.columns(3)
        with img_cols[0]:
            st.image(cv2.cvtColor(low_img, cv2.COLOR_BGR2RGB), caption="ä½ç”»è³ª", use_container_width=True)
        with img_cols[1]:
            st.image(cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB), caption="AIè£œå®Œå¾Œ", use_container_width=True)
        with img_cols[2]:
            st.image(cv2.cvtColor(high_img, cv2.COLOR_BGR2RGB), caption="é«˜ç”»è³ª(æ­£è§£)", use_container_width=True)
        
        target_img = enhanced_img
        
        # è§£æãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸå‡¦ç†
        st.markdown("---")
        
        # 3Dè¡¨é¢è§£æï¼ˆè‚Œè³ªç”¨ï¼‰
        if "3D" in analysis_mode or "ä¸¡æ–¹" in analysis_mode:
            st.subheader("ğŸŒ 3Dè¡¨é¢è§£æï¼ˆè‚Œè³ªè©•ä¾¡ï¼‰")
            
            with st.spinner('ğŸ” 3ã¤ã®ç”»åƒã®3Dè¡¨é¢ã‚’è§£æä¸­...'):
                # ä½ç”»è³ªç”»åƒã®3Dè§£æ
                roughness_low = calculate_surface_roughness(low_img)
                fd_3d_low, box_sizes_3d_low, counts_3d_low = fractal_dimension_3d_surface(low_img)
                
                # AIè£œæ­£å¾Œç”»åƒã®3Dè§£æ
                roughness_enhanced = calculate_surface_roughness(enhanced_img)
                fd_3d_enhanced, box_sizes_3d_enhanced, counts_3d_enhanced = fractal_dimension_3d_surface(enhanced_img)
                
                # é«˜ç”»è³ªç”»åƒã®3Dè§£æ
                roughness_high = calculate_surface_roughness(high_img)
                fd_3d_high, box_sizes_3d_high, counts_3d_high = fractal_dimension_3d_surface(high_img)
            
            if fd_3d_low is not None and fd_3d_enhanced is not None and fd_3d_high is not None:
                # 3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¯”è¼ƒ
                st.subheader("ğŸ“Š 3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¯”è¼ƒ")
                
                fd_3d_cols = st.columns(3)
                with fd_3d_cols[0]:
                    st.metric("ğŸ“± ä½ç”»è³ª", f"{fd_3d_low:.4f}")
                with fd_3d_cols[1]:
                    delta_3d = fd_3d_enhanced - fd_3d_low
                    st.metric("ğŸ¤– AIè£œæ­£å¾Œ", f"{fd_3d_enhanced:.4f}", delta=f"{delta_3d:+.4f}")
                with fd_3d_cols[2]:
                    st.metric("ğŸ“· é«˜ç”»è³ª(ç›®æ¨™)", f"{fd_3d_high:.4f}")
                
                # 3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒæ¯”è¼ƒã‚°ãƒ©ãƒ•ï¼ˆ1ã¤ã«ã¾ã¨ã‚ãŸæŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ï¼‰
                st.subheader("ğŸ“ˆ 3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¨ç§»ï¼ˆçµ±åˆã‚°ãƒ©ãƒ•ï¼‰")
                
                fig_3d_comparison = plt.figure(figsize=(14, 6))
                
                # log-logãƒ—ãƒ­ãƒƒãƒˆï¼ˆ3ã¤ã®ç”»åƒã‚’ã¾ã¨ã‚ã¦è¡¨ç¤ºï¼‰
                ax = fig_3d_comparison.add_subplot(111)
                
                # ä½ç”»è³ª
                if box_sizes_3d_low is not None and counts_3d_low is not None:
                    log_sizes_low = np.log(box_sizes_3d_low)
                    log_counts_low = np.log(counts_3d_low)
                    ax.plot(log_sizes_low, log_counts_low, 'o-', color='#e74c3c', 
                           linewidth=2, markersize=6, label=f'ä½ç”»è³ª (FD={fd_3d_low:.4f})', alpha=0.7)
                    
                    # å›å¸°ç›´ç·š
                    coeffs_low = np.polyfit(log_sizes_low, log_counts_low, 1)
                    fitted_low = np.polyval(coeffs_low, log_sizes_low)
                    ax.plot(log_sizes_low, fitted_low, '--', color='#e74c3c', linewidth=1.5, alpha=0.5)
                
                # AIè£œæ­£å¾Œ
                if box_sizes_3d_enhanced is not None and counts_3d_enhanced is not None:
                    log_sizes_enhanced = np.log(box_sizes_3d_enhanced)
                    log_counts_enhanced = np.log(counts_3d_enhanced)
                    ax.plot(log_sizes_enhanced, log_counts_enhanced, 's-', color='#3498db', 
                           linewidth=2, markersize=6, label=f'AIè£œæ­£å¾Œ (FD={fd_3d_enhanced:.4f})', alpha=0.7)
                    
                    # å›å¸°ç›´ç·š
                    coeffs_enhanced = np.polyfit(log_sizes_enhanced, log_counts_enhanced, 1)
                    fitted_enhanced = np.polyval(coeffs_enhanced, log_sizes_enhanced)
                    ax.plot(log_sizes_enhanced, fitted_enhanced, '--', color='#3498db', linewidth=1.5, alpha=0.5)
                
                # é«˜ç”»è³ª
                if box_sizes_3d_high is not None and counts_3d_high is not None:
                    log_sizes_high = np.log(box_sizes_3d_high)
                    log_counts_high = np.log(counts_3d_high)
                    ax.plot(log_sizes_high, log_counts_high, '^-', color='#2ecc71', 
                           linewidth=2, markersize=6, label=f'é«˜ç”»è³ª (FD={fd_3d_high:.4f})', alpha=0.7)
                    
                    # å›å¸°ç›´ç·š
                    coeffs_high = np.polyfit(log_sizes_high, log_counts_high, 1)
                    fitted_high = np.polyval(coeffs_high, log_sizes_high)
                    ax.plot(log_sizes_high, fitted_high, '--', color='#2ecc71', linewidth=1.5, alpha=0.5)
                
                # ç†æƒ³ç¯„å›²ã‚’è¡¨ç¤ºï¼ˆèƒŒæ™¯ï¼‰
                y_min, y_max = ax.get_ylim()
                ax.axhspan(y_min, y_max, alpha=0.05, color='green', zorder=0)
                ax.text(0.02, 0.98, f'ç†æƒ³ç¯„å›²: FD {SKIN_FD_IDEAL_MIN}~{SKIN_FD_IDEAL_MAX}', 
                       transform=ax.transAxes, va='top', fontsize=9, 
                       bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))
                
                ax.set_xlabel('log(ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º)', fontsize=11)
                ax.set_ylabel('log(ã‚«ã‚¦ãƒ³ãƒˆæ•°)', fontsize=11)
                ax.set_title('3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¯”è¼ƒ (log-logãƒ—ãƒ­ãƒƒãƒˆ)', fontsize=12, pad=10)
                ax.legend(loc='best', fontsize=10, framealpha=0.9)
                ax.grid(True, alpha=0.3, linestyle='--')
                
                plt.tight_layout()
                st.pyplot(fig_3d_comparison)
                plt.close(fig_3d_comparison)
                
                # AIè£œæ­£å¾Œç”»åƒã®è‚Œè³ªè©•ä¾¡
                skin_eval, skin_eval_text = evaluate_skin_quality(fd_3d_enhanced, roughness_enhanced)
                
                # è©•ä¾¡çµæœè¡¨ç¤º
                st.subheader("ğŸ¯ AIè£œæ­£å¾Œã®è‚Œè³ªè©•ä¾¡")
                st.success(f"âœ… 3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ(AIè£œæ­£å¾Œ): **{fd_3d_enhanced:.4f}**")
                
                eval_cols = st.columns(4)
                with eval_cols[0]:
                    st.metric("ğŸ¯ ç·åˆã‚¹ã‚³ã‚¢", f"{skin_eval['total_score']:.1f}ç‚¹")
                with eval_cols[1]:
                    st.metric("ğŸ“Š è©•ä¾¡ãƒ©ãƒ³ã‚¯", skin_eval_text)
                with eval_cols[2]:
                    if skin_eval['in_ideal_range']:
                        st.metric("âœ… ç†æƒ³ç¯„å›²", "ç¯„å›²å†…", delta="è‰¯å¥½")
                    else:
                        st.metric("âš ï¸ ç†æƒ³ç¯„å›²", "ç¯„å›²å¤–", delta=skin_eval['fd_comment'])
                with eval_cols[3]:
                    st.metric("ğŸ“ FDè©•ä¾¡", f"{skin_eval['fd_score']:.1f}ç‚¹")
                
                # 3ã¤ã®ç”»åƒã®3Dè§£æã‚°ãƒ©ãƒ•ã‚’ä¸¦ã¹ã¦è¡¨ç¤º
                st.subheader("ğŸ“ˆ å„ç”»åƒã®3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ")
                
                analysis_cols = st.columns(3)
                with analysis_cols[0]:
                    st.markdown("**ä½ç”»è³ª**")
                    fig_3d_low = plot_3d_fractal_analysis(box_sizes_3d_low, counts_3d_low, fd_3d_low)
                    st.pyplot(fig_3d_low)
                    plt.close(fig_3d_low)
                
                with analysis_cols[1]:
                    st.markdown("**AIè£œæ­£å¾Œ**")
                    fig_3d_enhanced = plot_3d_fractal_analysis(box_sizes_3d_enhanced, counts_3d_enhanced, fd_3d_enhanced)
                    st.pyplot(fig_3d_enhanced)
                    plt.close(fig_3d_enhanced)
                
                with analysis_cols[2]:
                    st.markdown("**é«˜ç”»è³ª**")
                    fig_3d_high = plot_3d_fractal_analysis(box_sizes_3d_high, counts_3d_high, fd_3d_high)
                    st.pyplot(fig_3d_high)
                    plt.close(fig_3d_high)
                
                # è¡¨é¢ç²—ã•æ¯”è¼ƒ
                st.subheader("ğŸ”¬ è¡¨é¢å‡¹å‡¸ã®æ¯”è¼ƒè§£æ")
                
                roughness_cols = st.columns(3)
                with roughness_cols[0]:
                    st.markdown("**ä½ç”»è³ª**")
                    fig_rough_low = plot_surface_roughness(low_img, roughness_low)
                    st.pyplot(fig_rough_low)
                    plt.close(fig_rough_low)
                
                with roughness_cols[1]:
                    st.markdown("**AIè£œæ­£å¾Œ**")
                    fig_rough_enhanced = plot_surface_roughness(enhanced_img, roughness_enhanced)
                    st.pyplot(fig_rough_enhanced)
                    plt.close(fig_rough_enhanced)
                
                with roughness_cols[2]:
                    st.markdown("**é«˜ç”»è³ª**")
                    fig_rough_high = plot_surface_roughness(high_img, roughness_high)
                    st.pyplot(fig_rough_high)
                    plt.close(fig_rough_high)
                
                # è©³ç´°æƒ…å ±ï¼ˆ3ã¤ã®ç”»åƒã®æ¯”è¼ƒï¼‰
                with st.expander("ğŸ“– 3Dè§£æã®è©³ç´°ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒ"):
                    detail_cols = st.columns(3)
                    
                    with detail_cols[0]:
                        st.markdown("**ä½ç”»è³ª - è¡¨é¢ç²—ã•æŒ‡æ¨™:**")
                        st.write(f"- 3D FD: {fd_3d_low:.4f}")
                        st.write(f"- æ¨™æº–åå·®: {roughness_low['std']:.2f}")
                        st.write(f"- å¹³å‡çµ¶å¯¾åå·®: {roughness_low['mad']:.2f}")
                        st.write(f"- å‹¾é…å¹³å‡: {roughness_low['gradient']:.2f}")
                        st.write(f"- ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³åˆ†æ•£: {roughness_low['laplacian']:.2f}")
                    
                    with detail_cols[1]:
                        st.markdown("**AIè£œæ­£å¾Œ - è¡¨é¢ç²—ã•æŒ‡æ¨™:**")
                        st.write(f"- 3D FD: {fd_3d_enhanced:.4f}")
                        st.write(f"- æ¨™æº–åå·®: {roughness_enhanced['std']:.2f}")
                        st.write(f"- å¹³å‡çµ¶å¯¾åå·®: {roughness_enhanced['mad']:.2f}")
                        st.write(f"- å‹¾é…å¹³å‡: {roughness_enhanced['gradient']:.2f}")
                        st.write(f"- ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³åˆ†æ•£: {roughness_enhanced['laplacian']:.2f}")
                    
                    with detail_cols[2]:
                        st.markdown("**é«˜ç”»è³ª - è¡¨é¢ç²—ã•æŒ‡æ¨™:**")
                        st.write(f"- 3D FD: {fd_3d_high:.4f}")
                        st.write(f"- æ¨™æº–åå·®: {roughness_high['std']:.2f}")
                        st.write(f"- å¹³å‡çµ¶å¯¾åå·®: {roughness_high['mad']:.2f}")
                        st.write(f"- å‹¾é…å¹³å‡: {roughness_high['gradient']:.2f}")
                        st.write(f"- ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³åˆ†æ•£: {roughness_high['laplacian']:.2f}")
                    
                    st.markdown("---")
                    st.markdown("**ç†æƒ³çš„ãªè‚Œã®åŸºæº–:**")
                    st.write(f"- ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: {SKIN_FD_IDEAL_MIN}~{SKIN_FD_IDEAL_MAX}")
            else:
                st.error("âŒ 3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
            st.markdown("---")
        
        # 2Dè§£æï¼ˆæ¨™æº–ï¼‰
        if "2D" in analysis_mode or "ä¸¡æ–¹" in analysis_mode:
            st.subheader("ğŸ“Š 2Dãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒæ¯”è¼ƒåˆ†æ")
            
            with st.spinner('ğŸ” 3ã¤ã®ç”»åƒã‚’è§£æä¸­...'):
                fd_low, _, _, _, _ = fractal_dimension(low_img, threshold_value, use_otsu)
                fd_enhanced, sizes, counts, binary, used_threshold = fractal_dimension(enhanced_img, threshold_value, use_otsu)
                fd_high, _, _, _, _ = fractal_dimension(high_img, threshold_value, use_otsu)
            
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            if fd_low is None or fd_enhanced is None or fd_high is None:
                st.error("âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            else:
                # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¯”è¼ƒè¡¨ç¤º
                fd_compare_cols = st.columns(3)
                with fd_compare_cols[0]:
                    st.metric("ğŸ“± ä½ç”»è³ª", f"{fd_low:.4f}")
                with fd_compare_cols[1]:
                    delta = fd_enhanced - fd_low
                    st.metric("ğŸ¤– AIè£œæ­£å¾Œ", f"{fd_enhanced:.4f}", delta=f"{delta:+.4f}")
                with fd_compare_cols[2]:
                    st.metric("ğŸ“· é«˜ç”»è³ª(ç›®æ¨™)", f"{fd_high:.4f}")
                
                # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒæ¯”è¼ƒã‚°ãƒ©ãƒ•
                st.subheader("ğŸ“ˆ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¨ç§»")
                fig_comparison = plot_fractal_comparison(fd_low, fd_enhanced, fd_high)
                st.pyplot(fig_comparison)
                plt.close(fig_comparison)
                
                # AIè£œæ­£ã®è©•ä¾¡
                evaluation, eval_text = evaluate_ai_correction(fd_low, fd_enhanced, fd_high)
                
                if evaluation:
                    st.subheader("ğŸ¯ AIè£œæ­£ç²¾åº¦è©•ä¾¡")
                    
                    eval_cols = st.columns(4)
                    with eval_cols[0]:
                        st.metric("æ”¹å–„ç‡", f"{evaluation['improvement_rate']:.1f}%")
                    with eval_cols[1]:
                        st.metric("è©•ä¾¡ãƒ©ãƒ³ã‚¯", eval_text)
                    with eval_cols[2]:
                        st.metric("ç›®æ¨™ã¨ã®å·®", f"{evaluation['target_diff']:.4f}")
                    with eval_cols[3]:
                        st.metric("æ”¹å–„åº¦", f"{evaluation['improvement']:.4f}")
                    
                    # è©•ä¾¡ã®è©³ç´°èª¬æ˜
                    with st.expander("ğŸ“– è©•ä¾¡åŸºæº–ã®è©³ç´°"):
                        st.markdown("""
                        **è©•ä¾¡ãƒ©ãƒ³ã‚¯:**
                        - ğŸŸ¢ **S (90%ä»¥ä¸Š)**: å„ªç§€ - é«˜ç”»è³ªã«ã»ã¼å®Œå…¨ã«è¿‘ã¥ã„ã¦ã„ã¾ã™
                        - ğŸ”µ **A (75-90%)**: è‰¯å¥½ - é«˜ã„è£œæ­£ç²¾åº¦ã‚’é”æˆã—ã¦ã„ã¾ã™
                        - ğŸŸ¡ **B (60-75%)**: æ™®é€š - ä¸€å®šã®è£œæ­£åŠ¹æœãŒè¦‹ã‚‰ã‚Œã¾ã™
                        - ğŸŸ  **C (40-60%)**: è¦æ”¹å–„ - è£œæ­£åŠ¹æœãŒé™å®šçš„ã§ã™
                        - ğŸ”´ **D (40%æœªæº€)**: ä¸è‰¯ - è£œæ­£ãŒä¸ååˆ†ã§ã™
                        
                        **æ”¹å–„ç‡**: ä½ç”»è³ªã‹ã‚‰é«˜ç”»è³ªã¸ã®è·é›¢ã®ã†ã¡ã€ã©ã‚Œã ã‘è¿‘ã¥ã„ãŸã‹ã‚’ç¤ºã—ã¾ã™
                        """)
    else:
        st.warning("âš ï¸ é«˜ç”»è³ªç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è£œå®Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        target_img = low_img
        
        st.markdown("---")
        
        # 3Dè¡¨é¢è§£æï¼ˆå˜ç‹¬ç”»åƒï¼‰
        if "3D" in analysis_mode or "ä¸¡æ–¹" in analysis_mode:
            st.subheader("ğŸŒ 3Dè¡¨é¢è§£æï¼ˆè‚Œè³ªè©•ä¾¡ï¼‰")
            
            with st.spinner('ğŸ” 3Dè¡¨é¢å‡¹å‡¸ã‚’è§£æä¸­...'):
                roughness = calculate_surface_roughness(target_img)
                fd_3d, box_sizes_3d, counts_3d = fractal_dimension_3d_surface(target_img)
            
            if fd_3d is not None:
                skin_eval, skin_eval_text = evaluate_skin_quality(fd_3d, roughness)
                
                st.success(f"âœ… 3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: **{fd_3d:.4f}**")
                
                eval_cols = st.columns(4)
                with eval_cols[0]:
                    st.metric("ğŸ¯ ç·åˆã‚¹ã‚³ã‚¢", f"{skin_eval['total_score']:.1f}ç‚¹")
                with eval_cols[1]:
                    st.metric("ğŸ“Š è©•ä¾¡ãƒ©ãƒ³ã‚¯", skin_eval_text)
                with eval_cols[2]:
                    if skin_eval['in_ideal_range']:
                        st.metric("âœ… ç†æƒ³ç¯„å›²", "ç¯„å›²å†…", delta="è‰¯å¥½")
                    else:
                        st.metric("âš ï¸ ç†æƒ³ç¯„å›²", "ç¯„å›²å¤–", delta=skin_eval['fd_comment'])
                with eval_cols[3]:
                    st.metric("ğŸ“ FDè©•ä¾¡", f"{skin_eval['fd_score']:.1f}ç‚¹")
                
                fig_3d_analysis = plot_3d_fractal_analysis(box_sizes_3d, counts_3d, fd_3d)
                st.pyplot(fig_3d_analysis)
                plt.close(fig_3d_analysis)
                
                fig_roughness = plot_surface_roughness(target_img, roughness)
                st.pyplot(fig_roughness)
                plt.close(fig_roughness)
            else:
                st.error("âŒ 3Dè¡¨é¢ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
            st.markdown("---")
        
        # 2Dè§£æï¼ˆå˜ç‹¬ç”»åƒï¼‰
        if "2D" in analysis_mode or "ä¸¡æ–¹" in analysis_mode:
            st.subheader("ğŸ“ˆ 2Dãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ")
            
            with st.spinner('ğŸ” è§£æä¸­...'):
                fd_enhanced, sizes, counts, binary, used_threshold = fractal_dimension(target_img, threshold_value, use_otsu)
            
            if fd_enhanced is None:
                st.error("âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            else:
                # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¡¨ç¤º
                col_fd1, col_fd2 = st.columns(2)
                with col_fd1:
                    st.metric("ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ", f"{fd_enhanced:.4f}")
                with col_fd2:
                    st.metric("ä½¿ç”¨ã—ãŸé–¾å€¤", f"{used_threshold}")
                
                # ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆã‚°ãƒ©ãƒ•ï¼ˆã‚µã‚¤ã‚ºç¸®å°ï¼‰
                st.subheader("ğŸ“‰ ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆè§£æ")
                
                # 0ã‚’é™¤å¤–ã—ã¦ã‚°ãƒ©ãƒ•æç”»
                valid_indices = [i for i, c in enumerate(counts) if c > 0]
                fig_boxcount = None  # åˆæœŸåŒ–
                if len(valid_indices) >= 2:
                    valid_sizes_plot = [sizes[i] for i in valid_indices]
                    valid_counts_plot = [counts[i] for i in valid_indices]
                    
                    fig_boxcount, ax = plt.subplots(figsize=(7, 4))  # 8,5 â†’ 7,4
                    ax.plot(np.log(valid_sizes_plot), np.log(valid_counts_plot), 
                           marker="o", linewidth=2, markersize=8, color='#3498db')
                    ax.set_xlabel("log(ãƒœãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º)", fontsize=10)
                    ax.set_ylabel("log(ã‚«ã‚¦ãƒ³ãƒˆæ•°)", fontsize=10)
                    ax.set_title("ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆæ³•ã«ã‚ˆã‚‹ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ", fontsize=11, pad=10)
                    ax.grid(True, alpha=0.3)
                    st.pyplot(fig_boxcount)
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã«ä¿å­˜ã—ã¦ã‹ã‚‰é–‰ã˜ã‚‹ï¼ˆå¾Œã§ä½¿ã†ï¼‰
                else:
                    st.warning("âš ï¸ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
                
                # äºŒå€¤åŒ–ç”»åƒè¡¨ç¤º
                st.subheader("ğŸ–¼ï¸ äºŒå€¤åŒ–ç”»åƒ")
                st.image(binary, caption="äºŒå€¤åŒ–çµæœ", use_container_width=True, clamp=True)
                
                # 3Dã‚°ãƒ©ãƒ•å‡ºåŠ›
                st.subheader("ğŸŒ 3D ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¡¨é¢")
                fig_3d = generate_3d_surface(binary)
                st.pyplot(fig_3d)
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã«ä¿å­˜ã—ã¦ã‹ã‚‰é–‰ã˜ã‚‹ï¼ˆå¾Œã§ä½¿ã†ï¼‰
                
                # ç©ºé–“å æœ‰ç‡
                black_rate, white_rate = calculate_occupancy(binary)
                
                st.subheader("ğŸ“Š ç©ºé–“å æœ‰ç‡")
                col_occ1, col_occ2 = st.columns(2)
                with col_occ1:
                    st.metric("é»’ãƒ”ã‚¯ã‚»ãƒ«", f"{black_rate:.2f}%")
                with col_occ2:
                    st.metric("ç™½ãƒ”ã‚¯ã‚»ãƒ«", f"{white_rate:.2f}%")
                
                # å††ã‚°ãƒ©ãƒ•ï¼ˆã‚µã‚¤ã‚ºç¸®å°ï¼‰
                fig_pie, ax_pie = plt.subplots(figsize=(5, 5))  # 6,6 â†’ 5,5
                ax_pie.pie([black_rate, white_rate], labels=["é»’", "ç™½"], autopct="%.1f%%", 
                           startangle=90, colors=['#2c3e50', '#ecf0f1'], textprops={'fontsize': 10})
                ax_pie.set_title("ç©ºé–“å æœ‰ç‡ã®åˆ†å¸ƒ", fontsize=11, pad=10)
                st.pyplot(fig_pie)
                plt.close(fig_pie)
                
                st.markdown("---")
                
                # çµæœã®ä¿å­˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                st.subheader("ğŸ’¾ çµæœã®ä¿å­˜")
                
                # CSVãƒ‡ãƒ¼ã‚¿ä½œæˆ
                results_data = {
                    "è§£ææ—¥æ™‚": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ(AIè£œæ­£å¾Œ)": fd_enhanced,
                    "é–¾å€¤": used_threshold,
                    "å¤§æ´¥æ³•ä½¿ç”¨": use_otsu,
                    "é»’ãƒ”ã‚¯ã‚»ãƒ«ç‡(%)": black_rate,
                    "ç™½ãƒ”ã‚¯ã‚»ãƒ«ç‡(%)": white_rate,
                    "ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ": use_augmentation,
                    "ãƒ¢ãƒ‡ãƒ«ç²¾åº¦": model_score if model_score else "N/A"
                }
                
                # é«˜ç”»è³ªç”»åƒãŒã‚ã‚‹å ´åˆã¯æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚‚è¿½åŠ ï¼ˆå¤‰æ•°ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ï¼‰
                # ã“ã‚Œã¯æ¯”è¼ƒç”»åƒè§£ææ™‚ã®ã¿æœ‰åŠ¹
                # results_data["ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ(ä½ç”»è³ª)"] = fd_low (å˜ç‹¬ç”»åƒã§ã¯æœªå®šç¾©)
                # results_data["ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ(é«˜ç”»è³ª)"] = fd_high (å˜ç‹¬ç”»åƒã§ã¯æœªå®šç¾©)
                
                csv_data = create_results_csv(results_data)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                download_cols = st.columns(4)
                
                with download_cols[0]:
                    st.download_button(
                        label="ğŸ“„ CSVå‡ºåŠ›",
                        data=csv_data,
                        file_name=f"fractal_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                
                with download_cols[1]:
                    img_bytes = save_image_to_bytes(target_img)
                    if img_bytes:
                        st.download_button(
                            label="ğŸ–¼ï¸ ç”»åƒ",
                            data=img_bytes,
                            file_name=f"image_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                            mime="image/png"
                        )
                
                with download_cols[2]:
                    if fig_boxcount is not None:
                        graph_bytes = fig_to_bytes(fig_boxcount)
                        st.download_button(
                            label="ğŸ“Š ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒˆ",
                            data=graph_bytes,
                            file_name=f"boxcount_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                            mime="image/png"
                        )
                    else:
                        st.info("ã‚°ãƒ©ãƒ•ãªã—")
                
                with download_cols[3]:
                    if fig_3d is not None:
                        graph_3d_bytes = fig_to_bytes(fig_3d)
                        st.download_button(
                            label="ğŸŒ 3Dã‚°ãƒ©ãƒ•",
                            data=graph_3d_bytes,
                            file_name=f"3d_surface_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                            mime="image/png"
                        )
                    else:
                        st.info("ã‚°ãƒ©ãƒ•ãªã—")
                
                # ã‚°ãƒ©ãƒ•ã‚’ã‚¯ãƒ­ãƒ¼ã‚º
                if fig_boxcount is not None:
                    plt.close(fig_boxcount)
                if fig_3d is not None:
                    plt.close(fig_3d)

else:
    st.info("ğŸ‘† ä½ç”»è³ªç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray; font-size: 12px;'>
    <p>ğŸ”¬ Fractal Analyzer V2 with AI Enhancement | Powered by Streamlit & OpenCV</p>
</div>
""", unsafe_allow_html=True)
