# -*- coding: utf-8 -*-
"""
è‚Œåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
é¡”æ¤œå‡ºã€éƒ¨ä½åˆ†å‰²ã€è‚Œãƒˆãƒ©ãƒ–ãƒ«æ¤œå‡ºæ©Ÿèƒ½ã‚’æä¾›
Python 3.13å¯¾å¿œç‰ˆ - OpenCV + dlib(ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
"""

import cv2
import numpy as np
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import matplotlib
import os
matplotlib.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False

# æ¤œå‡ºå™¨ã®åˆæœŸåŒ–ï¼ˆé…å»¶ãƒ­ãƒ¼ãƒ‰ï¼‰
_face_mesh = None
_face_cascade = None
_dlib_detector = None
_dlib_predictor = None
_mediapipe_available = False

def _init_face_detectors():
    """é¡”æ¤œå‡ºå™¨ã‚’åˆæœŸåŒ–"""
    global _face_cascade, _dlib_detector, _dlib_predictor, _mediapipe_available, _face_mesh
    
    # OpenCV Haar Cascadeï¼ˆå¿…ãšå‹•ãï¼‰
    if _face_cascade is None:
        candidates = [
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml',
            cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml',
        ]
        for cascade_path in candidates:
            if os.path.exists(cascade_path):
                clf = cv2.CascadeClassifier(cascade_path)
                if not clf.empty():
                    _face_cascade = clf
                    break
        if _face_cascade is None:
            print("Warning: Haar cascade not found. OpenCV face detection may fail.")
    
    # MediaPipeï¼ˆPython 3.12ä»¥ä¸‹ã®ã¿ï¼‰
    if _face_mesh is None:
        try:
            import mediapipe as mp
            mp_face_mesh = mp.solutions.face_mesh
            _face_mesh = mp_face_mesh.FaceMesh(
                static_image_mode=True,
                max_num_faces=1,
                refine_landmarks=True,
                min_detection_confidence=0.1,
                min_tracking_confidence=0.1
            )
            _mediapipe_available = True
            print("MediaPipeåˆæœŸåŒ–æˆåŠŸ")
        except ImportError:
            _mediapipe_available = False
            print("MediaPipeåˆ©ç”¨ä¸å¯ - OpenCVãƒ™ãƒ¼ã‚¹ã®æ¤œå‡ºã‚’ä½¿ç”¨")
    
    # dlibï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if _dlib_detector is None:
        try:
            import dlib
            _dlib_detector = dlib.get_frontal_face_detector()
            # 68ç‚¹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯äºˆæ¸¬å™¨ï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰
            predictor_path = "shape_predictor_68_face_landmarks.dat"
            if os.path.exists(predictor_path):
                _dlib_predictor = dlib.shape_predictor(predictor_path)
        except ImportError:
            pass


def get_face_mesh():
    """MediaPipe Face Meshã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global _face_mesh, _mediapipe_available
    _init_face_detectors()
    return _face_mesh if _mediapipe_available else None


def get_face_cascade():
    """OpenCV Haar Cascadeé¡”æ¤œå‡ºå™¨ã‚’å–å¾—"""
    global _face_cascade
    _init_face_detectors()
    return _face_cascade


def detect_face_opencv(image):
    """
    OpenCVã‚’ä½¿ç”¨ã—ã¦é¡”ã‚’æ¤œå‡ºã—ã€é¡”é ˜åŸŸã®çŸ©å½¢ã‚’è¿”ã™
    
    Returns:
        (x, y, w, h) or None
    """
    _init_face_detectors()
    
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # è¤‡æ•°ã®å‰å‡¦ç†ã‚’è©¦è¡Œ
    preprocessing_methods = [
        ("original", gray),
        ("clahe", cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(gray)),
        ("equalized", cv2.equalizeHist(gray)),
    ]
    
    for method_name, processed_gray in preprocessing_methods:
        if _face_cascade is not None and not _face_cascade.empty():
            # ç”»åƒã‚µã‚¤ã‚ºã«å¿œã˜ã¦æœ€å°ã‚µã‚¤ã‚ºã‚’å¯å¤‰è¨­å®š
            h_img, w_img = processed_gray.shape[:2]
            min_side = max(30, int(min(h_img, w_img) * 0.08))
            min_size = (min_side, min_side)

            # è¤‡æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒªãƒˆãƒ©ã‚¤
            param_sets = [
                dict(scaleFactor=1.1, minNeighbors=5, minSize=min_size),
                dict(scaleFactor=1.05, minNeighbors=4, minSize=min_size),
                dict(scaleFactor=1.2, minNeighbors=3, minSize=(30, 30)),
            ]
            for params in param_sets:
                faces = _face_cascade.detectMultiScale(
                    processed_gray,
                    **params,
                    flags=cv2.CASCADE_SCALE_IMAGE
                )
                if len(faces) > 0:
                    x, y, w, h = max(faces, key=lambda f: f[2] * f[3])
                    print(f"OpenCV Haar Cascade ({method_name}, params={params})ã§é¡”æ¤œå‡ºæˆåŠŸ")
                    return (x, y, w, h)
    
    # dlibã‚’è©¦è¡Œ
    if _dlib_detector is not None:
        try:
            faces = _dlib_detector(gray, 1)
            if len(faces) > 0:
                face = max(faces, key=lambda r: r.width() * r.height())
                x, y = face.left(), face.top()
                w, h = face.width(), face.height()
                print("dlibã§é¡”æ¤œå‡ºæˆåŠŸ")
                return (x, y, w, h)
        except:
            pass
    
    # ç”»åƒä¸­å¤®ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    # é¡”ãŒå¤§ããã€å‰å‡¦ç†ã§ã¯æ¤œå‡ºã§ããªã„ã‚±ãƒ¼ã‚¹å‘ã‘
    try:
        h_img, w_img = image.shape[:2]
        cx, cy = w_img // 2, h_img // 2
        fw = int(w_img * 0.6)
        fh = int(h_img * 0.7)
        x = max(0, cx - fw // 2)
        y = max(0, cy - int(fh * 0.45))  # çœ‰ã€œé¡ã‚ãŸã‚Šã‚’ä¸­å¿ƒã«ã‚„ã‚„ä¸Šå¯„ã›
        w = min(fw, w_img - x)
        h = min(fh, h_img - y)
        print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä¸­å¤®æ¨å®šçŸ©å½¢ã§é¡”é ˜åŸŸã‚’ä»®å®š")
        return (x, y, w, h)
    except Exception:
        pass

    return None


def detect_face_landmarks(image):
    """
    é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æ¤œå‡º
    MediaPipeãŒåˆ©ç”¨å¯èƒ½ãªã‚‰478ç‚¹ã€ãã†ã§ãªã‘ã‚Œã°ç°¡æ˜“çš„ãªé¡”é ˜åŸŸæƒ…å ±ã‚’è¿”ã™
    
    Args:
        image: BGRç”»åƒ
    
    Returns:
        landmarks: MediaPipeãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã€ã¾ãŸã¯ç°¡æ˜“FaceRegionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€å¤±æ•—æ™‚ã¯None
    """
    _init_face_detectors()
    
    original = image.copy()
    h, w = original.shape[:2]
    
    # MediaPipeãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆ
    if _mediapipe_available and _face_mesh is not None:
        preprocessing_methods = [
            ("original", lambda img: img),
            ("clahe", apply_clahe),
            ("gamma_bright", lambda img: apply_gamma(img, 1.5)),
            ("gamma_dark", lambda img: apply_gamma(img, 0.7)),
            ("histogram_eq", apply_histogram_equalization),
        ]
        
        for method_name, preprocess_func in preprocessing_methods:
            try:
                processed = preprocess_func(original.copy())
                img = normalize_image_size(processed)
                rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                
                results = _face_mesh.process(rgb_image)
                
                if results.multi_face_landmarks:
                    print(f"MediaPipe ({method_name})ã§é¡”æ¤œå‡ºæˆåŠŸ")
                    return results.multi_face_landmarks[0]
            except Exception as e:
                continue
    
    # OpenCVãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    face_rect = detect_face_opencv(original)
    if face_rect is not None:
        # ç°¡æ˜“çš„ãªFaceRegionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        return SimpleFaceRegion(face_rect, (w, h))
    
    return None


class SimpleFaceRegion:
    """OpenCVã§æ¤œå‡ºã—ãŸé¡”é ˜åŸŸã‚’è¡¨ã™ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, face_rect, image_size):
        """
        Args:
            face_rect: (x, y, w, h) é¡”ã®çŸ©å½¢
            image_size: (width, height) ç”»åƒã‚µã‚¤ã‚º
        """
        self.face_rect = face_rect
        self.image_size = image_size
        self.is_simple = True  # MediaPipeã§ã¯ãªã„ã“ã¨ã‚’ç¤ºã™ãƒ•ãƒ©ã‚°
        
        # ä»®æƒ³çš„ãªãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’ç”Ÿæˆ
        self.landmark = self._generate_virtual_landmarks()
    
    def _generate_virtual_landmarks(self):
        """é¡”ã®çŸ©å½¢ã‹ã‚‰ä»®æƒ³çš„ãªãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’ç”Ÿæˆ"""
        x, y, w, h = self.face_rect
        img_w, img_h = self.image_size
        
        # æ­£è¦åŒ–åº§æ¨™ã§ä»®æƒ³ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’ç”Ÿæˆï¼ˆ478ç‚¹ã«è¿‘ä¼¼ï¼‰
        landmarks = []
        
        # é¡”ã®å„éƒ¨ä½ã®ç›¸å¯¾ä½ç½®ï¼ˆçµŒé¨“çš„ãªæ¯”ç‡ï¼‰
        # é¡: ä¸Šéƒ¨15-35%
        # ç›®: 35-45%
        # é¼»: 45-70%
        # å£: 70-85%
        # é¡: 85-100%
        
        for i in range(478):
            # ç°¡ç•¥åŒ–ã®ãŸã‚ã€é¡”ã®çŸ©å½¢å†…ã«ãƒ©ãƒ³ãƒ€ãƒ ã«ç‚¹ã‚’é…ç½®
            # å®Ÿéš›ã«ã¯å„éƒ¨ä½ã®å…¸å‹çš„ãªä½ç½®ã«åŸºã¥ã„ã¦é…ç½®
            rel_x = (i % 22) / 22.0  # 0-1ã®ç¯„å›²
            rel_y = (i // 22) / 22.0
            
            norm_x = (x + w * rel_x) / img_w
            norm_y = (y + h * rel_y) / img_h
            
            landmarks.append(VirtualLandmark(norm_x, norm_y))
        
        return landmarks


class VirtualLandmark:
    """ä»®æƒ³çš„ãªãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ç‚¹"""
    def __init__(self, x, y):
        self.x = x
        self.y = y


def normalize_image_size(image, target_max=1024, target_min=480):
    """ç”»åƒã‚µã‚¤ã‚ºã‚’æ­£è¦åŒ–"""
    h, w = image.shape[:2]
    
    if max(w, h) > target_max:
        scale = target_max / max(w, h)
        new_w = int(w * scale)
        new_h = int(h * scale)
        return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    elif max(w, h) < target_min:
        scale = target_min / max(w, h)
        new_w = int(w * scale)
        new_h = int(h * scale)
        return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
    return image


def apply_clahe(image):
    """CLAHEã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿"""
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    enhanced = cv2.merge([l, a, b])
    return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)


def apply_gamma(image, gamma):
    """ã‚¬ãƒ³ãƒè£œæ­£"""
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
    return cv2.LUT(image, table)


def apply_histogram_equalization(image):
    """ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ä¸€åŒ–"""
    img_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
    img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])
    return cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)


def extract_face_regions(image, landmarks):
    """
    é¡”ç”»åƒã‹ã‚‰å„éƒ¨ä½ã‚’æŠ½å‡º
    MediaPipeãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã¾ãŸã¯SimpleFaceRegionï¼ˆOpenCVãƒ™ãƒ¼ã‚¹ï¼‰ã«å¯¾å¿œ
    
    Args:
        image: BGRç”»åƒ
        landmarks: MediaPipeã®é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ ã¾ãŸã¯ SimpleFaceRegion
    
    Returns:
        dict: å„éƒ¨ä½ã®ç”»åƒã¨åº§æ¨™ {region_name: {'image': img, 'bbox': (x, y, w, h)}}
    """
    h, w = image.shape[:2]
    regions = {}
    
    # SimpleFaceRegionï¼ˆOpenCVãƒ™ãƒ¼ã‚¹ï¼‰ã®å ´åˆã¯ã€é¡”ã®çŸ©å½¢ã‹ã‚‰éƒ¨ä½ã‚’æ¨å®š
    if hasattr(landmarks, 'is_simple') and landmarks.is_simple:
        return extract_face_regions_from_rect(image, landmarks.face_rect)
    
    # MediaPipeãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®å ´åˆ
    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’ç”»åƒåº§æ¨™ã«å¤‰æ›
    points = []
    for landmark in landmarks.landmark:
        x = int(landmark.x * w)
        y = int(landmark.y * h)
        points.append((x, y))
    points = np.array(points)
    
    # é¡ï¼ˆãŠã§ã“ï¼‰: é¡”ä¸Šéƒ¨
    forehead_indices = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 
                        397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 
                        172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109]
    if all(i < len(points) for i in forehead_indices):
        forehead_points = points[forehead_indices]
        x, y, w_region, h_region = cv2.boundingRect(forehead_points)
        # ä¸Šæ–¹å‘ã«æ‹¡å¼µï¼ˆé«ªã®ç”Ÿãˆéš›ã¾ã§ï¼‰
        y_start = max(0, y - h_region // 2)
        y_end = y + h_region
        regions['forehead'] = {
            'image': image[y_start:y_end, x:x+w_region],
            'bbox': (x, y_start, w_region, y_end - y_start)
        }
    
    # å·¦é ¬
    left_cheek_indices = [116, 123, 147, 213, 192, 214, 212, 202, 204, 194, 135, 
                          210, 169, 170, 171, 208, 32, 49, 48, 64, 98]
    if all(i < len(points) for i in left_cheek_indices):
        left_points = points[left_cheek_indices]
        x, y, w_region, h_region = cv2.boundingRect(left_points)
        regions['left_cheek'] = {
            'image': image[y:y+h_region, x:x+w_region],
            'bbox': (x, y, w_region, h_region)
        }
    
    # å³é ¬
    right_cheek_indices = [345, 352, 376, 433, 416, 434, 432, 422, 424, 418, 364,
                           430, 394, 395, 396, 428, 262, 279, 278, 294, 327]
    if all(i < len(points) for i in right_cheek_indices):
        right_points = points[right_cheek_indices]
        x, y, w_region, h_region = cv2.boundingRect(right_points)
        regions['right_cheek'] = {
            'image': image[y:y+h_region, x:x+w_region],
            'bbox': (x, y, w_region, h_region)
        }
    
    # é¼»
    nose_indices = [4, 5, 195, 197, 196, 174, 198, 236, 3, 51, 45, 6, 168, 122, 
                    188, 412, 351, 419, 248, 281, 275, 440, 456, 399, 437]
    if all(i < len(points) for i in nose_indices):
        nose_points = points[nose_indices]
        x, y, w_region, h_region = cv2.boundingRect(nose_points)
        # é¼»ã‚’ã•ã‚‰ã«ã‚ãšã‹ã«å³ä¸‹ã¸ï¼ˆ+2.5%å¹…ã€+2%é«˜ï¼‰
        shift_x = max(1, int(0.025 * w))
        shift_y = max(1, int(0.020 * h))
        x = max(0, min(x + shift_x, w - w_region))
        y = max(0, min(y + shift_y, h - h_region))
        regions['nose'] = {
            'image': image[y:y+h_region, x:x+w_region],
            'bbox': (x, y, w_region, h_region)
        }
    
    # å£å‘¨ã‚Š
    mouth_indices = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324,
                     318, 402, 317, 14, 87, 178, 88, 95, 78, 191, 80, 81, 82]
    if all(i < len(points) for i in mouth_indices):
        mouth_points = points[mouth_indices]
        x, y, w_region, h_region = cv2.boundingRect(mouth_points)
        # å‘¨è¾ºï¼ˆå£å‘¨ã‚Šï¼‰ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼šæ¨ª10%ã€ä¸Š9%ã€ä¸‹16%ï¼ˆã‚‚ã†å°‘ã—ä¸‹å¯„ã›ï¼‰
        pad_x = max(2, int(w_region * 0.10))
        pad_top = max(1, int(h_region * 0.09))
        pad_bot = max(2, int(h_region * 0.16))
        x1 = max(0, x - pad_x)
        x2 = min(w, x + w_region + pad_x)
        y1 = max(0, y - pad_top)
        y2 = min(h, y + h_region + pad_bot)
        # å…¨ä½“ã‚’ã•ã‚‰ã«ä¸‹ã¸2%ï¼ˆç”»åƒé«˜åŸºæº–ï¼‰
        shift_down = max(1, int(0.02 * h))
        y1 = min(h - 1, y1 + shift_down)
        y2 = min(h, max(y1 + 1, y2 + max(1, int(0.01 * h))))
        regions['mouth_area'] = {
            'image': image[y1:y2, x1:x2],
            'bbox': (x1, y1, x2 - x1, y2 - y1)
        }
        mouth_y_end = y2
    
    # é¡
    # é¡ï¼ˆä¸‹é¡ãƒ©ã‚¤ãƒ³ã®ã¿ã«é™å®šã—ã¦çŸ©å½¢åŒ–ï¼‰
    chin_jaw_indices = [152, 377, 400, 378, 379, 365, 397, 288, 361, 323, 454, 356]
    if all(i < len(points) for i in chin_jaw_indices):
        chin_points = points[chin_jaw_indices]
        cx, cy, cw, ch = cv2.boundingRect(chin_points)
        jaw_max_y = int(np.max(chin_points[:, 1]))
        jaw_min_y = int(np.min(chin_points[:, 1]))
        # å£é ˜åŸŸã®ä¸‹ç«¯ã‚ˆã‚Šå°‘ã—ä¸‹ã‹ã‚‰é–‹å§‹ã€‚é¡ãƒ©ã‚¤ãƒ³ã‚’ä¸‹å›ã‚Šã™ããªã„ã‚ˆã†åˆ¶é™ã€‚
        margin = max(2, int(0.02 * h))
        base_start = cy + int(ch * 0.18)
        try:
            base_start = max(base_start, mouth_y_end + margin)
        except NameError:
            pass
        # é¡ãƒ©ã‚¤ãƒ³ä»˜è¿‘ã«ã‚¯ãƒ©ãƒ³ãƒ—ï¼ˆä¸‹ã¸ã¯+2%hã¾ã§ï¼‰
        y_start = max(jaw_min_y, min(base_start, jaw_max_y - int(0.04 * h)))
        y_end = min(h, min(jaw_max_y + int(0.02 * h), y_start + int(0.08 * h)))
        # æ¨ªã¯å°‘ã—å†…å´ã«ï¼ˆé ¬ã‚’å«ã¿ã™ããªã„ã‚ˆã†ã«ï¼‰
        x1 = max(0, cx + int(cw * 0.05))
        x2 = min(w, cx + cw - int(cw * 0.05))
        if y_end > y_start and x2 > x1:
            regions['chin'] = {
                'image': image[y_start:y_end, x1:x2],
                'bbox': (x1, y_start, x2 - x1, y_end - y_start)
            }
    
    # ç›®ã®ä¸‹ï¼ˆã‚¯ãƒãƒ»ãã™ã¿æ¤œå‡ºç”¨ï¼‰
    left_under_eye_indices = [226, 247, 30, 29, 27, 28, 56, 190, 243, 112, 26, 22, 23, 24]
    right_under_eye_indices = [446, 467, 260, 259, 257, 258, 286, 414, 463, 341, 256, 252, 253, 254]
    
    if all(i < len(points) for i in left_under_eye_indices):
        left_ue_points = points[left_under_eye_indices]
        x, y, w_region, h_region = cv2.boundingRect(left_ue_points)
        regions['left_under_eye'] = {
            'image': image[y:y+h_region, x:x+w_region],
            'bbox': (x, y, w_region, h_region)
        }
    
    if all(i < len(points) for i in right_under_eye_indices):
        right_ue_points = points[right_under_eye_indices]
        x, y, w_region, h_region = cv2.boundingRect(right_ue_points)
        regions['right_under_eye'] = {
            'image': image[y:y+h_region, x:x+w_region],
            'bbox': (x, y, w_region, h_region)
        }
    
    return regions


def extract_face_regions_from_rect(image, face_rect):
    """
    é¡”ã®çŸ©å½¢ã‹ã‚‰å„éƒ¨ä½ã‚’æ¨å®šã—ã¦æŠ½å‡ºï¼ˆOpenCVãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    é¡”ã®ä¸€èˆ¬çš„ãªæ¯”ç‡ã«åŸºã¥ã„ã¦éƒ¨ä½ã‚’æ¨å®š
    
    Args:
        image: BGRç”»åƒ
        face_rect: (x, y, w, h) é¡”ã®çŸ©å½¢
    
    Returns:
        dict: å„éƒ¨ä½ã®ç”»åƒã¨åº§æ¨™
    """
    h, w = image.shape[:2]
    fx, fy, fw, fh = face_rect
    
    regions = {}
    
    # é¡”ã®æ¯”ç‡ã«åŸºã¥ã„ã¦éƒ¨ä½ã‚’æ¨å®š
    # é¡: é¡”ã®ä¸Šéƒ¨ 0-25%
    forehead_y1 = fy
    forehead_y2 = fy + int(fh * 0.25)
    forehead_x1 = fx + int(fw * 0.15)
    forehead_x2 = fx + int(fw * 0.85)
    if forehead_y2 > forehead_y1 and forehead_x2 > forehead_x1:
        regions['forehead'] = {
            'image': image[forehead_y1:forehead_y2, forehead_x1:forehead_x2],
            'bbox': (forehead_x1, forehead_y1, forehead_x2-forehead_x1, forehead_y2-forehead_y1)
        }
    
    # å·¦é ¬: é¡”ã®å·¦å´ 35-65%ã®é«˜ã•ã€5-35%ã®å¹…
    lc_y1 = fy + int(fh * 0.35)
    lc_y2 = fy + int(fh * 0.70)
    lc_x1 = fx + int(fw * 0.05)
    lc_x2 = fx + int(fw * 0.35)
    if lc_y2 > lc_y1 and lc_x2 > lc_x1:
        regions['left_cheek'] = {
            'image': image[lc_y1:lc_y2, lc_x1:lc_x2],
            'bbox': (lc_x1, lc_y1, lc_x2-lc_x1, lc_y2-lc_y1)
        }
    
    # å³é ¬: é¡”ã®å³å´ 35-65%ã®é«˜ã•ã€65-95%ã®å¹…
    rc_y1 = fy + int(fh * 0.35)
    rc_y2 = fy + int(fh * 0.70)
    rc_x1 = fx + int(fw * 0.65)
    rc_x2 = fx + int(fw * 0.95)
    if rc_y2 > rc_y1 and rc_x2 > rc_x1:
        regions['right_cheek'] = {
            'image': image[rc_y1:rc_y2, rc_x1:rc_x2],
            'bbox': (rc_x1, rc_y1, rc_x2-rc_x1, rc_y2-rc_y1)
        }
    
    # é¼»: é¡”ã®ä¸­å¤® 32-65%ã®é«˜ã•ã€å¹…ã¯ã•ã‚‰ã«å³å¯„ã‚Šï¼ˆ36-60%ï¼‰
    nose_y1 = fy + int(fh * 0.32)
    nose_y2 = fy + int(fh * 0.65)
    nose_x1 = fx + int(fw * 0.36)
    nose_x2 = fx + int(fw * 0.60)
    if nose_y2 > nose_y1 and nose_x2 > nose_x1:
        regions['nose'] = {
            'image': image[nose_y1:nose_y2, nose_x1:nose_x2],
            'bbox': (nose_x1, nose_y1, nose_x2-nose_x1, nose_y2-nose_y1)
        }
    
    # å£å‘¨ã‚Š: ä¸‹ã’ã™ãã¦é¦–ã«ã‹ã‹ã‚‰ãªã„ã‚ˆã†ã«åˆ¶é™
    mouth_y1 = max(fy + int(fh * 0.60), nose_y2 - int(fh * 0.06))
    mouth_y2 = min(fy + int(fh * 0.78), fy + int(fh * 0.82))
    mouth_x1 = fx + int(fw * 0.32)
    mouth_x2 = fx + int(fw * 0.68)
    if mouth_y2 > mouth_y1 and mouth_x2 > mouth_x1:
        regions['mouth_area'] = {
            'image': image[mouth_y1:mouth_y2, mouth_x1:mouth_x2],
            'bbox': (mouth_x1, mouth_y1, mouth_x2-mouth_x1, mouth_y2-mouth_y1)
        }
    
    # é¡: é«˜ã•ã‚’æœ€å¤§8%fhã€ä¸‹ç«¯ã¯é¡”çŸ©å½¢ã®93-96%ã«åˆ¶é™
    chin_x1 = fx + int(fw * 0.35)
    chin_x2 = fx + int(fw * 0.65)
    chin_y1 = min(fy + int(fh * 0.88), mouth_y2 + int(0.03 * fh))
    chin_y2 = min(fy + int(fh * 0.96), chin_y1 + int(fh * 0.08))
    if chin_y2 > chin_y1 and chin_x2 > chin_x1:
        regions['chin'] = {
            'image': image[chin_y1:chin_y2, chin_x1:chin_x2],
            'bbox': (chin_x1, chin_y1, chin_x2-chin_x1, chin_y2-chin_y1)
        }
    
    # å·¦ç›®ã®ä¸‹ï¼ˆã‚¯ãƒã®éƒ¨åˆ†ï¼‰: 42-55%ã®é«˜ã•ã€15-40%ã®å¹…
    # ç›®ã¯ç´„25-35%ã®é«˜ã•ã«ã‚ã‚Šã€ãã®ä¸‹ã®ã‚¯ãƒãƒ»ãŸã‚‹ã¿éƒ¨åˆ†
    lue_y1 = fy + int(fh * 0.42)
    lue_y2 = fy + int(fh * 0.55)
    lue_x1 = fx + int(fw * 0.12)
    lue_x2 = fx + int(fw * 0.42)
    if lue_y2 > lue_y1 and lue_x2 > lue_x1:
        regions['left_under_eye'] = {
            'image': image[lue_y1:lue_y2, lue_x1:lue_x2],
            'bbox': (lue_x1, lue_y1, lue_x2-lue_x1, lue_y2-lue_y1)
        }
    
    # å³ç›®ã®ä¸‹ï¼ˆã‚¯ãƒã®éƒ¨åˆ†ï¼‰: 42-55%ã®é«˜ã•ã€60-88%ã®å¹…
    rue_y1 = fy + int(fh * 0.42)
    rue_y2 = fy + int(fh * 0.55)
    rue_x1 = fx + int(fw * 0.58)
    rue_x2 = fx + int(fw * 0.88)
    if rue_y2 > rue_y1 and rue_x2 > rue_x1:
        regions['right_under_eye'] = {
            'image': image[rue_y1:rue_y2, rue_x1:rue_x2],
            'bbox': (rue_x1, rue_y1, rue_x2-rue_x1, rue_y2-rue_y1)
        }
    
    return regions


def detect_skin_troubles(region_image, region_name: str) -> Dict:
    """
    è‚Œãƒˆãƒ©ãƒ–ãƒ«ã‚’æ¤œå‡ºï¼ˆãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒãƒ™ãƒ¼ã‚¹ + ç”»åƒå‡¦ç†ï¼‰
    
    æ¤œå‡ºã§ãã‚‹è‚Œãƒˆãƒ©ãƒ–ãƒ«:
    - ä¹¾ç‡¥ï¼ˆã‚­ãƒ¡ã®ä¹±ã‚Œï¼‰: é«˜FDå€¤
    - æ¯›ç©´ã®ç›®ç«‹ã¡: é«˜FDå€¤ + æš—ç‚¹æ¤œå‡º
    - ã‚·ãƒ¯: é«˜FDå€¤ + ã‚¨ãƒƒã‚¸æ¤œå‡º
    - è‰²ãƒ ãƒ©ï¼ˆãã™ã¿ï¼‰: è‰²ã®æ¨™æº–åå·®
    - ãƒ‹ã‚­ãƒ“ãƒ»å¹ãå‡ºç‰©: èµ¤ã¿æ¤œå‡º
    - ã‚¯ãƒ: æš—ã•æ¤œå‡ºï¼ˆç›®ã®ä¸‹ã®ã¿ï¼‰
    - ãƒ†ã‚«ãƒªï¼ˆçš®è„‚éå¤šï¼‰: æ˜åº¦ã®é«˜ã„é ˜åŸŸ
    
    Args:
        region_image: éƒ¨ä½ã®ç”»åƒ
        region_name: éƒ¨ä½å
    
    Returns:
        dict: æ¤œå‡ºã•ã‚ŒãŸè‚Œãƒˆãƒ©ãƒ–ãƒ«æƒ…å ±
    """
    if region_image is None or region_image.size == 0:
        return {'error': 'ç”»åƒãŒä¸æ­£ã§ã™'}
    
    troubles = {}
    
    # åŸºæœ¬çš„ãªç”»åƒçµ±è¨ˆ
    gray = cv2.cvtColor(region_image, cv2.COLOR_BGR2GRAY)
    mean_brightness = np.mean(gray)
    std_brightness = np.std(gray)
    
    # HSVè‰²ç©ºé–“ã«å¤‰æ›
    hsv = cv2.cvtColor(region_image, cv2.COLOR_BGR2HSV)
    
    # 1. æ¯›ç©´ã®ç›®ç«‹ã¡æ¤œå‡ºï¼ˆæš—ç‚¹ã‚«ã‚¦ãƒ³ãƒˆï¼‰
    _, dark_spots = cv2.threshold(gray, mean_brightness - std_brightness, 255, cv2.THRESH_BINARY_INV)
    dark_spot_ratio = np.sum(dark_spots > 0) / dark_spots.size
    troubles['pore_visibility'] = {
        'score': min(dark_spot_ratio * 100, 100),
        'level': 'é«˜' if dark_spot_ratio > 0.15 else 'ä¸­' if dark_spot_ratio > 0.08 else 'ä½'
    }
    
    # 2. ã‚·ãƒ¯æ¤œå‡ºï¼ˆã‚¨ãƒƒã‚¸å¼·åº¦ï¼‰
    edges = cv2.Canny(gray, 50, 150)
    edge_ratio = np.sum(edges > 0) / edges.size
    troubles['wrinkles'] = {
        'score': min(edge_ratio * 500, 100),  # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        'level': 'é«˜' if edge_ratio > 0.12 else 'ä¸­' if edge_ratio > 0.06 else 'ä½'
    }
    
    # 3. è‰²ãƒ ãƒ©ãƒ»ãã™ã¿æ¤œå‡º
    color_std = np.std(region_image, axis=(0, 1)).mean()
    troubles['color_unevenness'] = {
        'score': min(color_std / 40 * 100, 100),
        'level': 'é«˜' if color_std > 35 else 'ä¸­' if color_std > 20 else 'ä½'
    }
    
    # 4. ãƒ‹ã‚­ãƒ“ãƒ»èµ¤ã¿æ¤œå‡ºï¼ˆèµ¤ãƒãƒ£ãƒ³ãƒãƒ«å„ªä½ï¼‰
    b, g, r = cv2.split(region_image)
    redness = np.mean(r) - np.mean(g)
    troubles['redness_acne'] = {
        'score': min(max(redness, 0) / 30 * 100, 100),
        'level': 'é«˜' if redness > 25 else 'ä¸­' if redness > 15 else 'ä½'
    }
    
    # 5. ã‚¯ãƒæ¤œå‡ºï¼ˆç›®ã®ä¸‹ã®ã¿ï¼‰
    if 'under_eye' in region_name:
        troubles['dark_circles'] = {
            'score': min((255 - mean_brightness) / 2.55, 100),
            'level': 'é«˜' if mean_brightness < 100 else 'ä¸­' if mean_brightness < 130 else 'ä½'
        }
    
    # 6. ãƒ†ã‚«ãƒªæ¤œå‡ºï¼ˆæ˜åº¦ã®é«˜ã„é ˜åŸŸï¼‰
    _, bright_spots = cv2.threshold(gray, mean_brightness + std_brightness, 255, cv2.THRESH_BINARY)
    bright_ratio = np.sum(bright_spots > 0) / bright_spots.size
    troubles['oiliness'] = {
        'score': min(bright_ratio * 200, 100),
        'level': 'é«˜' if bright_ratio > 0.20 else 'ä¸­' if bright_ratio > 0.10 else 'ä½'
    }
    
    # 7. è‚Œã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ç²—ã•ï¼ˆå¾Œã§FDå€¤ã‚’è¿½åŠ ï¼‰
    troubles['texture_roughness'] = {
        'score': 0,  # FDå€¤ã§ä¸Šæ›¸ãã•ã‚Œã‚‹
        'level': 'æœªè¨ˆç®—'
    }
    
    return troubles


def create_trouble_report(troubles_by_region: Dict, fd_by_region: Dict) -> str:
    """
    è‚Œãƒˆãƒ©ãƒ–ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    
    Args:
        troubles_by_region: éƒ¨ä½åˆ¥ã®è‚Œãƒˆãƒ©ãƒ–ãƒ«æƒ…å ±
        fd_by_region: éƒ¨ä½åˆ¥ã®ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
    
    Returns:
        str: ãƒ¬ãƒãƒ¼ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
    """
    report_lines = ["# ğŸ” è‚Œãƒˆãƒ©ãƒ–ãƒ«æ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆ\n"]
    
    # å„éƒ¨ä½ã®ãƒ¬ãƒãƒ¼ãƒˆ
    region_names_jp = {
        'forehead': 'é¡',
        'left_cheek': 'å·¦é ¬',
        'right_cheek': 'å³é ¬',
        'nose': 'é¼»',
        'mouth_area': 'å£å‘¨ã‚Š',
        'chin': 'é¡',
        'left_under_eye': 'å·¦ç›®ã®ä¸‹',
        'right_under_eye': 'å³ç›®ã®ä¸‹'
    }
    
    for region, troubles in troubles_by_region.items():
        region_jp = region_names_jp.get(region, region)
        report_lines.append(f"\n## ğŸ“ {region_jp}\n")
        
        # FDå€¤
        if region in fd_by_region:
            fd_val = fd_by_region[region]
            report_lines.append(f"- **ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ**: {fd_val:.4f}")
        
        # ä¸»è¦ãªãƒˆãƒ©ãƒ–ãƒ«
        high_troubles = []
        for trouble_name, trouble_data in troubles.items():
            if trouble_data.get('level') == 'é«˜':
                trouble_jp = {
                    'pore_visibility': 'æ¯›ç©´ã®ç›®ç«‹ã¡',
                    'wrinkles': 'ã‚·ãƒ¯',
                    'color_unevenness': 'è‰²ãƒ ãƒ©ãƒ»ãã™ã¿',
                    'redness_acne': 'ãƒ‹ã‚­ãƒ“ãƒ»èµ¤ã¿',
                    'dark_circles': 'ã‚¯ãƒ',
                    'oiliness': 'ãƒ†ã‚«ãƒª',
                    'texture_roughness': 'ã‚­ãƒ¡ã®ç²—ã•'
                }.get(trouble_name, trouble_name)
                high_troubles.append(trouble_jp)
        
        if high_troubles:
            report_lines.append(f"- âš ï¸ **æ¤œå‡ºã•ã‚ŒãŸãƒˆãƒ©ãƒ–ãƒ«**: {', '.join(high_troubles)}")
        else:
            report_lines.append("- âœ… **ç‰¹ã«å•é¡Œãªã—**")
    
    return '\n'.join(report_lines)


# éƒ¨ä½åã®æ—¥æœ¬èªãƒãƒƒãƒ”ãƒ³ã‚°
REGION_NAMES_JP = {
    'forehead': 'é¡',
    'left_cheek': 'å·¦é ¬',
    'right_cheek': 'å³é ¬',
    'nose': 'é¼»',
    'mouth_area': 'å£å‘¨ã‚Š',
    'chin': 'é¡',
    'left_under_eye': 'å·¦ç›®ã®ä¸‹',
    'right_under_eye': 'å³ç›®ã®ä¸‹'
}

# è‚Œãƒˆãƒ©ãƒ–ãƒ«åã®æ—¥æœ¬èªãƒãƒƒãƒ”ãƒ³ã‚°
TROUBLE_NAMES_JP = {
    'pore_visibility': 'æ¯›ç©´ã®ç›®ç«‹ã¡',
    'wrinkles': 'ã‚·ãƒ¯',
    'color_unevenness': 'è‰²ãƒ ãƒ©ãƒ»ãã™ã¿',
    'redness_acne': 'ãƒ‹ã‚­ãƒ“ãƒ»èµ¤ã¿',
    'dark_circles': 'ã‚¯ãƒ',
    'oiliness': 'ãƒ†ã‚«ãƒª',
    'texture_roughness': 'ã‚­ãƒ¡ã®ç²—ã•ï¼ˆFDå€¤ï¼‰'
}
