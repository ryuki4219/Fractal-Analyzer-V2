"""
AIå­¦ç¿’æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®AIäºˆæ¸¬ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã‹ç¢ºèªã—ã¾ã™
"""
import cv2
import numpy as np
from lightgbm import LGBMRegressor
import matplotlib.pyplot as plt

# GPUå¯¾å¿œ
USE_CUPY = False
try:
    import cupy as cp
    _ = cp.zeros(1)
    USE_CUPY = True
    xp = cp
except:
    USE_CUPY = False
    xp = np

def to_xp(arr):
    return cp.asarray(arr) if USE_CUPY else np.asarray(arr)

def to_host(arr):
    return cp.asnumpy(arr) if USE_CUPY else arr

def calculate_fd(img_bgr, scales=(2,4,8,16,32,64)):
    """ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã‚’è¨ˆç®—"""
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32)
    H, W = img_gray.shape
    
    Nh_vals = []
    valid_scales = []
    
    for h in scales:
        Hc = (H // h) * h
        Wc = (W // h) * h
        if Hc < h or Wc < h:
            continue
        
        gray_crop = img_gray[:Hc, :Wc]
        arr = to_xp(gray_crop)
        
        new_shape = (Hc//h, h, Wc//h, h)
        blocks = arr.reshape(new_shape).transpose(0,2,1,3)
        
        mean_blk = blocks.mean(axis=(2,3))
        sq_mean = (blocks**2).mean(axis=(2,3))
        std_blk = xp.sqrt(xp.maximum(0, sq_mean - mean_blk**2))
        
        nh = std_blk / float(h)
        nh_total = float(to_host(nh.sum()))
        
        Nh_vals.append(nh_total + 1e-12)
        valid_scales.append(h)
    
    if len(valid_scales) < 3:
        return None, [], []
    
    log_h = np.log(np.array(valid_scales, dtype=np.float64))
    log_Nh = np.log(np.array(Nh_vals, dtype=np.float64))
    
    coeffs = np.polyfit(log_h, log_Nh, 1)
    D = abs(coeffs[0])
    
    return float(D), valid_scales, Nh_vals

def extract_features(img_bgr):
    """ç‰¹å¾´é‡æŠ½å‡º"""
    gray = cv2.cvtColor(cv2.resize(img_bgr, (256, 256)), cv2.COLOR_BGR2GRAY).astype(np.float32)
    
    mean_val = float(gray.mean())
    std_val = float(gray.std())
    
    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)
    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
    edge_mean = float(np.mean(np.sqrt(gx**2 + gy**2)))
    
    noise_level = float(np.mean(np.abs(gray - cv2.GaussianBlur(gray, (3,3), 1))))
    
    probs, _ = np.histogram(gray.flatten(), bins=256, range=(0,255), density=True)
    probs = probs + 1e-12
    entropy = -np.sum(probs * np.log2(probs))
    
    return [mean_val, std_val, edge_mean, noise_level, entropy]

def create_test_images(n_samples=10):
    """ãƒ†ã‚¹ãƒˆç”¨ã®ç”»åƒãƒšã‚¢ã‚’ç”Ÿæˆ"""
    print("ãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆä¸­...")
    
    high_imgs = []
    low_imgs = []
    
    for i in range(n_samples):
        # é«˜ç”»è³ªç”»åƒï¼ˆ512x512ï¼‰
        img_high = np.random.randint(0, 256, (512, 512, 3), dtype=np.uint8)
        
        # ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ 
        for _ in range(50):
            x, y = np.random.randint(0, 450), np.random.randint(0, 450)
            size = np.random.randint(20, 80)
            color = tuple(np.random.randint(0, 256, 3).tolist())
            cv2.rectangle(img_high, (x, y), (x+size, y+size), color, -1)
        
        # ä½ç”»è³ªç”»åƒï¼ˆãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°+ãƒã‚¤ã‚ºï¼‰
        img_low = cv2.resize(img_high, (128, 128))
        img_low = cv2.resize(img_low, (512, 512))
        
        # ãƒã‚¤ã‚ºè¿½åŠ 
        noise = np.random.normal(0, 20, img_low.shape).astype(np.int16)
        img_low = np.clip(img_low.astype(np.int16) + noise, 0, 255).astype(np.uint8)
        
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼
        img_low = cv2.GaussianBlur(img_low, (5, 5), 1.5)
        
        high_imgs.append(img_high)
        low_imgs.append(img_low)
    
    print(f"âœ… {n_samples}çµ„ã®ç”»åƒãƒšã‚¢ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    return high_imgs, low_imgs

def test_ai_learning():
    """AIå­¦ç¿’ã®ãƒ†ã‚¹ãƒˆ"""
    print("="*60)
    print("ğŸ”¬ AIå­¦ç¿’æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*60)
    
    # ãƒ†ã‚¹ãƒˆç”»åƒç”Ÿæˆ
    n_train = 15
    n_test = 5
    
    print(f"\nğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {n_train}çµ„")
    print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {n_test}çµ„")
    
    high_train, low_train = create_test_images(n_train)
    high_test, low_test = create_test_images(n_test)
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®FDã‚’è¨ˆç®—
    print("\nğŸ”¢ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®FDè¨ˆç®—ä¸­...")
    X_train = []
    y_train = []
    
    for i, (low, high) in enumerate(zip(low_train, high_train)):
        feat = extract_features(low)
        D_high, _, _ = calculate_fd(high)
        
        if D_high is not None:
            X_train.append(feat)
            y_train.append(D_high)
            print(f"  ã‚µãƒ³ãƒ—ãƒ«{i+1}: ç‰¹å¾´é‡={[f'{f:.2f}' for f in feat[:3]]}..., é«˜ç”»è³ªFD={D_high:.4f}")
    
    X_train = np.array(X_train)
    y_train = np.array(y_train)
    
    print(f"\nâœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(X_train)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"   FDç¯„å›²: {y_train.min():.4f} ï½ {y_train.max():.4f}")
    print(f"   FDå¹³å‡: {y_train.mean():.4f} Â± {y_train.std():.4f}")
    
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    print("\nğŸ¤– LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
    model = LGBMRegressor(
        n_estimators=100,
        max_depth=8,
        learning_rate=0.05,
        n_jobs=-1,
        verbose=-1
    )
    model.fit(X_train, y_train)
    print("âœ… å­¦ç¿’å®Œäº†")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
    print("\nğŸ“ˆ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ä¸­...")
    D_high_test = []
    D_low_test = []
    D_pred_test = []
    
    for i, (low, high) in enumerate(zip(low_test, high_test)):
        D_high, _, _ = calculate_fd(high)
        D_low, _, _ = calculate_fd(low)
        
        feat = extract_features(low)
        D_pred = float(model.predict([feat])[0])
        
        if D_high is not None and D_low is not None:
            D_high_test.append(D_high)
            D_low_test.append(D_low)
            D_pred_test.append(D_pred)
            
            error_low = abs(D_high - D_low)
            error_pred = abs(D_high - D_pred)
            improvement = ((error_low - error_pred) / error_low * 100) if error_low > 0 else 0
            
            print(f"\nã‚µãƒ³ãƒ—ãƒ«{i+1}:")
            print(f"  é«˜ç”»è³ªFD: {D_high:.4f}")
            print(f"  ä½ç”»è³ªFD: {D_low:.4f} (èª¤å·®: {error_low:.4f})")
            print(f"  AIäºˆæ¸¬FD: {D_pred:.4f} (èª¤å·®: {error_pred:.4f})")
            print(f"  æ”¹å–„åº¦: {improvement:+.1f}%")
    
    # çµ±è¨ˆæƒ…å ±
    D_high_arr = np.array(D_high_test)
    D_low_arr = np.array(D_low_test)
    D_pred_arr = np.array(D_pred_test)
    
    mae_low = np.mean(np.abs(D_high_arr - D_low_arr))
    mae_pred = np.mean(np.abs(D_high_arr - D_pred_arr))
    improvement_avg = ((mae_low - mae_pred) / mae_low * 100) if mae_low > 0 else 0
    
    print("\n" + "="*60)
    print("ğŸ“Š ç·åˆè©•ä¾¡")
    print("="*60)
    print(f"MAE (ä½ç”»è³ª):     {mae_low:.4f}")
    print(f"MAE (AIè£œæ­£):     {mae_pred:.4f}")
    print(f"å¹³å‡æ”¹å–„åº¦:       {improvement_avg:+.1f}%")
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤º
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # æ•£å¸ƒå›³
    ax1.scatter(D_high_arr, D_low_arr, label='ä½ç”»è³ª', alpha=0.6, s=100)
    ax1.scatter(D_high_arr, D_pred_arr, label='AIè£œæ­£', alpha=0.9, s=100)
    ax1.plot([D_high_arr.min(), D_high_arr.max()], 
             [D_high_arr.min(), D_high_arr.max()], 'k--', alpha=0.5)
    ax1.set_xlabel('é«˜ç”»è³ªFD')
    ax1.set_ylabel('äºˆæ¸¬FD')
    ax1.set_title('FDäºˆæ¸¬çµæœ')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # èª¤å·®æ¯”è¼ƒ
    errors_low = np.abs(D_high_arr - D_low_arr)
    errors_pred = np.abs(D_high_arr - D_pred_arr)
    x = np.arange(len(D_high_test))
    
    ax2.bar(x - 0.2, errors_low, 0.4, label='ä½ç”»è³ªèª¤å·®', alpha=0.7)
    ax2.bar(x + 0.2, errors_pred, 0.4, label='AIè£œæ­£èª¤å·®', alpha=0.7)
    ax2.set_xlabel('ã‚µãƒ³ãƒ—ãƒ«ç•ªå·')
    ax2.set_ylabel('èª¤å·® (çµ¶å¯¾å€¤)')
    ax2.set_title('èª¤å·®æ¯”è¼ƒ')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('ai_test_result.png', dpi=150, bbox_inches='tight')
    print(f"\nğŸ“Š ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: ai_test_result.png")
    plt.show()
    
    print("\n" + "="*60)
    if improvement_avg > 5:
        print("âœ… AIå­¦ç¿’ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
    elif improvement_avg > 0:
        print("âš ï¸ AIå­¦ç¿’ã¯å‹•ä½œã—ã¦ã„ã¾ã™ãŒã€æ”¹å–„åº¦ãŒä½ã„ã§ã™")
    else:
        print("âŒ AIå­¦ç¿’ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    print("="*60)

if __name__ == "__main__":
    test_ai_learning()
